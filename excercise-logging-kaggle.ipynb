{"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOJ/5ObnNi0xK/87TmxXw2u","provenance":[]},"gpuClass":"standard","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Trénink Modelovu s protokolováním v TensorBoard, cvičení\n\n#### **Zadání:**\n1. Přidejte vrstvy CNN jako obrázky do TensorBoard.\n2. Po aktivaci přidejte výstup vrstev CNN a uvidíte, co se naučili. \n3. Doplňte convolution matrix. \n","metadata":{"id":"u4h2xPHrC_n4"}},{"cell_type":"code","source":"%matplotlib inline","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1669061632762,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"UNHXoPc96_t0","execution":{"iopub.status.busy":"2024-09-27T16:51:32.951148Z","iopub.execute_input":"2024-09-27T16:51:32.951524Z","iopub.status.idle":"2024-09-27T16:51:32.958306Z","shell.execute_reply.started":"2024-09-27T16:51:32.951472Z","shell.execute_reply":"2024-09-27T16:51:32.957432Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt  # one of the best graphics library for python\nplt.style.use('ggplot')","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1669061632763,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"2aLmy8Nk6_t1","execution":{"iopub.status.busy":"2024-09-27T16:51:32.960032Z","iopub.execute_input":"2024-09-27T16:51:32.960462Z","iopub.status.idle":"2024-09-27T16:51:32.967159Z","shell.execute_reply.started":"2024-09-27T16:51:32.960425Z","shell.execute_reply":"2024-09-27T16:51:32.966224Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport seaborn as sns\n\nimport multiprocessing as mp\nmp.set_start_method('spawn', force=True)\n\nfrom typing import Iterable\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torchvision import datasets, transforms\n\nfrom torch.optim import lr_scheduler\n\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom sklearn.metrics import confusion_matrix","metadata":{"executionInfo":{"elapsed":2255,"status":"ok","timestamp":1669061635015,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"hQuEMH7a6_t1","execution":{"iopub.status.busy":"2024-09-27T16:51:32.968805Z","iopub.execute_input":"2024-09-27T16:51:32.969093Z","iopub.status.idle":"2024-09-27T16:51:53.972881Z","shell.execute_reply.started":"2024-09-27T16:51:32.969061Z","shell.execute_reply":"2024-09-27T16:51:53.971720Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## TensorBoard Dashboard\n\nPojďme nastavit řídicí panel TensorBorad.\n\nPojďme definovat nadřazený log adresář. Všechny logy zapíšeme do adresáře.","metadata":{"id":"A0BbG9N8lAxf"}},{"cell_type":"code","source":"logdir = \"/kaggle/working/logs_fashion_mnist\"","metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1669061639374,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"kswJUFX9kcQN","execution":{"iopub.status.busy":"2024-09-27T16:51:53.974693Z","iopub.execute_input":"2024-09-27T16:51:53.975280Z","iopub.status.idle":"2024-09-27T16:51:53.979964Z","shell.execute_reply.started":"2024-09-27T16:51:53.975243Z","shell.execute_reply":"2024-09-27T16:51:53.978931Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!tensorboard --version","metadata":{"execution":{"iopub.status.busy":"2024-09-27T16:51:53.981495Z","iopub.execute_input":"2024-09-27T16:51:53.981967Z","iopub.status.idle":"2024-09-27T16:52:02.235359Z","shell.execute_reply.started":"2024-09-27T16:51:53.981915Z","shell.execute_reply":"2024-09-27T16:52:02.234103Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"2.16.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n!tar xf ./ngrok-v3-stable-linux-amd64.tgz -C /usr/local/bin","metadata":{"execution":{"iopub.status.busy":"2024-09-27T16:52:02.238064Z","iopub.execute_input":"2024-09-27T16:52:02.238441Z","iopub.status.idle":"2024-09-27T16:52:05.491302Z","shell.execute_reply.started":"2024-09-27T16:52:02.238400Z","shell.execute_reply":"2024-09-27T16:52:05.490019Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"--2024-09-27 16:52:03--  https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\nResolving bin.equinox.io (bin.equinox.io)... 18.205.222.128, 54.161.241.46, 54.237.133.81, ...\nConnecting to bin.equinox.io (bin.equinox.io)|18.205.222.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 9085090 (8.7M) [application/octet-stream]\nSaving to: 'ngrok-v3-stable-linux-amd64.tgz'\n\nngrok-v3-stable-lin 100%[===================>]   8.66M  45.8MB/s    in 0.2s    \n\n2024-09-27 16:52:03 (45.8 MB/s) - 'ngrok-v3-stable-linux-amd64.tgz' saved [9085090/9085090]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Add to the console:** \n```cmd \n!ngrok authtoken <authtoken>\n```","metadata":{}},{"cell_type":"code","source":"pool = mp.Pool(processes = 10)\nresults_of_processes = [pool.apply_async(os.system, args=(cmd, ), callback = None )\n                        for cmd in [\n                        f\"tensorboard --logdir ./logs_fashion_mnist --load_fast=false --host 0.0.0.0 --port 6006 &\",\n                        \"/usr/local/bin/ngrok http 6006 &\"\n                        ]]","metadata":{"execution":{"iopub.status.busy":"2024-09-27T16:52:16.825255Z","iopub.execute_input":"2024-09-27T16:52:16.825715Z","iopub.status.idle":"2024-09-27T16:52:16.982441Z","shell.execute_reply.started":"2024-09-27T16:52:16.825672Z","shell.execute_reply":"2024-09-27T16:52:16.981155Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","metadata":{"execution":{"iopub.status.busy":"2024-09-27T16:52:16.985402Z","iopub.execute_input":"2024-09-27T16:52:16.985895Z","iopub.status.idle":"2024-09-27T16:52:18.674985Z","shell.execute_reply.started":"2024-09-27T16:52:16.985839Z","shell.execute_reply":"2024-09-27T16:52:18.673619Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"https://7934-35-243-215-80.ngrok-free.app\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Spusťte TensorBoard v buňce notebooku.\n\nJakmile přidáme protokoly do adresáře protokolů, budou viditelné na řídicím panelu.","metadata":{"id":"2Lt1fOQtypZw"}},{"cell_type":"markdown","source":"# 2. Nástroje tréninku</font><a name=\"utils\"></a>","metadata":{"id":"hDyy_tUF6_t3","lines_to_next_cell":2}},{"cell_type":"markdown","source":"## <font style=\"color:green\">2.1. Získejte data Fashion MNIST</font>","metadata":{"id":"0zA7UDEV6_t3"}},{"cell_type":"code","source":"# Fashion mnist class name\nfashion_mnist_classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n                         'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n","metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1669061647699,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"jxLysSQ26_t3","execution":{"iopub.status.busy":"2024-09-27T16:52:18.676859Z","iopub.execute_input":"2024-09-27T16:52:18.677323Z","iopub.status.idle":"2024-09-27T16:52:18.683624Z","shell.execute_reply.started":"2024-09-27T16:52:18.677271Z","shell.execute_reply":"2024-09-27T16:52:18.682319Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Utilita pro přidání obrázků jako vstupů","metadata":{"id":"cppw1jUjdvmG"}},{"cell_type":"code","source":"def get_random_inputs_labels(inputs, targets, n=100):\n    \"\"\"\n    get random inputs and labels\n    \"\"\"\n\n    assert len(inputs) == len(targets)\n\n    rand_indices = torch.randperm(len(targets))\n    \n    data = inputs[rand_indices][:n]\n    \n    labels = targets[rand_indices][:n]\n    \n    class_labels = [fashion_mnist_classes[lab] for lab in labels]\n    \n    return data, class_labels","metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1669061647699,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"9l8X266I6_t4","execution":{"iopub.status.busy":"2024-09-27T16:52:18.685280Z","iopub.execute_input":"2024-09-27T16:52:18.685829Z","iopub.status.idle":"2024-09-27T16:52:18.697014Z","shell.execute_reply.started":"2024-09-27T16:52:18.685776Z","shell.execute_reply":"2024-09-27T16:52:18.695947Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Funkce ovladače TensorBoard\n","metadata":{"id":"HmIZm2vieypU"}},{"cell_type":"code","source":"def add_data_embedings(dataset, tb_writer, n=100, global_step=1, tag=\"embedings\"):\n    \"\"\"\n    Add a few inputs and labels to tensorboard. \n    \"\"\"\n    \n    images, labels = get_random_inputs_labels(inputs=dataset.data, targets=dataset.targets, n=n)\n    \n    # Add image as embedding to tensorboard\n    tb_writer.add_embedding(mat = images.view(-1, 28 * 28), \n                            metadata=labels, \n                            label_img=images.unsqueeze(1),\n                            global_step=global_step,\n                            tag=tag)\n    return","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1669061647699,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"OSR_NaBx6_t5","execution":{"iopub.status.busy":"2024-09-27T16:52:18.700988Z","iopub.execute_input":"2024-09-27T16:52:18.701797Z","iopub.status.idle":"2024-09-27T16:52:18.710986Z","shell.execute_reply.started":"2024-09-27T16:52:18.701757Z","shell.execute_reply":"2024-09-27T16:52:18.709889Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Funkce pro získání dat","metadata":{}},{"cell_type":"code","source":"def get_data(batch_size, data_root, tb_writer, num_workers=1, data_augmentation=False):\n    \n    # common transforms\n    common_transforms = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.2860, ), (0.3530, ))\n    ])\n    \n    # if data_augmentation is true \n    # data augmentation implementation\n    if data_augmentation:\n        train_transforms = transforms.Compose([\n            transforms.RandomChoice([\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomVerticalFlip(),\n                transforms.RandomRotation(90, fill=(0,)),\n                transforms.RandomCrop(28, padding=4, fill=(0,))\n            ]),\n            transforms.ToTensor(),\n            transforms.Normalize((0.2860, ), (0.3530, ))\n        ])\n    # else do common transforms\n    else:\n        train_transforms = common_transforms\n        \n        \n    \n    # train dataloader\n    traindata = datasets.FashionMNIST(root=data_root, train=True, download=True, transform=train_transforms)\n    \n    train_loader = torch.utils.data.DataLoader(\n        traindata,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers\n    )\n    \n    # test dataloader\n    testdata = datasets.FashionMNIST(root=data_root, train=False, download=True, transform=common_transforms)\n    \n    test_loader = torch.utils.data.DataLoader(\n        testdata,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers\n    )\n    \n    # add embedding / projector\n    \n    add_data_embedings(testdata, tb_writer, n=100)\n    return train_loader, test_loader","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1669061647700,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"oF0nqTJp6_t5","execution":{"iopub.status.busy":"2024-09-27T16:52:18.712503Z","iopub.execute_input":"2024-09-27T16:52:18.714143Z","iopub.status.idle":"2024-09-27T16:52:18.726595Z","shell.execute_reply.started":"2024-09-27T16:52:18.714104Z","shell.execute_reply":"2024-09-27T16:52:18.725457Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">2.2. Konfigurace systému</font>","metadata":{"id":"d29Sv9WU6_t6"}},{"cell_type":"code","source":"@dataclass\nclass SystemConfiguration:\n    '''\n    Describes the common system setting needed for reproducible training\n    '''\n    seed: int = 21  # seed number to set the state of all random number generators\n    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1669061647700,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"3EdqIDSn6_t6","execution":{"iopub.status.busy":"2024-09-27T16:52:18.728616Z","iopub.execute_input":"2024-09-27T16:52:18.729061Z","iopub.status.idle":"2024-09-27T16:52:18.738732Z","shell.execute_reply.started":"2024-09-27T16:52:18.729013Z","shell.execute_reply":"2024-09-27T16:52:18.737360Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## 2.3. <font>Konfigurace tréninku</font>","metadata":{"id":"UCb48bLj6_t6"}},{"cell_type":"code","source":"@dataclass\nclass TrainingConfiguration:\n    '''\n    Describes configuration of the training process\n    '''\n    batch_size: int = 32  \n    epochs_count: int = 50  \n    init_learning_rate: float = 0.02  # initial learning rate for lr scheduler\n    decay_rate: float = 0.1  \n    log_interval: int = 500  \n    test_interval: int = 1  \n    data_root: str = \"/kaggle/working/\" \n    num_workers: int = 2 \n    device: str = 'cuda'  \n    \n","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1669061647700,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"kzQW6sat6_t7","execution":{"iopub.status.busy":"2024-09-27T16:52:18.740179Z","iopub.execute_input":"2024-09-27T16:52:18.740561Z","iopub.status.idle":"2024-09-27T16:52:18.748446Z","shell.execute_reply.started":"2024-09-27T16:52:18.740515Z","shell.execute_reply":"2024-09-27T16:52:18.747289Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">2.4. Nastavení systému</font>","metadata":{"id":"wcUOeFZv6_t7"}},{"cell_type":"code","source":"def setup_system(system_config: SystemConfiguration) -> None:\n    torch.manual_seed(system_config.seed)\n    if torch.cuda.is_available():\n        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1669061647701,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"W7mqFui56_t7","execution":{"iopub.status.busy":"2024-09-27T16:52:18.749524Z","iopub.execute_input":"2024-09-27T16:52:18.749909Z","iopub.status.idle":"2024-09-27T16:52:18.760459Z","shell.execute_reply.started":"2024-09-27T16:52:18.749872Z","shell.execute_reply":"2024-09-27T16:52:18.759166Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## 2.5. <font>Predikce</font>","metadata":{"id":"QBFQ_OeB6_t7"}},{"cell_type":"code","source":"def prediction(model, device, batch_input, max_prob=True):\n    \"\"\"\n    get prediction for batch inputs\n    \"\"\"\n    \n    # send model to cpu/cuda according to your system configuration\n    model.to(device)\n    \n    # it is important to do model.eval() before prediction\n    model.eval()\n\n    data = batch_input.to(device)\n\n    output = model(data)\n\n    # get probability score using softmax\n    prob = F.softmax(output, dim=1)\n    \n    if max_prob:\n        # get the max probability\n        pred_prob = prob.data.max(dim=1)[0]\n    else:\n        pred_prob = prob.data\n    \n    # get the index of the max probability\n    pred_index = prob.data.max(dim=1)[1]\n    \n    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1669061647701,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"BA_XsSFp6_t8","execution":{"iopub.status.busy":"2024-09-27T16:52:18.761908Z","iopub.execute_input":"2024-09-27T16:52:18.762264Z","iopub.status.idle":"2024-09-27T16:52:18.771049Z","shell.execute_reply.started":"2024-09-27T16:52:18.762210Z","shell.execute_reply":"2024-09-27T16:52:18.769898Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def get_target_and_prob(model, dataloader, device):\n    \"\"\"\n    get targets and prediction probabilities\n    \"\"\"\n    \n    pred_prob = []\n    targets = []\n    \n    for _, (data, target) in enumerate(dataloader):\n        \n        _, prob = prediction(model, device, data, max_prob=False)\n        \n        pred_prob.append(prob)\n        \n        target = target.numpy()\n        targets.append(target)\n        \n    targets = np.concatenate(targets)\n    targets = targets.astype(int)\n    pred_prob = np.concatenate(pred_prob, axis=0)\n    \n    return targets, pred_prob\n    \n    ","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1669061647701,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"zK9Fi9sW6_t8","execution":{"iopub.status.busy":"2024-09-27T16:52:18.772518Z","iopub.execute_input":"2024-09-27T16:52:18.772896Z","iopub.status.idle":"2024-09-27T16:52:18.780829Z","shell.execute_reply.started":"2024-09-27T16:52:18.772859Z","shell.execute_reply":"2024-09-27T16:52:18.779645Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Utilita k přidání PR křivky do TensorBoard","metadata":{"id":"Vm2TDYJAgfZ7"}},{"cell_type":"code","source":"def add_pr_curves_to_tensorboard(model, dataloader, device, tb_writer, epoch, num_classes=10):\n    \"\"\"\n    Add precession and recall curve to tensorboard.\n    \"\"\"\n    \n    targets, pred_prob = get_target_and_prob(model, dataloader, device)\n    \n    for cls_idx in range(num_classes):\n        binary_target = targets == cls_idx\n        true_prediction_prob = pred_prob[:, cls_idx]\n        \n        # add PR curve to tensorboard\n        tb_writer.add_pr_curve(tag=fashion_mnist_classes[cls_idx], \n                               labels=binary_target, \n                               predictions=true_prediction_prob, \n                               global_step=epoch)\n        \n    return\n    ","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1669061647701,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"wmWHJvuv6_t9","execution":{"iopub.status.busy":"2024-09-27T16:52:18.782628Z","iopub.execute_input":"2024-09-27T16:52:18.783057Z","iopub.status.idle":"2024-09-27T16:52:18.791603Z","shell.execute_reply.started":"2024-09-27T16:52:18.783020Z","shell.execute_reply":"2024-09-27T16:52:18.790568Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Utilita k přidání obrázků do TensorBoard","metadata":{"id":"Id6Ny8ptioLS"}},{"cell_type":"code","source":"def add_wrong_prediction_to_tensorboard(model, dataloader, device, tb_writer, \n                                        epoch, tag='Wrong_Predections', max_images='all'):\n    \"\"\"\n    Add wrong predicted images to tensorboard.\n    \"\"\"\n    #number of images in one row\n    num_images_per_row = 8\n    im_scale = 3\n    \n    plot_images = []\n    wrong_labels = []\n    pred_prob = []\n    right_label = []\n    \n    for _, (data, target) in enumerate(dataloader):\n        \n        \n        images = data.numpy()\n        pred, prob = prediction(model, device, data)\n        target = target.numpy()\n        indices = pred.astype(int) != target.astype(int)\n        \n        plot_images.append(images[indices])\n        wrong_labels.append(pred[indices])\n        pred_prob.append(prob[indices])\n        right_label.append(target[indices])\n        \n    plot_images = np.concatenate(plot_images, axis=0).squeeze()\n    wrong_labels = np.concatenate(wrong_labels)\n    wrong_labels = wrong_labels.astype(int)\n    right_label = np.concatenate(right_label)\n    right_label = right_label.astype(int)\n    pred_prob = np.concatenate(pred_prob)\n    \n    \n    if max_images == 'all':\n        num_images = len(images)\n    else:\n        num_images = min(len(plot_images), max_images)\n        \n    fig_width = num_images_per_row * im_scale\n    \n    if num_images % num_images_per_row == 0:\n        num_row = num_images/num_images_per_row\n    else:\n        num_row = int(num_images/num_images_per_row) + 1\n        \n    fig_height = num_row * im_scale\n        \n    plt.style.use('default')\n    plt.rcParams[\"figure.figsize\"] = (fig_width, fig_height)\n    fig = plt.figure()\n    \n    for i in range(num_images):\n        plt.subplot(num_row, num_images_per_row, i+1, xticks=[], yticks=[])\n        plt.imshow(plot_images[i], cmap='gray')\n        plt.gca().set_title('{0}({1:.2}), {2}'.format(fashion_mnist_classes[wrong_labels[i]], \n                                                          pred_prob[i], \n                                                          fashion_mnist_classes[right_label[i]]))\n        \n    # add figure to tensorboard\n    tb_writer.add_figure(tag=tag,\n                         figure=fig, \n                         global_step=epoch)\n    \n    return\n","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1669061647702,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"BGNtCR3J6_t9","execution":{"iopub.status.busy":"2024-09-27T16:52:18.793056Z","iopub.execute_input":"2024-09-27T16:52:18.793425Z","iopub.status.idle":"2024-09-27T16:52:18.809374Z","shell.execute_reply.started":"2024-09-27T16:52:18.793389Z","shell.execute_reply":"2024-09-27T16:52:18.808304Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## 2.6. <font>Funkce trénování</font>\n","metadata":{"id":"viaN6t6o6_t9"}},{"cell_type":"code","source":"def train(\n    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n    train_loader: torch.utils.data.DataLoader, epoch_idx: int, tb_writer: SummaryWriter\n) -> None:\n    \n    # change model in training mode\n    model.train()\n    \n    # to get batch loss\n    batch_loss = np.array([])\n    \n    # to get batch accuracy\n    batch_acc = np.array([])\n        \n    for batch_idx, (data, target) in enumerate(train_loader):\n        \n        # clone target\n        indx_target = target.clone()\n        # send data to device (its is mandatory if GPU has to be used)\n        data = data.to(train_config.device)\n        # send target to device\n        target = target.to(train_config.device)\n\n        # reset parameters gradient to zero\n        optimizer.zero_grad()\n        \n        # forward pass to the model\n        output = model(data)\n        \n        # cross entropy loss\n        loss = F.cross_entropy(output, target)\n        \n        # find gradients w.r.t training parameters\n        loss.backward()\n        # Update parameters using gardients\n        optimizer.step()\n        \n        batch_loss = np.append(batch_loss, [loss.item()])\n        \n        # Score to probability using softmax\n        prob = F.softmax(output, dim=1)\n            \n        # get the index of the max probability\n        pred = prob.data.max(dim=1)[1]  \n                        \n        # correct prediction\n        correct = pred.cpu().eq(indx_target).sum()\n            \n        # accuracy\n        acc = float(correct) / float(len(data))\n        \n        batch_acc = np.append(batch_acc, [acc])\n\n        if batch_idx % train_config.log_interval == 0 and batch_idx > 0:\n            \n            total_batch = epoch_idx * len(train_loader.dataset)/train_config.batch_size + batch_idx\n            # add scalar log to tensorboard\n            tb_writer.add_scalar('Loss/train-batch', loss.item(), total_batch)\n            tb_writer.add_scalar('Accuracy/train-batch', acc, total_batch)\n            \n    epoch_loss = batch_loss.mean()\n    epoch_acc = batch_acc.mean()\n    return epoch_loss, epoch_acc","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1669061647702,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"gwMz2dke6_t-","execution":{"iopub.status.busy":"2024-09-27T16:52:18.814599Z","iopub.execute_input":"2024-09-27T16:52:18.815005Z","iopub.status.idle":"2024-09-27T16:52:18.829517Z","shell.execute_reply.started":"2024-09-27T16:52:18.814966Z","shell.execute_reply":"2024-09-27T16:52:18.828419Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## <font>2.7. Funkce validace</font>","metadata":{"id":"KVGp5EBc6_t-"}},{"cell_type":"code","source":"def validate(\n    train_config: TrainingConfiguration,\n    model: nn.Module,\n    test_loader: torch.utils.data.DataLoader\n) -> float:\n    # \n    model.eval()\n    test_loss = 0\n    count_corect_predictions = 0\n    for data, target in test_loader:\n        indx_target = target.clone()\n        data = data.to(train_config.device)\n        \n        target = target.to(train_config.device)\n        \n        output = model(data)\n        # add loss for each mini batch\n        test_loss += F.cross_entropy(output, target).item()\n        \n        # get probability score using softmax\n        prob = F.softmax(output, dim=1)\n        \n        # get the index of the max probability\n        pred = prob.data.max(dim=1)[1] \n        \n        # add correct prediction count\n        count_corect_predictions += pred.cpu().eq(indx_target).sum()\n\n    # average over number of mini-batches\n    test_loss = test_loss / len(test_loader)  \n    \n    # average over number of dataset\n    accuracy = 100. * count_corect_predictions / len(test_loader.dataset)\n    \n    return test_loss, accuracy/100.0","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1669061647702,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"obl7OTpF6_t-","execution":{"iopub.status.busy":"2024-09-27T16:52:18.830921Z","iopub.execute_input":"2024-09-27T16:52:18.831277Z","iopub.status.idle":"2024-09-27T16:52:18.842509Z","shell.execute_reply.started":"2024-09-27T16:52:18.831240Z","shell.execute_reply":"2024-09-27T16:52:18.841453Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Funkce pro přidání váh modelu jako histogram","metadata":{"id":"QROVqcdBMq9p"}},{"cell_type":"code","source":"def add_model_weights_as_histogram(model, tb_writer, epoch):\n    \"\"\"\n    Get named parameters and plot as histogram\n    \"\"\"\n    for name, param in model.named_parameters():\n        # add model weight as histogram to tensorboard\n        tb_writer.add_histogram(name.replace('.', '/'), param.data.cpu().abs(), epoch)\n    return","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1669061647703,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"QUyTq7ej6_t_","execution":{"iopub.status.busy":"2024-09-27T16:52:18.844139Z","iopub.execute_input":"2024-09-27T16:52:18.844482Z","iopub.status.idle":"2024-09-27T16:52:18.854088Z","shell.execute_reply.started":"2024-09-27T16:52:18.844446Z","shell.execute_reply":"2024-09-27T16:52:18.852921Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Funkce pro zobrazení konvolučních vrstev při inicializaci modelu","metadata":{}},{"cell_type":"code","source":"def add_output_conv_start_training(model, input_image, tb_writer, layer_names=None):\n    \"\"\"\n    Adds the outputs of the model's convolutional layers as images to TensorBoard\n    \"\"\"\n    x = input_image  # Začneme s input image\n    conv_layer_count = 0  # Počítadlo konvolučních vrstev\n    \n    # Pokud nejsou názvy vrstev poskytnuty, automaticky je vygenerujeme\n    if layer_names is None:\n        layer_names = [f'conv_{i+1}' for i, layer in enumerate(model.modules()) if isinstance(layer, nn.Conv2d)]\n    \n    for idx, layer in enumerate(model._body):\n        # Pro každou vrstvu zkontrolujeme, zda je to konvoluční vrstva\n        if isinstance(layer, nn.Conv2d):\n            # Aplikujeme konvoluční vrstvu a aktivaci\n            x = F.relu(layer(x))\n            \n            # Přidáme feature mapy vrstvy do TensorBoard\n            for i in range(x.size(1)):  # Pro každý kanál ve feature mapě\n                feature_map = x[0, i, :, :].unsqueeze(0)  # Extrakce jednoho kanálu\n\n                # Získání názvu vrstvy (automaticky generovaný nebo zadaný uživatelem)\n                layer_name = layer_names[conv_layer_count]  # Použijeme counter, abychom měli správný index\n                tb_writer.add_image(f'start_feature_maps/{layer_name}/channel_{i}', feature_map)\n            \n            conv_layer_count += 1  # Zvyšujeme počítadlo konvolučních vrstev\n\n    return","metadata":{"execution":{"iopub.status.busy":"2024-09-27T16:52:18.855293Z","iopub.execute_input":"2024-09-27T16:52:18.855688Z","iopub.status.idle":"2024-09-27T16:52:18.866440Z","shell.execute_reply.started":"2024-09-27T16:52:18.855627Z","shell.execute_reply":"2024-09-27T16:52:18.865292Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Funkce pro zobrazení výsledků konvolučních vrstev při tréninku ","metadata":{}},{"cell_type":"code","source":"def add_output_conv(model, input_image, tb_writer, epoch, layer_names=None):\n    \"\"\"\n    Logs feature maps of all convolutional layers to TensorBoard for a specific epoch.\n    \n    Args:\n        model: The neural network model.\n        input_image: Input image or batch of images.\n        tb_writer: TensorBoard writer.\n        epoch: Current epoch number.\n        layer_names: List of layer names (optional).\n    \"\"\"\n    # Move input to model's device (if not already)\n    input_image = input_image.to(next(model.parameters()).device)\n    \n    # Start with input image\n    x = input_image\n    conv_layer_count = 0  # Počítadlo konvolučních vrstev\n    \n    # Pokud nejsou názvy vrstev poskytnuty, automaticky je vygenerujeme\n    if layer_names is None:\n        layer_names = [f'conv_{i+1}' for i, layer in enumerate(model.modules()) if isinstance(layer, nn.Conv2d)]\n    \n    # Iterate through the model's layers\n    for idx, layer in enumerate(model._body):\n        \n        # Apply the layer (if it's Conv2d)\n        if isinstance(layer, torch.nn.Conv2d):\n            x = F.relu(layer(x))  # Apply ReLU activation function\n\n            # Add feature maps of this convolutional layer to TensorBoard\n            for i in range(x.size(1)):  # For each channel (filter output)\n                feature_map = x[0, i, :, :].unsqueeze(0)  # Single channel extraction\n                \n                # Získání názvu vrstvy (automaticky generovaný nebo zadaný uživatelem)\n                layer_name = layer_names[conv_layer_count]  # Použijeme counter pro správné názvy vrstev\n                \n                # Add epoch info in TensorBoard name\n                tb_writer.add_image(f'feature_maps/{layer_name}/channel_{i}/epoch_{epoch}', feature_map)\n            \n            conv_layer_count += 1  # Zvyšujeme počítadlo konvolučních vrstev\n\n    return\n","metadata":{"execution":{"iopub.status.busy":"2024-09-27T16:52:18.867701Z","iopub.execute_input":"2024-09-27T16:52:18.868165Z","iopub.status.idle":"2024-09-27T16:52:18.881531Z","shell.execute_reply.started":"2024-09-27T16:52:18.868127Z","shell.execute_reply":"2024-09-27T16:52:18.880547Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Funkce přidání modelu jako grafu do TensorBoard","metadata":{"id":"iugkXzscQXhg"}},{"cell_type":"code","source":"def add_network_graph_tensorboard(model, inputs, tb_writer):\n    # add model to tensorboard\n    tb_writer.add_graph(model, inputs)\n    return","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1669061647703,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"98TpwWdg6_t_","execution":{"iopub.status.busy":"2024-09-27T16:52:18.883410Z","iopub.execute_input":"2024-09-27T16:52:18.883949Z","iopub.status.idle":"2024-09-27T16:52:18.892315Z","shell.execute_reply.started":"2024-09-27T16:52:18.883888Z","shell.execute_reply":"2024-09-27T16:52:18.891178Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"Funkce pro vygerenování predikcí ve spravném formátu","metadata":{}},{"cell_type":"code","source":"def get_target_and_classes_cm(model, dataloader, device):\n    \"\"\"\n    Get true targets and predicted classes from the model.\n    \"\"\"\n    model.eval()\n    targets = []\n    pred_classes = []\n    \n    with torch.no_grad():\n        for data, target in dataloader:\n            data = data.to(device)\n            target = target.to(device)\n            \n            # Get model output (logits or probabilities)\n            output = model(data)\n            \n            # Get predicted classes (use argmax to get the index of the highest probability)\n            pred = torch.argmax(output, dim=1)\n            \n            # Append to lists\n            pred_classes.append(pred.cpu().numpy())\n            targets.append(target.cpu().numpy())\n    \n    # Convert lists to numpy arrays\n    targets = np.concatenate(targets)\n    pred_classes = np.concatenate(pred_classes)\n    \n    return targets, pred_classes","metadata":{"execution":{"iopub.status.busy":"2024-09-27T16:52:18.893738Z","iopub.execute_input":"2024-09-27T16:52:18.894155Z","iopub.status.idle":"2024-09-27T16:52:18.904257Z","shell.execute_reply.started":"2024-09-27T16:52:18.894103Z","shell.execute_reply":"2024-09-27T16:52:18.902858Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### Funkce pro přidání Confusion matrix","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix_to_tensorboard(model, tb_writer, dataloader, device, class_names, epoch, normalize=True):\n    # Get true targets and predicted classes\n    targets, pred_classes = get_target_and_classes_cm(model, dataloader, device)\n    \n    # Compute the confusion matrix\n    cm = confusion_matrix(targets, pred_classes, normalize='true' if normalize else None)  \n    \n    # Create a plot using matplotlib\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    \n    ax.set_xlabel('Predicted labels')\n    ax.set_ylabel('True labels')\n    ax.set_title(f'Confusion Matrix at Epoch {epoch}')\n    \n    # Add the confusion matrix figure to TensorBoard\n    tb_writer.add_figure('Confusion Matrix', fig, global_step=epoch)\n    \n    # Close the plot to free memory\n    plt.close(fig)\n\n    return ","metadata":{"execution":{"iopub.status.busy":"2024-09-27T16:52:18.907933Z","iopub.execute_input":"2024-09-27T16:52:18.908313Z","iopub.status.idle":"2024-09-27T16:52:18.917526Z","shell.execute_reply.started":"2024-09-27T16:52:18.908275Z","shell.execute_reply":"2024-09-27T16:52:18.916439Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## <font>2.8. Hlavní funkce pro trénink a validaci</font>","metadata":{"id":"PTsJV6lf6_t_"}},{"cell_type":"code","source":"def main(model, class_names, optimizer, tb_writer, scheduler=None, system_configuration=SystemConfiguration(), \n         training_configuration=TrainingConfiguration(), data_augmentation=False):\n    \n    # system configuration\n    setup_system(system_configuration)\n\n    # batch size\n    batch_size_to_set = training_configuration.batch_size\n    # num_workers\n    num_workers_to_set = training_configuration.num_workers\n    # epochs\n    epoch_num_to_set = training_configuration.epochs_count\n\n    # if GPU is available use training config, \n    # else lower batch_size, num_workers and epochs count\n    if torch.cuda.is_available():\n        device = \"cuda\"\n    else:\n        device = \"cpu\"\n        batch_size_to_set = 16\n        num_workers_to_set = 2\n\n    # data loader\n    train_loader, test_loader = get_data(\n        batch_size=batch_size_to_set,\n        data_root=training_configuration.data_root,\n        tb_writer=tb_writer,\n        num_workers=num_workers_to_set,\n        data_augmentation=data_augmentation\n    )\n    \n    \n    # Update training configuration\n    training_configuration = TrainingConfiguration(\n        device=device,\n        batch_size=batch_size_to_set,\n        num_workers=num_workers_to_set\n    )\n        \n    # send model to device (GPU/CPU)\n    model.to(training_configuration.device)\n    \n    \n    # add network graph with inputs info\n    images, labels = next(iter(test_loader))\n    \n    \n    # add network graph with inputs info\n    images = images.to(training_configuration.device)\n    add_network_graph_tensorboard(model, images, tb_writer)\n    add_output_conv_start_training(model, images, tb_writer)\n\n    best_loss = torch.tensor(np.inf)\n    \n    # epoch train/test loss\n    epoch_train_loss = np.array([])\n    epoch_test_loss = np.array([])\n    \n    # epoch train/test accuracy\n    epoch_train_acc = np.array([])\n    epoch_test_acc = np.array([])\n    \n    \n    # training time measurement\n    t_begin = time.time()\n    for epoch in range(training_configuration.epochs_count):\n        \n        # Train\n        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch, tb_writer)\n        \n        # Log feature maps for the current epoch\n        images, labels = next(iter(train_loader))  # Get a batch of images\n        add_output_conv(model, images, tb_writer, epoch)\n        \n        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n        \n        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n        \n        # add scalar (loss/accuracy) to tensorboard\n        tb_writer.add_scalar('Loss/Train',train_loss, epoch)\n        tb_writer.add_scalar('Accuracy/Train', train_acc, epoch)\n\n        elapsed_time = time.time() - t_begin\n        speed_epoch = elapsed_time / (epoch + 1)\n        speed_batch = speed_epoch / len(train_loader)\n        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n        \n        # add time metadata to tensorboard\n        tb_writer.add_scalar('Time/elapsed_time', elapsed_time, epoch)\n        tb_writer.add_scalar('Time/speed_epoch', speed_epoch, epoch)\n        tb_writer.add_scalar('Time/speed_batch', speed_batch, epoch)\n        tb_writer.add_scalar('Time/eta', eta, epoch)\n\n        # Validate\n        if epoch % training_configuration.test_interval == 0:\n            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n            \n            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n        \n            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n            \n            # add scalar (loss/accuracy) to tensorboard\n            tb_writer.add_scalar('Loss/Validation', current_loss, epoch)\n            tb_writer.add_scalar('Accuracy/Validation', current_accuracy, epoch)\n            \n            # add scalars (loss/accuracy) to tensorboard\n            tb_writer.add_scalars('Loss/train-val', {'train': train_loss, \n                                           'validation': current_loss}, epoch)\n            tb_writer.add_scalars('Accuracy/train-val', {'train': train_acc, \n                                               'validation': current_accuracy}, epoch)\n            \n            if current_loss < best_loss:\n                best_loss = current_loss\n                \n            # add wrong predicted image to tensorboard\n            add_wrong_prediction_to_tensorboard(model, test_loader, \n                                                training_configuration.device, \n                                                tb_writer, epoch, max_images=300)\n            \n            # add confusion matrix to tensorboard\n            plot_confusion_matrix_to_tensorboard(model, tb_writer, test_loader, \n                                                 training_configuration.device, class_names, \n                                                 epoch, normalize=True)\n            \n        # scheduler step/ update learning rate\n        if scheduler is not None:\n            scheduler.step()\n            \n        # adding model weights to tensorboard as histogram\n        add_model_weights_as_histogram(model, tb_writer, epoch)\n        \n        # add pr curves to tensor board\n        add_pr_curves_to_tensorboard(model, test_loader, \n                                     training_configuration.device, \n                                     tb_writer, epoch, num_classes=10)\n        \n                \n    print(\"Total time: {:.2f}, Best Loss: {:.3f}\".format(time.time() - t_begin, best_loss))\n    \n    \n    \n    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1669061647703,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"ibuO_Pt06_uA","execution":{"iopub.status.busy":"2024-09-27T16:52:18.919197Z","iopub.execute_input":"2024-09-27T16:52:18.919638Z","iopub.status.idle":"2024-09-27T16:52:18.949813Z","shell.execute_reply.started":"2024-09-27T16:52:18.919580Z","shell.execute_reply":"2024-09-27T16:52:18.948610Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## <font>2.9. Optimalizátor a plánovač</font>","metadata":{"id":"NqUUz16L6_uB"}},{"cell_type":"code","source":"def get_optimizer_and_scheduler(model):\n    train_config = TrainingConfiguration()\n\n    init_learning_rate = train_config.init_learning_rate\n\n    # optimizer\n    optimizer = optim.SGD(\n        model.parameters(),\n        lr = init_learning_rate,\n        momentum = 0.9\n    )\n\n    decay_rate = train_config.decay_rate\n\n    lmbda = lambda epoch: 1/(1 + decay_rate * epoch)\n\n    # Scheduler\n    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lmbda)\n    \n    return optimizer, scheduler\n    \n","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1669061647704,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"OSbMH4SA6_uB","execution":{"iopub.status.busy":"2024-09-27T16:52:18.951370Z","iopub.execute_input":"2024-09-27T16:52:18.951835Z","iopub.status.idle":"2024-09-27T16:52:18.962324Z","shell.execute_reply.started":"2024-09-27T16:52:18.951786Z","shell.execute_reply":"2024-09-27T16:52:18.961210Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# 3. Definice modelu</font><a name=\"model\"></a>","metadata":{"id":"nKf327z56_uB"}},{"cell_type":"code","source":"class MediumModel(nn.Module):\n    def __init__(self, dropout=0.0, batch_norm=False):\n        super().__init__()\n\n        # convolution layers\n        if batch_norm:\n            self._body = nn.Sequential(\n                nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5),\n                nn.BatchNorm2d(16),\n                nn.ReLU(inplace=True),\n\n                nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5),\n                nn.BatchNorm2d(32),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=2),\n\n                nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n                nn.BatchNorm2d(64),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=2),\n                nn.Dropout(dropout)\n            )\n        else:\n             self._body = nn.Sequential(\n                nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5),\n                nn.ReLU(inplace=True),\n\n                nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=2),\n\n                nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=2),\n                nn.Dropout(dropout)\n            )\n            \n        \n        # Fully connected layers\n        self._head = nn.Sequential(\n            \n            nn.Linear(in_features=64 * 4 * 4, out_features=512), \n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout),\n            \n            nn.Linear(in_features=512, out_features=128), \n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout),\n            \n            nn.Linear(in_features=128, out_features=10)\n        )\n\n    def forward(self, x):\n        x = self._body(x)\n        x = x.view(x.size()[0], -1)\n        x = self._head(x)\n        return x","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1669061647704,"user":{"displayName":"Prakash Chandra","userId":"10422130858424396378"},"user_tz":-330},"id":"A1e7E_826_uC","execution":{"iopub.status.busy":"2024-09-27T16:52:18.964492Z","iopub.execute_input":"2024-09-27T16:52:18.965434Z","iopub.status.idle":"2024-09-27T16:52:18.979757Z","shell.execute_reply.started":"2024-09-27T16:52:18.965374Z","shell.execute_reply":"2024-09-27T16:52:18.978719Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## 3.1. Experiment 1: Trénink bez regulizace","metadata":{"id":"PZEMLQGz6_uC"}},{"cell_type":"code","source":"\nmodel = MediumModel()\n\n# get optimizer and scheduler\noptimizer, scheduler = get_optimizer_and_scheduler(model)\n\n# Tensorboard summary writer\nno_regularization_sw = SummaryWriter(os.path.join(logdir, 'no_regularization'))   \n\n# train and validate\nmodel, train_loss_exp2, train_acc_exp2, val_loss_exp2, val_acc_exp2 = main(model,\n                                                                           fashion_mnist_classes,\n                                                                           optimizer,\n                                                                           no_regularization_sw,\n                                                                           scheduler)\nno_regularization_sw.close()","metadata":{"id":"4KKy_tIi6_uC","outputId":"043b0e6f-45f8-485c-ae92-07be79e8616f","execution":{"iopub.status.busy":"2024-09-27T16:52:18.981216Z","iopub.execute_input":"2024-09-27T16:52:18.981934Z","iopub.status.idle":"2024-09-27T17:42:55.382633Z","shell.execute_reply.started":"2024-09-27T16:52:18.981893Z","shell.execute_reply":"2024-09-27T17:42:55.381419Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /kaggle/working/FashionMNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 26421880/26421880 [00:02<00:00, 12774778.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /kaggle/working/FashionMNIST/raw/train-images-idx3-ubyte.gz to /kaggle/working/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /kaggle/working/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29515/29515 [00:00<00:00, 297235.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /kaggle/working/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /kaggle/working/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /kaggle/working/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/4422102 [00:00<?, ?it/s]TensorBoard 2.16.2 at http://0.0.0.0:6006/ (Press CTRL+C to quit)\n100%|██████████| 4422102/4422102 [00:05<00:00, 754113.65it/s] \n","output_type":"stream"},{"name":"stdout","text":"Extracting /kaggle/working/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /kaggle/working/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /kaggle/working/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5148/5148 [00:00<00:00, 9049571.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /kaggle/working/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /kaggle/working/FashionMNIST/raw\n\nTotal time: 3019.80, Best Loss: 0.251\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3.2. Experiment 2: trénink s regularizací","metadata":{"id":"KTNuYYPV6_uC"}},{"cell_type":"code","source":"model = MediumModel(0.25, batch_norm=True)\n\noptimizer, scheduler = get_optimizer_and_scheduler(model)\n\n# Tensorboard summary writer\nregularization_sw = SummaryWriter(os.path.join(logdir, 'regularization'))  \n\nmodel, train_loss_exp9, train_acc_exp9, val_loss_exp9, val_acc_exp9 = main(model,\n                                                                           fashion_mnist_classes,\n                                                                           optimizer, \n                                                                           regularization_sw,\n                                                                           scheduler,\n                                                                           data_augmentation=True)\n\nregularization_sw.close()","metadata":{"id":"dRet0JQs6_uC","execution":{"iopub.status.busy":"2024-09-27T17:42:55.384511Z","iopub.execute_input":"2024-09-27T17:42:55.385519Z","iopub.status.idle":"2024-09-27T18:37:30.457813Z","shell.execute_reply.started":"2024-09-27T17:42:55.385475Z","shell.execute_reply":"2024-09-27T18:37:30.456591Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Total time: 3270.67, Best Loss: 0.201\n","output_type":"stream"}]},{"cell_type":"markdown","source":"***Vyčištění výstupu***","metadata":{}},{"cell_type":"code","source":"rm /kaggle/working/ngrok-v3-stable-linux-amd64.tgz","metadata":{"id":"t4-sr6UTltuk","execution":{"iopub.status.busy":"2024-09-27T18:37:30.459212Z","iopub.execute_input":"2024-09-27T18:37:30.459566Z","iopub.status.idle":"2024-09-27T18:37:32.014008Z","shell.execute_reply.started":"2024-09-27T18:37:30.459529Z","shell.execute_reply":"2024-09-27T18:37:32.012707Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}]}]}