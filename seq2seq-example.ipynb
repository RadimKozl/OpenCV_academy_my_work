{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6863003,"sourceType":"datasetVersion","datasetId":3944299}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **<font style=\"color:black\">Sequence to Sequence text generation by PyTorch (seq2seq)</font>**\n-------------------\n\n>Note: Apply it to machine translation on a dataset with German to English sentences, specifically the Multi30k dataset.","metadata":{}},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Installation and import libraries</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"!pip install spacy\n!pip install tokenizers\n!pip install sacrebleu\n!pip install tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:41:10.702092Z","iopub.execute_input":"2025-02-23T19:41:10.702311Z","iopub.status.idle":"2025-02-23T19:41:25.484985Z","shell.execute_reply.started":"2025-02-23T19:41:10.702292Z","shell.execute_reply":"2025-02-23T19:41:25.483908Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.11.0a1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.28.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.28.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nRequirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.21.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.28.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.9.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.1.31)\nCollecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.1.1 sacrebleu-2.5.1\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport spacy\nimport random\nfrom torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\nfrom torch.utils.data import Dataset, DataLoader\nfrom sacrebleu import corpus_bleu\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom torch.nn.utils.rnn import pad_sequence\nfrom tqdm import tqdm  # Import tqdm for the progress bar\n\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:41:25.486157Z","iopub.execute_input":"2025-02-23T19:41:25.486476Z","iopub.status.idle":"2025-02-23T19:41:43.794180Z","shell.execute_reply.started":"2025-02-23T19:41:25.486448Z","shell.execute_reply":"2025-02-23T19:41:43.793274Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Utils support function</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"!python -m spacy download de_core_news_sm\n!python -m spacy download en_core_web_sm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:41:43.795155Z","iopub.execute_input":"2025-02-23T19:41:43.795751Z","iopub.status.idle":"2025-02-23T19:41:59.887096Z","shell.execute_reply.started":"2025-02-23T19:41:43.795719Z","shell.execute_reply":"2025-02-23T19:41:59.886256Z"}},"outputs":[{"name":"stdout","text":"Collecting de-core-news-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.11.0a1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.28.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.28.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\nInstalling collected packages: de-core-news-sm\nSuccessfully installed de-core-news-sm-3.7.0\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('de_core_news_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\nCollecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.0a1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.28.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.28.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Load spacy models for German and English\nspacy_ger = spacy.load(\"de_core_news_sm\")\nspacy_eng = spacy.load(\"en_core_web_sm\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:41:59.889557Z","iopub.execute_input":"2025-02-23T19:41:59.889784Z","iopub.status.idle":"2025-02-23T19:42:01.751898Z","shell.execute_reply.started":"2025-02-23T19:41:59.889764Z","shell.execute_reply":"2025-02-23T19:42:01.751221Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def tokenize_ger(text):\n    return [tok.text for tok in spacy_ger.tokenizer(text)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:01.753095Z","iopub.execute_input":"2025-02-23T19:42:01.753300Z","iopub.status.idle":"2025-02-23T19:42:01.756993Z","shell.execute_reply.started":"2025-02-23T19:42:01.753281Z","shell.execute_reply":"2025-02-23T19:42:01.756099Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def tokenize_eng(text):\n    return [tok.text for tok in spacy_eng.tokenizer(text)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:01.757887Z","iopub.execute_input":"2025-02-23T19:42:01.758209Z","iopub.status.idle":"2025-02-23T19:42:01.776473Z","shell.execute_reply.started":"2025-02-23T19:42:01.758173Z","shell.execute_reply":"2025-02-23T19:42:01.775362Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"def translate_sentence(model, sentence, german_vocab, english_vocab, device, max_length=50):\n    model.eval()\n\n    tokens = [token.lower() for token in sentence]\n    tokens = [german_vocab.sos_token] + tokens + [german_vocab.eos_token]\n    indices = [german_vocab[token] for token in tokens]\n    sentence_tensor = torch.LongTensor(indices).unsqueeze(0).to(device)  # (1, seq_len)\n\n    with torch.no_grad():\n        hidden, cell = model.encoder(sentence_tensor)  # (num_layers, 1, hidden_size)\n        print(f\"hidden shape: {hidden.shape}, cell shape: {cell.shape}\")\n\n    outputs = [english_vocab[english_vocab.sos_token]]\n\n    for _ in range(max_length):\n        previous_word = torch.LongTensor([outputs[-1]]).to(device)  # (1,)\n        with torch.no_grad():\n            output, hidden, cell = model.decoder(previous_word, hidden, cell)\n            best_guess = output.argmax(1).item()\n        outputs.append(best_guess)\n        if best_guess == english_vocab[english_vocab.eos_token]:\n            break\n\n    translated_sentence = [english_vocab.lookup_token(idx) for idx in outputs]\n    return translated_sentence[1:]","metadata":{"execution":{"iopub.status.busy":"2025-02-23T18:22:12.926336Z","iopub.execute_input":"2025-02-23T18:22:12.926637Z","iopub.status.idle":"2025-02-23T18:22:12.937661Z","shell.execute_reply.started":"2025-02-23T18:22:12.926609Z","shell.execute_reply":"2025-02-23T18:22:12.937016Z"}}},{"cell_type":"code","source":"def translate_sentence(model, sentence, german_vocab, english_vocab, device, max_length=50):\n    model.eval()\n\n    # Handle different input types\n    if isinstance(sentence, str):\n        # Tokenize string input\n        tokens = [token.text.lower() for token in german_vocab.tokenizer(sentence)]\n        tokens = [german_vocab.sos_token] + tokens + [german_vocab.eos_token]\n        indices = [german_vocab[token] for token in tokens]\n    elif isinstance(sentence, torch.Tensor):\n        # Use tensor directly as indices\n        indices = sentence.tolist()  # Convert tensor to list of indices\n        indices = [german_vocab[german_vocab.sos_token]] + indices + [german_vocab[german_vocab.eos_token]]\n    else:\n        raise ValueError(\"Sentence must be a string or a torch.Tensor\")\n\n    sentence_tensor = torch.LongTensor(indices).unsqueeze(0).to(device)\n\n    # Encode sentence\n    with torch.no_grad():\n        hidden, cell = model.encoder(sentence_tensor)\n\n    outputs = [english_vocab[english_vocab.sos_token]]\n\n    for _ in range(max_length):\n        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n        with torch.no_grad():\n            output, hidden, cell = model.decoder(previous_word, hidden, cell)\n            best_guess = output.argmax(1).item()\n        outputs.append(best_guess)\n        if best_guess == english_vocab[english_vocab.eos_token]:\n            break\n\n    translated_sentence = [english_vocab.lookup_token(idx) for idx in outputs]\n    return translated_sentence[1:]  # Exclude <sos>","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:01.777429Z","iopub.execute_input":"2025-02-23T19:42:01.777669Z","iopub.status.idle":"2025-02-23T19:42:01.787902Z","shell.execute_reply.started":"2025-02-23T19:42:01.777645Z","shell.execute_reply":"2025-02-23T19:42:01.787366Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def bleu_score(data, model, german_vocab, english_vocab, device):\n    targets = []\n    outputs = []\n    for src, trg in data:\n        print(f\"src type: {type(src)}, shape: {src.shape}\")\n        print(f\"trg type: {type(trg)}, shape: {trg.shape}\")\n        prediction = translate_sentence(model, src, german_vocab, english_vocab, device)\n        prediction = prediction[:-1]  # Remove <eos> token\n        target_tokens = [english_vocab.lookup_token(idx.item()) for idx in trg]\n        targets.append(target_tokens)\n        outputs.append(prediction)\n    return corpus_bleu(outputs, targets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:01.788611Z","iopub.execute_input":"2025-02-23T19:42:01.788892Z","iopub.status.idle":"2025-02-23T19:42:01.803034Z","shell.execute_reply.started":"2025-02-23T19:42:01.788864Z","shell.execute_reply":"2025-02-23T19:42:01.802202Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def save_checkpoint(state, filename=\"/kaggle/working/my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    torch.save(state, filename)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:01.803871Z","iopub.execute_input":"2025-02-23T19:42:01.804141Z","iopub.status.idle":"2025-02-23T19:42:01.815129Z","shell.execute_reply.started":"2025-02-23T19:42:01.804110Z","shell.execute_reply":"2025-02-23T19:42:01.814546Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def load_checkpoint(checkpoint, model, optimizer):\n    print(\"=> Loading checkpoint\")\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:01.815891Z","iopub.execute_input":"2025-02-23T19:42:01.816106Z","iopub.status.idle":"2025-02-23T19:42:01.826481Z","shell.execute_reply.started":"2025-02-23T19:42:01.816088Z","shell.execute_reply":"2025-02-23T19:42:01.825927Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class Vocabulary:\n    def __init__(self, tokens=None):\n        self.token_to_idx = {}\n        self.idx_to_token = []\n        self.special_tokens = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n\n        # Add special tokens to the vocabulary\n        for token in self.special_tokens:\n            self.add_token(token)\n\n        if tokens:\n            self.build_vocab(tokens)\n\n        # Set attributes for special tokens\n        self.pad_token = \"<pad>\"\n        self.sos_token = \"<sos>\"\n        self.eos_token = \"<eos>\"\n        self.unk_token = \"<unk>\"\n\n    def build_vocab(self, tokens, min_freq=2, max_size=10000):\n        token_counts = Counter(tokens)\n        for token, count in token_counts.items():\n            if count >= min_freq:\n                self.add_token(token)\n                if len(self.token_to_idx) >= max_size:\n                    break\n\n    def add_token(self, token):\n        if token not in self.token_to_idx:\n            self.token_to_idx[token] = len(self.idx_to_token)\n            self.idx_to_token.append(token)\n\n    def __len__(self):\n        return len(self.idx_to_token)\n\n    def __getitem__(self, token):\n        return self.token_to_idx.get(token, self.token_to_idx[self.unk_token])\n\n    def lookup_token(self, idx):\n        return self.idx_to_token[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:01.827521Z","iopub.execute_input":"2025-02-23T19:42:01.827795Z","iopub.status.idle":"2025-02-23T19:42:01.838410Z","shell.execute_reply.started":"2025-02-23T19:42:01.827767Z","shell.execute_reply":"2025-02-23T19:42:01.837745Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class Multi30kDataset(Dataset):\n    def __init__(self, src_path, trg_path, german_vocab, english_vocab):\n        self.src_sentences = self.load_data(src_path)\n        self.trg_sentences = self.load_data(trg_path)\n        self.german_vocab = german_vocab\n        self.english_vocab = english_vocab\n\n    def load_data(self, data_path):\n        with open(data_path, 'r', encoding='utf-8') as file:\n            return file.readlines()\n\n    def __len__(self):\n        return len(self.src_sentences)\n\n    def __getitem__(self, idx):\n        src = self.src_sentences[idx].strip()\n        trg = self.trg_sentences[idx].strip()\n        src_tokens = tokenize_ger(src)\n        trg_tokens = tokenize_eng(trg)\n        src_indices = [self.german_vocab[token] for token in src_tokens]\n        trg_indices = [self.english_vocab[token] for token in trg_tokens]\n        return torch.tensor(src_indices), torch.tensor(trg_indices)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:01.839273Z","iopub.execute_input":"2025-02-23T19:42:01.839563Z","iopub.status.idle":"2025-02-23T19:42:01.853141Z","shell.execute_reply.started":"2025-02-23T19:42:01.839536Z","shell.execute_reply":"2025-02-23T19:42:01.852397Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"def collate_fn(batch, pad_idx):\n    src_batch, trg_batch = zip(*batch)\n    src_batch = pad_sequence(src_batch, padding_value=pad_idx)\n    trg_batch = pad_sequence(trg_batch, padding_value=pad_idx)\n    return src_batch, trg_batch","metadata":{"execution":{"iopub.status.busy":"2025-02-23T14:38:48.689001Z","iopub.execute_input":"2025-02-23T14:38:48.689216Z","iopub.status.idle":"2025-02-23T14:38:48.733092Z","shell.execute_reply.started":"2025-02-23T14:38:48.689197Z","shell.execute_reply":"2025-02-23T14:38:48.732455Z"}}},{"cell_type":"code","source":"def collate_fn(batch, pad_idx):\n    src_batch, trg_batch = zip(*batch)\n    src_batch = pad_sequence(src_batch, padding_value=pad_idx, batch_first=True)\n    trg_batch = pad_sequence(trg_batch, padding_value=pad_idx, batch_first=True)\n    max_len = max(src_batch.size(1), trg_batch.size(1))\n    if src_batch.size(1) < max_len:\n        src_padding = torch.full((src_batch.size(0), max_len - src_batch.size(1)), pad_idx, dtype=torch.long)\n        src_batch = torch.cat([src_batch, src_padding], dim=1)\n    if trg_batch.size(1) < max_len:\n        trg_padding = torch.full((trg_batch.size(0), max_len - trg_batch.size(1)), pad_idx, dtype=torch.long)\n        trg_batch = torch.cat([trg_batch, trg_padding], dim=1)\n    #print(f\"src_batch type: {src_batch.dtype}, trg_batch type: {trg_batch.dtype}\")\n    return src_batch, trg_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:01.856369Z","iopub.execute_input":"2025-02-23T19:42:01.856677Z","iopub.status.idle":"2025-02-23T19:42:01.870432Z","shell.execute_reply.started":"2025-02-23T19:42:01.856623Z","shell.execute_reply":"2025-02-23T19:42:01.869646Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Load data\ntrain_src_path = os.path.join('/kaggle','input','multi30k-de-en','training','train.de')\ntrain_trg_path = os.path.join('/kaggle','input','multi30k-de-en','training','train.en')\nvalid_src_path = os.path.join('/kaggle','input','multi30k-de-en','validation','val.de')\nvalid_trg_path = os.path.join('/kaggle','input','multi30k-de-en','validation','val.en')\ntest_src_path = os.path.join('/kaggle','input','multi30k-de-en','mmt16_task1_test','test.de')\ntest_trg_path = os.path.join('/kaggle','input','multi30k-de-en','mmt16_task1_test','test.en')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:01.872226Z","iopub.execute_input":"2025-02-23T19:42:01.872517Z","iopub.status.idle":"2025-02-23T19:42:01.880918Z","shell.execute_reply.started":"2025-02-23T19:42:01.872494Z","shell.execute_reply":"2025-02-23T19:42:01.880087Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Build vocabularies\ngerman_tokens_train = []\nenglish_tokens_train = []\ngerman_tokens_valid = []\nenglish_tokens_valid = []\ngerman_tokens_test = []\nenglish_tokens_test = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:01.881692Z","iopub.execute_input":"2025-02-23T19:42:01.881960Z","iopub.status.idle":"2025-02-23T19:42:01.893721Z","shell.execute_reply.started":"2025-02-23T19:42:01.881932Z","shell.execute_reply":"2025-02-23T19:42:01.893060Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"with open(train_src_path, 'r', encoding='utf-8') as file:\n    for line in file:\n        german_tokens_train.extend(tokenize_ger(line.strip()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:01.894605Z","iopub.execute_input":"2025-02-23T19:42:01.894905Z","iopub.status.idle":"2025-02-23T19:42:03.658595Z","shell.execute_reply.started":"2025-02-23T19:42:01.894881Z","shell.execute_reply":"2025-02-23T19:42:03.657678Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"with open(train_trg_path, 'r', encoding='utf-8') as file:\n    for line in file:\n        english_tokens_train.extend(tokenize_eng(line.strip()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:03.659598Z","iopub.execute_input":"2025-02-23T19:42:03.659819Z","iopub.status.idle":"2025-02-23T19:42:04.824701Z","shell.execute_reply.started":"2025-02-23T19:42:03.659800Z","shell.execute_reply":"2025-02-23T19:42:04.824033Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"with open(valid_src_path, 'r', encoding='utf-8') as file:\n    for line in file:\n        german_tokens_valid.extend(tokenize_ger(line.strip()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:04.825490Z","iopub.execute_input":"2025-02-23T19:42:04.825778Z","iopub.status.idle":"2025-02-23T19:42:04.886910Z","shell.execute_reply.started":"2025-02-23T19:42:04.825749Z","shell.execute_reply":"2025-02-23T19:42:04.886127Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"with open(valid_trg_path, 'r', encoding='utf-8') as file:\n    for line in file:\n        english_tokens_valid.extend(tokenize_eng(line.strip()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:04.887849Z","iopub.execute_input":"2025-02-23T19:42:04.888140Z","iopub.status.idle":"2025-02-23T19:42:04.929639Z","shell.execute_reply.started":"2025-02-23T19:42:04.888110Z","shell.execute_reply":"2025-02-23T19:42:04.929099Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"with open(test_src_path, 'r', encoding='utf-8') as file:\n    for line in file:\n        german_tokens_test.extend(tokenize_ger(line.strip()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:04.930335Z","iopub.execute_input":"2025-02-23T19:42:04.930571Z","iopub.status.idle":"2025-02-23T19:42:04.984527Z","shell.execute_reply.started":"2025-02-23T19:42:04.930539Z","shell.execute_reply":"2025-02-23T19:42:04.983955Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"with open(test_trg_path, 'r', encoding='utf-8') as file:\n    for line in file:\n        english_tokens_test.extend(tokenize_eng(line.strip()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:04.985231Z","iopub.execute_input":"2025-02-23T19:42:04.985445Z","iopub.status.idle":"2025-02-23T19:42:05.029211Z","shell.execute_reply.started":"2025-02-23T19:42:04.985426Z","shell.execute_reply":"2025-02-23T19:42:05.028481Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"german_vocab_train = Vocabulary()\nenglish_vocab_train = Vocabulary()\ngerman_vocab_valid = Vocabulary()\nenglish_vocab_valid = Vocabulary()\ngerman_vocab_test = Vocabulary()\nenglish_vocab_test = Vocabulary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.029965Z","iopub.execute_input":"2025-02-23T19:42:05.030214Z","iopub.status.idle":"2025-02-23T19:42:05.033928Z","shell.execute_reply.started":"2025-02-23T19:42:05.030194Z","shell.execute_reply":"2025-02-23T19:42:05.032961Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"german_vocab_train.build_vocab(german_tokens_train)\nenglish_vocab_train.build_vocab(english_tokens_train)\ngerman_vocab_valid.build_vocab(german_tokens_valid)\nenglish_vocab_valid.build_vocab(english_tokens_valid)\ngerman_vocab_test.build_vocab(german_tokens_test)\nenglish_vocab_test.build_vocab(english_tokens_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.034610Z","iopub.execute_input":"2025-02-23T19:42:05.034906Z","iopub.status.idle":"2025-02-23T19:42:05.148426Z","shell.execute_reply.started":"2025-02-23T19:42:05.034879Z","shell.execute_reply":"2025-02-23T19:42:05.147703Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Training hyperparameters\nnum_epochs = 100\nlearning_rate = 0.001\nbatch_size = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.149302Z","iopub.execute_input":"2025-02-23T19:42:05.149645Z","iopub.status.idle":"2025-02-23T19:42:05.177061Z","shell.execute_reply.started":"2025-02-23T19:42:05.149614Z","shell.execute_reply":"2025-02-23T19:42:05.176184Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Model hyperparameters\nload_model = False\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ninput_size_encoder = len(german_vocab_train)\ninput_size_decoder = len(english_vocab_train)\noutput_size = len(english_vocab_train)\nencoder_embedding_size = 300\ndecoder_embedding_size = 300\nhidden_size = 1024\nnum_layers = 2\nenc_dropout = 0.5\ndec_dropout = 0.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.177971Z","iopub.execute_input":"2025-02-23T19:42:05.178203Z","iopub.status.idle":"2025-02-23T19:42:05.189115Z","shell.execute_reply.started":"2025-02-23T19:42:05.178183Z","shell.execute_reply":"2025-02-23T19:42:05.188390Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Tensorboard to get nice loss plot\nwriter = SummaryWriter(f\"runs/loss_plot\")\nstep = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.189938Z","iopub.execute_input":"2025-02-23T19:42:05.190145Z","iopub.status.idle":"2025-02-23T19:42:05.201734Z","shell.execute_reply.started":"2025-02-23T19:42:05.190126Z","shell.execute_reply":"2025-02-23T19:42:05.201091Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Create data loaders\ntrain_dataset = Multi30kDataset(train_src_path, train_trg_path, german_vocab_train, english_vocab_train)\nvalid_dataset = Multi30kDataset(valid_src_path, valid_trg_path, german_vocab_valid, english_vocab_valid)\ntest_dataset = Multi30kDataset(test_src_path, test_trg_path, german_vocab_test, english_vocab_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.202544Z","iopub.execute_input":"2025-02-23T19:42:05.202795Z","iopub.status.idle":"2025-02-23T19:42:05.231304Z","shell.execute_reply.started":"2025-02-23T19:42:05.202776Z","shell.execute_reply":"2025-02-23T19:42:05.230571Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Check the length of the dataset\nprint(f\"Number of samples in train dataset: {len(train_dataset)}\")\nprint(f\"Number of samples in train dataset: {len(valid_dataset)}\")\nprint(f\"Number of samples in train dataset: {len(test_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.232161Z","iopub.execute_input":"2025-02-23T19:42:05.232456Z","iopub.status.idle":"2025-02-23T19:42:05.237506Z","shell.execute_reply.started":"2025-02-23T19:42:05.232427Z","shell.execute_reply":"2025-02-23T19:42:05.236759Z"}},"outputs":[{"name":"stdout","text":"Number of samples in train dataset: 29001\nNumber of samples in train dataset: 1015\nNumber of samples in train dataset: 1000\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"datasets_list = [train_dataset, valid_dataset, test_dataset]\nnames_list = ['train dataset', 'validation dataset', 'test dataset']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.238266Z","iopub.execute_input":"2025-02-23T19:42:05.238593Z","iopub.status.idle":"2025-02-23T19:42:05.250238Z","shell.execute_reply.started":"2025-02-23T19:42:05.238532Z","shell.execute_reply":"2025-02-23T19:42:05.249542Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Inspect a few samples\nfor p, dataset in enumerate(datasets_list):\n    print(f'Show {names_list[p]} samples.\\n')\n    for i in range(min(5, len(dataset))):\n        src, trg = train_dataset[i]\n        print(f\"Source: {src}\")\n        print(f\"Target: {trg}\")\n    print(100*'-')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.251069Z","iopub.execute_input":"2025-02-23T19:42:05.251294Z","iopub.status.idle":"2025-02-23T19:42:05.305044Z","shell.execute_reply.started":"2025-02-23T19:42:05.251276Z","shell.execute_reply":"2025-02-23T19:42:05.304448Z"}},"outputs":[{"name":"stdout","text":"Show train dataset samples.\n\nSource: tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])\nTarget: tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\nSource: tensor([17,  7, 18, 19, 20, 21,  3, 16])\nTarget: tensor([15, 16, 17, 18, 19,  9, 20, 21, 22, 23, 24, 14])\nSource: tensor([22, 23, 24, 25, 11, 21, 26, 27, 28, 16])\nTarget: tensor([25, 26, 27, 28, 29, 21, 30, 31, 14])\nSource: tensor([22, 29, 11, 30, 31, 32, 33, 34, 35, 36, 37, 38, 21, 39, 16])\nTarget: tensor([25, 32, 17, 21, 33, 34, 35, 36, 37, 21, 38, 39, 21, 40, 14])\nSource: tensor([ 4,  7, 40, 41, 42, 37, 43, 44, 45, 16])\nTarget: tensor([ 4, 16,  9, 41, 42, 43, 44, 45, 14])\n----------------------------------------------------------------------------------------------------\nShow validation dataset samples.\n\nSource: tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])\nTarget: tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\nSource: tensor([17,  7, 18, 19, 20, 21,  3, 16])\nTarget: tensor([15, 16, 17, 18, 19,  9, 20, 21, 22, 23, 24, 14])\nSource: tensor([22, 23, 24, 25, 11, 21, 26, 27, 28, 16])\nTarget: tensor([25, 26, 27, 28, 29, 21, 30, 31, 14])\nSource: tensor([22, 29, 11, 30, 31, 32, 33, 34, 35, 36, 37, 38, 21, 39, 16])\nTarget: tensor([25, 32, 17, 21, 33, 34, 35, 36, 37, 21, 38, 39, 21, 40, 14])\nSource: tensor([ 4,  7, 40, 41, 42, 37, 43, 44, 45, 16])\nTarget: tensor([ 4, 16,  9, 41, 42, 43, 44, 45, 14])\n----------------------------------------------------------------------------------------------------\nShow test dataset samples.\n\nSource: tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])\nTarget: tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\nSource: tensor([17,  7, 18, 19, 20, 21,  3, 16])\nTarget: tensor([15, 16, 17, 18, 19,  9, 20, 21, 22, 23, 24, 14])\nSource: tensor([22, 23, 24, 25, 11, 21, 26, 27, 28, 16])\nTarget: tensor([25, 26, 27, 28, 29, 21, 30, 31, 14])\nSource: tensor([22, 29, 11, 30, 31, 32, 33, 34, 35, 36, 37, 38, 21, 39, 16])\nTarget: tensor([25, 32, 17, 21, 33, 34, 35, 36, 37, 21, 38, 39, 21, 40, 14])\nSource: tensor([ 4,  7, 40, 41, 42, 37, 43, 44, 45, 16])\nTarget: tensor([ 4, 16,  9, 41, 42, 43, 44, 45, 14])\n----------------------------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=lambda b: collate_fn(b, pad_idx=german_vocab_train[\"<pad>\"]))\nvalid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True, collate_fn=lambda b: collate_fn(b, pad_idx=german_vocab_valid[\"<pad>\"]))\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, collate_fn=lambda b: collate_fn(b, pad_idx=german_vocab_test[\"<pad>\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.305766Z","iopub.execute_input":"2025-02-23T19:42:05.306026Z","iopub.status.idle":"2025-02-23T19:42:05.310665Z","shell.execute_reply.started":"2025-02-23T19:42:05.306006Z","shell.execute_reply":"2025-02-23T19:42:05.309836Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"for batch_idx, (src, trg) in enumerate(train_loader):\n    print(f\"Batch {batch_idx}: src shape={src.shape}, trg shape={trg.shape}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.311426Z","iopub.execute_input":"2025-02-23T19:42:05.311693Z","iopub.status.idle":"2025-02-23T19:42:05.364863Z","shell.execute_reply.started":"2025-02-23T19:42:05.311667Z","shell.execute_reply":"2025-02-23T19:42:05.364283Z"}},"outputs":[{"name":"stdout","text":"Batch 0: src shape=torch.Size([64, 23]), trg shape=torch.Size([64, 23])\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"for batch_idx, (src, trg) in enumerate(valid_loader):\n    print(f\"Batch {batch_idx}: src shape={src.shape}, trg shape={trg.shape}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.365626Z","iopub.execute_input":"2025-02-23T19:42:05.365863Z","iopub.status.idle":"2025-02-23T19:42:05.378941Z","shell.execute_reply.started":"2025-02-23T19:42:05.365833Z","shell.execute_reply":"2025-02-23T19:42:05.378202Z"}},"outputs":[{"name":"stdout","text":"Batch 0: src shape=torch.Size([64, 33]), trg shape=torch.Size([64, 33])\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"for batch_idx, (src, trg) in enumerate(test_loader):\n    print(f\"Batch {batch_idx}: src shape={src.shape}, trg shape={trg.shape}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.379598Z","iopub.execute_input":"2025-02-23T19:42:05.379783Z","iopub.status.idle":"2025-02-23T19:42:05.394985Z","shell.execute_reply.started":"2025-02-23T19:42:05.379767Z","shell.execute_reply":"2025-02-23T19:42:05.394407Z"}},"outputs":[{"name":"stdout","text":"Batch 0: src shape=torch.Size([64, 25]), trg shape=torch.Size([64, 25])\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"def collate_fn(batch, pad_idx):\n    src_batch, trg_batch = zip(*batch)\n    src_batch = pad_sequence(src_batch, padding_value=pad_idx, batch_first=True)\n    trg_batch = pad_sequence(trg_batch, padding_value=pad_idx, batch_first=True)\n    \n    max_len = max(src_batch.size(1), trg_batch.size(1))\n    \n    if src_batch.size(1) < max_len:\n        src_padding = torch.full((src_batch.size(0), max_len - src_batch.size(1)), pad_idx, dtype=torch.long)\n        src_batch = torch.cat([src_batch, src_padding], dim=1)\n    \n    if trg_batch.size(1) < max_len:\n        trg_padding = torch.full((trg_batch.size(0), max_len - trg_batch.size(1)), pad_idx, dtype=torch.long)\n        trg_batch = torch.cat([trg_batch, trg_padding], dim=1)\n    \n    #print(f\"Sample src type: {src.dtype}, trg type: {trg.dtype}\")\n    return src_batch, trg_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.395845Z","iopub.execute_input":"2025-02-23T19:42:05.396129Z","iopub.status.idle":"2025-02-23T19:42:05.401177Z","shell.execute_reply.started":"2025-02-23T19:42:05.396101Z","shell.execute_reply":"2025-02-23T19:42:05.400391Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout):\n        super(Encoder, self).__init__()\n        self.dropout = nn.Dropout(dropout)\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n\n    def forward(self, x):\n        embedding = self.dropout(self.embedding(x))\n        outputs, (hidden, cell) = self.rnn(embedding)\n        return hidden, cell","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.401905Z","iopub.execute_input":"2025-02-23T19:42:05.402125Z","iopub.status.idle":"2025-02-23T19:42:05.412512Z","shell.execute_reply.started":"2025-02-23T19:42:05.402106Z","shell.execute_reply":"2025-02-23T19:42:05.411875Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, dropout):\n        super(Decoder, self).__init__()\n        self.dropout = nn.Dropout(dropout)\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x, hidden, cell):\n        # x: (batch_size,) e.g., (1,)\n        x = x.unsqueeze(1)  # (batch_size, 1) e.g., (1, 1)\n        embedding = self.dropout(self.embedding(x))  # (batch_size, 1, embedding_size) e.g., (1, 1, embedding_size)\n        #print(f\"embedding shape: {embedding.shape}\")\n        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))  # outputs: (batch_size, 1, hidden_size)\n        #print(f\"outputs shape: {outputs.shape}\")\n        predictions = self.fc(outputs.squeeze(1))  # (batch_size, output_size)\n        return predictions, hidden, cell","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.413185Z","iopub.execute_input":"2025-02-23T19:42:05.413379Z","iopub.status.idle":"2025-02-23T19:42:05.426905Z","shell.execute_reply.started":"2025-02-23T19:42:05.413362Z","shell.execute_reply":"2025-02-23T19:42:05.426282Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n\n    def forward(self, source, target, teacher_force_ratio=0.5):\n        batch_size = source.shape[0]\n        target_len = target.shape[1]\n        target_vocab_size = len(english_vocab_train)  # Adjust based on your vocabulary\n\n        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(self.device)\n\n        hidden, cell = self.encoder(source)  # (batch_size, seq_len) -> (num_layers, batch_size, hidden_size)\n        x = target[:, 0]  # (batch_size,)\n\n        for t in range(1, target_len):\n            output, hidden, cell = self.decoder(x, hidden, cell)\n            outputs[:, t, :] = output\n            best_guess = output.argmax(1)\n            x = target[:, t] if random.random() < teacher_force_ratio else best_guess\n\n        return outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.427681Z","iopub.execute_input":"2025-02-23T19:42:05.427871Z","iopub.status.idle":"2025-02-23T19:42:05.438683Z","shell.execute_reply.started":"2025-02-23T19:42:05.427855Z","shell.execute_reply":"2025-02-23T19:42:05.437909Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout).to(device)\ndecoder_net = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dec_dropout).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:05.439690Z","iopub.execute_input":"2025-02-23T19:42:05.439966Z","iopub.status.idle":"2025-02-23T19:42:06.047810Z","shell.execute_reply.started":"2025-02-23T19:42:05.439938Z","shell.execute_reply":"2025-02-23T19:42:06.046918Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"model = Seq2Seq(encoder_net, decoder_net, device).to(device)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:06.051734Z","iopub.execute_input":"2025-02-23T19:42:06.051979Z","iopub.status.idle":"2025-02-23T19:42:08.354656Z","shell.execute_reply.started":"2025-02-23T19:42:06.051958Z","shell.execute_reply":"2025-02-23T19:42:08.353993Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# In your model initialization\nfor name, param in model.named_parameters():\n    if param.numel() == 0:\n        print(f\"Warning: Zero-element tensor detected in parameter '{name}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:08.355687Z","iopub.execute_input":"2025-02-23T19:42:08.356183Z","iopub.status.idle":"2025-02-23T19:42:08.359962Z","shell.execute_reply.started":"2025-02-23T19:42:08.356160Z","shell.execute_reply":"2025-02-23T19:42:08.359066Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"pad_idx = english_vocab_train[\"<pad>\"]\ncriterion = nn.CrossEntropyLoss(ignore_index=pad_idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:08.360679Z","iopub.execute_input":"2025-02-23T19:42:08.360952Z","iopub.status.idle":"2025-02-23T19:42:08.378971Z","shell.execute_reply.started":"2025-02-23T19:42:08.360931Z","shell.execute_reply":"2025-02-23T19:42:08.378223Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"if load_model:\n    load_checkpoint(torch.load(\"/kaggle/working/my_checkpoint.pth.tar\"), model, optimizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:08.379621Z","iopub.execute_input":"2025-02-23T19:42:08.379855Z","iopub.status.idle":"2025-02-23T19:42:08.390953Z","shell.execute_reply.started":"2025-02-23T19:42:08.379815Z","shell.execute_reply":"2025-02-23T19:42:08.390129Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:08.391967Z","iopub.execute_input":"2025-02-23T19:42:08.392271Z","iopub.status.idle":"2025-02-23T19:42:08.404007Z","shell.execute_reply.started":"2025-02-23T19:42:08.392242Z","shell.execute_reply":"2025-02-23T19:42:08.403192Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"def translate_sentence(model, sentence, german_vocab, english_vocab, device, max_length=50):\n    model.eval()  # Ensure evaluation mode\n\n    # Tokenize and convert sentence to tensor\n    tokens = [token.lower() for token in sentence]\n    tokens = [german_vocab.sos_token] + tokens + [german_vocab.eos_token]\n    indices = [german_vocab[token] for token in tokens]\n    # Correct shape to (batch_size, seq_len)\n    sentence_tensor = torch.LongTensor(indices).unsqueeze(0).to(device)  # Shape: (1, seq_len)\n\n    # Encode sentence\n    with torch.no_grad():\n        hidden, cell = model.encoder(sentence_tensor)  # Shape: (num_layers, 1, hidden_size)\n\n    outputs = [english_vocab[english_vocab.sos_token]]\n\n    for _ in range(max_length):\n        # Correct shape to (batch_size,)\n        previous_word = torch.LongTensor([outputs[-1]]).to(device)  # Shape: (1,)\n        with torch.no_grad():\n            output, hidden, cell = model.decoder(previous_word, hidden, cell)\n            best_guess = output.argmax(1).item()\n        outputs.append(best_guess)\n        if best_guess == english_vocab[english_vocab.eos_token]:\n            break\n\n    translated_sentence = [english_vocab.lookup_token(idx) for idx in outputs]\n    return translated_sentence[1:]  # Exclude start token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:08.404850Z","iopub.execute_input":"2025-02-23T19:42:08.405129Z","iopub.status.idle":"2025-02-23T19:42:08.413254Z","shell.execute_reply.started":"2025-02-23T19:42:08.405106Z","shell.execute_reply":"2025-02-23T19:42:08.412543Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Example usage with a small batch\nexample_batch = [train_dataset[i] for i in range(2)]  # Get a small batch for testing\ncollated_batch = collate_fn(example_batch, pad_idx=german_vocab_train[\"<pad>\"])\nprint(f\"Collated source batch shape: {collated_batch[0].shape}\")\nprint(f\"Collated target batch shape: {collated_batch[1].shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:08.414017Z","iopub.execute_input":"2025-02-23T19:42:08.414312Z","iopub.status.idle":"2025-02-23T19:42:08.429681Z","shell.execute_reply.started":"2025-02-23T19:42:08.414291Z","shell.execute_reply":"2025-02-23T19:42:08.428937Z"}},"outputs":[{"name":"stdout","text":"Collated source batch shape: torch.Size([2, 13])\nCollated target batch shape: torch.Size([2, 13])\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    print(f\"[Epoch {epoch} / {num_epochs}]\")\n    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n    save_checkpoint(checkpoint)\n\n    model.eval()\n    translated_sentence = translate_sentence(model, sentence, german_vocab_train, english_vocab_train, device)\n    print(f\"Translated example sentence: \\n {translated_sentence}\")\n\n    model.train()\n    for batch_idx, (inp_data, target) in enumerate(tqdm(train_loader, desc=f\"Training Epoch {epoch}\", leave=True)):\n        inp_data, target = inp_data.to(device, dtype=torch.long), target.to(device, dtype=torch.long)\n        #print(f\"inp_data shape: {inp_data.shape}, target shape: {target.shape}\")\n        output = model(inp_data, target)\n        #print(f\"output shape: {output.shape}\")\n        \n        output = output[:, 1:].reshape(-1, output.shape[-1])  # Skip <sos>\n        target = target[:, 1:].reshape(-1)  # Skip <sos>\n        #print(f\"output_flat shape: {output.shape}, target_flat shape: {target.shape}\")\n        \n        optimizer.zero_grad()\n        loss = criterion(output, target)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n        optimizer.step()\n        \n        writer.add_scalar(\"Training loss\", loss.item(), global_step=step)\n        step += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T19:42:08.430452Z","iopub.execute_input":"2025-02-23T19:42:08.430638Z"}},"outputs":[{"name":"stdout","text":"[Epoch 0 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['backward', 'Tall', 'operates', 'operates', 'trims', 'room', 'room', 'ready', 'ready', 'guitarists', 'guitarists', 'shopping', 'counter', 'counter', 'break', 'crabs', 'crabs', 'crabs', 'weapon', 'weapon', 'tinsel', 'Snow', 'stuck', 'stuck', 'stuck', 'stuck', 'stuck', 'athlete', 'Motorcycle', 'Motorcycle', 'Motorcycle', 'Adult', 'Mouse', 'forming', 'ready', 'tinsel', 'tinsel', 'bystander', 'ready', 'sews', 'sews', 'hunched', 'tinsel', 'tinsel', 'sews', 'Snow', 'ready', 'tinsel', 'tinsel', 'sews']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 0: 100%|██████████| 454/454 [01:29<00:00,  5.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['young', 'woman', 'is', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 1: 100%|██████████| 454/454 [01:37<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'of', 'a', '<unk>', ',', 'a', 'a', ',', 'and', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2: 100%|██████████| 454/454 [01:37<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'of', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3: 100%|██████████| 454/454 [01:37<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 4: 100%|██████████| 454/454 [01:37<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 5 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 5: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 6 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '.', '.', '.', '.', '.', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 6: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 7 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 7: 100%|██████████| 454/454 [01:38<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 8 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 8: 100%|██████████| 454/454 [01:37<00:00,  4.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 9 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 9: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 10 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', '<unk>', '<unk>', 'I', '<unk>', '<unk>', 'I', '<unk>', '<unk>', 'I', '<unk>', '<unk>', 'I', '<unk>', '<unk>', 'I', '<unk>', '<unk>', 'I', 'I', '<unk>', '<unk>', 'I', '<unk>', '<unk>', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 10: 100%|██████████| 454/454 [01:37<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 11 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 11: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 12 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 12: 100%|██████████| 454/454 [01:37<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 13 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 13: 100%|██████████| 454/454 [01:37<00:00,  4.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 14 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 14: 100%|██████████| 454/454 [01:37<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 15 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'to', '<unk>', '.', '<unk>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 15: 100%|██████████| 454/454 [01:38<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 16 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', 'the', 'prop', '.', 'the', 'prop', '.', 'the', 'prop', '.', 'the']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 16: 100%|██████████| 454/454 [01:37<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 17 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'mold', '<unk>', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 17: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 18 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 18: 100%|██████████| 454/454 [01:38<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 19 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', 'I', 'I', 'I', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'possibly', '<unk>', '<unk>', '<unk>', 'possibly', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 19: 100%|██████████| 454/454 [01:38<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 20 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'for', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 20: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 21 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', 'representing', 'South', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 21: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 22 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['New', '<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', 'I', 'I', 'I', 'I', '<unk>', '<unk>', 'I', '<unk>', '<unk>', '<unk>', 'I', 'all', 'all', 'black', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '.', '.', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 22: 100%|██████████| 454/454 [01:37<00:00,  4.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 23 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', 'you', '<unk>', '<unk>', 'I', 'I', 'I', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '\"', '.', '<unk>', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 23: 100%|██████████| 454/454 [01:35<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 24 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', 'I', 'say', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 24: 100%|██████████| 454/454 [01:35<00:00,  4.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 25 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', 'let', '<unk>', 'I', 'I', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '.', '<unk>', '.', '.', '.', '<unk>', '<unk>', '.', '.', '.', '.', '<unk>', '.', '.', '.', '<unk>', '<unk>', '.', '<unk>', '.', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 25: 100%|██████████| 454/454 [01:35<00:00,  4.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 26 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', 'I', 'I', 'I', 'I', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 26: 100%|██████████| 454/454 [01:36<00:00,  4.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 27 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', 'you', '<unk>', '<unk>', 'I', 'I', 'I', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '\"', '<unk>', '<unk>', '<unk>', '\"', '<unk>', '<unk>', '<unk>', '.', '\"', '.', '\"', '.', '\"', '.', '\"', '.', '\"', '.', '\"', '.', '\"', '.', '\"', '.', '\"']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 27: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 28 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', 'the', '<unk>', '<unk>', 'I', 'say', '<unk>', '<unk>', '<unk>', 'hold', 'a', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'funky', 'funky', '<unk>', '<unk>', 'funky', 'funky', 'funky', 'funky', 'funky', 'funky', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 28: 100%|██████████| 454/454 [01:34<00:00,  4.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 29 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', 'I', 'I', 'I', 'I', '<unk>', 'a', 'heart', '<unk>', 'so', 'heart', '<unk>', '<unk>', 'heart', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<unk>', '.', '<unk>', '.', '.', '.', '.', '\"', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 29: 100%|██████████| 454/454 [01:33<00:00,  4.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 30 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', 'the', '<unk>', 'I', 'I', 'I', 'I', '<unk>', '\"', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '\"', '<unk>', '\"', '<unk>', '\"', '<unk>', '\"', '<unk>', '\"', '<unk>', '\"', '<unk>', '\"', '<unk>', '\"', '<unk>', '\"', '<unk>', '\"', '<unk>', '\"', '<unk>', '\"', '<unk>', '\"', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 30: 100%|██████████| 454/454 [01:33<00:00,  4.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 31 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', 'you', '<unk>', 'I', 'I', 'I', 'I', 'I', 'be', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'heart', 'heart', 'heart', 'heart', '<unk>', '<unk>', 'heart', '<unk>', '<unk>', 'heart', '<unk>', 'the', '<unk>', '<unk>', 'the', '<unk>', '<unk>', 'one', 'of', 'the', '<unk>', '<unk>', '\"', 'mold', '.', 'one', 'of', 'the', '<unk>', '<unk>', '\"', 'mold', '.', 'mold']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 31: 100%|██████████| 454/454 [01:34<00:00,  4.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 32 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '\"', '<unk>', '\"', '<unk>', '\"', '<unk>', '\"', 'one', 'group', 'of', 'the', '<unk>', '<unk>', 'one', 'one', 'one', 'one', '<unk>', '\"', '<unk>', '<unk>', 'one', 'of', 'the', '<unk>', '<unk>', '\"', '\"', '.', '\"', '.', '\"', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 32: 100%|██████████| 454/454 [01:37<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 33 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', 'I', 'I', 'I', '\"', '<unk>', '<unk>', 'heart', '<unk>', '<unk>', 'pick', 'up', 'a', '<unk>', '<unk>', 'heart', 'up', 'one', '<unk>', 'one', 'heart', 'one', 'heart', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'up', 'the', '<unk>', '<unk>', 'up', 'the', '<unk>', '<unk>', 'up', 'the', 'funky', '.', 'up']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 33: 100%|██████████| 454/454 [01:35<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 34 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', 'I', 'I', 'I', '<unk>', '<unk>', 'heart', '<unk>', 'heart', 'heart', '<unk>', 'some', '<unk>', '<unk>', 'some', '<unk>', '<unk>', '<unk>', 'some', '<unk>', '<unk>', '<unk>', 'some', '<unk>', '<unk>', '<unk>', 'some', 'some', '<unk>', '<unk>', '<unk>', '<unk>', 'some', 'some', 'some', '<unk>', '<unk>', '<unk>', '<unk>', 'some', 'some', 'some', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 34: 100%|██████████| 454/454 [01:34<00:00,  4.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 35 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'my', '<unk>', '<unk>', 'I', 'I', 'I', 'I', 'I', '\"', '<unk>', '\"', 'heart', '\"', '\"', '<unk>', '\"', 'heart', '\"', '<unk>', '\"', 'one', 'heart', 'heart', '<unk>', '<unk>', 'one', 'heart', '<unk>', '\"', 'one', '<unk>', '\"', 'one', '<unk>', '<unk>', 'one', '<unk>', 'one', '<unk>', 'one', '<unk>', 'one', '<unk>', 'one', '<unk>', 'one', '<unk>', 'one', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 35: 100%|██████████| 454/454 [01:37<00:00,  4.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 36 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'one', 'of', 'the', '<unk>', 'one', 'heart', 'one', 'heart', 'one', 'heart', 'one', 'has', '<unk>', '<unk>', 'one', '<unk>', 'one', 'has', '<unk>', '.', 'mold', 'mold', '.', 'mold', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 36: 100%|██████████| 454/454 [01:37<00:00,  4.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 37 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', 'I', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'a', 'group', 'of', '\"', '<unk>', '<unk>', '\"', 'one', 'of', 'the', '<unk>', '<unk>', '\"', 'one', 'has', 'one', 'group', 'of', 'the', '<unk>', 'one', 'of', 'the', '<unk>', 'one', 'of', 'the', 'one', 'of', 'the', '<unk>', 'one', 'of', 'the', 'one', 'of', 'the']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 37: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 38 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n [',', '<unk>', ',', '<unk>', '<unk>', 'I', 'watch', 'the', '<unk>', 'to', 'be', '<unk>', '<unk>', '\"', 'heart', 'heart', '<unk>', '<unk>', '<unk>', '<unk>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', 'up', '.', 'up', '.', 'up', '.', 'up', '.', 'up']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 38: 100%|██████████| 454/454 [01:38<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 39 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', 'let', ',', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'give', 'give', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '<unk>', '<unk>', 'the', '<unk>', 'one', 'the', 'one', 'the', 'one', 'the', 'one', 'the', 'one', 'the', 'mold', 'the', 'mold', 'the', 'mold', '.', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold', 'mold']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 39: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 40 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', 'I', 'I', '<unk>', '<unk>', '<unk>', '<unk>', 'youth', 'give', '<unk>', '<unk>', '<unk>', '<unk>', '.', '.', '.', 'one', 'of', 'us', '.', 'up', '.', 'up', '.', 'up', '.', 'up', '.', 'up', '.', 'up', '.', '.', '.', 'up', '.', '.', 'up', '.', '.', '.', 'up', '.', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 40: 100%|██████████| 454/454 [01:38<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 41 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '\"', '<unk>', 'over', 'the', '<unk>', 'one', 'heart', 'one', 'heart', 'one', 'heart', 'one', 'heart', 'one', 'heart', 'one', 'heart', '.', '.', '.', '.', '.', '\"', 'one', '.', '.', '.', '.', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 41: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 42 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', 'you', '<unk>', 'I', 'I', '<unk>', '<unk>', 'only', 'only', '<unk>', '<unk>', 'pick', 'up', '<unk>', '<unk>', '\"', '<unk>', '.', '\"', '.', '\"', 'one', 'one', 'one', 'heart', 'one', 'is', '<unk>', 'the', '<unk>', '.', '\"', 'mold', '.', '\"', 'mold', '.', '\"', '.', '.', '\"', '.', '.', '\"', '.', '.', '\"', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 42: 100%|██████████| 454/454 [01:38<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 43 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', \"'s\", '<unk>', 'I', 'I', 'watch', '<unk>', '<unk>', '<unk>', '\"', 'hold', '<unk>', '<unk>', '<unk>', 'give', 'give', 'up', 'the', '<unk>', '.', 'the', 'the', 'one', 'one', 'one', 'one', 'one', 'one', 'the', 'one', 'looking', 'so', '.', 'up', 'the', '<unk>', '.', '.', '.', '\"', 'poster', '.', '\"', '.', '.', '\"', '.', '.', '\"']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 43: 100%|██████████| 454/454 [01:37<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 44 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', ',', '<unk>', '<unk>', 'I', 'I', 'say', '\"', '<unk>', '\"', 'heart', '<unk>', 'heart', '<unk>', '<unk>', '\"', '<unk>', 'over', '<unk>', '<unk>', '<unk>', '<unk>', '.', 'heart', '.', 'heart', '\"', '<unk>', '<unk>', 'up', '\"', 'mold', '.', 'up', '.', '<unk>', '.', '<unk>', '.', 'up', '\"', '<unk>', '.', '<unk>', '<unk>', '.', '<unk>', '.', '<unk>', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 44: 100%|██████████| 454/454 [01:37<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 45 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'my', '<unk>', '<unk>', 'or', 'I', '<unk>', 'or', '<unk>', '<unk>', '<unk>', '\"', '<unk>', 'some', 'some', '<unk>', '<unk>', 'over', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'up', '.', '<unk>', '<unk>', '.', '.', '<unk>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 45: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 46 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', '<unk>', 'is', '<unk>', 'to', 'give', 'a', 'farm', 'home', 'home', 'each', 'other', 'home', 'over', 'each', 'other', \"'s\", '<unk>', 'for', 'one', 'little', '<unk>', '<unk>', 'one', '<unk>', 'one', 'with', 'one', '<unk>', 'one', 'up', 'one', 'of', 'the', '<unk>', 'one', 'one', '.', 'looking', 'up', '.', 'looking', 'up', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 46: 100%|██████████| 454/454 [01:36<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 47 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', 'I', 'I', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'over', 'the', '<unk>', 'one', 'of', 'the', '<unk>', 'one', 'one', 'one', 'one', 'one', '<unk>', 'one', 'one', '<unk>', 'one', 'one', '<unk>', 'up', '.', 'up', '.', '.', '.', '.', '.', '.', '.', 'looking', 'looking', '.', '.', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 47: 100%|██████████| 454/454 [01:37<00:00,  4.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 48 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['restaurant', ',', '<unk>', '<unk>', 'I', 'I', '<unk>', '<unk>', '<unk>', 'or', '\"', '<unk>', '<unk>', 'heart', '<unk>', 'a', 'little', '<unk>', '<unk>', 'over', '<unk>', '<unk>', 'over', '<unk>', '<unk>', '<unk>', 'one', '<unk>', 'has', '<unk>', '<unk>', 'up', 'one', '<unk>', '<unk>', 'one', '<unk>', '<unk>', 'looking', 'up', 'mold', '<unk>', 'mold', '.', '<unk>', 'looking', 'up', 'as', 'a', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 48: 100%|██████████| 454/454 [01:37<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 49 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'my', ',', '<unk>', 'one', '<unk>', 'I', 'see', 'the', '<unk>', '<unk>', '<unk>', 'a', '<unk>', '<unk>', '<unk>', 'some', '<unk>', 'some', '<unk>', 'some', '<unk>', 'some', '<unk>', '<unk>', '<unk>', 'one', '<unk>', 'some', '<unk>', '<unk>', '<unk>', 'a', 'long', '<unk>', '<unk>', 'long', '<unk>', 'long', '<unk>', 'long', '<unk>', '<unk>', '<unk>', '<unk>', 'long', '<unk>', 'looking', 'up', 'the']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 49: 100%|██████████| 454/454 [01:37<00:00,  4.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 50 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', ',', '<unk>', '<unk>', 'I', 'or', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'a', '<unk>', '<unk>', 'one', '<unk>', 'one', '<unk>', 'one', 'little', 'one', '<unk>', 'one', '<unk>', 'one', 'player', '<unk>', 'the', 'mold', 'one', 'of', 'the', 'funky', 'looking', 'up', 'as', 'she', 'crosses', 'the', 'mold', 'looking', 'up', 'mold', 'mold', 'mold', 'mold', 'mold']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 50: 100%|██████████| 454/454 [01:38<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 51 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'my', 'let', '<unk>', '<unk>', 'watch', 'watch', '<unk>', '<unk>', 'watch', '<unk>', '<unk>', 'a', 'farm', ',', 'but', 'a', '<unk>', 'one', 'player', '<unk>', 'little', 'one', 'over', 'one', 'little', '<unk>', 'over', 'one', '<unk>', 'one', 'player', 'looking', 'up', 'the', '<unk>', 'the', '<unk>', 'looking', 'up', 'the', '<unk>', 'looking', 'up', 'the', '<unk>', 'looking', 'up', 'the', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 51: 100%|██████████| 454/454 [01:37<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 52 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', ',', '<unk>', '<unk>', 'I', 'I', '<unk>', '<unk>', 'I', 'I', '<unk>', '\"', '<unk>', 'heart', 'is', '<unk>', '<unk>', '\"', 'one', 'team', '<unk>', 'little', '<unk>', '<unk>', 'one', '<unk>', '<unk>', 'up', '<unk>', '<unk>', 'of', 'the', '<unk>', 'one', 'of', 'the', '<unk>', '<unk>', 'of', 'the', '<unk>', 'looking', 'up', 'to', 'mold', '.', 'to', 'the', '<unk>', 'that']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 52: 100%|██████████| 454/454 [01:38<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 53 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', \"'s\", 'you', '<unk>', ',', 'I', 'I', '<unk>', 'the', '\"', '<unk>', '\"', '<unk>', 'a', 'very', '<unk>', 'of', 'the', '<unk>', 'one', '<unk>', 'one', 'of', 'one', '<unk>', 'one', 'little', 'one', '<unk>', 'one', '<unk>', 'one', 'up', 'one', 'looking', 'up', 'the', 'one', 'of', 'has', '<unk>', 'looking', 'up', 'the', 'one', 'of', 'has', '<unk>', 'looking', 'up']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 53: 100%|██████████| 454/454 [01:37<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 54 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', ',', '<unk>', '<unk>', 'I', 'works', 'be', '<unk>', 'a', 'black', 'and', 'black', '<unk>', '<unk>', '<unk>', 'some', '<unk>', '<unk>', 'up', 'up', 'one', 'one', 'one', 'has', 'one', '<unk>', 'one', 'up', 'has', 'one', 'one', 'that', 'has', '<unk>', 'up', 'up', 'the', '<unk>', 'one', 'up', 'up', 'to', 'the', 'right', 'that', 'is', 'that', '<unk>', 'that']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 54: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 55 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', ',', 'I', '<unk>', '\"', '<unk>', '\"', '<unk>', 'a', 'pick', 'up', 'a', '<unk>', '<unk>', 'the', 'one', 'one', 'one', 'of', 'one', '<unk>', 'one', 'of', 'the', '<unk>', '<unk>', '<unk>', '.', 'looking', 'looking', 'mold', '.', 'looking', 'looking', 'mold', '.', '.', 'looking', 'looking', '.', 'mold', '.', 'looking', 'looking', 'mold', '.', 'mold']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 55: 100%|██████████| 454/454 [01:37<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 56 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', 'be', 'I', '<unk>', '\"', '<unk>', 'a', 'a', '<unk>', '<unk>', 'but', 'one', 'of', 'the', '<unk>', 'car', '.', 'the', '<unk>', '<unk>', 'the', 'the', '<unk>', 'one', 'of', 'the', 'funky', '<unk>', '<unk>', 'I', '<unk>', 'up', 'the', '<unk>', 'looking', 'up', '.', '.', 'up', '<unk>', '.', '<unk>', '.', 'up', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 56: 100%|██████████| 454/454 [01:37<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 57 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', \"'s\", 'you', '<unk>', 'I', 'watch', 'watch', '<unk>', 'out', 'a', 'a', '<unk>', 'youth', '<unk>', '<unk>', '<unk>', '<unk>', 'one', '<unk>', 'one', 'player', 'in', 'the', '<unk>', '<unk>', 'up', 'the', '<unk>', '<unk>', 'up', 'what', 'appears', 'to', '<unk>', '.', '<unk>', 'looking', 'up', 'the', '<unk>', 'looking', 'up', '.', '.', 'looking', 'up', '.', '<unk>', 'looking', 'up']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 57: 100%|██████████| 454/454 [01:37<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 58 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', ',', '<unk>', 'I', 'should', '<unk>', '<unk>', '<unk>', 'a', 'a', '<unk>', '<unk>', 'red', 'team', 'over', 'a', '<unk>', 'team', 'over', 'a', 'very', '<unk>', '.', '.', '.', 'looking', 'over', 'the', 'right', '.', '.', 'up', 'to', '<unk>', '.', 'up', 'the', '<unk>', 'up', 'up', '.', 'up', 'the', '<unk>', 'up', 'to', '<unk>', 'up', 'to']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 58: 100%|██████████| 454/454 [01:35<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 59 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'I', 'name', '<unk>', 'I', 'I', 'watch', 'only', 'only', 'only', 'to', 'pick', 'a', 'pick', '<unk>', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', 'up', 'the', '<unk>', '.', 'up', 'to', '<unk>', '.', '.', 'looking']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 59: 100%|██████████| 454/454 [01:37<00:00,  4.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 60 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', ',', '<unk>', ',', 'I', 'watch', ',', '<unk>', '<unk>', 'be', '<unk>', 'to', 'pick', 'a', '<unk>', '<unk>', 'pick', 'for', 'the', '<unk>', '.', 'the', 'what', 'have', '<unk>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 60: 100%|██████████| 454/454 [01:37<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 61 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'I', '<unk>', '<unk>', 'I', 'should', 'I', '<unk>', 'on', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'one', 'one', 'one', 'one', 'one', 'one', 'that', 'that', 'has', '<unk>', '\"', '.', '<unk>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 61: 100%|██████████| 454/454 [01:37<00:00,  4.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 62 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', 'name', '<unk>', ',', 'I', '<unk>', 'I', 'say', '<unk>', '<unk>', 'to', 'pick', 'a', '<unk>', '<unk>', 'pick', 'up', 'of', 'the', '<unk>', 'one', 'of', 'the', '<unk>', 'looking', 'up', 'mold', '.', 'up', '.', 'up', '.', 'up', '.', 'up', '.', 'up', '.', 'up', '.', 'up', '.', '.', '.', 'up', '.', '.', '.', 'up']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 62: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 63 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', 'watch', 'a', '<unk>', 'to', 'pick', 'up', 'a', '<unk>', '<unk>', '<unk>', 'one', 'little', 'one', 'one', 'one', 'little', 'one', '<unk>', '<unk>', 'that', 'is', '<unk>', 'some', 'funky', '<unk>', '<unk>', '.', '.', '.', '.', '.', 'looking', 'so', 'as', 'the', '<unk>', 'looking', 'so', \"'\", '<unk>', '.', '.', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 63: 100%|██████████| 454/454 [01:37<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 64 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', ',', '<unk>', '<unk>', 'I', 'I', 'say', '<unk>', 'signs', 'to', 'pick', 'out', 'of', 'the', '<unk>', 'but', 'but', 'one', 'little', 'one', 'has', '<unk>', 'little', 'little', 'has', '<unk>', '<unk>', '<unk>', 'looking', 'up', 'as', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '.', 'looking', '<unk>', '.', '.', '<unk>', '<unk>', '.', '.', '.', '.', '.', 'looking']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 64: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 65 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', '<unk>', '<unk>', 'on', 'the', '<unk>', 'of', 'red', '<unk>', '<unk>', 'is', 'little', '<unk>', 'little', 'little', '<unk>', 'up', 'some', '<unk>', 'the', '<unk>', 'up', 'up', 'the', '<unk>', 'up', 'up', 'the', '<unk>', 'up', 'the', '<unk>', 'position', 'as', 'the', '<unk>', '<unk>', '<unk>', '.', '.', '.', '.', '.', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 65: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 66 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', ',', '<unk>', '<unk>', 'I', 'be', 'singing', 'a', '<unk>', '<unk>', '\"', '<unk>', 'a', 'pick', 'up', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', 'one', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', '.', 'looking']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 66: 100%|██████████| 454/454 [01:37<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 67 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', \"'s\", '<unk>', '<unk>', 'watch', 'watch', 'watch', '<unk>', '<unk>', 'hold', 'a', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'one', '<unk>', 'one', '<unk>', 'one', '<unk>', 'one', '<unk>', '<unk>', '<unk>', '.', '<unk>', '.', '<unk>', '<unk>', '<unk>', '.', '<unk>', '.', 'looking', 'up', '.', '.', '.', '.', '.', '.', 'looking', 'up', '.', '.', 'looking', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 67: 100%|██████████| 454/454 [01:38<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 68 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'members', '<unk>', '<unk>', 'I', 'I', '<unk>', '<unk>', '<unk>', 'a', 'pick', 'a', '<unk>', 'a', 'pick', 'up', 'for', 'pick', 'up', 'some', '<unk>', '<unk>', '.', '.', 'one', 'player', 'has', '<unk>', '<unk>', 'one', '<unk>', '\"', '<unk>', 'up', 'the', '<unk>', 'looking', 'up', 'the', '<unk>', 'looking', 'has', '\"', 'sign', '.', 'up', '.', 'with', '\"', 'sign']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 68: 100%|██████████| 454/454 [01:37<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 69 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', ',', '<unk>', 'from', 'I', '<unk>', 'or', '<unk>', '<unk>', 'a', '<unk>', '<unk>', 'but', '<unk>', '<unk>', '<unk>', '<unk>', 'some', '<unk>', '<unk>', 'some', '<unk>', '<unk>', 'some', '<unk>', '<unk>', 'up', 'some', 'funky', '<unk>', 'green', 'mold', 'tips', 'one', '<unk>', 'one', 'green', 'one', 'looking', 'the', 'mold', 'looking', 'up', 'mold', 'the', '<unk>', 'looking', '.', 'mold']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 69: 100%|██████████| 454/454 [01:34<00:00,  4.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 70 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', 'I', 'be', '<unk>', '<unk>', 'pick', 'a', 'pick', 'a', 'pick', 'a', 'pick', 'a', 'pick', 'a', 'pick', 'up', 'one', '<unk>', 'one', 'one', 'one', 'one', 'one', 'one', 'heart', 'the', '<unk>', 'one', 'is', '<unk>', 'some', 'funky', '<unk>', '.', 'one', 'green', 'one', '.', 'the', '<unk>', '<unk>', '<unk>', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 70: 100%|██████████| 454/454 [01:33<00:00,  4.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 71 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', 'let', '<unk>', 'I', 'I', 'I', 'watch', 'on', 'a', 'pick', 'up', 'pick', 'up', '<unk>', 'pick', 'up', '.', '<unk>', '<unk>', '.', '.', 'one', '<unk>', 'one', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '\"', 'have', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 71: 100%|██████████| 454/454 [01:33<00:00,  4.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 72 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', \"'s\", 'snowboarding', '<unk>', 'I', 'I', 'be', '<unk>', 'to', 'pick', 'a', '<unk>', '<unk>', 'to', '<unk>', 'a', '<unk>', '.', '.', 'one', 'of', 'the', '<unk>', 'one', 'of', 'the', '<unk>', 'one', 'the', '<unk>', 'one', 'has', 'a', '<unk>', 'one', 'by', 'the', '<unk>', 'has', 'one', 'of', 'the', 'face', 'has', 'the', 'a', '<unk>', 'has', 'the', 'funky']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 72: 100%|██████████| 454/454 [01:37<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 73 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'the', 'let', '<unk>', 'I', 'I', 'be', 'singing', 'with', 'a', 'silver', 'only', '<unk>', 'some', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'one', 'black', 'one', 'black', 'one', 'one', 'one', 'one', 'one', 'of', 'one', 'of', 'one', 'of', 'one', '<unk>', 'one', 'one', 'of', 'the', '<unk>', 'one', 'of', 'the', '<unk>', 'one', 'of']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 73: 100%|██████████| 454/454 [01:38<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 74 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'my', 'let', '<unk>', 'I', 'I', 'watch', 'watch', 'a', 'farm', 'to', 'pick', 'up', 'a', 'pick', 'up', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', 'the', '<unk>', 'one', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', 'one', '<unk>', 'one', '<unk>', '<unk>', '<unk>', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 74: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 75 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', \"'s\", 'you', '<unk>', 'I', 'I', 'I', 'I', 'be', 'watch', 'a', 'white', '<unk>', 'and', 'to', '<unk>', '<unk>', 'but', '<unk>', '<unk>', '<unk>', 'but', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '\"', 'have', '<unk>', '<unk>', '<unk>', '\"', 'and', '<unk>', '<unk>', '\"', 'and', '<unk>', '<unk>', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 75: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 76 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'my', 'let', '<unk>', 'I', 'I', 'I', 'I', 'be', '<unk>', 'watch', 'a', 'young', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'for', '<unk>', '<unk>', '<unk>', 'the', 'the', '<unk>', '<unk>', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'the', '<unk>', 'the', '<unk>', '<unk>', '<unk>', '<unk>', 'the', 'funky', '<unk>', 'as', 'the', 'funky', 'looking', 'as', 'one', 'funky', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 76: 100%|██████████| 454/454 [01:37<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 77 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'my', '<unk>', '<unk>', 'I', 'I', 'be', '<unk>', 'off', '-', '<unk>', '<unk>', 'pick', 'up', '<unk>', 'pick', 'up', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<unk>', '.', '<unk>', '<unk>', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 78: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 79 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'my', 'let', 'with', 'I', 'I', 'hold', 'on', 'the', '<unk>', 'out', 'of', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', 'the', '<unk>', '<unk>', 'the', '<unk>', '.', 'the', '<unk>', '.', 'the', '<unk>', '.', '.', '.', '.', '.', '.', '.', '.', '.', 'up', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 79: 100%|██████████| 454/454 [01:37<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 80 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'the', '<unk>', '<unk>', 'I', 'I', 'be', '<unk>', 'on', 'a', 'red', 'and', 'red', 'team', 'tips', 'over', '<unk>', '<unk>', 'for', 'the', '<unk>', '<unk>', '<unk>', 'tips', 'tips', 'up', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '<unk>', 'the', '<unk>', '<unk>', 'the', '<unk>', 'looking', 'up', 'the', 'the']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 80: 100%|██████████| 454/454 [01:37<00:00,  4.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 81 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n [',', '<unk>', ',', '<unk>', 'the', 'watch', 'watch', ',', 'hold', 'a', 'a', 'and', 'red', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'face', ',', 'as', 'the', '<unk>', 'one', '<unk>', 'as', 'the', '<unk>', 'one', 'of', 'the', '<unk>', 'looking', 'up', 'as', 'she', 'appears', 'to', 'be', 'looking', 'the', 'mold', 'as', 'she', 'looks', 'very', 'mold']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 81: 100%|██████████| 454/454 [01:38<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 82 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', \"'s\", 'let', \"'s\", 'South', '<unk>', 'watch', ',', 'I', 'watch', 'here', 'hold', 'a', '<unk>', 'but', 'but', 'some', 'little', 'little', 'little', 'little', 'little', '<unk>', '<unk>', 'some', 'some', 'some', '<unk>', '<unk>', '<unk>', 'some', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<unk>', '.', '<unk>', '<unk>', '.', '<unk>', '.', '<unk>', '<unk>', 'as', 'the', '<unk>', '<unk>', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 82: 100%|██████████| 454/454 [01:37<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 83 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'the', 'baseball', '<unk>', 'watch', 'baseball', '<unk>', 'be', 'the', '<unk>', 'to', 'the', '<unk>', 'team', 'on', '\"', '5', '<unk>', 'by', 'some', '<unk>', '<unk>', '.', 'some', 'funky', '<unk>', '.', 'some', 'funky', '<unk>', '.', 'some', 'funky', '<unk>', '.', 'some', 'funky', '<unk>', '.', 'some', 'funky', '<unk>', '.', 'green', 'one', '<unk>', 'as', 'the', '<unk>', 'one']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 83: 100%|██████████| 454/454 [01:38<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 84 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'the', 'the', 'one', 'the', 'I', 'be', '<unk>', '<unk>', 'a', 'little', 'restaurant', 'sponsored', 'with', 'some', 'little', '<unk>', 'some', 'some', 'little', 'little', '<unk>', '.', '<unk>', '<unk>', 'some', 'little', '<unk>', '<unk>', 'some', 'funky', '<unk>', '<unk>', 'some', 'funky', '.', '.', 'that', 'has', 'some', 'funky', 'looking', 'up', 'that', 'has', 'some', 'funky', 'looking', 'green', 'mold']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 84: 100%|██████████| 454/454 [01:38<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 85 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'the', 'one', '<unk>', 'I', 'I', 'the', 'I', '<unk>', '\"', 'watch', 'a', 'red', 'team', 'but', 'over', '<unk>', '<unk>', 'little', 'little', 'some', 'some', 'some', 'some', 'green', 'some', 'green', 'some', 'green', '<unk>', '.', 'up', 'the', '<unk>', '<unk>', '.', '.', '.', '.', 'green', 'and', 'green', '<unk>', 'as', 'the', 'looking', 'looking', 'up', 'and', 'the']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 85: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 86 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', ',', 'name', '<unk>', ',', 'I', 'watch', 'here', '<unk>', '<unk>', 'pick', 'up', 'a', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'some', '<unk>', '<unk>', '<unk>', 'some', '<unk>', 'green', 'some', 'green', '<unk>', 'green', '<unk>', 'green', '<unk>', 'green', '<unk>', 'green', '<unk>', 'green', '<unk>', 'green', 'green', 'green', 'green', 'green', 'green', 'green', 'green', 'green']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 86: 100%|██████████| 454/454 [01:38<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 87 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', 'Cafe', 'that', \"'s\", 'I', '<unk>', 'on', 'here', '<unk>', 'here', 'hold', '<unk>', 'of', 'pick', 'up', 'every', '<unk>', '<unk>', 'from', 'the', '<unk>', '<unk>', '<unk>', 'mold', '.', 'up', 'mold', '<unk>', '<unk>', 'have', 'the', '<unk>', 'green', 'mold', 'up', 'up', 'up', 'the', '<unk>', '<unk>', '.', 'face', 'have', 'up', 'mold', 'green', 'mold', '.', 'up']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 87: 100%|██████████| 454/454 [01:38<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 88 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', ',', 'name', '<unk>', '<unk>', 'baseball', 'team', 'is', '<unk>', 'a', '<unk>', '<unk>', 'but', '<unk>', '<unk>', 'little', 'little', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'green', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<unk>', '<unk>', '<unk>', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 88: 100%|██████████| 454/454 [01:38<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 89 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'as', 'I', 'watch', 'watch', 'watch', 'I', 'I', 'be', '<unk>', 'a', '<unk>', 'to', '<unk>', 'a', '<unk>', '<unk>', 'pick', 'up', 'to', '<unk>', '<unk>', '<unk>', '<unk>', 'by', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<unk>', '<unk>', '.', 'up', '.', '<unk>', '<unk>', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 89: 100%|██████████| 454/454 [01:37<00:00,  4.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 90 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'is', 'one', '<unk>', 'I', 'I', '<unk>', 'be', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'some', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'that', 'that', '<unk>', '<unk>', '<unk>', 'one', 'that', \"'s\", 'one', 'that']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 90: 100%|██████████| 454/454 [01:37<00:00,  4.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 91 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'coming', 'let', '<unk>', 'I', 'I', '<unk>', 'be', '<unk>', 'to', 'pick', 'up', 'a', '<unk>', '<unk>', '<unk>', 'up', 'for', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<unk>', 'one', '<unk>', '<unk>', '.', '<unk>', '<unk>', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 91: 100%|██████████| 454/454 [01:38<00:00,  4.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 92 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', '<unk>', 'is', '<unk>', 'I', 'I', 'watch', 'a', 'a', 'I', 'hold', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'one', 'up', 'by', 'some', '<unk>', '<unk>', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 92: 100%|██████████| 454/454 [01:38<00:00,  4.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 93 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', \"'s\", 'let', '<unk>', 'the', 'watch', 'I', 'hold', 'the', '<unk>', ',', 'red', 'track', 'floor', 'but', '<unk>', '<unk>', '<unk>', 'some', 'some', 'flower', '<unk>', 'up', 'for', '<unk>', \"'s\", 'one', '<unk>', 'one', 'up', 'the', '<unk>', 'one', 'of', 'the', '<unk>', 'one', 'up', 'the', '<unk>', 'one', 'up', 'the', '<unk>', 'up', '.', '.', '.', 'up', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 93: 100%|██████████| 454/454 [01:37<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 94 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'the', 'let', '<unk>', 'I', \"'\", '<unk>', '<unk>', 'the', '<unk>', '<unk>', 'is', '<unk>', 'a', 'little', 'little', 'player', 'with', 'the', 'little', '<unk>', 'of', 'the', '<unk>', 'is', 'green', '<unk>', 'green', 'green', 'team', 'green', 'green', 'team', 'green', 'green', 'team', 'green', 'green', 'team', 'green', 'green', 'team', 'green', 'green', 'team', 'green', '<unk>', 'green', 'team', 'green']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 94: 100%|██████████| 454/454 [01:38<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 95 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'the', 'one', '<unk>', 'I', 'I', 'be', '\"', '<unk>', 'is', '\"', '<unk>', '<unk>', '<unk>', '<unk>', 'some', 'some', '<unk>', '<unk>', 'that', 'some', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'funky', 'funky', '<unk>', 'funky', 'funky', '<unk>', 'funky', 'funky', '<unk>', 'funky', 'funky', '<unk>']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 95: 100%|██████████| 454/454 [01:38<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 96 / 100]\n=> Saving checkpoint\nTranslated example sentence: \n ['<unk>', 'is', 'let', '<unk>', 'I', 'should', 'be', '<unk>', 'a', '<unk>', 'and', '<unk>', 'to', '<unk>', 'a', '<unk>', 'that', 'is', '<unk>', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>', '<unk>', 'that', 'that', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>', '.', '<unk>', '.']\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 96:  48%|████▊     | 216/454 [00:46<00:48,  4.88it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"if load_model:\n    load_checkpoint(torch.load(\"/kaggle/working/my_checkpoint.pth.tar\"), model, optimizer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"src, trg = test_dataset[0]\nprint(f\"Src indices: {src}, Tokens: {[german_vocab_train.lookup_token(idx.item()) for idx in src]}\")\nprint(f\"Trg indices: {trg}, Tokens: {[english_vocab_train.lookup_token(idx.item()) for idx in trg]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\"\ntranslated = translate_sentence(model, sentence, german_vocab_train, english_vocab_train, device)\nprint(f\"Translated: {translated}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"score = bleu_score(test_dataset, model, german_vocab_train, english_vocab_train, device)\nprint(f\"Bleu score {score * 100:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def zip_folder_with_shutil(source_folder, output_path):\n    '''Function for zip TensorBoard data'''\n    shutil.make_archive(output_path, 'zip', source_folder)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/runs', '/kaggle/working/runs')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Preferences</font>**\n-------------------\n\n- [YOUTUBE - Pytorch Seq2Seq Tutorial for Machine Translation](https://www.youtube.com/watch?v=EoGUlvhRYpk&list=PLhhyoLH6Ijfyl_VMCsi54UqGQafGkNOQH)\n- [GitHub - Machine-Learning-Collection](https://github.com/aladdinpersson/Machine-Learning-Collection)","metadata":{}}]}