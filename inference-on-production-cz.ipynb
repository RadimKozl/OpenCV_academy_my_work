{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Inference on Production","title_sidebar":"Contents","toc_cell":true,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Inference o produkci<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Lightning-Module\" data-toc-modified-id=\"Lightning-Module-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Modul Lightning</a></span></li><li><span><a href=\"#Get-the-Checkpoint\" data-toc-modified-id=\"Get-the-Checkpoint-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Get the Checkpoint</a></span></li><li><span><a href=\"#Convert-to-ONNX-Format\" data-toc-modified-id=\"Convert-to-ONNX-Format-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Převedeme do formátu ONNX</a></span></li><li><span><a href=\"#Sample-Inference\" data-toc-modified-id=\"Sample-Inference-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Ukázka závěru</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>References</a></span></li></ul></div>","metadata":{"toc":true}},{"cell_type":"markdown","source":"1. Předpokládejme, že váš tým pracuje na projektu, kde potřebujete pracovat na některých problémech ML.\n2. Co když si vyberete jeden problém a vyřešíte ho pomocí rámce PyTorch, zatímco váš kolega udělá to samé pomocí Tensorflow.\n3. Oba problémy, o kterých víme, jsou součástí většího projektu. Nyní, jak dospět ke společnému formátu pro sdílení modelů ML.\n\n\n<a target=\"_blank\" href=\"https://onnx.ai/\">ONNX: Open Neural Network Exchange</a> je jeden takový otevřený formát, který umožňuje výměnu modelů mezi různými <a target=\"_blank\" href=\"https://onnx.ai/supported-tools\">ML frameworky a nástroji</a>.\n\n\n**V tomto notebooku uvidíme, jak převést uložený kontrolní bod PyTorch Lightning na model ONNX. Vezměme si příklad kontrolního bodu uloženého notebookem tréninku na MNIST.**","metadata":{}},{"cell_type":"code","source":"import pytorch_lightning as pl\nfrom torchmetrics import Accuracy\nfrom torchmetrics import AverageMeter\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)  # filter UserWarning\n\ntorch.multiprocessing.set_start_method('spawn', force=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modul Lightning\n\nModul Lighting nám poskytuje definici modelu pro načtení modelu z kontrolních bodů.","metadata":{}},{"cell_type":"code","source":"class LeNet5(pl.LightningModule):  # here nn.Module is replaced by LightningModule\n    def __init__(self, learning_rate=0.01, num_classes=10):\n        super().__init__()\n\n        # Save the arguments as hyperparameters.\n        self.save_hyperparameters()\n        self.num_classes = num_classes\n\n        # convolution layers\n        self._body = nn.Sequential(\n            # First convolution Layer\n            # input size = (32, 32), output size = (28, 28)\n            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n            # ReLU activation\n            nn.ReLU(inplace=True),\n            # Max pool 2-d\n            nn.MaxPool2d(kernel_size=2),\n\n            # Second convolution layer\n            # input size = (14, 14), output size = (10, 10)\n            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),\n            # output size = (5, 5)\n        )\n\n        # Fully connected layers\n        self._head = nn.Sequential(\n            # First fully connected layer\n            # in_features = total number of weights in last conv layer = 16 * 5 * 5\n            nn.Linear(in_features=16 * 5 * 5, out_features=120),\n\n            # ReLU activation\n            nn.ReLU(inplace=True),\n\n            # second fully connected layer\n            # in_features = output of last linear layer = 120\n            nn.Linear(in_features=120, out_features=84),\n\n            # ReLU activation\n            nn.ReLU(inplace=True),\n\n            # Third fully connected layer. It is also the output layer\n            # in_features = output of last linear layer = 84\n            # and out_features = number of classes = 10 (MNIST data 0-9)\n            nn.Linear(in_features=84, out_features=self.num_classes))\n\n        acc_obj = Accuracy(num_classes=self.num_classes)\n        # use .clone() so that each metric can maintain its own state\n        self.train_acc = acc_obj.clone()\n        self.valid_acc = acc_obj.clone()\n\n        # Using average meter to accumulate losses and get mean of the metrics\n        average_meter = AverageMeter()\n        self.train_loss = average_meter.clone()\n        self.valid_loss = average_meter.clone()\n\n    def forward(self, x):\n        # apply feature extractor\n        x = self._body(x)\n        # flatten the output of conv layers\n        # dimension should be batch_size * number_of weights_in_last conv_layer\n        x = x.view(x.size()[0], -1)\n        # apply classification head\n        x = self._head(x)\n        return x\n\n    def on_train_epoch_start(self):\n        super().on_train_epoch_start()\n\n        # Reset state variables for train metrics to \n        # their default values before start of each epoch\n    \n        self.train_acc.reset()\n        self.train_loss.reset()\n\n    def on_validation_epoch_start(self):\n        super().on_validation_epoch_start()\n        \n        # Reset state variables for validation metrics to \n        # their default values before start of each epoch\n        \n        self.valid_acc.reset()\n        self.valid_loss.reset()\n        \n    def training_step(self, batch, batch_idx):\n\n        # get data and labels from batch\n        data, target = batch\n\n        # get prediction\n        output = self(data)\n\n        # calculate batch loss\n        loss = F.cross_entropy(output, target)\n\n        # get probability score using softmax\n        prob = F.softmax(output, dim=1)\n\n        # get the index of the max probability\n        pred = prob.data.max(dim=1)[1]\n\n        # Using Module API\n        # calculate and accumulate batch accuracy\n        acc = self.train_acc(pred, target)\n\n        # accumulate batch loss\n        self.train_loss(loss)\n        # # -----------------\n\n        # LOG METRICS to a logger. Default: Tensorboard\n        self.log(\"train/batch_loss\", loss, prog_bar=False)\n\n        # logging and adding current batch_acc to progress_bar\n        self.log(\"train/batch_acc\", acc, prog_bar=True)\n\n        # Using Module API, we only need to return the loss\n        return loss\n       \n    def training_epoch_end(self, training_step_outputs):\n        # Using Module API\n        # Compute epoch loss and accuracy\n        avg_train_loss = self.train_loss.compute()\n        avg_train_acc = self.train_acc.compute()\n        # # -----------------\n\n        self.log(\"train/loss\", avg_train_loss, prog_bar=True)\n        self.log(\"train/acc\", avg_train_acc, prog_bar=True)\n        # Set X-axis as epoch number for epoch-level metrics\n        self.log(\"step\", self.current_epoch)\n\n    def validation_step(self, batch, batch_idx):\n\n        # get data and labels from batch\n        data, target = batch\n\n        # get prediction\n        output = self(data)\n\n        # calculate loss\n        loss = F.cross_entropy(output, target)\n\n        # get probability score using softmax\n        prob = F.softmax(output, dim=1)\n\n        # get the index of the max probability\n        pred = torch.argmax(prob, dim=1)\n        \n        # Using Module API\n        # accumulate validation accuracy and loss\n        self.valid_acc(pred, target)\n        self.valid_loss(loss)\n        \n        \n    def validation_epoch_end(self, validation_step_outputs):\n        # Using Module API\n        avg_val_loss = self.valid_loss.compute()\n        avg_val_acc = self.valid_acc.compute()\n        \n        self.log(\"valid/acc\", avg_val_acc, prog_bar=True)\n        self.log(\"valid/loss\", avg_val_loss, prog_bar=True)\n        # use epoch as X-axis\n        self.log(\"step\", self.current_epoch)\n\n    def configure_optimizers(self):\n        return torch.optim.SGD(self.parameters(),\n                               lr=self.hparams.learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:48:10.046478Z","iopub.status.idle":"2024-10-04T13:48:10.046983Z","shell.execute_reply.started":"2024-10-04T13:48:10.046729Z","shell.execute_reply":"2024-10-04T13:48:10.046753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Získejte kontrolní bod\n\nNačteme jeden z kontrolních bodů uložených při posledním tréninku.\n\nNapsali jsme pro něj pomocnou funkci. Vezme adresář protokolu tréninku PyTorch Lighting a spustí číslo verze, aby vrátil odpovídající cestu `.ckpt`.\n\nTuto funkci budete znát z poslední lekce.","metadata":{}},{"cell_type":"code","source":"import os\n\ndef get_latest_run_version_ckpt_epoch_no(lightning_logs_dir='lightning_logs', run_version=None):\n    if run_version is None:\n        run_version = 0\n        for dir_name in os.listdir(lightning_logs_dir):\n            if 'version' in dir_name:\n                if int(dir_name.split('_')[1]) > run_version:\n                    run_version = int(dir_name.split('_')[1])\n                \n    checkpoints_dir = os.path.join(lightning_logs_dir, 'version_{}'.format(run_version), 'checkpoints')\n    \n    files = os.listdir(checkpoints_dir)\n    ckpt_filename = None\n    for file in files:\n        if file.endswith('.ckpt'):\n            ckpt_filename = file\n        \n    if ckpt_filename is not None:\n        ckpt_path = os.path.join(checkpoints_dir, ckpt_filename)\n    else:\n        print('CKPT file is not present')\n    \n    return ckpt_path","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:48:10.048669Z","iopub.status.idle":"2024-10-04T13:48:10.049189Z","shell.execute_reply.started":"2024-10-04T13:48:10.048941Z","shell.execute_reply":"2024-10-04T13:48:10.048981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Získejte cestu modelu `.ckpt`.**","metadata":{}},{"cell_type":"code","source":"# get checkpoint path\nckpt_path = get_latest_run_version_ckpt_epoch_no(run_version=0)\nprint('ckpt_path: {}'.format(ckpt_path))","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:48:10.051578Z","iopub.status.idle":"2024-10-04T13:48:10.052094Z","shell.execute_reply.started":"2024-10-04T13:48:10.051826Z","shell.execute_reply":"2024-10-04T13:48:10.051848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Převést do formátu ONNX\n\nNapsali jsme funkci pro převod modelu `.ckpt` na model `.onnx`. \n\nFunkce bere jako argumenty definici modelu, cestu `.ckpt` a cestu k souboru `.onnx`. A převeďte soubor `.ckpt` na `.onnx` a vraťte cestu `.onnx`. \n\nZjistili jsme, že `input_sample` se používá s metodou konverze `.ckpt` na `.onnx` `to_onnx`. Tento vzorový vstup fixuje vstupní velikost a zavazuje nás, abychom ji použili v době odvození.\n\nZískejte podrobnosti <a target=\"_blank\" href=\"https://pytorch-lightning.readthedocs.io/en/stable/common/production_inference.html\">here</a>.","metadata":{}},{"cell_type":"code","source":"import onnxruntime\n\ndef convert_to_onnx_model(model, ckpt_path, onnx_path=None):\n    \n    # ONNX filename\n    if onnx_path is None:\n        onnx_path = ckpt_path[:-4] + 'onnx'\n        \n    # Load the checkpoint\n    ckpt_model = model.load_from_checkpoint(ckpt_path)\n    \n    # Freeze the network\n    ckpt_model.freeze()\n    \n    ckpt_model.eval()\n    \n    # Add a sample input. Here input shape = (batch_size, num_channel, height, width)\n    input_sample = torch.randn((1, 1, 32, 32))\n    \n    # convert to ONNX model\n    ckpt_model.to_onnx(onnx_path, input_sample, export_params=True)\n    \n    return onnx_path","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:48:10.053804Z","iopub.status.idle":"2024-10-04T13:48:10.054308Z","shell.execute_reply.started":"2024-10-04T13:48:10.054080Z","shell.execute_reply":"2024-10-04T13:48:10.054104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Převeďte `.ckpt` na `.onnx`.**","metadata":{}},{"cell_type":"code","source":"# initiate the model\nmodel = LeNet5()\n\n# convert the checkpoint to onnx format\nonnx_model_path = convert_to_onnx_model(model, ckpt_path)\nprint('onnx_model_path: {}'.format(onnx_model_path))","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:48:10.056512Z","iopub.status.idle":"2024-10-04T13:48:10.057010Z","shell.execute_reply.started":"2024-10-04T13:48:10.056753Z","shell.execute_reply":"2024-10-04T13:48:10.056776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ukázka závěru\n\n**Kroky pro odvození s modelem `.onnx`:**\n\n- Zahajte relaci. Jedná se o jednorázovou operaci.\n\n- Získejte název vstupu z relace. Opět jednorázová operace.\n\n- Připravte vstup.\n\n- Spusťte relaci se vstupem.","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# init a session\nsess = onnxruntime.InferenceSession(onnx_model_path)\n\n# get input name from session\ninput_name = sess.get_inputs()[0].name\n\n# prepare inputs\ninputs = {input_name: np.random.randn(1, 1, 32, 32).astype(np.float32)}\n\n# get output\noutputs = sess.run(None, inputs)\n\nprint(outputs)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:48:10.059593Z","iopub.status.idle":"2024-10-04T13:48:10.060090Z","shell.execute_reply.started":"2024-10-04T13:48:10.059834Z","shell.execute_reply":"2024-10-04T13:48:10.059856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reference\n\n\n1. <a target=\"_blank\" href=\"https://pytorch-lightning.readthedocs.io/en/stable/common/production_inference.html\">https://pytorch-lightning.readthedocs.io/en/stable/common/production_inference.html</a>\n2. <a target=\"_blank\" href=\"https://docs.microsoft.com/en-us/windows/ai/windows-ml/get-onnx-model\">https://docs.microsoft.com/en-us/windows/ai/windows-ml/get-onnx-model</a>\n3. <a target=\"_blank\" href=\"https://onnx.ai/\">https://onnx.ai/</a>\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}