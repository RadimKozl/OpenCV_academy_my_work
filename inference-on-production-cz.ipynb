{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Inference on Production","title_sidebar":"Contents","toc_cell":true,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Inference o produkci<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Lightning-Module\" data-toc-modified-id=\"Lightning-Module-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Modul Lightning</a></span></li><li><span><a href=\"#Get-the-Checkpoint\" data-toc-modified-id=\"Get-the-Checkpoint-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Get the Checkpoint</a></span></li><li><span><a href=\"#Convert-to-ONNX-Format\" data-toc-modified-id=\"Convert-to-ONNX-Format-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Převedeme do formátu ONNX</a></span></li><li><span><a href=\"#Sample-Inference\" data-toc-modified-id=\"Sample-Inference-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Ukázka závěru</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>References</a></span></li></ul></div>","metadata":{"toc":true}},{"cell_type":"markdown","source":"1. Předpokládejme, že váš tým pracuje na projektu, kde potřebujete pracovat na některých problémech ML.\n2. Co když si vyberete jeden problém a vyřešíte ho pomocí rámce PyTorch, zatímco váš kolega udělá to samé pomocí Tensorflow.\n3. Oba problémy, o kterých víme, jsou součástí většího projektu. Nyní, jak dospět ke společnému formátu pro sdílení modelů ML.\n\n\n<a target=\"_blank\" href=\"https://onnx.ai/\">ONNX: Open Neural Network Exchange</a> je jeden takový otevřený formát, který umožňuje výměnu modelů mezi různými <a target=\"_blank\" href=\"https://onnx.ai/supported-tools\">ML frameworky a nástroji</a>.\n\n\n**V tomto notebooku uvidíme, jak převést uložený kontrolní bod PyTorch Lightning na model ONNX. Vezměme si příklad kontrolního bodu uloženého notebookem tréninku na MNIST.**","metadata":{}},{"cell_type":"markdown","source":"## ***Instalace knihovny [PyThorch Lightning](https://lightning.ai/docs/pytorch/stable/)***","metadata":{}},{"cell_type":"code","source":"!pip install lightning\n!pip install onnx\n!pip install onnxruntime\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:40:26.994500Z","iopub.execute_input":"2024-10-04T18:40:26.994863Z","iopub.status.idle":"2024-10-04T18:41:08.625098Z","shell.execute_reply.started":"2024-10-04T18:40:26.994828Z","shell.execute_reply":"2024-10-04T18:41:08.624135Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting lightning\n  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.2)\nRequirement already satisfied: fsspec<2026.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.6.1)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.7)\nRequirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\nRequirement already satisfied: torch<4.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.4.0)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.4.2)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.4)\nRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.12.2)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.4.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.9.5)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (70.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.1.0->lightning) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.1.0->lightning) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.1.0->lightning) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.1.0->lightning) (3.1.4)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.26.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=2.1.0->lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.7)\nDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: lightning\nSuccessfully installed lightning-2.4.0\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (1.17.0)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from onnx) (1.26.4)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx) (3.20.3)\nCollecting onnxruntime\n  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\nCollecting coloredlogs (from onnxruntime)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (24.3.25)\nRequirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (21.3)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (1.13.3)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime) (3.1.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\nDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.19.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## ***Stáhnutí souborů s modelem***","metadata":{}},{"cell_type":"code","source":"!mkdir /kaggle/working/lightning_logs\n\n!wget \"https://raw.githubusercontent.com/RadimKozl/OpenCV_academy_my_work/refs/heads/main/lightning_logs.zip\" -O /kaggle/working/lightning_logs/lightning_logs.zip\n\n!ls /kaggle/working/\n\n!unzip /kaggle/working/lightning_logs/lightning_logs.zip -d /kaggle/working/lightning_logs/\n\n!rm /kaggle/working/lightning_logs/lightning_logs.zip","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:41:08.627471Z","iopub.execute_input":"2024-10-04T18:41:08.627960Z","iopub.status.idle":"2024-10-04T18:41:14.060164Z","shell.execute_reply.started":"2024-10-04T18:41:08.627907Z","shell.execute_reply":"2024-10-04T18:41:14.058890Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"--2024-10-04 18:41:10--  https://raw.githubusercontent.com/RadimKozl/OpenCV_academy_my_work/refs/heads/main/lightning_logs.zip\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 234749 (229K) [application/zip]\nSaving to: '/kaggle/working/lightning_logs/lightning_logs.zip'\n\n/kaggle/working/lig 100%[===================>] 229.25K  --.-KB/s    in 0.06s   \n\n2024-10-04 18:41:10 (4.06 MB/s) - '/kaggle/working/lightning_logs/lightning_logs.zip' saved [234749/234749]\n\nlightning_logs\nArchive:  /kaggle/working/lightning_logs/lightning_logs.zip\n   creating: /kaggle/working/lightning_logs/version_0/\n   creating: /kaggle/working/lightning_logs/version_0/checkpoints/\n  inflating: /kaggle/working/lightning_logs/version_0/events.out.tfevents.1728052476.5246e9c3bd7b.30.0  \n  inflating: /kaggle/working/lightning_logs/version_0/hparams.yaml  \n  inflating: /kaggle/working/lightning_logs/version_0/checkpoints/ckpt_009.ckpt  \n","output_type":"stream"}]},{"cell_type":"code","source":"import onnxruntime\nimport pytorch_lightning as pl\nfrom torchmetrics import Accuracy\nfrom torchmetrics import MeanMetric\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)  # filter UserWarning\n\ntorch.multiprocessing.set_start_method('spawn', force=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:41:14.061743Z","iopub.execute_input":"2024-10-04T18:41:14.062078Z","iopub.status.idle":"2024-10-04T18:41:23.814322Z","shell.execute_reply.started":"2024-10-04T18:41:14.062042Z","shell.execute_reply":"2024-10-04T18:41:23.813429Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Modul Lightning\n\nModul Lighting nám poskytuje definici modelu pro načtení modelu z kontrolních bodů.","metadata":{}},{"cell_type":"code","source":"class LeNet5(pl.LightningModule):  # here nn.Module is replaced by LightningModule\n    def __init__(self, learning_rate=0.01, num_classes=10):\n        super().__init__()\n\n        # Save the arguments as hyperparameters.\n        self.save_hyperparameters()\n        self.num_classes = num_classes\n\n        # convolution layers\n        self._body = nn.Sequential(\n            # First convolution Layer\n            # input size = (32, 32), output size = (28, 28)\n            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n            # ReLU activation\n            nn.ReLU(inplace=True),\n            # Max pool 2-d\n            nn.MaxPool2d(kernel_size=2),\n\n            # Second convolution layer\n            # input size = (14, 14), output size = (10, 10)\n            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),\n            # output size = (5, 5)\n        )\n\n        # Fully connected layers\n        self._head = nn.Sequential(\n            # First fully connected layer\n            # in_features = total number of weights in last conv layer = 16 * 5 * 5\n            nn.Linear(in_features=16 * 5 * 5, out_features=120),\n\n            # ReLU activation\n            nn.ReLU(inplace=True),\n\n            # second fully connected layer\n            # in_features = output of last linear layer = 120\n            nn.Linear(in_features=120, out_features=84),\n\n            # ReLU activation\n            nn.ReLU(inplace=True),\n\n            # Third fully connected layer. It is also the output layer\n            # in_features = output of last linear layer = 84\n            # and out_features = number of classes = 10 (MNIST data 0-9)\n            nn.Linear(in_features=84, out_features=self.num_classes))\n\n        acc_obj = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n        # use .clone() so that each metric can maintain its own state\n        self.train_acc = acc_obj.clone()\n        self.valid_acc = acc_obj.clone()\n\n        # Using average meter to accumulate losses and get mean of the metrics\n        average_meter = MeanMetric()\n        self.train_loss = average_meter.clone()\n        self.valid_loss = average_meter.clone()\n\n    def forward(self, x):\n        # apply feature extractor\n        x = self._body(x)\n        # flatten the output of conv layers\n        # dimension should be batch_size * number_of weights_in_last conv_layer\n        x = x.view(x.size()[0], -1)\n        # apply classification head\n        x = self._head(x)\n        return x\n\n    def on_train_epoch_start(self):\n        super().on_train_epoch_start()\n\n        # Reset state variables for train metrics to \n        # their default values before start of each epoch\n    \n        self.train_acc.reset()\n        self.train_loss.reset()\n\n    def on_validation_epoch_start(self):\n        super().on_validation_epoch_start()\n        \n        # Reset state variables for validation metrics to \n        # their default values before start of each epoch\n        \n        self.valid_acc.reset()\n        self.valid_loss.reset()\n        \n    def training_step(self, batch, batch_idx):\n\n        # get data and labels from batch\n        data, target = batch\n\n        # get prediction\n        output = self(data)\n\n        # calculate batch loss\n        loss = F.cross_entropy(output, target)\n\n        # get probability score using softmax\n        prob = F.softmax(output, dim=1)\n\n        # get the index of the max probability\n        pred = prob.data.max(dim=1)[1]\n\n        # Using Module API\n        # calculate and accumulate batch accuracy\n        acc = self.train_acc(pred, target)\n\n        # accumulate batch loss\n        self.train_loss(loss)\n        # # -----------------\n\n        # LOG METRICS to a logger. Default: Tensorboard\n        self.log(\"train/batch_loss\", loss, prog_bar=False)\n\n        # logging and adding current batch_acc to progress_bar\n        self.log(\"train/batch_acc\", acc, prog_bar=True)\n\n        # Using Module API, we only need to return the loss\n        return loss\n       \n    def training_epoch_end(self, training_step_outputs):\n        # Using Module API\n        # Compute epoch loss and accuracy\n        avg_train_loss = self.train_loss.compute()\n        avg_train_acc = self.train_acc.compute()\n        # # -----------------\n\n        self.log(\"train/loss\", avg_train_loss, prog_bar=True)\n        self.log(\"train/acc\", avg_train_acc, prog_bar=True)\n        # Set X-axis as epoch number for epoch-level metrics\n        self.log(\"step\", self.current_epoch)\n\n    def validation_step(self, batch, batch_idx):\n\n        # get data and labels from batch\n        data, target = batch\n\n        # get prediction\n        output = self(data)\n\n        # calculate loss\n        loss = F.cross_entropy(output, target)\n\n        # get probability score using softmax\n        prob = F.softmax(output, dim=1)\n\n        # get the index of the max probability\n        pred = torch.argmax(prob, dim=1)\n        \n        # Using Module API\n        # accumulate validation accuracy and loss\n        self.valid_acc(pred, target)\n        self.valid_loss(loss)\n        \n        \n    def validation_epoch_end(self, validation_step_outputs):\n        # Using Module API\n        avg_val_loss = self.valid_loss.compute()\n        avg_val_acc = self.valid_acc.compute()\n        \n        self.log(\"valid/acc\", avg_val_acc, prog_bar=True)\n        self.log(\"valid/loss\", avg_val_loss, prog_bar=True)\n        # use epoch as X-axis\n        self.log(\"step\", self.current_epoch)\n\n    def configure_optimizers(self):\n        return torch.optim.SGD(self.parameters(),\n                               lr=self.hparams.learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:41:23.816722Z","iopub.execute_input":"2024-10-04T18:41:23.817147Z","iopub.status.idle":"2024-10-04T18:41:23.839712Z","shell.execute_reply.started":"2024-10-04T18:41:23.817111Z","shell.execute_reply":"2024-10-04T18:41:23.838756Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Získejte kontrolní bod\n\nNačteme jeden z kontrolních bodů uložených při posledním tréninku.\n\nNapsali jsme pro něj pomocnou funkci. Vezme adresář protokolu tréninku PyTorch Lighting a spustí číslo verze, aby vrátil odpovídající cestu `.ckpt`.\n\nTuto funkci budete znát z poslední lekce.","metadata":{}},{"cell_type":"code","source":"import os\n\ndef get_latest_run_version_ckpt_epoch_no(lightning_logs_dir='/kaggle/working/lightning_logs', run_version=None):\n    if run_version is None:\n        run_version = 0\n        for dir_name in os.listdir(lightning_logs_dir):\n            if 'version' in dir_name:\n                if int(dir_name.split('_')[1]) > run_version:\n                    run_version = int(dir_name.split('_')[1])\n                \n    checkpoints_dir = os.path.join(lightning_logs_dir, 'version_{}'.format(run_version), 'checkpoints')\n    \n    files = os.listdir(checkpoints_dir)\n    ckpt_filename = None\n    for file in files:\n        if file.endswith('.ckpt'):\n            ckpt_filename = file\n        \n    if ckpt_filename is not None:\n        ckpt_path = os.path.join(checkpoints_dir, ckpt_filename)\n    else:\n        print('CKPT file is not present')\n    \n    return ckpt_path","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:41:23.840876Z","iopub.execute_input":"2024-10-04T18:41:23.841578Z","iopub.status.idle":"2024-10-04T18:41:23.856827Z","shell.execute_reply.started":"2024-10-04T18:41:23.841530Z","shell.execute_reply":"2024-10-04T18:41:23.855810Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**Získejte cestu modelu `.ckpt`.**","metadata":{}},{"cell_type":"code","source":"# get checkpoint path\nckpt_path = get_latest_run_version_ckpt_epoch_no(run_version=0)\nprint('ckpt_path: {}'.format(ckpt_path))","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:41:23.857830Z","iopub.execute_input":"2024-10-04T18:41:23.858116Z","iopub.status.idle":"2024-10-04T18:41:23.871199Z","shell.execute_reply.started":"2024-10-04T18:41:23.858083Z","shell.execute_reply":"2024-10-04T18:41:23.870349Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"ckpt_path: /kaggle/working/lightning_logs/version_0/checkpoints/ckpt_009.ckpt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Převést do formátu ONNX\n\nNapsali jsme funkci pro převod modelu `.ckpt` na model `.onnx`. \n\nFunkce bere jako argumenty definici modelu, cestu `.ckpt` a cestu k souboru `.onnx`. A převeďte soubor `.ckpt` na `.onnx` a vraťte cestu `.onnx`. \n\nZjistili jsme, že `input_sample` se používá s metodou konverze `.ckpt` na `.onnx` `to_onnx`. Tento vzorový vstup fixuje vstupní velikost a zavazuje nás, abychom ji použili v době odvození.\n\nZískejte podrobnosti <a target=\"_blank\" href=\"https://pytorch-lightning.readthedocs.io/en/stable/common/production_inference.html\">here</a>.","metadata":{}},{"cell_type":"code","source":"def convert_to_onnx_model(model_class, ckpt_path, onnx_path=None):\n    \n    # ONNX filename\n    if onnx_path is None:\n        onnx_path = ckpt_path[:-4] + 'onnx'\n        \n    # Load the checkpoint\n    ckpt_model = model_class.load_from_checkpoint(ckpt_path)\n    \n    # Freeze the network\n    ckpt_model.freeze()\n    \n    ckpt_model.eval()\n    \n    # Add a sample input. Here input shape = (batch_size, num_channel, height, width)\n    input_sample = torch.randn((1, 1, 32, 32))\n    \n    # convert to ONNX model\n    ckpt_model.to_onnx(onnx_path, input_sample, export_params=True)\n    \n    return onnx_path","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:41:23.872177Z","iopub.execute_input":"2024-10-04T18:41:23.872478Z","iopub.status.idle":"2024-10-04T18:41:23.881293Z","shell.execute_reply.started":"2024-10-04T18:41:23.872439Z","shell.execute_reply":"2024-10-04T18:41:23.880442Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"**Převeďte `.ckpt` na `.onnx`.**","metadata":{}},{"cell_type":"code","source":"# initiate the model\nmodel = LeNet5()\n\n# convert the checkpoint to onnx format\nonnx_model_path = convert_to_onnx_model(LeNet5, ckpt_path)\nprint('onnx_model_path: {}'.format(onnx_model_path))","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:41:23.882448Z","iopub.execute_input":"2024-10-04T18:41:23.883682Z","iopub.status.idle":"2024-10-04T18:41:25.335617Z","shell.execute_reply.started":"2024-10-04T18:41:23.883646Z","shell.execute_reply":"2024-10-04T18:41:25.334595Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"onnx_model_path: /kaggle/working/lightning_logs/version_0/checkpoints/ckpt_009.onnx\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Ukázka závěru\n\n**Kroky pro odvození s modelem `.onnx`:**\n\n- Zahajte relaci. Jedná se o jednorázovou operaci.\n\n- Získejte název vstupu z relace. Opět jednorázová operace.\n\n- Připravte vstup.\n\n- Spusťte relaci se vstupem.","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# init a session\nsess = onnxruntime.InferenceSession(onnx_model_path)\n\n# get input name from session\ninput_name = sess.get_inputs()[0].name\n\n# prepare inputs\ninputs = {input_name: np.random.randn(1, 1, 32, 32).astype(np.float32)}\n\n# get output\noutputs = sess.run(None, inputs)\n\nprint(outputs)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:41:25.336983Z","iopub.execute_input":"2024-10-04T18:41:25.337716Z","iopub.status.idle":"2024-10-04T18:41:25.352387Z","shell.execute_reply.started":"2024-10-04T18:41:25.337664Z","shell.execute_reply":"2024-10-04T18:41:25.351312Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[array([[-0.3288347 , -1.1747322 ,  0.5060428 , -0.27771673,  0.2461939 ,\n        -0.70036477, -0.47910607,  0.8947681 ,  0.10573294,  0.03755153]],\n      dtype=float32)]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Reference\n\n\n1. <a target=\"_blank\" href=\"https://pytorch-lightning.readthedocs.io/en/stable/common/production_inference.html\">https://pytorch-lightning.readthedocs.io/en/stable/common/production_inference.html</a>\n2. <a target=\"_blank\" href=\"https://docs.microsoft.com/en-us/windows/ai/windows-ml/get-onnx-model\">https://docs.microsoft.com/en-us/windows/ai/windows-ml/get-onnx-model</a>\n3. <a target=\"_blank\" href=\"https://onnx.ai/\">https://onnx.ai/</a>\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}