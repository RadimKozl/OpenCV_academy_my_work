{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **<font style=\"color:black\">Base example RNN net</font>**","metadata":{}},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Installation and Imports libraries</font>**","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torchvision\nimport torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\nimport torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\nimport torch.nn.functional as F # All functions that don't have any parameters\nfrom torch.utils.data import DataLoader # Gives easier dataset managment and creates mini batches\nimport torchvision.datasets as datasets # Has standard datasets we can import in a nice way\nimport torchvision.transforms as transforms # Transformations we can perfrom on our dataset\nfrom torch.utils.data import (\n    DataLoader,\n) # Gives easier dataset managment by creating mini batches etc.\n\nfrom tqdm import tqdm # For a nice progree bar","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T11:07:16.498120Z","iopub.execute_input":"2025-02-18T11:07:16.498375Z","iopub.status.idle":"2025-02-18T11:07:26.851869Z","shell.execute_reply.started":"2025-02-18T11:07:16.498353Z","shell.execute_reply":"2025-02-18T11:07:26.851242Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Settings for train</font>**","metadata":{}},{"cell_type":"code","source":"# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T11:07:26.852699Z","iopub.execute_input":"2025-02-18T11:07:26.853160Z","iopub.status.idle":"2025-02-18T11:07:26.937919Z","shell.execute_reply.started":"2025-02-18T11:07:26.853128Z","shell.execute_reply":"2025-02-18T11:07:26.937093Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Hyperparameters\ninput_size = 28\nsequence_length = 28\nnum_layers = 2\nhidden_size = 256\nnum_classes = 10\nlearning_rate = 0.001\nbatch_size = 64\nnum_epochs = 60","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T11:08:15.740301Z","iopub.execute_input":"2025-02-18T11:08:15.740618Z","iopub.status.idle":"2025-02-18T11:08:15.744909Z","shell.execute_reply.started":"2025-02-18T11:08:15.740581Z","shell.execute_reply":"2025-02-18T11:08:15.744277Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Create RNN model</font>**","metadata":{}},{"cell_type":"code","source":"# Create RNN Network\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n        super(RNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n\n    def forward(self, x):\n        # Set initial hidden and cell states\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n\n        # Forward propagate RNN\n        out, _ = self.rnn(x, h0)\n        out = out.reshape(out.shape[0], -1)\n\n        # Decode the hidden state of the last time step\n        out = self.fc(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T11:08:15.745966Z","iopub.execute_input":"2025-02-18T11:08:15.746209Z","iopub.status.idle":"2025-02-18T11:08:15.766394Z","shell.execute_reply.started":"2025-02-18T11:08:15.746190Z","shell.execute_reply":"2025-02-18T11:08:15.765779Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Load Data</font>**","metadata":{}},{"cell_type":"code","source":"!mkdir /kaggle/working/dataset/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T11:08:15.767827Z","iopub.execute_input":"2025-02-18T11:08:15.768116Z","iopub.status.idle":"2025-02-18T11:08:15.918917Z","shell.execute_reply.started":"2025-02-18T11:08:15.768096Z","shell.execute_reply":"2025-02-18T11:08:15.918102Z"}},"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘/kaggle/working/dataset/’: File exists\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"train_dataset = datasets.MNIST(root=os.path.join('/kaggle','working','dataset'), train=True, transform=transforms.ToTensor(), download=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T11:08:15.920270Z","iopub.execute_input":"2025-02-18T11:08:15.920508Z","iopub.status.idle":"2025-02-18T11:08:16.003497Z","shell.execute_reply.started":"2025-02-18T11:08:15.920487Z","shell.execute_reply":"2025-02-18T11:08:16.002780Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"test_dataset = datasets.MNIST(root=os.path.join('/kaggle','working','dataset'), train=False, transform=transforms.ToTensor(), download=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T11:08:16.004230Z","iopub.execute_input":"2025-02-18T11:08:16.004442Z","iopub.status.idle":"2025-02-18T11:08:16.019372Z","shell.execute_reply.started":"2025-02-18T11:08:16.004422Z","shell.execute_reply":"2025-02-18T11:08:16.018831Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T11:08:16.020165Z","iopub.execute_input":"2025-02-18T11:08:16.020360Z","iopub.status.idle":"2025-02-18T11:08:16.028442Z","shell.execute_reply.started":"2025-02-18T11:08:16.020343Z","shell.execute_reply":"2025-02-18T11:08:16.027666Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Initialize RNN network</font>**","metadata":{}},{"cell_type":"code","source":"model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T11:08:16.029196Z","iopub.execute_input":"2025-02-18T11:08:16.029379Z","iopub.status.idle":"2025-02-18T11:08:16.052592Z","shell.execute_reply.started":"2025-02-18T11:08:16.029363Z","shell.execute_reply":"2025-02-18T11:08:16.052011Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Loss and Optimizer</font>**","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T11:08:16.053241Z","iopub.execute_input":"2025-02-18T11:08:16.053491Z","iopub.status.idle":"2025-02-18T11:08:16.068905Z","shell.execute_reply.started":"2025-02-18T11:08:16.053462Z","shell.execute_reply":"2025-02-18T11:08:16.068138Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Train Network</font>**","metadata":{}},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n        # Get data to cuda if possible\n        data = data.to(device=device).squeeze(1)\n        targets = targets.to(device=device)\n\n        # forward\n        scores = model(data)\n        loss = criterion(scores, targets)\n\n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n\n        # gradient descent update step/adam step\n        optimizer.step()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T11:08:16.070848Z","iopub.execute_input":"2025-02-18T11:08:16.071095Z","iopub.status.idle":"2025-02-18T11:15:38.843188Z","shell.execute_reply.started":"2025-02-18T11:08:16.071075Z","shell.execute_reply":"2025-02-18T11:15:38.842337Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 938/938 [00:07<00:00, 126.90it/s]\n100%|██████████| 938/938 [00:07<00:00, 125.40it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.88it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.02it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.43it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.51it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.67it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.38it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.57it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.91it/s]\n100%|██████████| 938/938 [00:07<00:00, 124.03it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.36it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.07it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.73it/s]\n100%|██████████| 938/938 [00:07<00:00, 124.56it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.85it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.06it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.73it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.02it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.64it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.35it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.37it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.11it/s]\n100%|██████████| 938/938 [00:07<00:00, 125.94it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.13it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.25it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.82it/s]\n100%|██████████| 938/938 [00:07<00:00, 125.58it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.82it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.96it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.04it/s]\n100%|██████████| 938/938 [00:07<00:00, 123.93it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.81it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.89it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.99it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.00it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.45it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.45it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.97it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.11it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.69it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.24it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.01it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.89it/s]\n100%|██████████| 938/938 [00:07<00:00, 125.28it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.86it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.21it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.28it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.39it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.14it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.90it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.57it/s]\n100%|██████████| 938/938 [00:07<00:00, 126.39it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.46it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.42it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.52it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.62it/s]\n100%|██████████| 938/938 [00:07<00:00, 125.90it/s]\n100%|██████████| 938/938 [00:07<00:00, 127.42it/s]\n100%|██████████| 938/938 [00:07<00:00, 128.21it/s]\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Check accuracy on training & test to see how good our model</font>**","metadata":{}},{"cell_type":"code","source":"def check_accuracy(loader, model):\n    num_correct = 0\n    num_samples = 0\n\n    # Set model to eval\n    model.eval()\n\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device=device).squeeze(1)\n            y = y.to(device=device)\n\n            scores = model(x)\n            _, predictions = scores.max(1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n\n    model.train()\n    return num_correct / num_samples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T11:15:38.844267Z","iopub.execute_input":"2025-02-18T11:15:38.844497Z","iopub.status.idle":"2025-02-18T11:15:38.849101Z","shell.execute_reply.started":"2025-02-18T11:15:38.844476Z","shell.execute_reply":"2025-02-18T11:15:38.848389Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\nprint(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T11:15:38.850061Z","iopub.execute_input":"2025-02-18T11:15:38.850342Z","iopub.status.idle":"2025-02-18T11:15:45.779674Z","shell.execute_reply.started":"2025-02-18T11:15:38.850303Z","shell.execute_reply":"2025-02-18T11:15:45.779025Z"}},"outputs":[{"name":"stdout","text":"Accuracy on training set: 97.08\nAccuracy on test set: 96.58\n","output_type":"stream"}],"execution_count":24}]}