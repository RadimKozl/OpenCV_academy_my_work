{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10911708,"sourceType":"datasetVersion","datasetId":6783030}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---------------\n\n# **<font style=\"color:Black\">Create OCR by PyTorch</font>**\n-------------------\n-----------------","metadata":{}},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Installation and import libraries</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"!pip install  pillow \n!pip install opencv-python","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:45:07.089868Z","iopub.execute_input":"2025-03-06T14:45:07.090180Z","iopub.status.idle":"2025-03-06T14:45:15.073526Z","shell.execute_reply.started":"2025-03-06T14:45:07.090149Z","shell.execute_reply":"2025-03-06T14:45:15.072457Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport random\nfrom PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter\nimport numpy as np\nimport cv2\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:45:15.074487Z","iopub.execute_input":"2025-03-06T14:45:15.074824Z","iopub.status.idle":"2025-03-06T14:45:20.939552Z","shell.execute_reply.started":"2025-03-06T14:45:15.074797Z","shell.execute_reply":"2025-03-06T14:45:20.938702Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Hyperparameters</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"OUTPUT_DIR = os.path.join('/kaggle','working','synthetic_data','images')\nMODEL_DIR = os.path.join('/kaggle','working','model_dir')\nLABELS_FILE = os.path.join('/kaggle','working','synthetic_data','labels.txt')\nNUM_SAMPLES = 1280  # Number of images generated\nIMG_WIDTH = 128\nIMG_HEIGHT = 32\nBATCH_SIZE = 32\nEPOCHS = 100\nLEARNING_RATE = 0.001\nCHARSET = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-*\"  # Group characters\nMAX_TEXT_LENGTH = 10  # Maximum length of text in an image\nFONT_DIR = os.path.join('/kaggle','input','google-fonts','GoogleFontScripts') # Folder with TrueType fonts (.ttf)\nBACKGROUND_DIR = os.path.join('/kaggle','working','backgrounds')  # New folder for background (optional)\nNUMBER_BACKGROUND_IMAGE = 20","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:45:20.940487Z","iopub.execute_input":"2025-03-06T14:45:20.940917Z","iopub.status.idle":"2025-03-06T14:45:20.945838Z","shell.execute_reply.started":"2025-03-06T14:45:20.940887Z","shell.execute_reply":"2025-03-06T14:45:20.945124Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Utils support functions</font>**\n-------------------","metadata":{}},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Create output folders</font>**","metadata":{}},{"cell_type":"code","source":"os.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(BACKGROUND_DIR, exist_ok=True)\n\n# Creates a new file\nwith open(LABELS_FILE, 'w') as fp:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:45:20.947830Z","iopub.execute_input":"2025-03-06T14:45:20.948113Z","iopub.status.idle":"2025-03-06T14:45:20.962153Z","shell.execute_reply.started":"2025-03-06T14:45:20.948088Z","shell.execute_reply":"2025-03-06T14:45:20.961335Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load the font list (add the paths to the .ttf files to the \"fonts\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"font_files = [\n    os.path.join(FONT_DIR, f) for f in os.listdir(FONT_DIR) \n    if f.endswith('.ttf') and os.path.isfile(os.path.join(FONT_DIR, f))\n]\nif not font_files:\n    raise FileNotFoundError(\"No fonts found in 'fonts' folder. Add .ttf files!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:45:20.963596Z","iopub.execute_input":"2025-03-06T14:45:20.963852Z","iopub.status.idle":"2025-03-06T14:45:21.405703Z","shell.execute_reply.started":"2025-03-06T14:45:20.963832Z","shell.execute_reply":"2025-03-06T14:45:21.405112Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generating a simple gradient background</font>**","metadata":{}},{"cell_type":"code","source":"def generate_gradient_background(filename, size=(128, 32)):\n    img = Image.new('L', size, color=230)  # Lighter gray as a base\n    draw = ImageDraw.Draw(img)\n    for y in range(size[1]):\n        # Soft gradient with low contrast\n        color = int(230 - 20 * (y / size[1]))  # From light gray to slightly darker\n        draw.line([(0, y), (size[0], y)], fill=color)\n    # Background blur\n    img = img.filter(ImageFilter.GaussianBlur(radius=2))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:45:21.406491Z","iopub.execute_input":"2025-03-06T14:45:21.406684Z","iopub.status.idle":"2025-03-06T14:45:21.411469Z","shell.execute_reply.started":"2025-03-06T14:45:21.406667Z","shell.execute_reply":"2025-03-06T14:45:21.410761Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generate a background with noise (paper texture)</font>**","metadata":{}},{"cell_type":"code","source":"def generate_paper_texture(filename, size=(128, 32)):\n    img = Image.new('L', size, color=220)  # Lighter gray\n    noise = np.random.normal(0, 5, size).astype(np.uint8)  # Less noise\n    noise_img = Image.fromarray(noise)\n    img.paste(noise_img, (0, 0), noise_img)\n    # Blur for a softer effect\n    img = img.filter(ImageFilter.GaussianBlur(radius=1.5))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:45:21.412273Z","iopub.execute_input":"2025-03-06T14:45:21.412554Z","iopub.status.idle":"2025-03-06T14:45:21.427084Z","shell.execute_reply.started":"2025-03-06T14:45:21.412527Z","shell.execute_reply":"2025-03-06T14:45:21.426232Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Creating multiple backgrounds</font>**","metadata":{}},{"cell_type":"code","source":"for i in range(NUMBER_BACKGROUND_IMAGE):\n    generate_gradient_background(f\"gradient_{i}.png\")\n    generate_paper_texture(f\"paper_{i}.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:45:21.427907Z","iopub.execute_input":"2025-03-06T14:45:21.428151Z","iopub.status.idle":"2025-03-06T14:45:21.485005Z","shell.execute_reply.started":"2025-03-06T14:45:21.428132Z","shell.execute_reply":"2025-03-06T14:45:21.484478Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load backgrounds (optional, add images to the \"backgrounds\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"background_files = (\n    [os.path.join(BACKGROUND_DIR, f) for f in os.listdir(BACKGROUND_DIR) \n     if f.endswith(('.png', '.jpg', '.jpeg'))] if os.path.exists(BACKGROUND_DIR) else []\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:45:21.485681Z","iopub.execute_input":"2025-03-06T14:45:21.485884Z","iopub.status.idle":"2025-03-06T14:45:21.489714Z","shell.execute_reply.started":"2025-03-06T14:45:21.485866Z","shell.execute_reply":"2025-03-06T14:45:21.488928Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Random text generation function</font>**","metadata":{}},{"cell_type":"code","source":"def generate_random_text(max_length):\n    length = random.randint(1, max_length)\n    return ''.join(random.choice(CHARSET) for _ in range(length))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:45:21.490504Z","iopub.execute_input":"2025-03-06T14:45:21.490753Z","iopub.status.idle":"2025-03-06T14:45:21.500135Z","shell.execute_reply.started":"2025-03-06T14:45:21.490728Z","shell.execute_reply":"2025-03-06T14:45:21.499482Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Functions for adding noise and distortions</font>**","metadata":{}},{"cell_type":"code","source":"def add_noise_and_distortion(img):\n    img_array = np.array(img)\n    # Mild Gaussian noise with lower intensity\n    if random.random() > 0.5:  # 50% šance\n        noise = np.random.normal(0, random.randint(5, 15), img_array.shape).astype(np.uint8)\n        img_array = cv2.add(img_array, noise)\n    # Subtle perspective distortion\n    rows, cols = img_array.shape\n    src_points = np.float32([[0, 0], [cols-1, 0], [0, rows-1], [cols-1, rows-1]])\n    dst_points = np.float32([\n        [random.uniform(0, 3), random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), random.uniform(0, 3)],\n        [random.uniform(0, 3), rows-1-random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), rows-1-random.uniform(0, 3)]\n    ])\n    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n    img_array = cv2.warpPerspective(img_array, matrix, (cols, rows))\n    return Image.fromarray(img_array)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:45:21.500960Z","iopub.execute_input":"2025-03-06T14:45:21.501179Z","iopub.status.idle":"2025-03-06T14:45:21.511936Z","shell.execute_reply.started":"2025-03-06T14:45:21.501152Z","shell.execute_reply":"2025-03-06T14:45:21.511324Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Improved image generation feature</font>**","metadata":{}},{"cell_type":"code","source":"def generate_synthetic_image(text, font_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n    # Background: We only use generated backgrounds\n    if background_files:\n        bg_path = random.choice(background_files)\n        img = Image.open(bg_path).convert('L').resize(img_size)\n    else:\n        img = Image.new('L', img_size, color=230)  # Světlejší šedá jako fallback\n        draw = ImageDraw.Draw(img)\n        for y in range(img_size[1]):\n            color = int(230 - 20 * (y / img_size[1]))  # Jemný gradient\n            draw.line([(0, y), (img_size[0], y)], fill=color)\n        img = img.filter(ImageFilter.GaussianBlur(radius=2))\n\n    draw = ImageDraw.Draw(img)\n\n    # Larger font size for readability\n    font_size = random.randint(20, min(IMG_HEIGHT-2, 28))\n    font = ImageFont.truetype(font_path, font_size)\n\n    # Text position\n    text_bbox = draw.textbbox((0, 0), text, font=font)\n    text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n    if text_width > IMG_WIDTH - 10:\n        return generate_synthetic_image(text[:MAX_TEXT_LENGTH//2], font_path, img_size)\n    x = random.randint(5, max(5, IMG_WIDTH - text_width - 5))\n    y = random.randint(5, max(5, IMG_HEIGHT - text_height - 5))\n\n    # Text Highlighting: Darker Color and Soft Outline\n    text_color = random.randint(0, 50)  # Darker shades for contrast\n    outline_color = 200  # Light gray outline\n    for offset_x in [-1, 0, 1]:\n        for offset_y in [-1, 0, 1]:\n            if offset_x != 0 or offset_y != 0:\n                draw.text((x + offset_x, y + offset_y), text, font=font, fill=outline_color)\n    draw.text((x, y), text, font=font, fill=text_color)\n\n    # Subtle noise and distortion (applied at lower intensity)\n    img = add_noise_and_distortion(img)\n\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:46:00.091236Z","iopub.execute_input":"2025-03-06T14:46:00.091630Z","iopub.status.idle":"2025-03-06T14:46:00.100089Z","shell.execute_reply.started":"2025-03-06T14:46:00.091597Z","shell.execute_reply":"2025-03-06T14:46:00.099123Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generování datasetu</font>**","metadata":{}},{"cell_type":"code","source":"def create_synthetic_dataset(num_samples):\n    labels = []\n    for i in range(num_samples):\n        text = generate_random_text(MAX_TEXT_LENGTH)\n        if not text:\n            continue\n        font_path = random.choice(font_files)\n        img = generate_synthetic_image(text, font_path)\n        img_name = f\"img_{i:05d}.png\"\n        img_path = os.path.join(OUTPUT_DIR, img_name)\n        img.save(img_path)\n        labels.append(f\"{img_name} {text}\")\n        if i % 100 == 0:\n            print(f\"Generated {i}/{num_samples} images\")\n    \n    if labels:\n        with open(LABELS_FILE, 'w') as f:\n            f.write(\"\\n\".join(labels))\n        print(f\"Dataset generated! Images saved in '{OUTPUT_DIR}', labels in '{LABELS_FILE}'\")\n    else:\n        print(\"No labels generated!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:46:04.521075Z","iopub.execute_input":"2025-03-06T14:46:04.521405Z","iopub.status.idle":"2025-03-06T14:46:04.526486Z","shell.execute_reply.started":"2025-03-06T14:46:04.521379Z","shell.execute_reply":"2025-03-06T14:46:04.525558Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Mapping characters to indices and back</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"char_to_idx = {char: idx + 1 for idx, char in enumerate(CHARSET)}  # 0 is reserved for blank (CTC)\nidx_to_char = {idx: char for char, idx in char_to_idx.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:46:06.821229Z","iopub.execute_input":"2025-03-06T14:46:06.821513Z","iopub.status.idle":"2025-03-06T14:46:06.825238Z","shell.execute_reply.started":"2025-03-06T14:46:06.821492Z","shell.execute_reply":"2025-03-06T14:46:06.824427Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom dataset</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRDataset(Dataset):\n    def __init__(self, image_dir, labels_file, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform\n        # Load labels from file (format: \"image_name.jpg text\")\n        self.data = []\n        with open(labels_file, 'r') as f:\n            for line in f:\n                img_name, text = line.strip().split(' ', 1)\n                self.data.append((img_name, text))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name, text = self.data[idx]\n        img_path = os.path.join(self.image_dir, img_name)\n        \n        # Load and preprocess the image\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n        img = img / 255.0  # Normalization\n        img = torch.tensor(img, dtype=torch.float32).unsqueeze(0)  # Add channel (1, H, W)\n\n        # Convert text to a sequence of indices\n        label = [char_to_idx[c] for c in text if c in char_to_idx]\n        label_length = len(label)\n        label = torch.tensor(label + [0] * (MAX_TEXT_LENGTH - label_length), dtype=torch.int64)\n        \n        return img, label, label_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:46:16.571326Z","iopub.execute_input":"2025-03-06T14:46:16.571626Z","iopub.status.idle":"2025-03-06T14:46:16.578142Z","shell.execute_reply.started":"2025-03-06T14:46:16.571605Z","shell.execute_reply":"2025-03-06T14:46:16.577274Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Model definition (CNN + RNN + CTC)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRModel(nn.Module):\n    def __init__(self, num_chars):\n        super(OCRModel, self).__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),  # Added another layer\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),  # Increased capacity\n            nn.ReLU()\n        )\n        self.linear = nn.Linear(512 * (IMG_HEIGHT // 4), 1024)  # Augmented input to RNN\n        self.rnn = nn.LSTM(1024, 256, num_layers=2, bidirectional=True, batch_first=True)  # Augmented LSTM\n        self.fc = nn.Linear(256 * 2, num_chars + 1)  # +1 for blank (CTC)\n\n    def forward(self, x):\n        x = self.cnn(x)\n        x = x.permute(0, 3, 1, 2)\n        x = x.reshape(x.size(0), x.size(1), -1)\n        x = self.linear(x)\n        x, _ = self.rnn(x)\n        x = self.fc(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:46:19.290997Z","iopub.execute_input":"2025-03-06T14:46:19.291367Z","iopub.status.idle":"2025-03-06T14:46:19.297671Z","shell.execute_reply.started":"2025-03-06T14:46:19.291343Z","shell.execute_reply":"2025-03-06T14:46:19.296904Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Training</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n        imgs, labels = imgs.to(device), labels.to(device)\n        label_lengths = label_lengths.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        outputs = outputs.log_softmax(2)\n\n        batch_size = imgs.size(0)\n        seq_length = outputs.size(1)\n        input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n\n        loss = criterion(outputs, labels, input_lengths, label_lengths)\n        if torch.isnan(loss) or torch.isinf(loss):\n            print(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n            continue\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n        optimizer.step()\n        total_loss += loss.item()\n\n        if batch_idx % 10 == 0:\n            # Diagnostika predikcí během tréninku\n            with torch.no_grad():\n                pred_texts = decode_prediction(outputs, idx_to_char)\n                print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n                print(f\"Sample predictions: {pred_texts[:3]}\")\n\n    avg_loss = total_loss / len(train_loader)\n    return avg_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:46:22.950400Z","iopub.execute_input":"2025-03-06T14:46:22.950841Z","iopub.status.idle":"2025-03-06T14:46:22.960291Z","shell.execute_reply.started":"2025-03-06T14:46:22.950806Z","shell.execute_reply":"2025-03-06T14:46:22.959428Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Inference (prediction)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def decode_prediction(output, idx_to_char):\n    output = output.argmax(2).cpu().numpy()  # (batch, seq_len)\n    texts = []\n    for pred in output:\n        pred_text = []\n        prev = -1\n        for idx in pred:\n            if idx != 0 and idx != prev:  # Odstraň blanky a duplicity\n                pred_text.append(idx_to_char.get(idx, ''))\n            prev = idx\n        decoded = ''.join(pred_text)\n        texts.append(decoded if decoded else '<empty>')\n    return texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:46:25.549425Z","iopub.execute_input":"2025-03-06T14:46:25.549717Z","iopub.status.idle":"2025-03-06T14:46:25.554475Z","shell.execute_reply.started":"2025-03-06T14:46:25.549696Z","shell.execute_reply":"2025-03-06T14:46:25.553557Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Main launch</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    if not font_files:\n        print(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n    else:\n        create_synthetic_dataset(NUM_SAMPLES)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n    if len(dataset) == 0:\n        print(\"Dataset is empty! Check labels.txt or image directory.\")\n    else:\n        train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n        model = OCRModel(num_chars=len(CHARSET)).to(device)\n        criterion = nn.CTCLoss(blank=0, zero_infinity=True)\n        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n\n        best_loss = float('inf')\n        for epoch in range(EPOCHS):\n            loss = train_model(model, train_loader, criterion, optimizer, device, epoch)\n            print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss:.4f}\")\n\n            # Test inference\n            model.eval()\n            with torch.no_grad():\n                for imgs, _, _ in train_loader:\n                    imgs = imgs.to(device)\n                    outputs = model(imgs)\n                    texts = decode_prediction(outputs, idx_to_char)\n                    print(\"Predictions:\", texts[:5])\n                    break\n            model.train()\n\n            # Scheduler krok\n            scheduler.step(loss)\n            print(f\"Current Learning Rate: {optimizer.param_groups[0]['lr']}\")\n\n            # Uložení nejlepšího modelu\n            if loss < best_loss:\n                best_loss = loss\n                torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'best_ocr_model.pth'))\n\n        torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'final_ocr_model.pth'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:46:31.564987Z","iopub.execute_input":"2025-03-06T14:46:31.565378Z","iopub.status.idle":"2025-03-06T14:49:36.016812Z","shell.execute_reply.started":"2025-03-06T14:46:31.565352Z","shell.execute_reply":"2025-03-06T14:49:36.015921Z"}},"outputs":[{"name":"stdout","text":"Generated 0/1280 images\nGenerated 100/1280 images\nGenerated 200/1280 images\nGenerated 300/1280 images\nGenerated 400/1280 images\nGenerated 500/1280 images\nGenerated 600/1280 images\nGenerated 700/1280 images\nGenerated 800/1280 images\nGenerated 900/1280 images\nGenerated 1000/1280 images\nGenerated 1100/1280 images\nGenerated 1200/1280 images\nDataset generated! Images saved in '/kaggle/working/synthetic_data/images', labels in '/kaggle/working/synthetic_data/labels.txt'\nEpoch 1, Batch 0/40, Loss: 34.0920\nSample predictions: ['i0', 'i0', 'i0']\nEpoch 1, Batch 10/40, Loss: 5.2154\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 1, Batch 20/40, Loss: 4.8447\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 1, Batch 30/40, Loss: 5.0010\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 1/100, Loss: 6.4946\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 2, Batch 0/40, Loss: 4.9154\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 2, Batch 10/40, Loss: 5.0434\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 2, Batch 20/40, Loss: 4.8274\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 2, Batch 30/40, Loss: 4.9394\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 2/100, Loss: 4.9376\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 3, Batch 0/40, Loss: 4.7754\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 3, Batch 10/40, Loss: 4.9521\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 3, Batch 20/40, Loss: 5.0973\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 3, Batch 30/40, Loss: 4.7995\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 3/100, Loss: 4.9285\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 4, Batch 0/40, Loss: 4.8098\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 4, Batch 10/40, Loss: 4.9906\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 4, Batch 20/40, Loss: 5.0077\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 4, Batch 30/40, Loss: 4.8250\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 4/100, Loss: 4.9170\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 5, Batch 0/40, Loss: 4.8399\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 5, Batch 10/40, Loss: 4.9379\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 5, Batch 20/40, Loss: 4.9970\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 5, Batch 30/40, Loss: 4.8306\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 5/100, Loss: 4.9202\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 6, Batch 0/40, Loss: 5.0287\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 6, Batch 10/40, Loss: 4.9688\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 6, Batch 20/40, Loss: 4.7416\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 6, Batch 30/40, Loss: 4.7647\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 6/100, Loss: 4.9066\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 7, Batch 0/40, Loss: 4.7941\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 7, Batch 10/40, Loss: 4.7910\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 7, Batch 20/40, Loss: 4.9420\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 7, Batch 30/40, Loss: 4.8735\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 7/100, Loss: 4.9030\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 8, Batch 0/40, Loss: 4.9497\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 8, Batch 10/40, Loss: 5.1147\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 8, Batch 20/40, Loss: 4.8340\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 8, Batch 30/40, Loss: 4.8444\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 8/100, Loss: 4.9000\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 9, Batch 0/40, Loss: 4.8887\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 9, Batch 10/40, Loss: 4.9229\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 9, Batch 20/40, Loss: 4.9262\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 9, Batch 30/40, Loss: 4.7487\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 9/100, Loss: 4.9082\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 10, Batch 0/40, Loss: 4.9164\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 10, Batch 10/40, Loss: 4.8741\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 10, Batch 20/40, Loss: 5.0029\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 10, Batch 30/40, Loss: 4.8072\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 10/100, Loss: 4.9048\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 11, Batch 0/40, Loss: 4.8623\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 11, Batch 10/40, Loss: 4.9080\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 11, Batch 20/40, Loss: 4.9247\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 11, Batch 30/40, Loss: 4.9410\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 11/100, Loss: 4.8987\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 12, Batch 0/40, Loss: 4.9373\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 12, Batch 10/40, Loss: 4.9429\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 12, Batch 20/40, Loss: 4.8439\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 12, Batch 30/40, Loss: 4.8270\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 12/100, Loss: 4.9124\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 13, Batch 0/40, Loss: 5.1576\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 13, Batch 10/40, Loss: 4.9866\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 13, Batch 20/40, Loss: 4.8444\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 13, Batch 30/40, Loss: 4.7730\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 13/100, Loss: 4.9018\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 14, Batch 0/40, Loss: 4.8921\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 14, Batch 10/40, Loss: 4.7559\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 14, Batch 20/40, Loss: 4.8095\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 14, Batch 30/40, Loss: 4.8757\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 14/100, Loss: 4.9024\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 15, Batch 0/40, Loss: 4.9026\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 15, Batch 10/40, Loss: 4.8132\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 15, Batch 20/40, Loss: 4.8885\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 15, Batch 30/40, Loss: 4.8834\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 15/100, Loss: 4.9069\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 16, Batch 0/40, Loss: 5.0160\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 16, Batch 10/40, Loss: 4.9341\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 16, Batch 20/40, Loss: 4.8980\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 16, Batch 30/40, Loss: 4.8044\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 16/100, Loss: 4.9012\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 17, Batch 0/40, Loss: 4.8783\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 17, Batch 10/40, Loss: 4.9082\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 17, Batch 20/40, Loss: 4.9454\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 17, Batch 30/40, Loss: 4.7709\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 17/100, Loss: 4.8982\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 18, Batch 0/40, Loss: 4.8445\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 18, Batch 10/40, Loss: 4.8716\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 18, Batch 20/40, Loss: 4.9299\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 18, Batch 30/40, Loss: 4.9124\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 18/100, Loss: 4.8978\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 19, Batch 0/40, Loss: 4.9087\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 19, Batch 10/40, Loss: 4.8552\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 19, Batch 20/40, Loss: 4.8561\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 19, Batch 30/40, Loss: 4.9118\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 19/100, Loss: 4.9139\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 20, Batch 0/40, Loss: 4.7827\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 20, Batch 10/40, Loss: 4.8744\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 20, Batch 20/40, Loss: 4.8915\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 20, Batch 30/40, Loss: 4.9804\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 20/100, Loss: 4.9073\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 21, Batch 0/40, Loss: 4.8429\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 21, Batch 10/40, Loss: 5.1046\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 21, Batch 20/40, Loss: 5.1180\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 21, Batch 30/40, Loss: 4.8474\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 21/100, Loss: 4.9038\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 22, Batch 0/40, Loss: 4.8671\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 22, Batch 10/40, Loss: 4.8900\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 22, Batch 20/40, Loss: 4.8172\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 22, Batch 30/40, Loss: 4.9261\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 22/100, Loss: 4.9014\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 23, Batch 0/40, Loss: 4.9619\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 23, Batch 10/40, Loss: 4.9884\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 23, Batch 20/40, Loss: 4.8436\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 23, Batch 30/40, Loss: 4.9556\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 23/100, Loss: 4.9018\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 24, Batch 0/40, Loss: 4.9646\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 24, Batch 10/40, Loss: 4.8170\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 24, Batch 20/40, Loss: 5.0370\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 24, Batch 30/40, Loss: 4.9630\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 24/100, Loss: 4.9049\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 25, Batch 0/40, Loss: 4.8516\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 25, Batch 10/40, Loss: 4.7972\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 25, Batch 20/40, Loss: 4.8535\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 25, Batch 30/40, Loss: 4.7533\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 25/100, Loss: 4.9019\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 26, Batch 0/40, Loss: 4.8623\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 26, Batch 10/40, Loss: 4.7848\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 26, Batch 20/40, Loss: 4.8129\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 26, Batch 30/40, Loss: 4.8219\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 26/100, Loss: 4.9068\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 27, Batch 0/40, Loss: 4.9661\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 27, Batch 10/40, Loss: 4.8674\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 27, Batch 20/40, Loss: 5.1508\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 27, Batch 30/40, Loss: 4.8632\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 27/100, Loss: 4.9007\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.001\nEpoch 28, Batch 0/40, Loss: 4.8019\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 28, Batch 10/40, Loss: 4.9128\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 28, Batch 20/40, Loss: 4.8409\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 28, Batch 30/40, Loss: 4.9499\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 28/100, Loss: 4.9054\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.0005\nEpoch 29, Batch 0/40, Loss: 5.3246\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 29, Batch 10/40, Loss: 4.9108\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 29, Batch 20/40, Loss: 4.9680\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 29, Batch 30/40, Loss: 4.7971\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 29/100, Loss: 4.8913\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.0005\nEpoch 30, Batch 0/40, Loss: 5.0004\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 30, Batch 10/40, Loss: 4.7778\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 30, Batch 20/40, Loss: 4.7465\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 30, Batch 30/40, Loss: 4.8421\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 30/100, Loss: 4.8863\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.0005\nEpoch 31, Batch 0/40, Loss: 4.8908\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 31, Batch 10/40, Loss: 4.9395\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 31, Batch 20/40, Loss: 4.9247\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 31, Batch 30/40, Loss: 4.8510\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 31/100, Loss: 4.8825\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.0005\nEpoch 32, Batch 0/40, Loss: 4.7355\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 32, Batch 10/40, Loss: 4.9947\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 32, Batch 20/40, Loss: 4.9712\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 32, Batch 30/40, Loss: 4.8684\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 32/100, Loss: 4.8845\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.0005\nEpoch 33, Batch 0/40, Loss: 4.9061\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 33, Batch 10/40, Loss: 4.7506\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 33, Batch 20/40, Loss: 4.9417\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 33, Batch 30/40, Loss: 4.8912\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 33/100, Loss: 4.8844\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.0005\nEpoch 34, Batch 0/40, Loss: 4.8294\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 34, Batch 10/40, Loss: 4.8913\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 34, Batch 20/40, Loss: 4.9225\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 34, Batch 30/40, Loss: 4.8668\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 34/100, Loss: 4.8832\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.0005\nEpoch 35, Batch 0/40, Loss: 4.8470\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 35, Batch 10/40, Loss: 4.8773\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 35, Batch 20/40, Loss: 4.8097\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 35, Batch 30/40, Loss: 5.0244\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 35/100, Loss: 4.8825\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.0005\nEpoch 36, Batch 0/40, Loss: 4.8977\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 36, Batch 10/40, Loss: 4.8519\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 36, Batch 20/40, Loss: 4.7741\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 36, Batch 30/40, Loss: 4.9357\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 36/100, Loss: 4.8878\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.0005\nEpoch 37, Batch 0/40, Loss: 4.7797\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 37, Batch 10/40, Loss: 4.8145\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 37, Batch 20/40, Loss: 4.8162\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 37, Batch 30/40, Loss: 4.9305\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 37/100, Loss: 4.8856\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.0005\nEpoch 38, Batch 0/40, Loss: 4.8108\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 38, Batch 10/40, Loss: 4.7273\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 38, Batch 20/40, Loss: 4.8952\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 38, Batch 30/40, Loss: 4.8141\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 38/100, Loss: 4.8890\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.0005\nEpoch 39, Batch 0/40, Loss: 4.9806\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 39, Batch 10/40, Loss: 4.8134\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 39, Batch 20/40, Loss: 4.7774\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 39, Batch 30/40, Loss: 5.0002\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 39/100, Loss: 4.8856\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.0005\nEpoch 40, Batch 0/40, Loss: 4.9093\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 40, Batch 10/40, Loss: 5.2866\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 40, Batch 20/40, Loss: 5.0425\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 40, Batch 30/40, Loss: 4.9358\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 40/100, Loss: 4.8857\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.0005\nEpoch 41, Batch 0/40, Loss: 4.8910\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 41, Batch 10/40, Loss: 4.7845\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 41, Batch 20/40, Loss: 4.8312\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 41, Batch 30/40, Loss: 4.8237\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 41/100, Loss: 4.8844\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.0005\nEpoch 42, Batch 0/40, Loss: 4.8835\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 42, Batch 10/40, Loss: 4.8479\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 42, Batch 20/40, Loss: 4.7195\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 42, Batch 30/40, Loss: 4.7976\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 42/100, Loss: 4.8824\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 43, Batch 0/40, Loss: 4.9277\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 43, Batch 10/40, Loss: 4.7728\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 43, Batch 20/40, Loss: 4.8307\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 43, Batch 30/40, Loss: 4.9087\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 43/100, Loss: 4.8749\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 44, Batch 0/40, Loss: 4.8211\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 44, Batch 10/40, Loss: 4.8148\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 44, Batch 20/40, Loss: 5.0998\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 44, Batch 30/40, Loss: 4.9459\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 44/100, Loss: 4.8750\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 45, Batch 0/40, Loss: 4.7674\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 45, Batch 10/40, Loss: 4.8838\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 45, Batch 20/40, Loss: 4.9379\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 45, Batch 30/40, Loss: 4.9904\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 45/100, Loss: 4.8750\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 46, Batch 0/40, Loss: 4.8336\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 46, Batch 10/40, Loss: 4.8194\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 46, Batch 20/40, Loss: 4.9847\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 46, Batch 30/40, Loss: 4.8771\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 46/100, Loss: 4.8756\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 47, Batch 0/40, Loss: 4.8375\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 47, Batch 10/40, Loss: 4.6697\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 47, Batch 20/40, Loss: 4.7675\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 47, Batch 30/40, Loss: 4.7617\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 47/100, Loss: 4.8724\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 48, Batch 0/40, Loss: 4.9766\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 48, Batch 10/40, Loss: 4.8824\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 48, Batch 20/40, Loss: 4.8006\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 48, Batch 30/40, Loss: 4.9059\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 48/100, Loss: 4.8736\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 49, Batch 0/40, Loss: 4.7399\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 49, Batch 10/40, Loss: 4.8614\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 49, Batch 20/40, Loss: 4.7500\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 49, Batch 30/40, Loss: 4.9336\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 49/100, Loss: 4.8739\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 50, Batch 0/40, Loss: 4.8419\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 50, Batch 10/40, Loss: 5.1779\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 50, Batch 20/40, Loss: 4.8718\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 50, Batch 30/40, Loss: 5.0675\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 50/100, Loss: 4.8737\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 51, Batch 0/40, Loss: 4.8689\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 51, Batch 10/40, Loss: 4.7695\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 51, Batch 20/40, Loss: 4.8670\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 51, Batch 30/40, Loss: 4.9739\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 51/100, Loss: 4.8760\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 52, Batch 0/40, Loss: 4.8942\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 52, Batch 10/40, Loss: 4.8252\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 52, Batch 20/40, Loss: 5.0087\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 52, Batch 30/40, Loss: 4.9525\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 52/100, Loss: 4.8750\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 53, Batch 0/40, Loss: 4.9726\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 53, Batch 10/40, Loss: 4.9188\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 53, Batch 20/40, Loss: 4.8732\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 53, Batch 30/40, Loss: 4.9656\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 53/100, Loss: 4.8734\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 54, Batch 0/40, Loss: 4.9780\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 54, Batch 10/40, Loss: 5.0025\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 54, Batch 20/40, Loss: 4.8125\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 54, Batch 30/40, Loss: 4.8903\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 54/100, Loss: 4.8775\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 55, Batch 0/40, Loss: 4.9075\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 55, Batch 10/40, Loss: 4.8892\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 55, Batch 20/40, Loss: 4.8157\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 55, Batch 30/40, Loss: 4.9534\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 55/100, Loss: 4.8760\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 56, Batch 0/40, Loss: 4.9321\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 56, Batch 10/40, Loss: 4.7991\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 56, Batch 20/40, Loss: 4.7981\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 56, Batch 30/40, Loss: 4.8000\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 56/100, Loss: 4.8809\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 57, Batch 0/40, Loss: 4.8441\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 57, Batch 10/40, Loss: 5.0063\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 57, Batch 20/40, Loss: 4.9567\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 57, Batch 30/40, Loss: 4.8488\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 57/100, Loss: 4.8779\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.00025\nEpoch 58, Batch 0/40, Loss: 4.8253\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 58, Batch 10/40, Loss: 4.9130\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 58, Batch 20/40, Loss: 4.9102\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 58, Batch 30/40, Loss: 4.9667\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 58/100, Loss: 4.8741\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 59, Batch 0/40, Loss: 4.7565\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 59, Batch 10/40, Loss: 4.8832\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 59, Batch 20/40, Loss: 4.8765\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 59, Batch 30/40, Loss: 4.8769\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 59/100, Loss: 4.8708\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 60, Batch 0/40, Loss: 4.8332\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 60, Batch 10/40, Loss: 4.8561\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 60, Batch 20/40, Loss: 4.8203\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 60, Batch 30/40, Loss: 4.8670\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 60/100, Loss: 4.8702\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 61, Batch 0/40, Loss: 4.9138\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 61, Batch 10/40, Loss: 4.9020\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 61, Batch 20/40, Loss: 4.8871\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 61, Batch 30/40, Loss: 4.9158\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 61/100, Loss: 4.8716\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 62, Batch 0/40, Loss: 4.8504\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 62, Batch 10/40, Loss: 4.7934\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 62, Batch 20/40, Loss: 4.7070\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 62, Batch 30/40, Loss: 4.7933\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 62/100, Loss: 4.8693\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 63, Batch 0/40, Loss: 4.8887\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 63, Batch 10/40, Loss: 4.9758\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 63, Batch 20/40, Loss: 4.8759\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 63, Batch 30/40, Loss: 4.8298\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 63/100, Loss: 4.8713\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 64, Batch 0/40, Loss: 4.8324\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 64, Batch 10/40, Loss: 4.7577\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 64, Batch 20/40, Loss: 4.7884\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 64, Batch 30/40, Loss: 4.8391\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 64/100, Loss: 4.8713\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 65, Batch 0/40, Loss: 4.8498\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 65, Batch 10/40, Loss: 4.7535\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 65, Batch 20/40, Loss: 4.7507\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 65, Batch 30/40, Loss: 4.9363\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 65/100, Loss: 4.8706\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 66, Batch 0/40, Loss: 4.9714\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 66, Batch 10/40, Loss: 4.7840\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 66, Batch 20/40, Loss: 4.8385\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 66, Batch 30/40, Loss: 4.9965\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 66/100, Loss: 4.8703\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 67, Batch 0/40, Loss: 4.8462\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 67, Batch 10/40, Loss: 4.8263\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 67, Batch 20/40, Loss: 5.0050\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 67, Batch 30/40, Loss: 4.8091\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 67/100, Loss: 4.8704\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 68, Batch 0/40, Loss: 4.9592\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 68, Batch 10/40, Loss: 4.8886\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 68, Batch 20/40, Loss: 4.9320\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 68, Batch 30/40, Loss: 4.7978\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 68/100, Loss: 4.8702\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 69, Batch 0/40, Loss: 4.8128\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 69, Batch 10/40, Loss: 4.7428\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 69, Batch 20/40, Loss: 4.8007\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 69, Batch 30/40, Loss: 4.8296\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 69/100, Loss: 4.8684\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 70, Batch 0/40, Loss: 4.9059\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 70, Batch 10/40, Loss: 4.9271\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 70, Batch 20/40, Loss: 4.9443\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 70, Batch 30/40, Loss: 4.8255\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 70/100, Loss: 4.8714\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 71, Batch 0/40, Loss: 4.7971\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 71, Batch 10/40, Loss: 4.8242\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 71, Batch 20/40, Loss: 5.0506\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 71, Batch 30/40, Loss: 4.9313\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 71/100, Loss: 4.8701\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 72, Batch 0/40, Loss: 4.8928\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 72, Batch 10/40, Loss: 4.7761\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 72, Batch 20/40, Loss: 4.7496\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 72, Batch 30/40, Loss: 5.0523\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 72/100, Loss: 4.8712\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 73, Batch 0/40, Loss: 4.7553\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 73, Batch 10/40, Loss: 4.9960\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 73, Batch 20/40, Loss: 4.8652\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 73, Batch 30/40, Loss: 4.7459\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 73/100, Loss: 4.8707\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 74, Batch 0/40, Loss: 4.7621\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 74, Batch 10/40, Loss: 4.8070\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 74, Batch 20/40, Loss: 4.7541\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 74, Batch 30/40, Loss: 4.9948\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 74/100, Loss: 4.8692\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 75, Batch 0/40, Loss: 4.8906\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 75, Batch 10/40, Loss: 4.8209\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 75, Batch 20/40, Loss: 4.6949\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 75, Batch 30/40, Loss: 4.8343\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 75/100, Loss: 4.8709\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 76, Batch 0/40, Loss: 4.7616\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 76, Batch 10/40, Loss: 4.8258\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 76, Batch 20/40, Loss: 4.8650\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 76, Batch 30/40, Loss: 4.8252\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 76/100, Loss: 4.8689\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 77, Batch 0/40, Loss: 5.0357\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 77, Batch 10/40, Loss: 4.8951\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 77, Batch 20/40, Loss: 4.9255\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 77, Batch 30/40, Loss: 4.7859\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 77/100, Loss: 4.8692\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 78, Batch 0/40, Loss: 4.8913\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 78, Batch 10/40, Loss: 4.8924\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 78, Batch 20/40, Loss: 4.8041\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 78, Batch 30/40, Loss: 4.7506\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 78/100, Loss: 4.8696\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 79, Batch 0/40, Loss: 4.8602\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 79, Batch 10/40, Loss: 4.6950\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 79, Batch 20/40, Loss: 4.8541\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 79, Batch 30/40, Loss: 4.8735\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 79/100, Loss: 4.8711\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 0.000125\nEpoch 80, Batch 0/40, Loss: 4.9259\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 80, Batch 10/40, Loss: 4.9523\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 80, Batch 20/40, Loss: 4.7563\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 80, Batch 30/40, Loss: 4.8078\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 80/100, Loss: 4.8709\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 6.25e-05\nEpoch 81, Batch 0/40, Loss: 4.7465\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 81, Batch 10/40, Loss: 4.8851\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 81, Batch 20/40, Loss: 4.7418\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 81, Batch 30/40, Loss: 4.7888\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 81/100, Loss: 4.8675\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 6.25e-05\nEpoch 82, Batch 0/40, Loss: 5.0362\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 82, Batch 10/40, Loss: 4.8069\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 82, Batch 20/40, Loss: 4.9198\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 82, Batch 30/40, Loss: 4.8315\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 82/100, Loss: 4.8680\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 6.25e-05\nEpoch 83, Batch 0/40, Loss: 4.8435\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 83, Batch 10/40, Loss: 4.8158\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 83, Batch 20/40, Loss: 4.8241\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 83, Batch 30/40, Loss: 4.7852\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 83/100, Loss: 4.8677\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 6.25e-05\nEpoch 84, Batch 0/40, Loss: 4.8856\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 84, Batch 10/40, Loss: 4.8208\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 84, Batch 20/40, Loss: 4.7763\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 84, Batch 30/40, Loss: 4.7951\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 84/100, Loss: 4.8675\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 6.25e-05\nEpoch 85, Batch 0/40, Loss: 4.7453\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 85, Batch 10/40, Loss: 4.9642\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 85, Batch 20/40, Loss: 4.9171\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 85, Batch 30/40, Loss: 4.7376\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 85/100, Loss: 4.8676\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 6.25e-05\nEpoch 86, Batch 0/40, Loss: 4.9452\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 86, Batch 10/40, Loss: 4.8814\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 86, Batch 20/40, Loss: 4.7532\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 86, Batch 30/40, Loss: 4.9977\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 86/100, Loss: 4.8693\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 6.25e-05\nEpoch 87, Batch 0/40, Loss: 4.9809\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 87, Batch 10/40, Loss: 4.7361\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 87, Batch 20/40, Loss: 4.9097\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 87, Batch 30/40, Loss: 4.7571\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 87/100, Loss: 4.8679\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 6.25e-05\nEpoch 88, Batch 0/40, Loss: 4.8007\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 88, Batch 10/40, Loss: 4.9403\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 88, Batch 20/40, Loss: 4.8895\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 88, Batch 30/40, Loss: 4.8782\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 88/100, Loss: 4.8674\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 6.25e-05\nEpoch 89, Batch 0/40, Loss: 4.9927\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 89, Batch 10/40, Loss: 5.0424\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 89, Batch 20/40, Loss: 4.8757\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 89, Batch 30/40, Loss: 4.8703\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 89/100, Loss: 4.8681\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 6.25e-05\nEpoch 90, Batch 0/40, Loss: 4.8548\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 90, Batch 10/40, Loss: 4.8231\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 90, Batch 20/40, Loss: 4.7477\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 90, Batch 30/40, Loss: 4.9865\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 90/100, Loss: 4.8685\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 6.25e-05\nEpoch 91, Batch 0/40, Loss: 4.8391\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 91, Batch 10/40, Loss: 4.9190\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 91, Batch 20/40, Loss: 4.9040\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 91, Batch 30/40, Loss: 4.9036\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 91/100, Loss: 4.8675\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 6.25e-05\nEpoch 92, Batch 0/40, Loss: 4.9639\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 92, Batch 10/40, Loss: 5.0070\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 92, Batch 20/40, Loss: 5.0331\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 92, Batch 30/40, Loss: 4.7854\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 92/100, Loss: 4.8688\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 3.125e-05\nEpoch 93, Batch 0/40, Loss: 4.7406\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 93, Batch 10/40, Loss: 4.8139\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 93, Batch 20/40, Loss: 4.8561\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 93, Batch 30/40, Loss: 4.8607\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 93/100, Loss: 4.8669\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 3.125e-05\nEpoch 94, Batch 0/40, Loss: 4.8444\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 94, Batch 10/40, Loss: 4.8597\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 94, Batch 20/40, Loss: 4.8152\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 94, Batch 30/40, Loss: 4.9009\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 94/100, Loss: 4.8667\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 3.125e-05\nEpoch 95, Batch 0/40, Loss: 4.7758\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 95, Batch 10/40, Loss: 4.8380\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 95, Batch 20/40, Loss: 4.7351\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 95, Batch 30/40, Loss: 4.8639\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 95/100, Loss: 4.8662\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 3.125e-05\nEpoch 96, Batch 0/40, Loss: 4.9561\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 96, Batch 10/40, Loss: 4.8744\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 96, Batch 20/40, Loss: 5.0347\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 96, Batch 30/40, Loss: 4.9262\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 96/100, Loss: 4.8662\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 3.125e-05\nEpoch 97, Batch 0/40, Loss: 4.9123\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 97, Batch 10/40, Loss: 4.7092\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 97, Batch 20/40, Loss: 4.8083\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 97, Batch 30/40, Loss: 4.8516\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 97/100, Loss: 4.8665\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 3.125e-05\nEpoch 98, Batch 0/40, Loss: 4.8561\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 98, Batch 10/40, Loss: 4.7353\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 98, Batch 20/40, Loss: 4.8906\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 98, Batch 30/40, Loss: 4.8572\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 98/100, Loss: 4.8665\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 3.125e-05\nEpoch 99, Batch 0/40, Loss: 4.6820\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 99, Batch 10/40, Loss: 4.9002\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 99, Batch 20/40, Loss: 4.9326\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 99, Batch 30/40, Loss: 4.9082\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 99/100, Loss: 4.8661\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 3.125e-05\nEpoch 100, Batch 0/40, Loss: 4.7354\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 100, Batch 10/40, Loss: 4.7430\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 100, Batch 20/40, Loss: 4.8246\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 100, Batch 30/40, Loss: 4.7624\nSample predictions: ['<empty>', '<empty>', '<empty>']\nEpoch 100/100, Loss: 4.8663\nPredictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nCurrent Learning Rate: 3.125e-05\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"def zip_folder_with_shutil(source_folder, output_path):\n    '''Function for zip dir data'''\n    shutil.make_archive(output_path, 'zip', source_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:49:53.319922Z","iopub.execute_input":"2025-03-06T14:49:53.320274Z","iopub.status.idle":"2025-03-06T14:49:53.324420Z","shell.execute_reply.started":"2025-03-06T14:49:53.320247Z","shell.execute_reply":"2025-03-06T14:49:53.323543Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/backgrounds', '/kaggle/working/backgrounds')\nzip_folder_with_shutil('/kaggle/working/synthetic_data', '/kaggle/working/synthetic_data')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T14:49:55.991400Z","iopub.execute_input":"2025-03-06T14:49:55.991686Z","iopub.status.idle":"2025-03-06T14:49:56.208779Z","shell.execute_reply.started":"2025-03-06T14:49:55.991664Z","shell.execute_reply":"2025-03-06T14:49:56.208153Z"}},"outputs":[],"execution_count":22}]}