{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10951507,"sourceType":"datasetVersion","datasetId":6783030}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---------------\n\n# **<font style=\"color:Black\">Create OCR by PyTorch</font>**\n-------------------\n-----------------","metadata":{}},{"cell_type":"code","source":"#!pip install tensorboard\n!tensorboard --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:34:24.873931Z","iopub.execute_input":"2025-03-08T11:34:24.874490Z","iopub.status.idle":"2025-03-08T11:34:43.770918Z","shell.execute_reply.started":"2025-03-08T11:34:24.874465Z","shell.execute_reply":"2025-03-08T11:34:43.769988Z"}},"outputs":[{"name":"stdout","text":"2025-03-08 11:34:29.629335: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-08 11:34:29.929297: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-08 11:34:30.022820: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2.17.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport random\nfrom PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter\nimport numpy as np\nimport cv2\n\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F  # Add this import\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:34:43.772012Z","iopub.execute_input":"2025-03-08T11:34:43.772422Z","iopub.status.idle":"2025-03-08T11:34:54.768726Z","shell.execute_reply.started":"2025-03-08T11:34:43.772385Z","shell.execute_reply":"2025-03-08T11:34:54.767907Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Hyperparameters</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"seed = 3\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:34:54.769541Z","iopub.execute_input":"2025-03-08T11:34:54.769996Z","iopub.status.idle":"2025-03-08T11:34:54.782754Z","shell.execute_reply.started":"2025-03-08T11:34:54.769972Z","shell.execute_reply":"2025-03-08T11:34:54.781918Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x77fe66f5add0>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"OUTPUT_DIR = os.path.join('/kaggle','working','synthetic_data','images')\nTENSORBOARD_DIR = os.path.join('/kaggle','working','runs')\nMODEL_DIR = os.path.join('/kaggle','working','model_dir')\nLABELS_FILE = os.path.join('/kaggle','working','synthetic_data','labels.txt')\nNUM_SAMPLES = 5120  # Number of images generated\nIMG_WIDTH = 128\nIMG_HEIGHT = 32\nBATCH_SIZE = 32\nEPOCHS = 20\nLEARNING_RATE = 1e-7 \nWEIGHT_DECAY = 1e-4  \nWARMUP_STEPS = 1000  \nENTROPY_WEIGHT = 2.0\nTEMPERATURE = 0.3\nDROPOUT = 0.7\nBEAM_WIDTH = 10\nLABEL_SMOOTHING = 0.2\nBLANK_PENALTY_WEIGHT = 3.0\nMAX_SEQ_LENGTH = 15\nCHARSET = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-*\"  # Group characters\nMAX_TEXT_LENGTH = 10  # Maximum length of text in an image\nFONT_DIR = os.path.join('/kaggle','input','google-fonts','GoogleFontScripts') # Folder with TrueType fonts (.ttf)\nBACKGROUND_DIR = os.path.join('/kaggle','working','backgrounds')  # New folder for background (optional)\nNUMBER_BACKGROUND_IMAGE = 1000","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:34:54.783604Z","iopub.execute_input":"2025-03-08T11:34:54.783863Z","iopub.status.idle":"2025-03-08T11:34:54.791493Z","shell.execute_reply.started":"2025-03-08T11:34:54.783839Z","shell.execute_reply":"2025-03-08T11:34:54.790675Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Utils support functions</font>**\n-------------------","metadata":{}},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Create output folders</font>**","metadata":{}},{"cell_type":"code","source":"os.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(BACKGROUND_DIR, exist_ok=True)\nos.makedirs(TENSORBOARD_DIR, exist_ok=True)\n\n# Creates a new file\nwith open(LABELS_FILE, 'w') as fp:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:34:54.792435Z","iopub.execute_input":"2025-03-08T11:34:54.792752Z","iopub.status.idle":"2025-03-08T11:34:54.803256Z","shell.execute_reply.started":"2025-03-08T11:34:54.792718Z","shell.execute_reply":"2025-03-08T11:34:54.802569Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load the font list (add the paths to the .ttf files to the \"fonts\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"font_files = [\n    os.path.join(FONT_DIR, f) for f in os.listdir(FONT_DIR) \n    if f.endswith('.ttf') and os.path.isfile(os.path.join(FONT_DIR, f))\n]\nif not font_files:\n    raise FileNotFoundError(\"No fonts found in 'fonts' folder. Add .ttf files!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:34:54.805278Z","iopub.execute_input":"2025-03-08T11:34:54.805519Z","iopub.status.idle":"2025-03-08T11:34:59.157019Z","shell.execute_reply.started":"2025-03-08T11:34:54.805491Z","shell.execute_reply":"2025-03-08T11:34:59.156104Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generating a simple gradient background</font>**","metadata":{}},{"cell_type":"code","source":"def generate_gradient_background(filename, size=(128, 32)):\n    img = Image.new('L', size, color=230)  # Lighter gray as a base\n    draw = ImageDraw.Draw(img)\n    for y in range(size[1]):\n        # Soft gradient with low contrast\n        color = int(230 - 20 * (y / size[1]))  # From light gray to slightly darker\n        draw.line([(0, y), (size[0], y)], fill=color)\n    # Background blur\n    img = img.filter(ImageFilter.GaussianBlur(radius=2))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:34:59.159081Z","iopub.execute_input":"2025-03-08T11:34:59.159504Z","iopub.status.idle":"2025-03-08T11:34:59.165129Z","shell.execute_reply.started":"2025-03-08T11:34:59.159467Z","shell.execute_reply":"2025-03-08T11:34:59.164325Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generate a background with noise (paper texture)</font>**","metadata":{}},{"cell_type":"code","source":"def generate_paper_texture(filename, size=(128, 32)):\n    img = Image.new('L', size, color=220)  # Lighter gray\n    noise = np.random.normal(0, 5, size).astype(np.uint8)  # Less noise\n    noise_img = Image.fromarray(noise)\n    img.paste(noise_img, (0, 0), noise_img)\n    # Blur for a softer effect\n    img = img.filter(ImageFilter.GaussianBlur(radius=1.5))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:34:59.165959Z","iopub.execute_input":"2025-03-08T11:34:59.166321Z","iopub.status.idle":"2025-03-08T11:34:59.176463Z","shell.execute_reply.started":"2025-03-08T11:34:59.166296Z","shell.execute_reply":"2025-03-08T11:34:59.175698Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Creating multiple backgrounds</font>**","metadata":{}},{"cell_type":"code","source":"for i in range(NUMBER_BACKGROUND_IMAGE):\n    generate_gradient_background(f\"gradient_{i}.png\")\n    generate_paper_texture(f\"paper_{i}.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:34:59.177387Z","iopub.execute_input":"2025-03-08T11:34:59.177645Z","iopub.status.idle":"2025-03-08T11:35:00.307599Z","shell.execute_reply.started":"2025-03-08T11:34:59.177624Z","shell.execute_reply":"2025-03-08T11:35:00.306847Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load backgrounds (optional, add images to the \"backgrounds\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"background_files = (\n    [os.path.join(BACKGROUND_DIR, f) for f in os.listdir(BACKGROUND_DIR) \n     if f.endswith(('.png', '.jpg', '.jpeg'))] if os.path.exists(BACKGROUND_DIR) else []\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.308428Z","iopub.execute_input":"2025-03-08T11:35:00.308733Z","iopub.status.idle":"2025-03-08T11:35:00.316763Z","shell.execute_reply.started":"2025-03-08T11:35:00.308701Z","shell.execute_reply":"2025-03-08T11:35:00.315897Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Random text generation function</font>**","metadata":{}},{"cell_type":"code","source":"def generate_random_text(max_length):\n    length = random.randint(1, max_length)\n    return ''.join(random.choice(CHARSET) for _ in range(length))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.317565Z","iopub.execute_input":"2025-03-08T11:35:00.317853Z","iopub.status.idle":"2025-03-08T11:35:00.324929Z","shell.execute_reply.started":"2025-03-08T11:35:00.317831Z","shell.execute_reply":"2025-03-08T11:35:00.324182Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Functions for adding noise and distortions</font>**","metadata":{}},{"cell_type":"code","source":"def add_noise_and_distortion(img):\n    img_array = np.array(img)\n    # Mild Gaussian noise with lower intensity\n    if random.random() > 0.5:  # 50% šance\n        noise = np.random.normal(0, random.randint(5, 15), img_array.shape).astype(np.uint8)\n        img_array = cv2.add(img_array, noise)\n    # Subtle perspective distortion\n    rows, cols = img_array.shape\n    src_points = np.float32([[0, 0], [cols-1, 0], [0, rows-1], [cols-1, rows-1]])\n    dst_points = np.float32([\n        [random.uniform(0, 3), random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), random.uniform(0, 3)],\n        [random.uniform(0, 3), rows-1-random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), rows-1-random.uniform(0, 3)]\n    ])\n    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n    img_array = cv2.warpPerspective(img_array, matrix, (cols, rows))\n    return Image.fromarray(img_array)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.325815Z","iopub.execute_input":"2025-03-08T11:35:00.326137Z","iopub.status.idle":"2025-03-08T11:35:00.336938Z","shell.execute_reply.started":"2025-03-08T11:35:00.326105Z","shell.execute_reply":"2025-03-08T11:35:00.336143Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Improved image generation feature</font>**","metadata":{}},{"cell_type":"code","source":"def generate_synthetic_image(text, font_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n    # Pozadí\n    if background_files:\n        bg_path = random.choice(background_files)\n        img = Image.open(bg_path).convert('L').resize(img_size)\n    else:\n        img = Image.new('L', img_size, color=230)\n        draw = ImageDraw.Draw(img)\n        for y in range(img_size[1]):\n            color = int(230 - 20 * (y / img_size[1]))\n            draw.line([(0, y), (img_size[0], y)], fill=color)\n        img = img.filter(ImageFilter.GaussianBlur(radius=2))\n\n    draw = ImageDraw.Draw(img)\n\n    # Iterativní úprava fontu a textu\n    font_size = random.randint(20, min(IMG_HEIGHT-2, 28))\n    max_attempts = 5  # Omezení počtu pokusů\n    for attempt in range(max_attempts):\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n        if text_width <= IMG_WIDTH - 10:  # Text vejde\n            break\n        elif len(text) > 1:  # Zkrať text, pokud je příliš dlouhý\n            text = text[:len(text)//2]\n        else:  # Sniž velikost fontu\n            font_size = max(10, font_size - 5)  # Minimální velikost 10\n\n    # Pokud se nepodaří, použij minimální font a jednopísmený text\n    if text_width > IMG_WIDTH - 10:\n        text = text[0]  # Použij první písmeno\n        font_size = 10\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n    # Pozice textu\n    x = random.randint(5, max(5, IMG_WIDTH - text_width - 5))\n    y = random.randint(5, max(5, IMG_HEIGHT - text_height - 5))\n\n    # Zvýraznění textu\n    text_color = random.randint(0, 50)\n    outline_color = 200\n    for offset_x in [-1, 0, 1]:\n        for offset_y in [-1, 0, 1]:\n            if offset_x != 0 or offset_y != 0:\n                draw.text((x + offset_x, y + offset_y), text, font=font, fill=outline_color)\n    draw.text((x, y), text, font=font, fill=text_color)\n\n    # Šum a deformace\n    img = add_noise_and_distortion(img)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.337933Z","iopub.execute_input":"2025-03-08T11:35:00.338319Z","iopub.status.idle":"2025-03-08T11:35:00.352557Z","shell.execute_reply.started":"2025-03-08T11:35:00.338284Z","shell.execute_reply":"2025-03-08T11:35:00.351650Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function for splitting labels</font>**","metadata":{}},{"cell_type":"code","source":"def split_labels(labels, label_lengths):\n    \"\"\"Split a flat tensor of labels into a list of label sequences based on lengths.\"\"\"\n    split_labels = []\n    start = 0\n    for length in label_lengths:\n        split_labels.append(labels[start:start + length])\n        start += length\n    return split_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.353459Z","iopub.execute_input":"2025-03-08T11:35:00.353779Z","iopub.status.idle":"2025-03-08T11:35:00.367034Z","shell.execute_reply.started":"2025-03-08T11:35:00.353747Z","shell.execute_reply":"2025-03-08T11:35:00.366154Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function of Beam search decoding</font>**","metadata":{}},{"cell_type":"code","source":"def beam_search_decode(output, idx_to_char, target_lengths=None, beam_width=10, blank_penalty=-0.5, length_penalty=-0.5):\n    probs = output.softmax(2).cpu().numpy()\n    T, B, C = probs.shape\n    predictions = []\n    \n    for b in range(B):\n        sequence_probs = [(0.0, [], 1.0)]\n        max_length = target_lengths[b].item() * 2 if target_lengths is not None else T  # Cap at 2x target length\n        for t in range(T):\n            new_sequences = []\n            for log_prob, seq, prob in sequence_probs:\n                if len(seq) >= max_length:\n                    new_sequences.append((log_prob, seq, prob))\n                    continue\n                top_k_probs, top_k_idx = torch.topk(torch.tensor(probs[t, b]), beam_width)\n                for k_prob, k_idx in zip(top_k_probs, top_k_idx):\n                    new_seq = seq + [k_idx.item()]\n                    new_prob = prob * k_prob.item()\n                    new_log_prob = log_prob + np.log(k_prob.item())\n                    if k_idx.item() == 0:\n                        new_log_prob += blank_penalty\n                    new_log_prob += length_penalty * len(new_seq)\n                    new_sequences.append((new_log_prob, new_seq, new_prob))\n            sequence_probs = sorted(new_sequences, key=lambda x: x[0], reverse=True)[:beam_width]\n        \n        best_seq = sequence_probs[0][1]\n        decoded = []\n        prev = -1\n        for idx in best_seq:\n            if idx != 0 and idx != prev:\n                decoded.append(idx_to_char.get(idx, ''))\n            prev = idx\n        predictions.append(''.join(decoded) if decoded else '<empty>')\n    \n    token_counts = Counter(best_seq)\n    print(f\"Token distribution (Batch {b}): {dict(token_counts)}\")\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.367928Z","iopub.execute_input":"2025-03-08T11:35:00.368204Z","iopub.status.idle":"2025-03-08T11:35:00.380551Z","shell.execute_reply.started":"2025-03-08T11:35:00.368158Z","shell.execute_reply":"2025-03-08T11:35:00.379779Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Custom collate function</font>**","metadata":{}},{"cell_type":"code","source":"def custom_collate_fn(batch):\n    images, labels, label_lengths = zip(*batch)\n    # Stack images (all same size)\n    images = torch.stack(images, dim=0)\n    # Concatenate labels into a flat tensor\n    labels = torch.cat(labels, dim=0)\n    # Convert label_lengths to tensor\n    label_lengths = torch.tensor(label_lengths, dtype=torch.long)\n    return images, labels, label_lengths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.381377Z","iopub.execute_input":"2025-03-08T11:35:00.381618Z","iopub.status.idle":"2025-03-08T11:35:00.394288Z","shell.execute_reply.started":"2025-03-08T11:35:00.381595Z","shell.execute_reply":"2025-03-08T11:35:00.393427Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generování datasetu</font>**","metadata":{}},{"cell_type":"code","source":"def create_synthetic_dataset(num_samples):\n    labels = []\n    for i in range(num_samples):\n        text = generate_random_text(MAX_TEXT_LENGTH)\n        if not text:\n            continue\n        font_path = random.choice(font_files)\n        img = generate_synthetic_image(text, font_path)\n        img_name = f\"img_{i:05d}.png\"\n        img_path = os.path.join(OUTPUT_DIR, img_name)\n        img.save(img_path)\n        labels.append(f\"{img_name}\\t{text}\")  # Use tab (\\t) instead of space\n        if i % 100 == 0:\n            print(f\"Generated {i}/{num_samples} images\")\n\n    if labels:\n        with open(LABELS_FILE, 'w') as f:\n            f.write(\"\\n\".join(labels))\n        print(f\"Dataset generated! Images saved in '{OUTPUT_DIR}', labels in '{LABELS_FILE}'\")\n    else:\n        print(\"No labels generated!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.395069Z","iopub.execute_input":"2025-03-08T11:35:00.395380Z","iopub.status.idle":"2025-03-08T11:35:00.409867Z","shell.execute_reply.started":"2025-03-08T11:35:00.395354Z","shell.execute_reply":"2025-03-08T11:35:00.408987Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Mapping characters to indices and back</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"char_to_idx = {char: idx + 1 for idx, char in enumerate(CHARSET)}  # 0 is reserved for blank (CTC)\nidx_to_char = {idx: char for char, idx in char_to_idx.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.410729Z","iopub.execute_input":"2025-03-08T11:35:00.410955Z","iopub.status.idle":"2025-03-08T11:35:00.421081Z","shell.execute_reply.started":"2025-03-08T11:35:00.410934Z","shell.execute_reply":"2025-03-08T11:35:00.420380Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom dataset</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRDataset(Dataset):\n    def __init__(self, image_dir, labels_file):\n        self.image_dir = image_dir\n        self.labels_file = labels_file\n        self.data = []\n        with open(labels_file, 'r') as f:\n            for line in f:\n                if not line.strip():  # Skip empty lines\n                    continue\n                image_path, label = line.strip().split('\\t')\n                label_length = len(label)\n                self.data.append((image_path, label, label_length))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_path, label, label_length = self.data[idx]\n        image = Image.open(os.path.join(self.image_dir, image_path)).convert('L')\n        image = transforms.ToTensor()(image)\n        label_encoded = torch.tensor([char_to_idx[c] for c in label], dtype=torch.long)\n        return image, label_encoded, label_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.421962Z","iopub.execute_input":"2025-03-08T11:35:00.422276Z","iopub.status.idle":"2025-03-08T11:35:00.433543Z","shell.execute_reply.started":"2025-03-08T11:35:00.422246Z","shell.execute_reply":"2025-03-08T11:35:00.432707Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom CTC Loss with Blank Penalty</font>**\n-------------------\n> CTC Loss with Entropy Regularization","metadata":{}},{"cell_type":"code","source":"class CTCLossWithBlankPenalty(nn.Module):\n    def __init__(self, blank=0, zero_infinity=True, blank_penalty_weight=1.0, entropy_weight=1.0, label_smoothing=0.2):\n        super().__init__()\n        self.ctc_loss = nn.CTCLoss(blank=blank, zero_infinity=zero_infinity)\n        self.blank_penalty_weight = blank_penalty_weight\n        self.entropy_weight = entropy_weight\n        self.label_smoothing = label_smoothing\n\n    def forward(self, log_probs, targets, input_lengths, target_lengths):\n        ctc_loss = self.ctc_loss(log_probs, targets, input_lengths, target_lengths)\n        blank_probs = log_probs[:, :, 0].exp().mean()\n        blank_penalty = -torch.log(1 - blank_probs + 1e-6) * self.blank_penalty_weight\n        entropy = -(log_probs.exp() * log_probs).sum(dim=-1).mean()  # Negative entropy\n        total_loss = ctc_loss + blank_penalty + self.entropy_weight * entropy\n        return total_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.437445Z","iopub.execute_input":"2025-03-08T11:35:00.437745Z","iopub.status.idle":"2025-03-08T11:35:00.450396Z","shell.execute_reply.started":"2025-03-08T11:35:00.437720Z","shell.execute_reply":"2025-03-08T11:35:00.449384Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Model definition (CNN + RNN + CTC)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRModel(nn.Module):\n    def __init__(self, num_chars):\n        super(OCRModel, self).__init__()\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.rnn = nn.LSTM(128 * (IMG_HEIGHT // 4), 256, num_layers=2, bidirectional=True, dropout=DROPOUT)\n        self.fc = nn.Linear(256 * 2, num_chars)\n        self.dropout = nn.Dropout(DROPOUT)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        batch, channels, height, width = x.size()\n        x = x.view(batch, channels * height, width).permute(2, 0, 1)\n        x = x[:MAX_SEQ_LENGTH]  # Truncate to MAX_SEQ_LENGTH\n        x, _ = self.rnn(x)\n        x = self.dropout(x)\n        x = self.fc(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.451710Z","iopub.execute_input":"2025-03-08T11:35:00.452019Z","iopub.status.idle":"2025-03-08T11:35:00.462435Z","shell.execute_reply.started":"2025-03-08T11:35:00.451988Z","shell.execute_reply":"2025-03-08T11:35:00.461600Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Training</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, device, epoch, warmup_steps=WARMUP_STEPS):\n    model.train()\n    total_loss = 0\n    global_step = epoch * len(train_loader)\n    \n    for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n        imgs, labels = imgs.to(device), labels.to(device)\n        label_lengths = label_lengths.to(device)\n\n        if global_step < warmup_steps:\n            lr_scale = min(1.0, float(global_step + 1) / warmup_steps)\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = LEARNING_RATE * lr_scale\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        outputs = outputs / TEMPERATURE\n        outputs = outputs.log_softmax(2)\n\n        batch_size = imgs.size(0)\n        seq_length = outputs.size(0)\n        input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n\n        loss = criterion(outputs, labels, input_lengths, label_lengths)\n        if torch.isnan(loss) or torch.isinf(loss):\n            print(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n            continue\n\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n        optimizer.step()\n        total_loss += loss.item()\n        global_step += 1\n\n        if batch_idx % 10 == 0:\n            with torch.no_grad():\n                pred_texts = beam_search_decode(outputs, idx_to_char, label_lengths)\n                raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n                blank_probs = outputs[:, :, 0].exp().mean().item()\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:3]]\n                \n                # Logování do TensorBoard\n                writer.add_scalar('Loss/train_batch', loss.item(), global_step)\n                writer.add_scalar('Blank_Probability/train_batch', blank_probs, global_step)\n                writer.add_scalar('Gradient_Norm/train_batch', grad_norm.item(), global_step)\n                \n                print(f\"Batch {batch_idx}, Gradient norm: {grad_norm.item():.4f}\")\n                print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n                print(f\"Avg Blank Probability: {blank_probs:.4f}\")\n                print(f\"Sample predictions: {pred_texts[:3]}\")\n                print(f\"Ground Truth (first 3): {ground_truth}\")\n                print(f\"Raw outputs (first 3): {raw_outputs}\")\n                print(f\"Input length: {seq_length}, Label lengths: {label_lengths[:3].tolist()}\")\n\n    avg_loss = total_loss / len(train_loader)\n    writer.add_scalar('Loss/train_epoch', avg_loss, epoch)\n    return avg_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.463386Z","iopub.execute_input":"2025-03-08T11:35:00.463702Z","iopub.status.idle":"2025-03-08T11:35:00.477309Z","shell.execute_reply.started":"2025-03-08T11:35:00.463670Z","shell.execute_reply":"2025-03-08T11:35:00.476462Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Inference (prediction)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def decode_prediction(output, idx_to_char):\n    probs = output.softmax(2)\n    max_probs, preds = probs.max(dim=2)\n    preds = preds.cpu().numpy()\n    max_probs = max_probs.cpu().numpy()\n    texts = []\n    for i, (pred, prob) in enumerate(zip(preds.T, max_probs.T)):\n        print(f\"Raw prediction {i} (pre-filter): {pred}, Max probs: {prob}\")\n        # Dynamic threshold: 75th percentile of max probs in this sequence\n        threshold = np.percentile(prob, 75)\n        print(f\"Dynamic threshold for prediction {i}: {threshold:.4f}\")\n        pred_text = []\n        prev = -1\n        for idx, p in zip(pred, prob):\n            if idx != 0 and idx != prev and p > threshold:\n                pred_text.append(idx_to_char.get(idx, ''))\n            prev = idx\n        decoded = ''.join(pred_text)\n        texts.append(decoded if decoded else '<empty>')\n    return texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.478233Z","iopub.execute_input":"2025-03-08T11:35:00.478546Z","iopub.status.idle":"2025-03-08T11:35:00.494902Z","shell.execute_reply.started":"2025-03-08T11:35:00.478514Z","shell.execute_reply":"2025-03-08T11:35:00.494016Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Main launch</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Inicializace TensorBoard writeru\n    log_dir = \"runs/ocr_experiment\"\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    writer = SummaryWriter(log_dir)\n\n    if not font_files:\n        print(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n    else:\n        create_synthetic_dataset(NUM_SAMPLES)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    full_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n\n    for i in range(5):\n        img, label, length = full_dataset[i]\n        plt.imshow(img.squeeze(), cmap='gray')\n        plt.title(''.join([idx_to_char.get(idx.item(), '') for idx in label[:length]]))\n        plt.show()\n    \n    if len(full_dataset) == 0:\n        print(\"Dataset is empty! Check labels.txt or image directory.\")\n    else:\n        # Curriculum phases with pre-filtering\n        model = OCRModel(num_chars=len(CHARSET)).to(device)\n        criterion = CTCLossWithBlankPenalty(\n            blank=0, zero_infinity=True, blank_penalty_weight=BLANK_PENALTY_WEIGHT,\n            entropy_weight=ENTROPY_WEIGHT, label_smoothing=LABEL_SMOOTHING\n        )\n        \n        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n\n        best_loss = float('inf')\n        \n        for epoch in range(EPOCHS):\n            # Filter full dataset based on curriculum phase\n            if epoch < 10:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 5]\n                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]  # lbl je řetězec\n                print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n            elif epoch < 15:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 7]\n                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]\n                print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n            else:\n                filtered_data = full_dataset.data\n                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]\n                print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n\n            # Create a new dataset with filtered data\n            curr_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n            curr_dataset.data = filtered_data  # Overwrite with filtered data\n\n            # Split into train and validation\n            train_size = int(0.8 * len(curr_dataset))\n            val_size = len(curr_dataset) - train_size\n            train_dataset, val_dataset = torch.utils.data.random_split(curr_dataset, [train_size, val_size])\n            print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n            \n            # Create data loaders\n            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n            val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n            \n            # Trénink s TensorBoard logováním\n            model.train()\n            total_loss = 0\n            global_step = epoch * len(train_loader)\n            for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n                imgs, labels = imgs.to(device), labels.to(device)\n                label_lengths = label_lengths.to(device)\n\n                if global_step < WARMUP_STEPS:\n                    lr_scale = min(1.0, float(global_step + 1) / WARMUP_STEPS)\n                    for param_group in optimizer.param_groups:\n                        param_group['lr'] = LEARNING_RATE * lr_scale\n\n                optimizer.zero_grad()\n                outputs = model(imgs)\n                outputs = outputs / TEMPERATURE\n                outputs = outputs.log_softmax(2)\n\n                batch_size = imgs.size(0)\n                seq_length = outputs.size(0)\n                input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n\n                loss = criterion(outputs, labels, input_lengths, label_lengths)\n                if torch.isnan(loss) or torch.isinf(loss):\n                    print(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n                    continue\n\n                loss.backward()\n                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n                optimizer.step()\n                total_loss += loss.item()\n                global_step += 1\n\n                if batch_idx % 10 == 0:\n                    with torch.no_grad():\n                        pred_texts = beam_search_decode(outputs, idx_to_char, label_lengths)\n                        raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n                        blank_probs = outputs[:, :, 0].exp().mean().item()\n                        label_sequences = split_labels(labels, label_lengths)\n                        ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                        for label_seq in label_sequences[:3]]\n                        \n                        # Logování do TensorBoard\n                        writer.add_scalar('Loss/train_batch', loss.item(), global_step)\n                        writer.add_scalar('Blank_Probability/train_batch', blank_probs, global_step)\n                        writer.add_scalar('Gradient_Norm/train_batch', grad_norm.item(), global_step)\n                        \n                        print(f\"Batch {batch_idx}, Gradient norm: {grad_norm.item():.4f}\")\n                        print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n                        print(f\"Avg Blank Probability: {blank_probs:.4f}\")\n                        print(f\"Sample predictions: {pred_texts[:3]}\")\n                        print(f\"Ground Truth (first 3): {ground_truth}\")\n                        print(f\"Raw outputs (first 3): {raw_outputs}\")\n                        print(f\"Input length: {seq_length}, Label lengths: {label_lengths[:3].tolist()}\")\n\n            avg_loss = total_loss / len(train_loader)\n            writer.add_scalar('Loss/train_epoch', avg_loss, epoch)\n            print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.4f}\")\n\n            # Validace s TensorBoard logováním\n            model.eval()\n            val_loss = 0\n            val_blank_probs = 0\n            with torch.no_grad():\n                for batch_idx, (imgs, labels, label_lengths) in enumerate(val_loader):\n                    imgs, labels = imgs.to(device), labels.to(device)\n                    label_lengths = label_lengths.to(device)\n                    outputs = model(imgs)\n                    outputs = outputs.log_softmax(2)\n                    seq_length = outputs.size(0)\n                    input_lengths = torch.full((imgs.size(0),), seq_length, dtype=torch.long).to(device)\n                    val_loss += criterion(outputs, labels, input_lengths, label_lengths).item()\n                    val_blank_probs += outputs[:, :, 0].exp().mean().item()\n                \n                val_loss /= len(val_loader)\n                val_blank_probs /= len(val_loader)\n                pred_texts = beam_search_decode(outputs, idx_to_char, label_lengths)\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:5]]\n                \n                # Logování validace do TensorBoard\n                writer.add_scalar('Loss/val_epoch', val_loss, epoch)\n                writer.add_scalar('Blank_Probability/val_epoch', val_blank_probs, epoch)\n                print(f\"Validation Loss: {val_loss:.4f}\")\n                print(\"Validation Predictions:\", pred_texts[:5])\n                print(\"Ground Truth:\", ground_truth)\n\n            scheduler.step()\n            print(f\"Current Learning Rate: {optimizer.param_groups[0]['lr']}\")\n\n            if val_loss < best_loss:\n                best_loss = val_loss\n                torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'best_ocr_model.pth'))\n\n        torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'final_ocr_model.pth'))\n    \n    # Uzavření TensorBoard writeru\n    writer.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:35:00.495895Z","iopub.execute_input":"2025-03-08T11:35:00.496211Z","iopub.status.idle":"2025-03-08T11:49:17.540474Z","shell.execute_reply.started":"2025-03-08T11:35:00.496157Z","shell.execute_reply":"2025-03-08T11:49:17.539635Z"}},"outputs":[{"name":"stdout","text":"Generated 0/5120 images\nGenerated 100/5120 images\nGenerated 200/5120 images\nGenerated 300/5120 images\nGenerated 400/5120 images\nGenerated 500/5120 images\nGenerated 600/5120 images\nGenerated 700/5120 images\nGenerated 800/5120 images\nGenerated 900/5120 images\nGenerated 1000/5120 images\nGenerated 1100/5120 images\nGenerated 1200/5120 images\nGenerated 1300/5120 images\nGenerated 1400/5120 images\nGenerated 1500/5120 images\nGenerated 1600/5120 images\nGenerated 1700/5120 images\nGenerated 1800/5120 images\nGenerated 1900/5120 images\nGenerated 2000/5120 images\nGenerated 2100/5120 images\nGenerated 2200/5120 images\nGenerated 2300/5120 images\nGenerated 2400/5120 images\nGenerated 2500/5120 images\nGenerated 2600/5120 images\nGenerated 2700/5120 images\nGenerated 2800/5120 images\nGenerated 2900/5120 images\nGenerated 3000/5120 images\nGenerated 3100/5120 images\nGenerated 3200/5120 images\nGenerated 3300/5120 images\nGenerated 3400/5120 images\nGenerated 3500/5120 images\nGenerated 3600/5120 images\nGenerated 3700/5120 images\nGenerated 3800/5120 images\nGenerated 3900/5120 images\nGenerated 4000/5120 images\nGenerated 4100/5120 images\nGenerated 4200/5120 images\nGenerated 4300/5120 images\nGenerated 4400/5120 images\nGenerated 4500/5120 images\nGenerated 4600/5120 images\nGenerated 4700/5120 images\nGenerated 4800/5120 images\nGenerated 4900/5120 images\nGenerated 5000/5120 images\nGenerated 5100/5120 images\nDataset generated! Images saved in '/kaggle/working/synthetic_data/images', labels in '/kaggle/working/synthetic_data/labels.txt'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {32: 2, 34: 1, 11: 1, 42: 1, 1: 2, 19: 1}\nBatch 0, Gradient norm: 15.1868\nEpoch 1, Batch 0/66, Loss: 30.6596\nAvg Blank Probability: 0.0148\nSample predictions: ['lv2a', 'elj3faja', 'kv-jaG']\nGround Truth (first 3): ['Up', '4Kv4', 'OFf']\nRaw outputs (first 3): [[12  5 11 11 19 12  6 47  1 27  1  1  1 50  1 19 56 10 10 56 10 34 27  1\n  32 33 32 10 43 42 34 32]\n [22 12 22  5 27 32  1 10 56  1 24 56  8  1  1 32 11  1 42 62  4 47 44 19\n  57 50  1  6  1 27 23 34]\n [55 10 63 34 19 56 47 11 48  1  1 42 24  1  1 43 12 32  1 10 34 56  1  1\n  48  1 22 12  1  1  1 11]]\nInput length: 15, Label lengths: [2, 4, 3]\nToken distribution (Batch 31): {56: 1, 17: 1}\nBatch 10, Gradient norm: 17.9880\nEpoch 1, Batch 10/66, Loss: 32.6031\nAvg Blank Probability: 0.0147\nSample predictions: ['Qj', '3a', 'asvlPj']\nGround Truth (first 3): ['X', 'K', '6eE']\nRaw outputs (first 3): [[43 56  1 12  6  1 36 43 29  6 13 30 12  4 25 12 10 63 14  1 29  6  4 56\n  34 11 42  6  1 43  1 56]\n [10  1 19  1  1 60 61  6  1 16  1  1 48 34 10  5 63 22 42 43 24 24  1  1\n  47 30 47  1 19  1 56 17]\n [ 1 34 22 10  1 32 12 10 43 56 42  1 10 32  2 50 22  6 12 62 47  1 43 34\n  22 30  6 43  1 47  1 10]]\nInput length: 15, Label lengths: [1, 1, 3]\nToken distribution (Batch 31): {4: 2, 1: 1, 5: 1}\nBatch 20, Gradient norm: 239.8956\nEpoch 1, Batch 20/66, Loss: 27.3617\nAvg Blank Probability: 0.0145\nSample predictions: ['UfADyQUlAj', 'HIFsFyml', 'sflVd2asa']\nGround Truth (first 3): ['u6XUi', 'qUYe', '*afWc']\nRaw outputs (first 3): [[47 34 19 14 24 42 12  6 47  1 10  6  1  1  1 12 22  8 63  6 63  6  1  6\n  56  1 56 45  1 32  1  4]\n [ 6 35 19 34 19 17 57 47  5 19 10 56 47  1 24 24  1 43  1 63 10 47 27 10\n   5 27 42 43  7 10 32  4]\n [27  0  6 32 22 34 32  1 16 19 12 11 56 11 47 50 35 47  5  1 25 47 22 10\n  13  1 16 10 13  6  1  1]]\nInput length: 15, Label lengths: [5, 4, 5]\nToken distribution (Batch 31): {4: 1, 47: 1, 33: 1, 35: 1}\nBatch 30, Gradient norm: 17.9936\nEpoch 1, Batch 30/66, Loss: 32.7842\nAvg Blank Probability: 0.0146\nSample predictions: ['HjyU', 'ayFLv8FrFH', 'HQaUHaFgda']\nGround Truth (first 3): ['9K', 'jEXUx', '8aW40']\nRaw outputs (first 3): [[34  1 34 10  1  6 50 20 56  5 35 32  1 27  4  1  1 48 63 21 19  1 10  1\n  34 10 34  6 11 10  1  4]\n [10 25 43 47  1 30 11  1 32  7  4 22 32  6 12 11  1 34 11 56 32 56 25  6\n  32 10 63 10 47 55 11 47]\n [25 32  1 34  7  1 63 50 60 14  1 47  1  1 30 19 11 63 11 61 63 34  4  6\n  32 36 41 34  1 10 47 33]]\nInput length: 15, Label lengths: [2, 5, 5]\nToken distribution (Batch 31): {10: 2, 11: 2, 12: 1, 1: 1, 50: 1, 5: 1, 35: 1, 19: 1}\nBatch 40, Gradient norm: 26.4210\nEpoch 1, Batch 40/66, Loss: 32.3072\nAvg Blank Probability: 0.0148\nSample predictions: ['Aj', 'kd', 'HaXyXI2']\nGround Truth (first 3): ['K', 'z', '5*m2']\nRaw outputs (first 3): [[27 11 34 19 34 34 22 19 34  1 34 48 10  4  1 43 22  1 11  2 11 11  1 56\n  10 55 10 10  1 10 32 10]\n [10  4  1 47 48 47 47  1 25 22 35  4  6  8 35  1 12 32  5  6  1  6 47  1\n  43  1 29 19 16 11 10 11]\n [29 55  1 20  1  1 47 56 63 34  1 59 10 32  1  1 27 11 10 43 35 12 32  6\n  11 10  1 10  1 19  1 11]]\nInput length: 15, Label lengths: [1, 1, 4]\nToken distribution (Batch 31): {1: 3, 10: 1}\nBatch 50, Gradient norm: 20.6184\nEpoch 1, Batch 50/66, Loss: 35.5464\nAvg Blank Probability: 0.0150\nSample predictions: ['a3', 'kl', 'HUkHd3FU']\nGround Truth (first 3): ['0', '3', 'Ox9Z']\nRaw outputs (first 3): [[ 1 11 34  1 10 24  1 10 42 22  1 63 24 12  1 19 16 50 10 47 63  1 24 32\n  10 10 25 10  1 19 56  1]\n [56 12 47  6  1 42 22  6 32 24 22 47 10  5 22 33  1 19  4 23  1 48  1  1\n   5 27 12  2  6 12 12  1]\n [10  7 11  1  1 32 10  1 10  1 11 34  1 10 34 19 35 56 11  5  1  6 32 32\n   1 56  4 46  4  1 48  1]]\nInput length: 15, Label lengths: [1, 1, 4]\nToken distribution (Batch 31): {11: 1, 50: 1, 19: 1, 1: 1}\nBatch 60, Gradient norm: 1471.7408\nEpoch 1, Batch 60/66, Loss: 31.4950\nAvg Blank Probability: 0.0147\nSample predictions: ['jdP-XFd-sa', 'fsakeaVAPA', 'k84a']\nGround Truth (first 3): ['p46O6', 'oChe-', 'Jf']\nRaw outputs (first 3): [[10  6 11  6  1 34  4 46 56 12 35 24 43 43  1  1 10 22  1 11 22 47 33 34\n   4 34 25 63 35  1 11 11]\n [ 4 19 61 63  1 10  1 35 12 10 11 19 42  4  4  1  4 47 10 43  1 32 19 27\n   1  1 10 34 27  1 10 50]\n [42  1 57  4 34 25 56 32  1  4  1 12 42  1 50 10  9 22 19 34 27  1  1  1\n   1  1  1 12 19  4 12 19]]\nInput length: 15, Label lengths: [5, 5, 2]\nEpoch 1/20, Loss: 33.5865\nToken distribution (Batch 8): {1: 10}\nValidation Loss: 32.6091\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['Ems', 'Dt', '4z', 'OdrNd', '8QWWA']\nCurrent Learning Rate: 1.2715201226395052e-08\nEpoch 2, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {1: 2, 43: 1, 34: 1}\nBatch 0, Gradient norm: 14.2525\nEpoch 2, Batch 0/66, Loss: 27.4157\nAvg Blank Probability: 0.0149\nSample predictions: ['pyjaQJea', 'UeFeaw', 'fPj3']\nGround Truth (first 3): ['VNbV', 'pn9', 'K3']\nRaw outputs (first 3): [[16 47  6  1 11  6  5  1 12 11  1 34 34 16  1 12 33 47 56 11 56 11 11 22\n  22 22  1 32 57 34 12  1]\n [25  5 42 37 12  1 10 11 56 22  1 12 33  1 50 10 12 10 10  1 10 57  1 10\n  35 42  1 16  5  4 50 43]\n [10 32 10  1  5 47 11 19 16 10 42 11 50  6 11 56 56 20 35  1 27 11  1  5\n   5 11  4 25  1  1 34  1]]\nInput length: 15, Label lengths: [4, 3, 2]\nToken distribution (Batch 31): {63: 1, 43: 1, 35: 1, 42: 1}\nBatch 10, Gradient norm: 18.7899\nEpoch 2, Batch 10/66, Loss: 34.6208\nAvg Blank Probability: 0.0149\nSample predictions: ['jI4vsf', 'eskjkaUk', 'a']\nGround Truth (first 3): ['CVN', '76rX', 'w']\nRaw outputs (first 3): [[10  5  1  4  1  1 34 42  1  1 11 12 10 11 12 34 11  4  1  5  6  1 10 47\n  12 10  1 19 14  4 10 63]\n [35 19  1 22 12 25 14 22  1 19  1  1 60  6 10 10 47 56  1 16 48 32  1 35\n   1 43  1 10  4 34 10 43]\n [57 11 19 12  1 11 10 10  9 34  1 22 11 32 35 10 47 11 10 34 35 34  4 11\n  22 25 48 27 32 43  1 35]]\nInput length: 15, Label lengths: [3, 4, 1]\nToken distribution (Batch 31): {34: 2, 6: 1, 1: 3, 32: 1, 19: 1, 10: 1, 7: 1}\nBatch 20, Gradient norm: 13.1725\nEpoch 2, Batch 20/66, Loss: 26.7734\nAvg Blank Probability: 0.0148\nSample predictions: ['ksajXHyVaC', 'aVdjaVDj', 'yUajsjsH']\nGround Truth (first 3): ['4hA6-', 'qLqg', 'LE5c']\nRaw outputs (first 3): [[11  1 25  1 47 56  1 10  1  1 47 42 10 16 22 43 10 50 24 43 10 63 10 63\n  16 63 34 12 24 56  1 34]\n [19 48 47 34 22 56 50 22 47  1 12 10 42 10  1 10  1 21 27 38  4 56 11 10\n  16 32 35 46 55 43  1  6]\n [ 1  4  1 10 60  1 22  4  1 10  1 32  1 10 32 24  1 56  1 24  4 25 50 10\n  22  4 11 12  1 32  1  1]]\nInput length: 15, Label lengths: [5, 4, 4]\nToken distribution (Batch 31): {63: 1, 47: 1, 12: 1, 42: 1, 51: 1, 34: 1}\nBatch 30, Gradient norm: 20.3092\nEpoch 2, Batch 30/66, Loss: 35.9976\nAvg Blank Probability: 0.0148\nSample predictions: ['jaFsvUad', 'AasP', 'da']\nGround Truth (first 3): ['3CFh', 'TK', 'B']\nRaw outputs (first 3): [[10 27  4 10 11 35 42  6 47 42 11 11 10 14  1 34 63 63 10 63 47 19  1  1\n   4 11 63 34 34  1 35 63]\n [ 1  1  1 12 35 20 34 19  1 47 42 35 57 63  4 32 56 25 10 42  1 47  1 34\n  28  1 35 25 32 32 13 47]\n [32 19  1 57  1 19 34 32  1 28 42 32 11  1 56 32 10  9 38 56 32 11 27 47\n  11 11 10  1 34 22  1 12]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {25: 1, 43: 1, 4: 2, 30: 1, 10: 1, 1: 1, 12: 1, 19: 1, 55: 1}\nBatch 40, Gradient norm: 27.7125\nEpoch 2, Batch 40/66, Loss: 43.2387\nAvg Blank Probability: 0.0148\nSample predictions: ['g642Udxde', 'sPFp', 'aRk']\nGround Truth (first 3): ['-Bk62', 'Ad', '7-']\nRaw outputs (first 3): [[ 7 19  1  1 11 35 10  4 11 60 30  5 11 10  1  1 19  1 22 10  1 34  1  1\n  56 34 34 11 25 35 43 25]\n [ 7 42 44  1 12 56 10 34 32 10 47 11  1 63  6 42 34  4 10 34 19 27 16 27\n  19  1  5 33 42 34  5 43]\n [59 32 11 47 43 33  1  1  1 61 42  6 12  1 24  6 12 19  1 42  1  1 42 27\n  30 10  1 22 56 10 11  4]]\nInput length: 15, Label lengths: [5, 2, 2]\nToken distribution (Batch 31): {1: 2, 4: 1, 11: 1, 34: 1, 22: 1}\nBatch 50, Gradient norm: 13.9799\nEpoch 2, Batch 50/66, Loss: 28.6024\nAvg Blank Probability: 0.0148\nSample predictions: ['kakfjav', 'aiXsaVU', 'Da']\nGround Truth (first 3): ['3uam', 'A6TT', 'E']\nRaw outputs (first 3): [[11  1 30 63 25  1 56  6 63 43 12  1  1  6  1 63  1 11  1 11  1 11 10 22\n  32  1 24  1 19 11  6  1]\n [ 1  9  1  6 47 56 47  1 34 19 10 61 19  1  1 50  0  9  4 34  4 43 10 12\n  32  2  5 11  4 35 10  1]\n [11 50 48 56 42  1  4 18  1 34  1 34  1  5  1 16 16  1 34 42  1 56  1 22\n  11 24 25 19 33 47 47  4]]\nInput length: 15, Label lengths: [4, 4, 1]\nToken distribution (Batch 31): {10: 1, 11: 1}\nBatch 60, Gradient norm: 241.2955\nEpoch 2, Batch 60/66, Loss: 39.1204\nAvg Blank Probability: 0.0148\nSample predictions: ['3ajn', 'FAPsjAkH', 'ajeFey8F']\nGround Truth (first 3): ['tP', 'orH2', 'jxG9']\nRaw outputs (first 3): [[56 32  1 28 14 10 19  1 34 11 10 16  6 56 10 56  1 34  1  1  6 34 19 12\n  56 43 12 24 56  1  4  0]\n [ 1 27 10 10  5  1  1  1  1 43 47  1  1 42  1 60 59  1 48  5  1 34  1 32\n  43 32  6 35 55 50  1 11]\n [10 42  5 55 57 32 25 28 43 34 48  1 50  1  6 32  5 47 50 10 43 47 33  1\n   1  6  1  5 47 48 48 10]]\nInput length: 15, Label lengths: [2, 4, 4]\nEpoch 2/20, Loss: 33.1518\nToken distribution (Batch 8): {1: 4}\nValidation Loss: 33.0653\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['nxOD', 'DYK', 'kXK', 'Bw', '*4VnO']\nCurrent Learning Rate: 3.138609259860176e-08\nEpoch 3, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {11: 1, 47: 1, 1: 2}\nBatch 0, Gradient norm: 19.6437\nEpoch 3, Batch 0/66, Loss: 34.5822\nAvg Blank Probability: 0.0146\nSample predictions: ['fIDaEa', '3ajk', 'aj']\nGround Truth (first 3): ['NXr', 'Ii', 'Z']\nRaw outputs (first 3): [[ 6 56  1 34 34  1  4 63 12 10  4 24 47 32 57 56  4  5  1 43 34 63  1 35\n  35  6 22 22 10  4 12 11]\n [35  1 10 11  1 35 13 11 42 34  1  1 16 48  1  1 63  1 56 22 47 43 12 22\n  57  1  1 34  4 32 24 47]\n [30 10 34 11 34 56  1 35 47  1  5 19  1 11 34 46 43 28  1 42  1 56  1 55\n  47 56 35  1  4  1 57  1]]\nInput length: 15, Label lengths: [3, 2, 1]\nToken distribution (Batch 31): {56: 1, 35: 1, 24: 1, 4: 1, 18: 1, 6: 1, 27: 1, 1: 3}\nBatch 10, Gradient norm: 233.4963\nEpoch 3, Batch 10/66, Loss: 40.4479\nAvg Blank Probability: 0.0149\nSample predictions: ['yjs2jsja', 'jX', 'HekladQjA']\nGround Truth (first 3): ['2b6t', 'z', 'UM8yk']\nRaw outputs (first 3): [[25 10 34 12  5 35 10 24  5 63 34  1 22 11 19 61  1 25  6 10 35  1 43 11\n  63  6 11  1  6 10  4 56]\n [10 50 34 10 35 56 32 34  1 47 56 32 10 10 32 25  1 61  6 35  1 10 30 35\n   6  1 40  0 32 10 56 35]\n [19  1  5 10  1 22 30 10  1  9 34 32 11  1 32 12 34  1 24 56  4 11 63 32\n   1  6 32 24 47 25 10 24]]\nInput length: 15, Label lengths: [4, 1, 5]\nToken distribution (Batch 31): {1: 2, 42: 2, 34: 1, 22: 1}\nBatch 20, Gradient norm: 904.9426\nEpoch 3, Batch 20/66, Loss: 31.5551\nAvg Blank Probability: 0.0148\nSample predictions: ['fA-s3ja8', 'jnaIxa', 'VFtaQ']\nGround Truth (first 3): ['AaGy', 'JnBX', 'QVW']\nRaw outputs (first 3): [[ 6 10 48 12  1  4  1  1  1 10  6 56 11 30 43  4 47 63 11 47 42 56 35 30\n  63 11 63 16  6 16  1  1]\n [27 14 32  7 34  4 35  1  6  1 24 57 11  6 56 35 19 28 11 30  4 55  1 12\n  30  1  4 32 16  1 10 42]\n [63  1 20 10 45 47 43  5 32 27 10  4 11 35 56  1  6 42 50 56 11 30  4 56\n   1 11 56 32 11  1  6 42]]\nInput length: 15, Label lengths: [4, 4, 3]\nToken distribution (Batch 31): {4: 1, 6: 1}\nBatch 30, Gradient norm: 14.2471\nEpoch 3, Batch 30/66, Loss: 29.3484\nAvg Blank Probability: 0.0146\nSample predictions: ['dF2ageU', '4Qva', 'kA']\nGround Truth (first 3): ['yz2K', 'Pn', 'd']\nRaw outputs (first 3): [[ 4 57 11  4 12 27 14 16 12  4 11 12 34  5 56 42 24 42  1  1 25  1 25 30\n   1  1  1  1 44 10 34  4]\n [32 43 27 24 42  1 24 32  1 32 22 30 10 35 34  1 22 12 47  6 10 12 10 19\n   1 19  4  5  1  5 47  6]\n [32 22  7 19 11  9 10 32 61 51 47 32 22 10 56 32 46 59 28 63 10  1  1 24\n  22 35 33  1 10  1 63  1]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {47: 1, 22: 1}\nBatch 40, Gradient norm: 19.5551\nEpoch 3, Batch 40/66, Loss: 35.5247\nAvg Blank Probability: 0.0149\nSample predictions: ['Pjlx', 'vald3tUl-', 'F2']\nGround Truth (first 3): ['HJ', 'lCXSq', 's']\nRaw outputs (first 3): [[42 22 32  1 34  1  4 48 14  4 34 56 32  1  1  4 10  6 34 26 10 47 63 12\n  12 61  1  1 63 56  1 47]\n [10  1 55  1 10 17 10  5 63  1  1 44 24 12  4 48  1  1 11 12 42  1 19  1\n   1 12 25 13 42 22  1 22]\n [12  1  1 22  6 34 33  4 35 36 32 17 10 51  1 19 35 43 11 32 43  1  1 32\n  10 32  1 14  1  6  1 47]]\nInput length: 15, Label lengths: [2, 5, 1]\nToken distribution (Batch 31): {1: 2, 50: 1, 10: 1, 11: 2, 27: 2, 34: 1, 19: 1}\nBatch 50, Gradient norm: 20.2124\nEpoch 3, Batch 50/66, Loss: 36.6793\nAvg Blank Probability: 0.0148\nSample predictions: ['qs', 'QjyE2Pwka', 'jI']\nGround Truth (first 3): ['h', 'HzLVh', 'P']\nRaw outputs (first 3): [[17 43 10 42 19  4  1  4  1  6  4  1 32  6 56 16  5  1 42 60 34 19 10  6\n   1 16 22 63 48 32 63  1]\n [19 10 35  1 47 50 10  1  1  1 25 47 11 10 10 35 47 43 50  1 27 22 56  1\n  63 55 22 11 35  1 34 50]\n [ 6 25 27  4 30 10 25 48  1  1  1 30 27  1 12 10 47 27  1 47  4  1 42  1\n  42 12 10 63  1  1 11 10]]\nInput length: 15, Label lengths: [1, 5, 1]\nToken distribution (Batch 31): {56: 1, 1: 3, 6: 1, 21: 1, 29: 1, 22: 1, 14: 1, 32: 1}\nBatch 60, Gradient norm: 21.0601\nEpoch 3, Batch 60/66, Loss: 33.2751\nAvg Blank Probability: 0.0149\nSample predictions: ['-fxU', 'a3OsaftV', 'j3ekagAs']\nGround Truth (first 3): ['x*', 'z2xI', 'ddhf']\nRaw outputs (first 3): [[63  1 10 47 34  1  4  1  4 22 35 56 10  1 24 57  1 11  1 30  6  1 34 48\n  10 22 12 12  6 63  1 56]\n [ 6 56 56 11  1  1 12 63  5 16 32  1 56 18 12 22 34  1 19 24 46 31  6 16\n  56  1  1 10  1 11  4  1]\n [24 41  5 48 22 30  4  1 10  1 19 22  4 11 10 11 10 22  1 13 35  1 35 47\n  32  4 47 34 35 34  1  1]]\nInput length: 15, Label lengths: [2, 4, 4]\nEpoch 3/20, Loss: 33.1391\nToken distribution (Batch 8): {1: 8}\nValidation Loss: 32.6301\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['XgM1X', 'UVE', 'oChe-', 'NjDj6', 'i9ud8']\nCurrent Learning Rate: 4.996878382120998e-08\nEpoch 4, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {5: 1, 18: 1, 19: 1, 32: 1, 27: 1, 55: 2, 35: 1, 9: 1, 50: 1}\nBatch 0, Gradient norm: 20.4934\nEpoch 4, Batch 0/66, Loss: 36.6805\nAvg Blank Probability: 0.0146\nSample predictions: ['IafvFAX', 'e-df', 'fV']\nGround Truth (first 3): ['r8lu', 'Xf', '-']\nRaw outputs (first 3): [[35  5  6 56 10 16 47  1  1  1  1 61  4  4 27 35  1 56 10 10 20  1 11 30\n  19  1 22  1  1 63 32  5]\n [ 1 63 48 35 34 16 10 47 34 56 22 47 12 47 32 34  4 10 35 32 25 32 10 47\n  11 47 11 25 30 12 63 18]\n [ 6  4  1 19  4 48 50 22 61 43 40  1 11  1 19 12 11  1 55 35  1 10 63 61\n  19  5  1 14 55 35 10 19]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {6: 2}\nBatch 10, Gradient norm: 22.6075\nEpoch 4, Batch 10/66, Loss: 38.0772\nAvg Blank Probability: 0.0148\nSample predictions: ['HFrUaU3a', 'vfa', 'fadja32a']\nGround Truth (first 3): ['zypb', 'P0', 'hrNK']\nRaw outputs (first 3): [[34 22  6 32  1 30 42  4  6 10 32 12 42 12  1 10  1  6 63 63 22 32 12 34\n   1 35  1 13 63  1 10  6]\n [32  6  1  1 22  1 47 32 32  4 43 34 19 47 10  1 11 10  6 30 24  1  6  1\n   6 56 30 12 34 34 42  6]\n [18  1  4 24 32 22  1  5  1  4 10 34 20 10  1  2  1 10  6 10  1  1  7  1\n  10 10 10 24 42 11 16  1]]\nInput length: 15, Label lengths: [4, 2, 4]\nToken distribution (Batch 31): {1: 2, 10: 1, 22: 1}\nBatch 20, Gradient norm: 18.1357\nEpoch 4, Batch 20/66, Loss: 32.6943\nAvg Blank Probability: 0.0147\nSample predictions: ['-UjI', 'tHQauBaPFa', 'avVQ']\nGround Truth (first 3): ['WJ', 'tgEPL', '-k']\nRaw outputs (first 3): [[63 20  1 56 10 34 27 19 13 10 47 33 19 47 10 12 63  1 24  6  1 12 11 27\n  28  1  6 22 43 10  1  1]\n [47 34 22  6 52 63 35 63 43  1 16  4  1  5  1  1 56 47 10 33  1  1  1 42\n   1 24 42 32 61 34  4 10]\n [10 43 48 55 35  4  6 20 56 32  8  4 34 10 47 38 10  1  1 19 16  1 11 47\n  34  1 11  6 32 30  1  1]]\nInput length: 15, Label lengths: [2, 5, 2]\nToken distribution (Batch 31): {1: 1, 55: 1, 42: 1, 34: 2, 9: 1}\nBatch 30, Gradient norm: 18.6570\nEpoch 4, Batch 30/66, Loss: 33.7583\nAvg Blank Probability: 0.0147\nSample predictions: ['Asa3aj', 'ajy', '2HFaFHaX']\nGround Truth (first 3): ['DwBi', 'G5', 'SqlG']\nRaw outputs (first 3): [[27  1 55  1 23 30 32  1 10 34 47 12 50  4  6 25 22 56 47  1 47 24 42 48\n  10 35  1 43 63 12 11  1]\n [19 10 34  6 19 43 16 63 47 56  1 33 35 22 12 10 47 22  1 63 42 12 19 13\n   5  1 12 10  1  6 19 55]\n [ 1 10 32  1 19 27 50 60 10  5 33  1 10 33 56 22  1 27 10 48 19 42  4 19\n  55 12 18 41 34 11 27 42]]\nInput length: 15, Label lengths: [4, 2, 4]\nToken distribution (Batch 31): {14: 1, 1: 1}\nBatch 40, Gradient norm: 100.0829\nEpoch 4, Batch 40/66, Loss: 33.5097\nAvg Blank Probability: 0.0148\nSample predictions: ['Vl', 'fF', 'aHvI']\nGround Truth (first 3): ['o', 'D', 'ce']\nRaw outputs (first 3): [[48  6  1 10 32 22 33  1 30 43 32 10 32 24  4  1  6 32 47  1 29 63 42 43\n   1 51 12 63  1 11  4 14]\n [12 32 34 56 35  1 35 10 24 35 32  4 10 16 63 34 48 30 24  1 34  1 22  1\n  10 56 34 10 10 32  1  1]\n [ 1 56 22  5 57  1  1 42 30 56  1 24  1 55  6  1  1 34  1 11  1 42 27 46\n  11 22  1  1 56 47  1  1]]\nInput length: 15, Label lengths: [1, 1, 2]\nToken distribution (Batch 31): {10: 1, 1: 2, 32: 1, 22: 1, 47: 1, 6: 1, 26: 1}\nBatch 50, Gradient norm: 46.4764\nEpoch 4, Batch 50/66, Loss: 37.0990\nAvg Blank Probability: 0.0148\nSample predictions: ['kax7faEi', 'jaFQ', 'ap']\nGround Truth (first 3): ['V6lI', '55', '3']\nRaw outputs (first 3): [[11 10  1 30  6 10  1 47 25  1 34  5 25 19  6 27 30 63 56 16 22 32 19 56\n  63  4 27 10 24  6 32 10]\n [ 1  1 16  9 42 55 56 12 34 19 12  1 12  4 32 34 10  6  1  1  1  1  1  1\n   1  1 10 20 22 10 43  1]\n [24 32  1 16 34  1 10 20 10 63 56 12 32 24 47 19 32 10 12 10 47 11 13 56\n  12 11 27 19 22  1  1  1]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {35: 1, 1: 1, 22: 2}\nBatch 60, Gradient norm: 14.7338\nEpoch 4, Batch 60/66, Loss: 29.5030\nAvg Blank Probability: 0.0149\nSample predictions: ['a2jAvUj', 'QaXUjtaIjX', '3HirFHav']\nGround Truth (first 3): ['TDXV', 'jfCBl', 'vOUX']\nRaw outputs (first 3): [[ 1 43 56 12 34 61 56 34 25 11  6 24 33 10 48 61  1 10 34 10  6 10  5 10\n   6 33 57 22 47 56 63 35]\n [ 1  1 34  1 32 10 43  1 11  6 63 32 33  1 43 32  1  1  1  1 10 22 42 34\n  30 25 12  1 10  1 63  1]\n [55 50  9 12  1 48  1  1 38 21  1 50  1  1 50 42 24  7 11 11 27 34 19 47\n  11 34 32  1 32  1 63 22]]\nInput length: 15, Label lengths: [4, 5, 4]\nEpoch 4/20, Loss: 33.3003\nToken distribution (Batch 8): {1: 10}\nValidation Loss: 33.0898\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['sIU', 'Dt', 'w19', 'h44Q', 'VjYzO']\nCurrent Learning Rate: 6.861297240664338e-08\nEpoch 5, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {35: 1, 1: 1}\nBatch 0, Gradient norm: 21.1130\nEpoch 5, Batch 0/66, Loss: 35.1859\nAvg Blank Probability: 0.0150\nSample predictions: ['kHiFjFk', 'kAj3kQ', 'akAIjH3ega']\nGround Truth (first 3): ['*m4W', 'FZD', '*glGz']\nRaw outputs (first 3): [[11 11  1 63 12 11 10 10  1 12 61 11 56 11  6 22 61 47 19 63 43 10 63  1\n  22  1 48  4 32 57 34 35]\n [34 27 11 12 10  1 10 42  1 34 34 19 32  1 50  4 10  1  1 11  1 63 16 11\n  34 32 34 24 56 20 11  1]\n [ 9 10 27 25  1 10 35 48  6 47  6 14  1 35 56 47 25  1 20  4  1 47 34 19\n  50 32 32  4 12 34  1 19]]\nInput length: 15, Label lengths: [4, 3, 5]\nToken distribution (Batch 31): {23: 1, 32: 1}\nBatch 10, Gradient norm: 14.4890\nEpoch 5, Batch 10/66, Loss: 28.6915\nAvg Blank Probability: 0.0150\nSample predictions: ['kjUsPVLilI', 'aUjljQaflr', 'kCpIkj']\nGround Truth (first 3): ['4ylL0', 'xDoww', 'Azb']\nRaw outputs (first 3): [[11  1 11  5 50 24 16  1  1 63 42  1 12  1  6 10  4  1 34 11 34  1  1  1\n   1  1 32  1 24 35 36 23]\n [10 47 29  1 25 48  1  7 22 47  1 10 35  0  1 55 23  1 24 34  4  4 16  1\n  56 11 46  6  1 34 56 32]\n [47 10 16 61 32 34 34  1 43  6 10 30  1 42 42  1 11  1  6  1 42 30 34 32\n  27 22 43 38 22  1 48  1]]\nInput length: 15, Label lengths: [5, 5, 3]\nToken distribution (Batch 31): {19: 1, 1: 1}\nBatch 20, Gradient norm: 18.4086\nEpoch 5, Batch 20/66, Loss: 32.9209\nAvg Blank Probability: 0.0147\nSample predictions: ['aUyHPa', 'fvaP', 'D3a28ia2k']\nGround Truth (first 3): ['FqIm', 'by', '-RY61']\nRaw outputs (first 3): [[ 1  6 30 63 56 13 24 22  1 11 35  1 43  1 14  1 47  1 24 10  4 43 10 42\n   4 16  5 19 56  1  1 19]\n [47 22 56 19 56  1 35 10 56 30 16 48 19  1 43  1  1 34  1 30 47 56  1 43\n  32  6 43 34 12  1  6  1]\n [25  1  1 22 56 10 35 10 48  6 11 11 22 56  6  4 32  1  1 34  1  1 27 34\n  10 22 12  1 10 32 22 50]]\nInput length: 15, Label lengths: [4, 2, 5]\nToken distribution (Batch 31): {4: 1, 43: 2, 63: 1, 6: 1, 5: 2, 32: 1, 10: 1, 28: 1}\nBatch 30, Gradient norm: 20.5617\nEpoch 5, Batch 30/66, Loss: 35.1605\nAvg Blank Probability: 0.0151\nSample predictions: ['kHavlHU', 'jaj', 'HkjarfsFxH']\nGround Truth (first 3): ['uJJX-', 'Pv', 'xM7tm']\nRaw outputs (first 3): [[11 10 34  1 10 11 12 50  4 50 47  1  4 22  1  1 34 12 24  1  4 61  6 10\n  11 12 19  1  6 34  1  4]\n [34 10 11 34 11  4 32  6 34 42 29 42  6 11  1 14  4  1 63 10  6 19  1 33\n  14 22  1 47 10 24 42 43]\n [34  1 10 32  1 27  1 27 34 19 28  1 22 25 32  1 10  1 19 32 34  4 43 42\n  11  1 10 44 12 27 19 63]]\nInput length: 15, Label lengths: [5, 2, 5]\nToken distribution (Batch 31): {63: 1, 34: 1, 24: 1, 50: 1}\nBatch 40, Gradient norm: 343.3823\nEpoch 5, Batch 40/66, Loss: 31.3883\nAvg Blank Probability: 0.0149\nSample predictions: ['aHFgsIla', 'avf3VjH', 'kjtDsH']\nGround Truth (first 3): ['ZXrt', '7SGL', 'Q5C']\nRaw outputs (first 3): [[ 1  1 11 42 34 56  1 34 10 43 10 63 25 44  1 11  1 24 25  1  1  6  1 10\n  34 56 10 42 11 33 42 63]\n [34 22 10 43 43 32 34  1 47  4 24 18 43 30 32 43 16 34 35 12 56 47 11 34\n   1 43  1 10 48 32  1 34]\n [32  6 20 22  6 19 47 10 22  5 56 22 34  1 35 34 22  1 22  1 19 42  1 35\n   1 35 10 30  1 48 47 24]]\nInput length: 15, Label lengths: [4, 4, 3]\nToken distribution (Batch 31): {22: 1, 1: 3, 35: 1, 12: 1, 5: 1, 11: 1}\nBatch 50, Gradient norm: 16.3801\nEpoch 5, Batch 50/66, Loss: 29.4339\nAvg Blank Probability: 0.0150\nSample predictions: ['vIUh', '4j', 'jPa2P']\nGround Truth (first 3): ['36', 'p', 'L2B']\nRaw outputs (first 3): [[22 57 10 43  1 18  1  1 10 63 18 32 10 12 42  1  1  1 43  4 24 56 47 10\n   1 13 42  1 34 11 56 22]\n [35 10 10 10 30 47  6  1  1  1  1 11 10 63 32  7 11  5 12 63  4 10 56 47\n  11  4 22 47 35 27  6  1]\n [47 32 42  1 11 48  1  1 10 14 10  1 19 20 35 32 43 11 48 56  1  5  5 43\n  55 46 10 57  1  1 10 35]]\nInput length: 15, Label lengths: [2, 1, 3]\nToken distribution (Batch 31): {61: 1, 1: 2, 34: 1, 25: 1, 47: 2, 7: 1}\nBatch 60, Gradient norm: 18.2371\nEpoch 5, Batch 60/66, Loss: 31.3765\nAvg Blank Probability: 0.0151\nSample predictions: ['pa', 'PjDijrA-l', 'spHjUpjHjv']\nGround Truth (first 3): ['4z', 'b4YLU', 'VjYzO']\nRaw outputs (first 3): [[16 42 19 34  5 43  4 12 12 43 56  1  6 50 61  1 10  1 10 16  1 42 48 10\n  32 10 11 13  6  1  6 61]\n [ 1 10 16 63 47 10 19 32  1 19  1  4 25 22 10  1  1  1 50  1 47  4 10 11\n   1  1  6 32  6  1 34  1]\n [ 1 10 34  1 19  1  1 19 13 34 16 32 43 35 11 10 57 42 23 10  1  1 11  1\n  10 19  6  1 45 47  4 34]]\nInput length: 15, Label lengths: [2, 5, 5]\nEpoch 5/20, Loss: 32.9040\nToken distribution (Batch 8): {1: 8}\nValidation Loss: 34.9586\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['rFyEG', '8', 'A5', 'F*y3i', 'K']\nCurrent Learning Rate: 8.747553917935012e-08\nEpoch 6, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {56: 1, 11: 1, 1: 3, 47: 1}\nBatch 0, Gradient norm: 1515.0116\nEpoch 6, Batch 0/66, Loss: 35.1266\nAvg Blank Probability: 0.0148\nSample predictions: ['fa', 'jwValgaH', 'aVU2']\nGround Truth (first 3): ['4F', 'tKd4F', 'IC']\nRaw outputs (first 3): [[ 6 10  1  1 16  4 63 33 34 10  4 32 11  1  1 19  1 11 50 11 12 10 22 56\n   4 24 42 34 10 63 32 56]\n [ 1 10 48 22  1 10 12 10 11  6 27 48  1 32  1 22  5 63  7  1 57  1 56 10\n  10 61  4 12 35  1 11 11]\n [ 1 23 47 32  6  1  1 19 32  1 32  4 22 25 32  1 22 63 10 43 32 27  1 56\n   8  6 31 50 19  1 16  1]]\nInput length: 15, Label lengths: [2, 5, 2]\nToken distribution (Batch 31): {1: 1, 4: 1, 56: 1, 32: 1}\nBatch 10, Gradient norm: 27.6921\nEpoch 6, Batch 10/66, Loss: 31.2333\nAvg Blank Probability: 0.0148\nSample predictions: ['auU', 'xHF2VFap', 'v-mj']\nGround Truth (first 3): ['p9', '7SGL', 'yN']\nRaw outputs (first 3): [[ 1 24 22 10 42  4 35 25  1 57  6 57 10 63 47 63  6 35 34  1  6 56 32  1\n   1 35 16 47 10 35 14  1]\n [ 1 34 63 16 48 56 22 24 55  6  1  1 34 56  1 11  1 34 35 55 10 10 56 12\n  11 13 34  1  1 11 47  4]\n [21 32 13 10 11 10 34 35  1 25  1 22 47 61 22 32 23 10 10 12  1 25 47  1\n  35 16 22  6  1 12 22 56]]\nInput length: 15, Label lengths: [2, 4, 2]\nToken distribution (Batch 31): {34: 1, 55: 1, 35: 1, 42: 2, 19: 1, 25: 1, 43: 1, 1: 2}\nBatch 20, Gradient norm: 47.9465\nEpoch 6, Batch 20/66, Loss: 32.7920\nAvg Blank Probability: 0.0147\nSample predictions: ['-aAlPk', 'dfUl', 'ajAaIH']\nGround Truth (first 3): ['Os7', 'RS', '7lDV']\nRaw outputs (first 3): [[63  4  1 12 56 42  1 12  1 35 35 32 63 22 42  1 11 20 10 22  4 55 63 25\n   1 11 33 22  6 42  5 34]\n [ 1  6  0 22 22 10 10 42  1 35  9 10 10 59 10 19 35 11  6 50  1 34 32 55\n  47 36 12 42 14 10 55 55]\n [27 47 10 12 11  1  7 35  1 43 42 25  1 35  1 63 35 34 10 34 12  1 32  1\n  42 48  1 10  1 56  1 35]]\nInput length: 15, Label lengths: [3, 2, 4]\nToken distribution (Batch 31): {34: 2, 24: 1, 27: 1, 21: 1, 4: 1, 47: 1, 55: 1}\nBatch 30, Gradient norm: 19.2152\nEpoch 6, Batch 30/66, Loss: 33.6937\nAvg Blank Probability: 0.0149\nSample predictions: ['ca', 'HAa2H', 'jpayaydk']\nGround Truth (first 3): ['kX', 'uHJ', 'AaGy']\nRaw outputs (first 3): [[ 3 34 10 16 56 18 63 34  1  4 14 11 34 42 34 34  1 32  1 12  1 12 10 34\n   1 56 10 10 56  1 34 34]\n [ 1 27 16 34  1  1 34  1 50  1 10  1  1 10 56  1 40 56  1 22 10  1 11 10\n   6 34  9 43 12 47 48 34]\n [ 1  1  1 12 56 32  6 12  1 32 36  1  1 56  1 50 34 55 56  1  4  1 12  5\n  32  6 22  1 19 42 43 24]]\nInput length: 15, Label lengths: [2, 3, 4]\nToken distribution (Batch 31): {63: 1, 16: 1, 23: 1, 5: 1}\nBatch 40, Gradient norm: 14.2623\nEpoch 6, Batch 40/66, Loss: 28.3273\nAvg Blank Probability: 0.0150\nSample predictions: ['aAsPsa', 'aIdak-', 'j3v2elxjd4']\nGround Truth (first 3): ['S65', '8NA', 'dX*TW']\nRaw outputs (first 3): [[ 1  1 10  1 24 47 19  1 32  1 12 35 27 42 56 12  1 11  6 20 63 32 10 32\n  11 34  4 42 19 11 20 63]\n [27 35 56 35 19 34 12 47  1 50 19 61 47 42 32 22 50 48 12 56 11 19 56  1\n  32 30 32 42 56 42 23 16]\n [19  4 22  1 10  1 19  1 32 24 43  1 42 42  1  1  1 12 32 48 11 43 47 43\n   1  1  1 19 19 56 23 23]]\nInput length: 15, Label lengths: [3, 3, 5]\nToken distribution (Batch 31): {32: 3, 4: 1, 24: 1, 19: 1}\nBatch 50, Gradient norm: 22.9887\nEpoch 6, Batch 50/66, Loss: 37.8682\nAvg Blank Probability: 0.0149\nSample predictions: ['a3PHFj', 'x2vIdpjHjU', 'ak']\nGround Truth (first 3): ['sLL', 'c6jM0', 'I']\nRaw outputs (first 3): [[ 1 24  1 14  1 32 43 48 12 34 34 11 10 42 22 50 34 29 11 11 13  4 32 30\n   1  1  1 48  1 22 56 32]\n [56 55 11  1 48 29 32  1 42 10  1  4 10 50 56 42 10 56 56  1 21  1  9  4\n  12 42 32  1 42 34 32  4]\n [42 22  1 19 63 63 46  1  1 19 19 23 43 50 57 10  4  1 35 12 34 35 42 10\n  16  1  1 19 11 11 10 24]]\nInput length: 15, Label lengths: [3, 5, 1]\nToken distribution (Batch 31): {1: 2, 43: 1, 34: 1, 19: 1, 23: 1}\nBatch 60, Gradient norm: 19.6834\nEpoch 6, Batch 60/66, Loss: 34.1063\nAvg Blank Probability: 0.0151\nSample predictions: ['-t', '-aFjAP', 'FIsd']\nGround Truth (first 3): ['R', 'GHo', 'YT']\nRaw outputs (first 3): [[63 63 32  1 19  1  1 32 32 63  6 63 34 35 10  1 24 29  1 19 10 34 10  1\n  32 10 50 42 10  1  1  1]\n [20  1 35 11 43 10 32 12  6 25 32  1 19 55 34 22  4 36  6 27  1 10 25 56\n   1 34  1 42  1 12 42  1]\n [63 32 19 12 43 11 32 25  1 56  5 32  6  6 19 27 10  5  1 12 27 34 11 47\n  47 32  1 48 12 27 34 43]]\nInput length: 15, Label lengths: [1, 3, 2]\nEpoch 6/20, Loss: 33.1464\nToken distribution (Batch 8): {1: 6}\nValidation Loss: 32.8094\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['CFS', 'efa8', 'Z*', 'JkOF3', '55Gq']\nCurrent Learning Rate: 1.0672901478267059e-07\nEpoch 7, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {1: 1, 13: 1}\nBatch 0, Gradient norm: 21.9391\nEpoch 7, Batch 0/66, Loss: 36.1386\nAvg Blank Probability: 0.0150\nSample predictions: ['aF4jas', 'aV-alays', 'HfX']\nGround Truth (first 3): ['jNX', '68hng', 'Pv']\nRaw outputs (first 3): [[ 1  1 34 22  1  1  5 35 34  6  1  1 10  1 10 46 43 11 10 47 32 14  6 10\n   1  1  9  6  1  1 25  1]\n [32 48  6 30 48 43 19 47  6 30  1 42 11 11  1  1 10  7  1 35  4 56 34 56\n  27 25 10 34 22  1 19 13]\n [57 63 50 22  1 63 50  1 30 16  4 34  6 10 10 19 19 20  1  9 48  6  1 34\n   4 61 35  1 56 47 32  4]]\nInput length: 15, Label lengths: [3, 5, 2]\nToken distribution (Batch 31): {1: 2, 11: 1, 27: 1, 22: 2, 10: 2, 32: 1, 25: 1}\nBatch 10, Gradient norm: 21.7241\nEpoch 7, Batch 10/66, Loss: 36.8910\nAvg Blank Probability: 0.0151\nSample predictions: ['jpsjaj3Vf', 'aHlpsa3', '-Pfl']\nGround Truth (first 3): ['E0V2k', 'VudB', 'Q*']\nRaw outputs (first 3): [[10  1 63 34 20 19 20 19  1 35 47 34 50 32  1  1 10 12 19 35 11 19 11 48\n   1 56 11  1 10 34 10  1]\n [16  1 42 22 32  1 23 47 34 34  5  4 46 27 12 11 34  4  1  1 42  1 36  8\n   5 24 18  1 56  1 10  1]\n [19 34  6  4  1  6 42  1  1  1 32 10  1  4 30 47  1 34  4  1  1 43 47 30\n  30  5  1 47 40 32  1 11]]\nInput length: 15, Label lengths: [5, 4, 2]\nToken distribution (Batch 31): {19: 1, 22: 1, 10: 1, 17: 1, 34: 2, 1: 1, 6: 1}\nBatch 20, Gradient norm: 16.7939\nEpoch 7, Batch 20/66, Loss: 27.4184\nAvg Blank Probability: 0.0150\nSample predictions: ['UvPFs', 'as', 'mylHID']\nGround Truth (first 3): ['Ufo', 'a', 'KV2']\nRaw outputs (first 3): [[47  1 13 32 42 34 32  6  1  1 43 16  1  1 50 61 23  1 10 56  1  6  4 22\n  56 25  4 23 56  1 34 19]\n [47 19 25  1  1 34 47 10  1 22 22 32 35  1 57 12 50 20 22 56 22 21 11 34\n  22  1 35 55  1 56 21 22]\n [22 24 12 35  1  4 32 10 11  1  1  1  1 50 33 61 12 27 35 55 42 19 22  6\n  63 22 47 34  1  1  1 10]]\nInput length: 15, Label lengths: [3, 1, 3]\nToken distribution (Batch 31): {19: 1, 34: 1, 33: 1, 32: 1, 1: 1, 50: 1}\nBatch 30, Gradient norm: 18.1366\nEpoch 7, Batch 30/66, Loss: 31.8381\nAvg Blank Probability: 0.0149\nSample predictions: ['lasFaeUFdw', 'ajaIas', '-adF2vU']\nGround Truth (first 3): ['U7Dtf', 'ZxKU', 'dWi3']\nRaw outputs (first 3): [[12  1 63 43  1 10 34 11 47 25  6 12 25 50 10  4 56 10 10 12  1 10 13 12\n   1 10  1 12  6 56 22 19]\n [ 1 10  1 36  1  1 23 22 34 19 42 24 19  1 12 56 10 11 30  1 56 63 13 43\n  11  1 16  1  1 16  6 34]\n [19  1  1  1 22 42 10 34  1  1  1 11 47 10 34 48 35 43 22 42  4 43 47 10\n  34 10  4 35  1 12 56 33]]\nInput length: 15, Label lengths: [5, 4, 4]\nToken distribution (Batch 31): {22: 1, 18: 1}\nBatch 40, Gradient norm: 20.0193\nEpoch 7, Batch 40/66, Loss: 29.7446\nAvg Blank Probability: 0.0151\nSample predictions: ['afUaFse-Q', 'HIsUa3v3va', 'paIskVQAU']\nGround Truth (first 3): ['uJJX-', 'wSqWA', 'xl1Yx']\nRaw outputs (first 3): [[ 1 34 16 11 34 35 34  1  1  1  1 43  4 10 47 10  1 56 10 47 10 47  1 11\n  16  1 56  1  4 34  1 22]\n [ 6 35  1 56  1 25 35 24  5  4  1 30  1 56 46  4 34 10 33 47  1 55 36  4\n  43 10  6 20 35 28  1 18]\n [47 19 35 51  4 30 10 34  1 27 50 47  1  1 10 32  1  1 14  1 35 25  4 34\n   1 63  1 16 47 42 56 22]]\nInput length: 15, Label lengths: [5, 5, 5]\nToken distribution (Batch 31): {56: 2}\nBatch 50, Gradient norm: 19.6441\nEpoch 7, Batch 50/66, Loss: 33.6575\nAvg Blank Probability: 0.0151\nSample predictions: ['HaHgiate', 'HaDaFa', 's-HysIFE']\nGround Truth (first 3): ['nQD9O', 'L2B', 'bFM5']\nRaw outputs (first 3): [[34 34 19 47 32 10 25  1  1  9  1 11 11 11 63  1 59 10 10 56 56 34 11 63\n  55  5  8  1  1  1  1 56]\n [ 1  1 63 22 12 12 46 60 32 11 34 18 16 35 10 56 10 43  1 27 56 47 24 16\n  55 43  1  1  6 34 56 56]\n [34 30 34 32 50  5 60  4  1 27 27 19 27  1 56 55  5 48  1 19 48  1  5  1\n  24  1 56  4 34  1 19 56]]\nInput length: 15, Label lengths: [5, 3, 4]\nToken distribution (Batch 31): {43: 1, 47: 1, 6: 1, 35: 1, 50: 1, 19: 1, 1: 1, 42: 1}\nBatch 60, Gradient norm: 19.0089\nEpoch 7, Batch 60/66, Loss: 33.1677\nAvg Blank Probability: 0.0152\nSample predictions: ['ICNav', 'kFlI', 'peAsATdyAs']\nGround Truth (first 3): ['RD6', 'iF', 'n3jVe']\nRaw outputs (first 3): [[35 11 16 12  1  1 47  1 22 10 42 10 24 20  1 11  1 11 11 11 32 10 32 56\n   1 27 32  5 22  1 18 43]\n [29 32  5 28 10 47 22 22 57  4  1 35 56  1 43 56 10 10  1  1  4 56  6  1\n  10 57 34 43  1 28  4 47]\n [40 12 27 50  1 10  1 32 12 50  1 30 27 47 30 27 11 30 27 24  1 10 35 30\n   1  1 43 34 32 50 21  6]]\nInput length: 15, Label lengths: [3, 2, 5]\nEpoch 7/20, Loss: 32.8171\nToken distribution (Batch 8): {1: 4}\nValidation Loss: 34.0585\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['Yvw', 'j4CGh', 'L', 'PuL', 'Ocf0']\nCurrent Learning Rate: 1.2657197398119848e-07\nEpoch 8, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {22: 1, 6: 1, 56: 1, 42: 1}\nBatch 0, Gradient norm: 15.2899\nEpoch 8, Batch 0/66, Loss: 29.5273\nAvg Blank Probability: 0.0152\nSample predictions: ['xAIadPyvr', '3mPV', 'daVj']\nGround Truth (first 3): ['MJOdz', '05', '5I8']\nRaw outputs (first 3): [[24 56  4  1 34 35 25 56  1 48 56 22 10 32 11 35 34  1  1  1  1  1 35 34\n  32 22 56 43 42 19  4 22]\n [27 13  1 22 24 47 34 10  1 34  1  4 47 10 56 35 35  1 34 47  1 50 11 11\n  22 43 34 12  1 42  1  6]\n [35 42 48 34  5 43 12 56  7 22 19 55 43  1 11 12 50  1  7  1  1  5  1  6\n  22  6  1 27 32 32  1 56]]\nInput length: 15, Label lengths: [5, 2, 3]\nToken distribution (Batch 31): {32: 1, 1: 1}\nBatch 10, Gradient norm: 21.3730\nEpoch 8, Batch 10/66, Loss: 31.6680\nAvg Blank Probability: 0.0152\nSample predictions: ['dFPzh3Gpa', 'FHy', '-kjs323']\nGround Truth (first 3): ['t0K4D', 'TK', 'ALMJ']\nRaw outputs (first 3): [[ 4 32 63  1 43 46 10  4 10 12 50 16 57  1 24 35 11 12  1  6 12  1 10 32\n  34  1 47 12  6 11  6 32]\n [32 34 11  9 19 12 43  6 12 42 11 22 63 11 35 11 38 32 22 19 32  1 32 43\n  19  1 63 47 42  1 11  1]\n [42 25 10 20 34 10 47  5 10  6 10  1 10 11  1 32 11 35 40  6 24 56  1 50\n  19  1  1 10  4 43 11 12]]\nInput length: 15, Label lengths: [5, 2, 4]\nToken distribution (Batch 31): {11: 1, 6: 1, 63: 1, 56: 2, 12: 1, 5: 1, 7: 1}\nBatch 20, Gradient norm: 17.6096\nEpoch 8, Batch 20/66, Loss: 31.7835\nAvg Blank Probability: 0.0149\nSample predictions: ['dvaUf', 'UQk2', 'deUa']\nGround Truth (first 3): ['T-F', '9W', 'IG']\nRaw outputs (first 3): [[ 4 47  4  1  4 19 34 25  1 63 61 56 12 10  1 25 19 10  4  6 11 32 16  1\n  10  4  5 10 47 25 10 11]\n [22 43  5 22 28 20 10 34  1  1 11 32  4 32  6  1 10 27 32 12  1 57  1 32\n   1  1 12 50 32  5 19  6]\n [ 1 11 47 35 19 10 10 34  1 10 50 43 32 47  5 43 61 27  1  1 34  1 10 19\n  11 19 16 43 45  1  1 63]]\nInput length: 15, Label lengths: [3, 2, 2]\nToken distribution (Batch 31): {34: 1, 48: 1, 47: 1, 1: 2, 18: 1, 25: 1, 12: 1}\nBatch 30, Gradient norm: 58.7834\nEpoch 8, Batch 30/66, Loss: 31.3616\nAvg Blank Probability: 0.0151\nSample predictions: ['jajva-', 'jajI-', '8jadfj']\nGround Truth (first 3): ['KqsU', 'F6Y', '8MW']\nRaw outputs (first 3): [[10 10 61 10 11  1 10  1 19 25 35 22 32 42 22 35 10  6 19 11 32 56 12  4\n  56 24  1 57 16 10  6 34]\n [ 1  1 10 34  1 22 12 50  1 32  1 11 10 47 56 30 42 10 56 63 12 12  1 20\n  10 19 10  1 12 19 10 48]\n [10 10  1  6  6  5 12 61 26 18 50 10 13 32 19 47 16  1  1 32  1 56  1 22\n  36 22  1  1  1  1 48 47]]\nInput length: 15, Label lengths: [4, 3, 3]\nToken distribution (Batch 31): {1: 1, 32: 1}\nBatch 40, Gradient norm: 19.7365\nEpoch 8, Batch 40/66, Loss: 35.1848\nAvg Blank Probability: 0.0151\nSample predictions: ['jQjsxg', '-j2dj', 'ksHdDyjy3j']\nGround Truth (first 3): ['lAV', '5Lpu', 'L-eej']\nRaw outputs (first 3): [[10 63 11  1  5  1  1  1 63 50 34  5  6  6 10  4 22  1 19 51  1 12  4 19\n  12 50 30  5 32 63  4  1]\n [43 10 19 10 34 10  1  6  1  5 56  1  1  1 47 34 43 32 29 47 56 11 22  1\n  22 56 22 27  1  1  5 32]\n [10 55 34  6  1 35 20 32 11 19 42  4  4 42 34  6 48 20 55 63 32 24  1 48\n   5  5  1 35  1 34  1 10]]\nInput length: 15, Label lengths: [3, 4, 5]\nToken distribution (Batch 31): {56: 1, 34: 2, 1: 2, 32: 2, 24: 1, 10: 1, 11: 1}\nBatch 50, Gradient norm: 76.6068\nEpoch 8, Batch 50/66, Loss: 32.9444\nAvg Blank Probability: 0.0150\nSample predictions: ['Qv', 'fkga', 'kX']\nGround Truth (first 3): ['G', 'Q*', 'K']\nRaw outputs (first 3): [[43  6 11 12 32 43 34  1 11 11 10 19  4  1  1 32 34  1  9 12 45 63 19  1\n  10 42  1 12 34 25 42 56]\n [22 11 50 33 35  4 11 47 11 27  1  4  1  1 10  5  4 33 19  1 42 34  1 11\n  47  6 10 34  1  7 22 34]\n [48  7 10  1 34 33 35 32 12 55 21 56 34 55 43  1 60 12 56  6 12 34 47 32\n  19 11 43 34 61 10 20 34]]\nInput length: 15, Label lengths: [1, 2, 1]\nToken distribution (Batch 31): {34: 1, 50: 1, 19: 1, 35: 1, 12: 1, 32: 1, 42: 1, 7: 1, 5: 1, 25: 1}\nBatch 60, Gradient norm: 26.1144\nEpoch 8, Batch 60/66, Loss: 40.1987\nAvg Blank Probability: 0.0151\nSample predictions: ['ja', 'ay3QfeiaU', 'aj']\nGround Truth (first 3): ['l', 'ZrSBq', 'c']\nRaw outputs (first 3): [[10  1  1 32 25  4 61  4 50 10  1  6  1 35  9  1  1 27  1 63  1 10  1 30\n  27  1 50 27 62 19 10 34]\n [ 1 25 10 11 56  1 11 43 16  1 33 12 19 10 22 63 33  1  5  1 42 10 10 32\n   1 10 22 63 19 13 19 50]\n [24 56 27 34 27  1 22 19 56  1  1 32 50 11 12 34 19  1 14  4 56 43  0  1\n  10  6  1 22 18  4 19 19]]\nInput length: 15, Label lengths: [1, 5, 1]\nEpoch 8/20, Loss: 33.4894\nToken distribution (Batch 8): {1: 8}\nValidation Loss: 34.0241\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['r*dU-', 'On', '2hT', 'iE3z5', 'q']\nCurrent Learning Rate: 1.472427795820856e-07\nEpoch 9, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {47: 1, 42: 1, 10: 2, 50: 1, 1: 1}\nBatch 0, Gradient norm: 220.0254\nEpoch 9, Batch 0/66, Loss: 34.0060\nAvg Blank Probability: 0.0151\nSample predictions: ['4V', 'aFIjg', 'HFXjajza']\nGround Truth (first 3): ['HT', 'Hlb', 'L7Vk']\nRaw outputs (first 3): [[57  1 34 32 19 10 11 33 43 63  1 24 22 34 10 48 63 10 47 16  1 22  4 22\n  11  1  1 10  1 56  1 47]\n [57  1 32  5  1  1 25 10  0 30  1 22 12 42 10  1  6 42  1 11 56 19 10 11\n   1 42  5  1 56 32 42 42]\n [57 32 50 56 35 10 22 56 34 11  1  6  1 63 11  1 11  1 19 43  1 50  1  1\n   6  1 12  6  1 10 32 10]]\nInput length: 15, Label lengths: [2, 3, 4]\nToken distribution (Batch 31): {1: 5, 7: 1, 27: 2, 47: 1, 56: 1}\nBatch 10, Gradient norm: 1569.8843\nEpoch 9, Batch 10/66, Loss: 34.4506\nAvg Blank Probability: 0.0154\nSample predictions: ['ada', 'klk2azVz', '-Haj3ea']\nGround Truth (first 3): ['ad', 'mQxk', 'YhVSr']\nRaw outputs (first 3): [[ 1 11 63 27 43 12 63 56 63 27  1 57  1 11  1 50 20  1  1  4 12 43  1 43\n  30 11 10  1  6  4 19  1]\n [ 4 12 34 19  1 33 35  1  7  6 22  4 34 11  1  1 56 19  6 17 35  1 50 47\n  11  1 24 24 34  1  1  1]\n [ 1 11  1 19 34 47 13 13  1 33  4 43 56 14 56  1 19  4 32 22 11  5 28 43\n  42  1  1 43 11 32 40  7]]\nInput length: 15, Label lengths: [2, 4, 5]\nToken distribution (Batch 31): {1: 1, 19: 1}\nBatch 20, Gradient norm: 545.7123\nEpoch 9, Batch 20/66, Loss: 30.5759\nAvg Blank Probability: 0.0154\nSample predictions: ['HafaHF', 'jUFAjIHa', 'jsaIdkDQ']\nGround Truth (first 3): ['0*T', '-zp9', 'DwBi']\nRaw outputs (first 3): [[34 10 10  1  1 50  4  6  1 30  6 25 56 42 50 16  1 17 10 35  6  1 24 43\n  19 47 22 11 63 19 50  1]\n [ 1 47 19  1  1  6 35 34 10 12  1  1 27 11 22  1  1 22 10  6  4 42  6  4\n  19 12 32  1  1 57 35 19]\n [ 6 32  1 47 42 55 35 56 32  1  1  4 10 34 47 35  1 11 10  1 56 22  1  4\n   1 34 34  1 56  6 11 32]]\nInput length: 15, Label lengths: [3, 4, 4]\nToken distribution (Batch 31): {32: 1, 52: 1, 22: 2, 34: 1, 42: 2, 26: 1}\nBatch 30, Gradient norm: 53.8111\nEpoch 9, Batch 30/66, Loss: 29.7116\nAvg Blank Probability: 0.0151\nSample predictions: ['Fxke', '3Qa', '4jQaU']\nGround Truth (first 3): ['dm', 's0', 'K2s']\nRaw outputs (first 3): [[32 56 57  1  1 11  4  4 12 10 43  5 12  1 16 24  1 30 24 11 63  1  1  4\n  47 47 57 10 10 61 43 32]\n [24 43 10  1 34 27  6  1 22  9 47  5  1  1 10  4 24 34  6 12  4  6 42  1\n  10 35 12 60 12 35 32 52]\n [11  1 10  1 32  4 10 61 47  1  1 10 25  5 60 12 47 32  6  0 11 48  5  6\n  57 63  1 50 11 47 22 22]]\nInput length: 15, Label lengths: [2, 2, 3]\nToken distribution (Batch 31): {32: 1, 19: 1}\nBatch 40, Gradient norm: 18.9009\nEpoch 9, Batch 40/66, Loss: 33.3472\nAvg Blank Probability: 0.0151\nSample predictions: ['Pa', 'lasfA', 'sU']\nGround Truth (first 3): ['z', 'g8X', 'Z']\nRaw outputs (first 3): [[42 12 19 16 24  1 12 13  6 34  1 34 42 27 47 10 48 47 10 11  1 10 12 34\n  19 11 34 10 48  1 23 32]\n [ 1  1 47 11 13 25 25  1 42 10 11 56 27  6 30 32  1 47 56 11 46 35 63  4\n   4  1 19 11 19 32 19 19]\n [10  1 34  1  1  1 30  4 32 27  1  1 32 47 56  1  1 34  7 19  4  1 11 55\n  34 35 42  5 32 46 10 48]]\nInput length: 15, Label lengths: [1, 3, 1]\nToken distribution (Batch 31): {22: 1, 63: 1}\nBatch 50, Gradient norm: 39.5280\nEpoch 9, Batch 50/66, Loss: 35.2547\nAvg Blank Probability: 0.0150\nSample predictions: ['aXa4PIlX', '-Us3ava', 'dljFde']\nGround Truth (first 3): ['KbANC', 'xj3G', 'T5Y']\nRaw outputs (first 3): [[ 1 63  4 43  1 10  1 56 22 56 22  1  1  1 19  1  5 32 11 10 10 46 34 47\n  34  4 22 47  1 10  1 22]\n [50 47 12  6 10  1 47 34  1  9 56 19 11  1 34 34  1  6 27 42  1  4 11 30\n  48 19  4 32 63 11 14 63]\n [ 1 19 10 50 19 55 19 10 22 43  1 42  1 32 35 32 34 34 19 30 61 27 12 11\n   5 47 30 32  1 19 28 10]]\nInput length: 15, Label lengths: [5, 4, 3]\nToken distribution (Batch 31): {1: 3, 5: 1, 11: 1, 48: 1, 56: 1, 10: 1}\nBatch 60, Gradient norm: 18.3052\nEpoch 9, Batch 60/66, Loss: 30.1341\nAvg Blank Probability: 0.0152\nSample predictions: ['HX', 'aX', 'alAy']\nGround Truth (first 3): ['8', 'w1', 'Mk']\nRaw outputs (first 3): [[34  1  1  1 42 63  1  6 63 19  1 34 12 48 47 25 19 10  1 43 34 10  6  1\n   4 14 10 11 42 32  6  1]\n [50  1 12 11  1 47 10  0 24  6 10  1  1 43  1  4 19 10 32  1  1 25 35  1\n  10 12 21  1 30  6 48  1]\n [33  1 27 10 16 10 33 22  1 32 34  5 14 35 10  1 22 32 16 56  1  4 32 12\n  19 42 10  1  1 19 34  1]]\nInput length: 15, Label lengths: [1, 2, 2]\nEpoch 9/20, Loss: 33.1872\nToken distribution (Batch 8): {1: 2}\nValidation Loss: 33.1556\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['*B', 'EG', 'L2B', 'XSpH', 'DK']\nCurrent Learning Rate: 1.690388570270353e-07\nEpoch 10, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {24: 1, 56: 2, 5: 1, 12: 1, 50: 1, 9: 1, 4: 1}\nBatch 0, Gradient norm: 13.1696\nEpoch 10, Batch 0/66, Loss: 26.9573\nAvg Blank Probability: 0.0153\nSample predictions: ['dUaDFa', 'fIXjaU3a', 'aA']\nGround Truth (first 3): ['3U6', 'Nsc6', 'p']\nRaw outputs (first 3): [[ 4  6  0 10 12 34 34 12 56 10  1  6  1 27 42 63 42 30  1  6 11 20  1 32\n   1 27 48 42  4 34  1 24]\n [47 35 27  4 22  4  4 34  5  1 19 10  1  1 24 11 12 22 11 42 10 35 47 14\n  43  1 48 11 22 34 47 56]\n [ 1 50 12 32 47 19  1 47 16  1 43  1 25 23  5 11  1 11 22 11 50 42 11  1\n  48 10 30 35 55  7  4  5]]\nInput length: 15, Label lengths: [3, 4, 1]\nToken distribution (Batch 31): {11: 1, 32: 1, 34: 1, 63: 1}\nBatch 10, Gradient norm: 17.3009\nEpoch 10, Batch 10/66, Loss: 31.3251\nAvg Blank Probability: 0.0154\nSample predictions: ['x3j3xIkdP', 'AU', '3a']\nGround Truth (first 3): ['ahDQZ', 'A', 'f']\nRaw outputs (first 3): [[24 27 56 11 12 10  1 12 50  1  1 34  1 34  1 47  4  1 43 34 19 42 30  0\n  20  1  4 12 12 10 61 11]\n [56 47  1 43 47 24 12 63 42  4 47 27  1 22  1 34 47 25 47 11 34 14 47  4\n   1 43 21 32  4 27 10 32]\n [10 47  1 13 47 23 34 32 47  6 34 32  6 34 32 32 21 10  4 35  1 47 27  5\n  47  1 25 55 25 42  1 34]]\nInput length: 15, Label lengths: [5, 1, 1]\nToken distribution (Batch 31): {4: 1, 14: 1, 32: 1, 13: 1, 1: 1, 12: 1}\nBatch 20, Gradient norm: 608.3057\nEpoch 10, Batch 20/66, Loss: 31.0871\nAvg Blank Probability: 0.0153\nSample predictions: ['aU4UdAH', '3yeAFaUd', 'aIjav2k']\nGround Truth (first 3): ['o68L', 'bneT', 'O5al']\nRaw outputs (first 3): [[ 1 56  1  1 32  1 23 56  1 10 43 33  1  4 55 12 23 56 27 47 42  1 22 56\n   1 12 22 20 10  6  1  4]\n [ 1 25 35 25  6 12 11 19 19 63  1 10  1  1  4 42 10 12  5  1 42  1 50 55\n  27  2  6 27  1 63  1 14]\n [47  5 10  1 10  6 47 10  1 22  1 47 63 32  4 43 10  1  1 55 42 25 19 32\n  22  1 25 47  1 10 12 32]]\nInput length: 15, Label lengths: [4, 4, 4]\nToken distribution (Batch 31): {19: 1, 51: 1, 1: 1, 10: 1}\nBatch 30, Gradient norm: 19.9919\nEpoch 10, Batch 30/66, Loss: 34.6414\nAvg Blank Probability: 0.0152\nSample predictions: ['kFfkj2tjaX', 'vHaX43jH3H', 'DP2kF2']\nGround Truth (first 3): ['j-D*x', 'c8sos', 'FLP']\nRaw outputs (first 3): [[11 22 30 32 11 32  4 18  6  6 11 10  1 10  6 10 43 63 10 32 12 34  1  1\n  10 11 32 56 10 22 47 19]\n [32 34 42 19 11 11 34 24  5  6 10 16 48  4 56  5 25 10 47 55 12 10 47  6\n   1  1  1 43 43  1 63 51]\n [ 6  1 55 63  1 10 48 42 33  5  1 10 25 32 21 55 32  1  1 35 11 43 63 63\n  34 22 22 11 43 12 50  1]]\nInput length: 15, Label lengths: [5, 5, 3]\nToken distribution (Batch 31): {47: 1, 1: 1, 10: 1, 50: 1, 30: 1, 32: 1}\nBatch 40, Gradient norm: 23.2394\nEpoch 10, Batch 40/66, Loss: 33.4165\nAvg Blank Probability: 0.0153\nSample predictions: ['-aHVHjQ', 'jTadHy', 'HaFIFaF']\nGround Truth (first 3): ['hACa', '5Za', 'oiUh']\nRaw outputs (first 3): [[63 10 34 30 10 35  1  1  1  1 30 11 56 43 10 42 11 56 10 34 10  1 56 47\n  25 63  1  6 34 48 10 47]\n [ 1 46  1 19 32 25  1 22 16 19 42 27  1 19 32 34 22 56 10 19 56 47  1 22\n  56 47 10 47 57  1 43  1]\n [ 1  1 32  1 18 55  1 22 43 11 48 48  1  6 14 11  1  1 24 34 20 47 34 48\n  43 43 47 34  1 28 56 10]]\nInput length: 15, Label lengths: [4, 3, 4]\nToken distribution (Batch 31): {14: 1, 1: 1}\nBatch 50, Gradient norm: 638.2493\nEpoch 10, Batch 50/66, Loss: 35.9313\nAvg Blank Probability: 0.0153\nSample predictions: ['fPl3paFaF', 'ja', 'jyIy']\nGround Truth (first 3): ['jY*7c', '5', 's0']\nRaw outputs (first 3): [[ 6 10 10  1 56 10  1  6  6 34 10 12 22  1 16 10 22 11  4 50  1  1 12  4\n  56 42  6  4 12 11 35 14]\n [42  1 25 61  6  5  5 50 10 32 19 50 10 24 47 42 24  1  4 11 20 32  1 22\n  24  1  6  1  4 34 35  1]\n [12  1 35 38 27 63 35  6  9 19  5 12 10 56 27 10  4  5  1  6 34 24  1 55\n  35 10  1 34 10  1  1  6]]\nInput length: 15, Label lengths: [5, 1, 2]\nToken distribution (Batch 31): {11: 1, 47: 1}\nBatch 60, Gradient norm: 18.9932\nEpoch 10, Batch 60/66, Loss: 32.5850\nAvg Blank Probability: 0.0151\nSample predictions: ['laHF2UeFeP', 'IaVajuIt', 'Iaga-y']\nGround Truth (first 3): ['pRXvu', 'oZROy', 'n4LAz']\nRaw outputs (first 3): [[12 35 35 30 24  4  5 63 10 35  1 27  6 34 22 43 43 56 20 10 19 25  1  1\n   1 56 32 19 34 11 11 11]\n [ 1  1  1 10 10  1 56  6  1 56 12  4 22 11 42 43 43 63 32 24 34  6 10 20\n  19 63  1 56 32 23 10 47]\n [34  1  1 32 27  4 19  1 11 56 56 35 35  1  1 22 43 63 30  1 20 19 11 34\n   1  1 27 22 16  4 34 10]]\nInput length: 15, Label lengths: [5, 5, 5]\nEpoch 10/20, Loss: 33.1110\nToken distribution (Batch 8): {1: 2}\nValidation Loss: 33.9386\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['Ck', 'R', 'En', 'jAh4', 'Du38J']\nCurrent Learning Rate: 1.9234506732942514e-07\nEpoch 11, Filtered data size: 3620, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {35: 1, 47: 3, 43: 1, 1: 1, 4: 1, 13: 1}\nBatch 0, Gradient norm: 13.1446\nEpoch 11, Batch 0/91, Loss: 26.7818\nAvg Blank Probability: 0.0153\nSample predictions: ['3ajzj', 'yd', '-lkvjsHk']\nGround Truth (first 3): ['uCYo', 'P', 'wx-je']\nRaw outputs (first 3): [[56 25 63 34 10 10 63 56 19  1 25 10 10 43  4 22  1  4  1  4 35  1  1 25\n   1  6 11  1 35 10 10 35]\n [ 1  4 12 20 35 63  1  1 19  1 47 50 35 19 10  1 51 48 48 10  1  5  4 43\n   6  1 19 19 32  1  4 47]\n [ 1 12 11 34 34 47 62 35  4 16  6  7 47  1  4 43  5 47 35 40 10 34 42 42\n  32  6  1 19  1  6 50 43]]\nInput length: 15, Label lengths: [4, 1, 5]\nToken distribution (Batch 31): {10: 2, 27: 1, 1: 1}\nBatch 10, Gradient norm: 16.1806\nEpoch 11, Batch 10/91, Loss: 30.6423\nAvg Blank Probability: 0.0149\nSample predictions: ['ajkHkaHa23f', 'AkagaHBvaj', 'yaH3']\nGround Truth (first 3): ['RqAgCd', 'biTha', '93']\nRaw outputs (first 3): [[ 1 27 25 11 32  1 63 32 34 11 19 56 34 35 16  1 10 19 34  1  1 56 22 34\n  32  1 42  1 11  1 47 10]\n [10 11  1 56 47  1 42 43  1  5  5 56 19 12 32 22 35 14 10 11  1 10  1  1\n   1  1 14  5  1 12 27 27]\n [10  1 34  1 10  1 32  4 48  6  4  1 50 32 48 35  1  1  4 32 27 12  1  1\n  24 19 27 34 59 63 19  1]]\nInput length: 15, Label lengths: [6, 5, 2]\nToken distribution (Batch 31): {11: 1, 42: 1, 1: 3, 55: 1, 30: 1, 32: 1}\nBatch 20, Gradient norm: 50.4116\nEpoch 11, Batch 20/91, Loss: 22.9940\nAvg Blank Probability: 0.0156\nSample predictions: ['3a3UfQjljDbt', 'aJiQa3UiP', 'HvaH3a-vyPjkF']\nGround Truth (first 3): ['gSGYn-', 'T9vty', '4haKGSo']\nRaw outputs (first 3): [[56  1 34 10 24 12 47 17  4 22 42 40 32 47 48 10 34 10  5 50  4  6  4 34\n   1  4  1 56 11 10 11 11]\n [ 1  1 22  5  1 47  5 11 24 17 22 34 35 63  5 47  1  1 43  1  1 63 25 57\n   4  4 35 63 35 22  4 42]\n [56 36  1 30 10 10 26  4 11 34 34 34  1 50 34 34  6  5  4 30 24 47  1 12\n  34 22 60 12  1  5  4  1]]\nInput length: 15, Label lengths: [6, 5, 7]\nToken distribution (Batch 31): {1: 3, 6: 1, 47: 2, 34: 1, 43: 1, 10: 2}\nBatch 30, Gradient norm: 7520.3359\nEpoch 11, Batch 30/91, Loss: 30.2429\nAvg Blank Probability: 0.0154\nSample predictions: ['aKHaHaHkugPI2s', 'dk', 'kXaD']\nGround Truth (first 3): ['Oqb511L', 'P', 'SF']\nRaw outputs (first 3): [[ 1  4 11 43  6 11  4  1 34  1  1 12 42  1 20 43  1  1 42  1  1 12 16  4\n   1  1 22 10  4 63  1  1]\n [37 11 50  1 35 27 32 17  1 12 19 47 55  4  1 63 34  4 47  1 27 32 10  6\n  22 10 12 47 32  4 22  1]\n [34  1  1 43 28  1 19 43 11 32  1  9 20  4  4 56  7  1 32  1 34 27 47 33\n  47 47  1 34 55 33 13  6]]\nInput length: 15, Label lengths: [7, 1, 2]\nToken distribution (Batch 31): {19: 1, 1: 3, 22: 1, 55: 1, 5: 1, 21: 1, 7: 1, 10: 1, 50: 1, 12: 1, 4: 1, 56: 1}\nBatch 40, Gradient norm: 28.3421\nEpoch 11, Batch 40/91, Loss: 24.0028\nAvg Blank Probability: 0.0154\nSample predictions: ['UHFeg8faHsa', '-aBaPkXHj', 'UsdLesSaIxglYU']\nGround Truth (first 3): ['aIZk9O', '30Ez6', 'K8vUvMN']\nRaw outputs (first 3): [[47 63 47 10  1 43  1 27 10 10 19 50 42 19  1  1 43  1 24  1 22 12  4 56\n   1 30 32 32 22  1 10 19]\n [34  1 19 34 56 12 32 20 32 34  5 11 10 33 34 63 50 12 32 16 27  1 11 11\n   1  1 63 22  5 10  1  1]\n [32  1  4 10 38  1 34 35  1 12  1 43  4  4 27 20 35 19 35  6 25 63 56 63\n  34  1 27 43 11  1 31  1]]\nInput length: 15, Label lengths: [6, 5, 7]\nToken distribution (Batch 31): {10: 1, 32: 1, 34: 1, 6: 3, 50: 1, 4: 1}\nBatch 50, Gradient norm: 15.3953\nEpoch 11, Batch 50/91, Loss: 28.7791\nAvg Blank Probability: 0.0154\nSample predictions: ['jHvpaP', 'FjaQlvaeaja', 'mjnakv']\nGround Truth (first 3): ['7ZZ', 'uWA78n0', 'dNm']\nRaw outputs (first 3): [[10 32 13 11 56 12 34 56 56  1 22  1 32 29  1 32 10 56  1 16 48 35  4 10\n  47 19 42 22  4 63  1 10]\n [34 10 10 42 10 22 19 10 56  1  4 30  1 19 34 11 43  1  1 25 12 13 56 32\n   7 43  4 22 24  1  1 32]\n [22 10 14 34 32  6  1 10  1 32 47  1 11 22 11 27 22  1 57  4 46 27 32 10\n  11 56 55 10 34 30 48 34]]\nInput length: 15, Label lengths: [3, 7, 3]\nToken distribution (Batch 31): {11: 1, 6: 1, 35: 1, 10: 1, 4: 1, 32: 1}\nBatch 60, Gradient norm: 130.3072\nEpoch 11, Batch 60/91, Loss: 32.5137\nAvg Blank Probability: 0.0154\nSample predictions: ['anaUHI', '3j', 'ljkPG3I']\nGround Truth (first 3): ['I*0', 'l', '3uam']\nRaw outputs (first 3): [[ 1 56 12  6  4 32  1  1 12  4 19 18 43  1 10 10 19 34  1 10 35 48 10  8\n   1 48  1 42 56 43  4 11]\n [14 10 10 11  1 24  1 11 10 34 16 22 61 27 34 22 25 32 19 34 47  1 22 43\n   5 34 34 11 56 10  5  6]\n [ 1 56 11 10 10 42 56 42 30  1 10 10  5  1  1  1 56 43 27  5 47 25 12 63\n   5  4 56 11 27 22 46 35]]\nInput length: 15, Label lengths: [3, 1, 4]\nToken distribution (Batch 31): {1: 1, 34: 1}\nBatch 70, Gradient norm: 15.3211\nEpoch 11, Batch 70/91, Loss: 28.9192\nAvg Blank Probability: 0.0155\nSample predictions: ['lfaH', 'xv3aHUlaXAaja', 'fiXja2sFHQaA']\nGround Truth (first 3): ['hQ', 'iikgJBB', 'ZyI9z8r']\nRaw outputs (first 3): [[12 24  6 13 56  1 19 24 43 22 11  5  1 20  1 10 43 10 43  0 22  1 34  1\n  56 30 10  1 56  7 24  1]\n [ 6 22  9  1  4  1 34  1 56 63  1 11  5 47 56 34 11 34 47 11 28 50 10 32\n  22 50 35  4 19 42  6 34]\n [ 1 56 50  1 34  1  5 47  5 47 31 32 16 63 10 19 47 12  1 60 53 23 11  5\n  13  4 34  1 12 10 27  1]]\nInput length: 15, Label lengths: [2, 7, 7]\nToken distribution (Batch 31): {19: 1, 34: 1, 1: 4, 55: 1, 22: 1, 11: 1, 42: 1}\nBatch 80, Gradient norm: 16.4181\nEpoch 11, Batch 80/91, Loss: 30.4264\nAvg Blank Probability: 0.0152\nSample predictions: ['Xf', 'rjtjFjfXk', 'avFIFf5aHI']\nGround Truth (first 3): ['3', 'd40XO', 'UeXm8Z']\nRaw outputs (first 3): [[50 18  1 34  1 33 56  4 10 32 48 30 22  1 20 32 10 42 10 43  4 57 32 25\n  63 32 12 22 42  4  1 19]\n [ 6 10 22 43 12 32 20 43 14  1 47 35 10 19 10 19 10  5 10 47 57 11  5 56\n  25 63  1  5 56 19  1 34]\n [ 6 20 32  1  9 47 11 50 11 32  1  6 34 11  1 22 11  1  4  6 63 48 22  1\n  12 24 32 48 34 61 32  1]]\nInput length: 15, Label lengths: [1, 5, 6]\nToken distribution (Batch 15): {1: 4, 22: 1, 40: 1, 6: 1, 12: 1, 9: 1, 63: 1}\nBatch 90, Gradient norm: 13.0692\nEpoch 11, Batch 90/91, Loss: 25.8820\nAvg Blank Probability: 0.0154\nSample predictions: ['Xvsa', 'kajlxifvejkXjs', 'Fa-aAasjFTk']\nGround Truth (first 3): ['HL', '9vQ54v5', 'TBnHM5*']\nRaw outputs (first 3): [[50 11 32 14 10 57 47  1 35  1 19 12 34  1  6  1]\n [22  1  1  5  1  7 42 50 27  1 19  1 56  1 22 22]\n [19 10  1 56  4  4 27 19  1 10 22  6 16 13 48 40]]\nInput length: 15, Label lengths: [2, 7, 7]\nEpoch 11/20, Loss: 28.4977\nToken distribution (Batch 19): {1: 12}\nValidation Loss: 27.6337\nValidation Predictions: ['a', 'a', 'a', 'a', 'aj']\nGround Truth: ['bLBIm9', 'h65z19', 'Noe', 'U-xr4', 'dh8hotR']\nCurrent Learning Rate: 2.4079101853620755e-07\nEpoch 12, Filtered data size: 3620, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {1: 1, 43: 1}\nBatch 0, Gradient norm: 1599.0742\nEpoch 12, Batch 0/91, Loss: 30.8226\nAvg Blank Probability: 0.0154\nSample predictions: ['veaHPfIzaFRwVa', 'DvkdQHda', 'F']\nGround Truth (first 3): ['h7epS8M', 'O-ir', 'c']\nRaw outputs (first 3): [[22 30 32 56 34  1 27 10  4 56 12  1 11 43  1  4 10 48  1  1 22 36 35 57\n  57  1  1 11  5 34  1  1]\n [ 5 22 32 40  1 12  6 10 24 56 19 11  4 38 32 27  1 32  1 30  6 63  1 46\n  10 48 10 34 12 34 63 43]\n [ 1 11 32 19 56 26  1 34 19 24 34 32 48  1 10 19  4 47 21 55 10 63 19 24\n   1 32 56  1  1  1 19 10]]\nInput length: 15, Label lengths: [7, 4, 1]\nToken distribution (Batch 31): {25: 1, 1: 3, 6: 1, 22: 1, 61: 1, 42: 1, 35: 1, 10: 1, 26: 1, 12: 1, 30: 2}\nBatch 10, Gradient norm: 17.3833\nEpoch 12, Batch 10/91, Loss: 30.6823\nAvg Blank Probability: 0.0156\nSample predictions: ['ajDFIvald', 'ma', 'dja']\nGround Truth (first 3): ['QGLe0', 'er', 'lm']\nRaw outputs (first 3): [[ 1 13  4 11 34 20 42 11  1 32  8  6 12 32 13 43  1 12  1 34 32 43  1 22\n  35 61 47 10 56 10  4 25]\n [10  1 10  4  4 32 10 42  1  5 19 19 56 10  1  6  6 35  6 11 32  4  1 47\n  43  1 10  6 10  4 25  1]\n [30  1  1 47 35  5 40  1 38  1  4 12  1 61 16  1 41 14 12 12 20 56 16  1\n   5  6  1 56  1 19 11  1]]\nInput length: 15, Label lengths: [5, 2, 2]\nToken distribution (Batch 31): {19: 1, 42: 1, 32: 3, 50: 1, 33: 1, 27: 2, 48: 1, 34: 2, 1: 1, 7: 1}\nBatch 20, Gradient norm: 14.7661\nEpoch 12, Batch 20/91, Loss: 27.0199\nAvg Blank Probability: 0.0156\nSample predictions: ['-ArjXjFAa3', 'A-ajXjHvyFVAjg', 'HI-']\nGround Truth (first 3): ['kHfqx', 'wn4a7rf', '1N']\nRaw outputs (first 3): [[63 27 34  1 34  4  1  1 32 35 35 34  1  1 56 63 34 63 32  1  1 22  1  1\n  47  6  1 18 34 47 10 19]\n [27 63 34 10  1  4  1 11 42  1 25 34  9  1  1 13 23 55 32 12 34 34 12 50\n  48 24 11  1 23 11 32 42]\n [18  1 35 30 27 10 47 32  1 22 10  1  1  1 32  1 22 19 32 47 42 34  1 50\n  11  1 47 32 57  1 22 32]]\nInput length: 15, Label lengths: [5, 7, 2]\nToken distribution (Batch 31): {63: 2, 43: 1, 35: 1, 34: 1, 30: 1, 10: 1, 1: 1, 7: 1, 32: 1}\nBatch 30, Gradient norm: 12.0763\nEpoch 12, Batch 30/91, Loss: 25.0902\nAvg Blank Probability: 0.0157\nSample predictions: ['-HF34', 'jQUv', 'afafFI']\nGround Truth (first 3): ['Yvw', 'rT', 'yGW']\nRaw outputs (first 3): [[63 10  1 22 11  6 24 63 11 11 63 63 12 11 35 19 32 32 11 23 11 25 32 16\n  24  4 25  1 43  1 11 63]\n [34 43  6  1 21 12 30 32 35 63 11  4  1 47 22  4  1 45  1  4 22  1 43 47\n   1 34 32 61 47 47  1 43]\n [32 47  1 47 63 32 11 35  1 34 12 63 56 10 24  1 32  1  1  6 47 27 56  1\n  13 33  6 57 56  7  1 35]]\nInput length: 15, Label lengths: [3, 2, 3]\nToken distribution (Batch 31): {1: 3, 25: 1, 56: 1, 35: 1, 22: 2}\nBatch 40, Gradient norm: 14.6714\nEpoch 12, Batch 40/91, Loss: 27.5258\nAvg Blank Probability: 0.0157\nSample predictions: ['advatd3Aas', 'yPUFUdaA', 'lktU']\nGround Truth (first 3): ['q6gTu', 'Ocf0', '02']\nRaw outputs (first 3): [[ 1 25 12 12 12 56 35 32 19 32 35 32  1 11 22 13 56 11 19 42 10 18 22 20\n  16 42  1 19  5 32 36  1]\n [ 4 42 11 10  6 47 25 47 34 21  1 12  1  1 25 56 19  6  5  1 33  6 35  4\n  19 10  1 48 56 47 13 25]\n [22 47 20 30  4  5  1 13  1 23 10 11  4  4  1 32 35  5  7 13 22 10  1 34\n   1  4 10  5  7 55 10  1]]\nInput length: 15, Label lengths: [5, 4, 2]\nToken distribution (Batch 31): {13: 1, 6: 1, 11: 1, 63: 1, 22: 1, 4: 1}\nBatch 50, Gradient norm: 13.6373\nEpoch 12, Batch 50/91, Loss: 26.2758\nAvg Blank Probability: 0.0158\nSample predictions: ['Jk4aUdAPUVHQUt', '-DgxashAa', 'dsaUa2fD']\nGround Truth (first 3): ['yeZBt6x', 'WJ3im', 'rj2Y']\nRaw outputs (first 3): [[36 63  4 32 43 10 25 57 11 56 11 10  6 10 34 63 25 56 42  1 63 12  1  4\n  50  1 34 27 10 63 63 13]\n [11 30 19 10 11  1 23 10 25 56  5 11 19 11  6 47 10 30  0 43  1 11 10  1\n   1 34 22 56  1 32  1  6]\n [57  7  1  6 32  5  1 11  1 10 48 44 10 47 22 27  5 50 16 10 32 14 63 19\n  50 21 47 50 11 63 56 11]]\nInput length: 15, Label lengths: [7, 5, 4]\nToken distribution (Batch 31): {34: 2, 7: 1, 10: 1, 43: 1, 6: 1, 32: 1, 19: 1, 27: 1, 56: 1}\nBatch 60, Gradient norm: 509.5684\nEpoch 12, Batch 60/91, Loss: 27.3768\nAvg Blank Probability: 0.0158\nSample predictions: ['nPUgwa', 'FesF4HavjsuA', '-x']\nGround Truth (first 3): ['2JT', 'nQoAFh', 'q']\nRaw outputs (first 3): [[14 32 63 56  1 56 57  1 35 47  1 12 32 32 12  1  1 10 10 63  4 16  6 10\n  56  4 22 34  4  6 22 34]\n [42  5 24 47 34 43 35  1  1 12 27 25 50 10 12  4  4 13 10 12  6 47  1 19\n   1 56  5 56  1  1 34 34]\n [47 19 25 47 32 32 11  1 34  4  1  1 55 12  6 11 25 36  6 30 24  1 10 19\n  43  6 47  1  1 19  1  7]]\nInput length: 15, Label lengths: [3, 6, 1]\nToken distribution (Batch 31): {10: 1, 27: 1, 16: 1, 11: 1}\nBatch 70, Gradient norm: 44.0766\nEpoch 12, Batch 70/91, Loss: 26.4562\nAvg Blank Probability: 0.0159\nSample predictions: ['sH', '2QIJ', 'faFej3gehvjm']\nGround Truth (first 3): ['k', 'T1', 'XaGhKvP']\nRaw outputs (first 3): [[19 55  6  1 11 25  6  6  3 47  1 34  1  1 10 22 14 24 34 56 32  5 22  1\n  11 34 47 10 10  1 16 10]\n [34 43  6 10 21 12 34 43 10 22 13 63 42 47 47 10  0  0 10 11 47 61  4 10\n  11 21 47 63 19  6 35 27]\n [ 1 35  1  5  1 42 14 20  1 32 10  1 34  1 10  1 32 22  5 25 27  1 10 32\n   1 42 12 24  1 48  4 16]]\nInput length: 15, Label lengths: [1, 2, 7]\nToken distribution (Batch 31): {1: 3, 9: 1, 10: 1, 5: 1}\nBatch 80, Gradient norm: 12.4407\nEpoch 12, Batch 80/91, Loss: 25.6245\nAvg Blank Probability: 0.0158\nSample predictions: ['lsAa-aPmIsis', '2asHfvjFsUsFH', 'madIak']\nGround Truth (first 3): ['YWmFk6', 'AjNIAzj', 'xe5']\nRaw outputs (first 3): [[12 55 13 63 22  1  6 63 34  1 16 47  4  4 47 32  4  1  1 27 32 22 30 48\n   1 56  1 19  1 55 56  1]\n [19  1  1  6 12  4 32 19 24 32  1 42 35 10  1 29 11  4 32 32 10 32 11 34\n  19  1 43 22 22 28 47  9]\n [27  1  4  1  1 34 50 28 47 10 42 34  6  6  1 30 19 11  1  1  4 30 34 22\n  10 32 47 24  5 42 56 10]]\nInput length: 15, Label lengths: [6, 7, 3]\nToken distribution (Batch 15): {10: 2, 1: 4, 56: 1, 50: 1, 42: 1, 35: 1, 5: 1, 24: 1}\nBatch 90, Gradient norm: 13.2360\nEpoch 12, Batch 90/91, Loss: 25.0755\nAvg Blank Probability: 0.0160\nSample predictions: ['aH', '-FaH', '3tPjaHIHaQH4FT']\nGround Truth (first 3): ['3', 'BQ', 'j39MjIY']\nRaw outputs (first 3): [[ 1 63 56 22 22  1  1  1 60 32 56 34 63  1  0 10]\n [34 32 20 14 42 12 32  5  4 19  1 22  1 47 32  1]\n [ 1  1 42 30 12  1  1 14 34  0  4 48 32 10 19 56]]\nInput length: 15, Label lengths: [1, 2, 7]\nEpoch 12/20, Loss: 28.3866\nToken distribution (Batch 19): {1: 4}\nValidation Loss: 27.8706\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['uduag5', 'v', 'kXK', '4oAo', 'Xgg*r']\nCurrent Learning Rate: 3.781152949374526e-07\nEpoch 13, Filtered data size: 3620, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {56: 2, 11: 1, 5: 1, 13: 1, 22: 1, 7: 1, 10: 1, 1: 2, 35: 1, 34: 2, 12: 1}\nBatch 0, Gradient norm: 26.0377\nEpoch 13, Batch 0/91, Loss: 29.3598\nAvg Blank Probability: 0.0160\nSample predictions: ['valI2jd', 'jePHUds2xkAeP', 'Fvaxv-avjAjaHD']\nGround Truth (first 3): ['DMYT*', '2m09p04', 'rsJczXz']\nRaw outputs (first 3): [[22 10 32 56 48 43 11 32 32 42 43 34 57 25 44 17  6  4  6 11 10  1 35  1\n  63  1 10 14  1  1 63 56]\n [ 1  5 22 56  1  1 34 22  1 61 27  6 10 61  4  1 34 12  1 10 43 34 46  1\n  56 47 10 43 34 10  1 11]\n [ 1  5  1 12 29  1  4  0  4 19 61 22 18 32 43 30  1 25 56 55  5  2 42  1\n  34 55 12 47  1  5  5  5]]\nInput length: 15, Label lengths: [5, 7, 7]\nToken distribution (Batch 31): {63: 1, 24: 1, 27: 2, 11: 1, 32: 1, 13: 1, 5: 1, 14: 1, 12: 1}\nBatch 10, Gradient norm: 14.9027\nEpoch 13, Batch 10/91, Loss: 27.8988\nAvg Blank Probability: 0.0161\nSample predictions: ['XvnkjF', 'jakAoaFkdgBH', 'QlfwaPfj3IjavQ']\nGround Truth (first 3): ['Zax', 'GblpNE', 'AO5O8Xz']\nRaw outputs (first 3): [[50 10 43 34 27 16 34 22 34  1  1  1 56 61 34 10 22  1 19 30  1  1 63 30\n  32 47  1 47 56  1 11 63]\n [22  1 12  1 42  5  1  1 48 43  1 18  1  1 35  5 19 42 43 24  1  5 47 19\n  24 35 34  4 30  0 11 24]\n [14 11  6 24 34  1 32 10 47  1  1  1 42 57 19 63  1 13  1 42 19 27  1  1\n  20 10 50 19 32  1 35 27]]\nInput length: 15, Label lengths: [3, 6, 7]\nToken distribution (Batch 31): {34: 1, 1: 2, 10: 2, 11: 1, 27: 1, 43: 1}\nBatch 20, Gradient norm: 56.9641\nEpoch 13, Batch 20/91, Loss: 31.4442\nAvg Blank Probability: 0.0161\nSample predictions: ['a', '4Dj', 'UFkz']\nGround Truth (first 3): ['c', 'DZ', 'yE']\nRaw outputs (first 3): [[ 1 57 47  1 43 19 11  1 47  1 11  1  1 32 47 42 50 11 63  4 34  4 63  1\n   6 34 19 10 34 22  1 34]\n [ 1 30 32 56  1 56 35 47 34  6 35 43 56 10 10  1 47 34 35 35 10 10  6  0\n  34  1 56 10 29 10 61  1]\n [10 10 11 18  4 32 63 42 25 12 11 11 19 19  1 24  6 60 63 22 32 10  1 47\n  47 34  6  1  1 11 10  1]]\nInput length: 15, Label lengths: [1, 2, 2]\nToken distribution (Batch 31): {25: 1, 4: 1, 6: 1, 5: 1, 1: 1, 47: 1, 21: 1, 42: 1}\nBatch 30, Gradient norm: 252.2972\nEpoch 13, Batch 30/91, Loss: 27.2730\nAvg Blank Probability: 0.0165\nSample predictions: ['fHajF3-A', 'jfUHI2gamH', 'fU8j-a']\nGround Truth (first 3): ['Gpz4l', 'gHBHK', 'wL7']\nRaw outputs (first 3): [[ 6 10  6 34 11 34 32  5  6  1  1 32  1 35 43  1  4 46 47  1  1  4  1  4\n   1  4 34 63 34 28 47 25]\n [34  6 47 22 11 12 32  4 63  1  1 30 10 32  4  1 34 10 10  4 19  0 43 35\n  32 24 48 19  1 22 63  4]\n [34 47 61 16 11  1  5  1 55 34  4 35  1 19 19 57 24 10 10 48  1  1 33  1\n  18 24  1 25  1  1 42  6]]\nInput length: 15, Label lengths: [5, 5, 3]\nToken distribution (Batch 31): {32: 1, 11: 1, 10: 2, 1: 4, 6: 1, 7: 1, 24: 1, 34: 1}\nBatch 40, Gradient norm: 17.4078\nEpoch 13, Batch 40/91, Loss: 28.8184\nAvg Blank Probability: 0.0163\nSample predictions: ['XsEkCaFdV', 'XH', '3FDvUl']\nGround Truth (first 3): ['xM7tm', '-', '7BJ']\nRaw outputs (first 3): [[50 50 56 16 19 47 22 12 10  1 34 19 32 17 30 34  1 20 19 19 27 11 32 50\n   1 42 12  1 25  6 47 32]\n [19 34 32 10 63  4 22  6  4  1 12 34 19 34  7 12  4  4 47 19  4 11 16 23\n  32 22 19 10 35 27 32 11]\n [31  6 30 32 34  1  1  1  6 35  1  6 23  1 47 19 48  4  0  6  6 38 10 34\n   1  5 48 17 51 35  1 10]]\nInput length: 15, Label lengths: [5, 1, 3]\nToken distribution (Batch 31): {20: 1, 10: 2, 27: 1, 1: 1, 56: 1, 43: 1, 32: 1, 24: 1, 12: 1}\nBatch 50, Gradient norm: 17.9587\nEpoch 13, Batch 50/91, Loss: 29.8735\nAvg Blank Probability: 0.0164\nSample predictions: ['DajH3Qa3ek', 'at', 'jljdVD']\nGround Truth (first 3): ['3cT-U7', 'R', '2XR']\nRaw outputs (first 3): [[30  1 10  1 11 19  1 46  1 56 35 11  1 11 10  4 33 19 19 22  1  1  1 22\n  24 32 10 11 10  1  6 20]\n [ 1 20 12  6 47  4 43 42  1 42 63  1 19  1  1 27 19 33 24  1 22 12  1 36\n   6  1 12 19 11  1 20 10]\n [10 56 10 42  6  6  5  1 10 32 19 51 35 16 27 11  6  1  4 47  5 63  1  1\n   0  1  6 43  1 32  7 27]]\nInput length: 15, Label lengths: [6, 1, 3]\nToken distribution (Batch 31): {10: 1, 11: 2, 12: 1, 1: 1, 27: 1}\nBatch 60, Gradient norm: 15.5732\nEpoch 13, Batch 60/91, Loss: 27.1284\nAvg Blank Probability: 0.0165\nSample predictions: ['maeHavaVCag3es', 'dHvkedCax', 'aUePQA']\nGround Truth (first 3): ['vYIU0WD', 'v8Nha', 'G4R']\nRaw outputs (first 3): [[13  4  1 47  1 10 34  6 22 27 33  1 56  1 47  1 63  4  4  1 50 42  6 56\n  32 35  1 56 11  9  6 10]\n [ 1 34 47  5 63 19  0 47  1 47 47  1 10  1 30 12  1 11  1 11 47  4 10 19\n  11 10 16  6 56 25 11 11]\n [ 5 22  5  1  1 57  7 34  1  1 34  6  5 10 25 11 22  1 42 16  1  5  1 35\n   1  1  1 47  5  1  1 11]]\nInput length: 15, Label lengths: [7, 5, 3]\nToken distribution (Batch 31): {19: 2, 32: 4, 22: 1, 9: 1, 5: 1, 35: 1, 53: 1, 1: 2, 10: 1}\nBatch 70, Gradient norm: 35.3122\nEpoch 13, Batch 70/91, Loss: 29.1522\nAvg Blank Probability: 0.0166\nSample predictions: ['3PfFasa2Q', 'ejkefxkBa', 'afaskvOyasIfak']\nGround Truth (first 3): ['RdZ1x', 'WOr3O', 'BVzm05v']\nRaw outputs (first 3): [[56  5  1  1  1 47 35 63 10 13 20  6 56 10  1 35 63  1  5  1 43 22 24  1\n  63  4 47 56  1  1 10 19]\n [42 10  6 10 22 35 50 32 10 32  1 11  6  1 55 10 19  1 25 30 11 27 47 34\n  25 19  4 32 22 22 43 32]\n [ 6 11  1 19 20 24  1 34  0 47 27 34  1 47  1 12 10 27 10  6  1  1 11 32\n   9 16 25 34  4  0 35 32]]\nInput length: 15, Label lengths: [5, 5, 7]\nToken distribution (Batch 31): {35: 1, 24: 1}\nBatch 80, Gradient norm: 24.0375\nEpoch 13, Batch 80/91, Loss: 28.1196\nAvg Blank Probability: 0.0166\nSample predictions: ['aUga', 'jHpI3xaGaklav', 'UaejFjt']\nGround Truth (first 3): ['oe', 'eKSRDzi', 'bxDZ']\nRaw outputs (first 3): [[ 1 10 47  1 16 10 57 56  1 63 24 19  1 12  4 11 24 42 47 10 56 10  1 63\n   0 19  1  1 47 47 34 35]\n [47 34  1  1 34 10 56 30 11 10  1 43  1 63 11 35 10 35  1  1 63 47  1 18\n  20 12  1  1 10 43 11 24]\n [ 7 16  5 11 22 19 22 28 11 47 27  1 26 12  5 25 47 57  0  1  5 10  1  0\n  35 11  7  1 10 42 32  1]]\nInput length: 15, Label lengths: [2, 7, 4]\nToken distribution (Batch 15): {22: 1, 35: 1}\nBatch 90, Gradient norm: 19.3200\nEpoch 13, Batch 90/91, Loss: 31.4716\nAvg Blank Probability: 0.0166\nSample predictions: ['kHPaFSjG', 'Hfva2ayUQlaUse', 'FaBfsU']\nGround Truth (first 3): ['FqXD', 't5ttxVy', 'LkN']\nRaw outputs (first 3): [[11 34 32  4 12 47 35  1  1 63  1  1 32 56 25 22]\n [34  6  1  1 19 23 42 34 16 63  4 32 42 47 35 35]\n [42 22 28 22  1 10 32 32  5 10 27 63  1  6 19  1]]\nInput length: 15, Label lengths: [4, 7, 3]\nEpoch 13/20, Loss: 28.2820\nToken distribution (Batch 19): {1: 14}\nValidation Loss: 27.9749\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['oiUh', 'PfCU3-m', 'n', 'o*N', 'C']\nCurrent Learning Rate: 5.08591449765592e-07\nEpoch 14, Filtered data size: 3620, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {63: 1, 26: 1, 55: 1, 34: 2, 1: 3, 42: 1, 48: 1, 50: 1, 10: 2, 35: 1}\nBatch 0, Gradient norm: 17.8829\nEpoch 14, Batch 0/91, Loss: 29.4060\nAvg Blank Probability: 0.0168\nSample predictions: ['vj', 'yUdaU23adajaj', 'afajaBIUtFaedf']\nGround Truth (first 3): ['e', 'E6RxizT', 'QjW7gxl']\nRaw outputs (first 3): [[22 25  1 19 32 42 24 32  1 48 34 24 56 47 11  1  1  1  4  1 20  0  1 56\n  35 22  1 11 34 56 12 63]\n [10 47  6 11 11  5 27 34  1 10  1 25 24  1 11  1  1 22 34 60 32 56 32  1\n  46 11 11 56 25  1 25 26]\n [56  4  1  1 22  1 47 61 12 34 32 32 27  1  1  1  1 20  1 22  6 47 56  6\n  12 22 36  1 56 38 56 55]]\nInput length: 15, Label lengths: [1, 7, 7]\nToken distribution (Batch 31): {4: 1, 22: 1, 27: 1, 19: 1, 57: 1, 6: 1, 36: 1, 1: 2, 42: 1}\nBatch 10, Gradient norm: 497.8313\nEpoch 14, Batch 10/91, Loss: 23.1944\nAvg Blank Probability: 0.0170\nSample predictions: ['afFajAj', 'hDdH', 'laPaQa']\nGround Truth (first 3): ['7N7d', '0D', 'ixDqn']\nRaw outputs (first 3): [[ 1  8 12  1 35 56 32  1 19 25 61 11  1 30 10  4  1 46 63 34 22 35  6 22\n   0 11 11 11 32  4  4  4]\n [ 6 30  1  1  5  5  1 10 21 11 63 28 32 10 34  5  1  1  1  1  1 12 33  1\n  12 34 20 20 57 61 48 22]\n [32  4  1 43  5 34 63 10 35 56 22 10 57 34 10 30 11 42  4  1  1 34 32  5\n   1 47 42 35  1 12 56 27]]\nInput length: 15, Label lengths: [4, 2, 5]\nToken distribution (Batch 31): {6: 1, 56: 1}\nBatch 20, Gradient norm: 20.2339\nEpoch 14, Batch 20/91, Loss: 28.5536\nAvg Blank Probability: 0.0172\nSample predictions: ['jtHjaJIfFv', 'aIjFjQ', 'VjftgHaHUl']\nGround Truth (first 3): ['tKd4F', 'tkL', 'V*czz']\nRaw outputs (first 3): [[10  1 48 43  4 25 12 10 47 34 43  1 34  1 10 12 10 63  1 28  4 13 56 11\n  10 11 32  1 11 10 50  6]\n [20 35 10 20  1 16 11  1 19  1 34  0 32 32 56 10  6  4 11 35 43 10 19 22\n  11  1 47  1 47 34 55 56]\n [34 10  6  1 16  5 47 56 35 19 19 10 19  1  1 19 42 11 11 35 42 18  1 19\n   1  1 11 29 12 56 42 35]]\nInput length: 15, Label lengths: [5, 3, 5]\nToken distribution (Batch 31): {1: 2, 12: 1, 42: 1, 11: 1, 24: 1}\nBatch 30, Gradient norm: 15.7908\nEpoch 14, Batch 30/91, Loss: 26.3207\nAvg Blank Probability: 0.0176\nSample predictions: ['FfaIdUajfaP', 'kaUv', 'FVvaRajVHvaj-k']\nGround Truth (first 3): ['XaGhKvP', 'VQ', 'PVS8nuq']\nRaw outputs (first 3): [[32 11 32 14 43 22 42  1 14  1  4  4  1 11 22 43 43 10 43  1 22  1  4 11\n   1  1 22 34  9  0  1  1]\n [ 6  1 48  1 25  0 20  1 34 34  1 10 42  1  4  4 10  1  4  1 55 32 24 42\n  11  1 11 34  1 32 12 12]\n [ 1 47 22  1  1  1 55 32  6 10 35  0 32 55 56  1 43 35 10 30  1 12  1  1\n  19 43 21 24 32 55  6 42]]\nInput length: 15, Label lengths: [7, 2, 7]\nToken distribution (Batch 31): {24: 2, 11: 1, 47: 1, 34: 1, 1: 2, 35: 1, 30: 1, 10: 1}\nBatch 40, Gradient norm: 10.2584\nEpoch 14, Batch 40/91, Loss: 22.4556\nAvg Blank Probability: 0.0171\nSample predictions: ['aFHaUPHiskA', 'Gwfk3s', 'Hj2eldsa']\nGround Truth (first 3): ['DQsMZ9', 'TAi', 'Q8dF']\nRaw outputs (first 3): [[ 1 33 34 42 32 11  6  4  1  4 10 34  1  1  1 22  6 48 22 22 32 10 12 34\n  30 27 11  1  1  1  1 24]\n [32 23 10 36 34 33  1 25 10 47 34 22  5 55 32  1 24 10 34 25  1 56 35 35\n   1 32  5 23 19  1  1 11]\n [34  6 55 47  1 57 34  1 11  0 32  1 22 61  1 34  1 34 34 48 24 42 19  1\n   1  6  1 11  1 32  6 47]]\nInput length: 15, Label lengths: [6, 3, 4]\nToken distribution (Batch 31): {1: 1, 12: 1, 42: 1, 4: 1, 16: 1, 63: 1, 11: 1, 34: 2, 10: 1, 47: 3, 22: 1}\nBatch 50, Gradient norm: 13.7250\nEpoch 14, Batch 50/91, Loss: 22.0615\nAvg Blank Probability: 0.0176\nSample predictions: ['-a3alksF', 'jxfFg3A2Ua', 'njaHUyagfe']\nGround Truth (first 3): ['*tIE', 'bVwNB', '19VXY']\nRaw outputs (first 3): [[63 10 14 43 47 32  1  1 10  1  1 32 12 11  1  1 19 50  1 34 34  1  5 50\n  27 32 32  1  6 63 34  1]\n [ 1 24 10 47 54 42 34 12 32 47 42 63 12 12 24 63  4  1  1 48 63  1 14 43\n  10  1  1 48 19 11  1 12]\n [56  6  1 19  6  1  6 42  1 10  0  9  6 44 34 12 48 16 43  1  1  1 10  1\n  19  6 63 25 47 48 56 42]]\nInput length: 15, Label lengths: [4, 5, 5]\nToken distribution (Batch 31): {1: 4, 32: 1, 5: 1, 40: 1, 10: 2, 33: 1, 34: 1, 9: 1}\nBatch 60, Gradient norm: 35.1138\nEpoch 14, Batch 60/91, Loss: 31.3953\nAvg Blank Probability: 0.0177\nSample predictions: ['a', 'HDAv', 'ak']\nGround Truth (first 3): ['u', '37', '6']\nRaw outputs (first 3): [[ 1 34  1  1 34  1 63  5 22  1 24 57 42 11 10  1  6  6  1  4  4 22  6 56\n  22  1 35 35 63 42  1  1]\n [ 1 30 11  1 19 32 12  0  4  1 13 55  1 27 32  1 43  1  1 36  1  1 10  1\n  10  1 10  6 27 27 34 32]\n [47 27  1 55 42  5 50  1  1 12  5 56  1  1 10 11 47 25  4 19 43 22 32 19\n   5 57  1 47 32 32 32  5]]\nInput length: 15, Label lengths: [1, 2, 1]\nToken distribution (Batch 31): {35: 1, 32: 2, 1: 1, 22: 1, 10: 2, 5: 1, 55: 1, 56: 1, 48: 1, 4: 1}\nBatch 70, Gradient norm: 176.1733\nEpoch 14, Batch 70/91, Loss: 29.4575\nAvg Blank Probability: 0.0177\nSample predictions: ['j3', 'fhamya', '2H']\nGround Truth (first 3): ['h', 'UVE', 'j']\nRaw outputs (first 3): [[10  6 55 63 13 32  1  6 10 24  0  1 35 63 15 11 47  6 48 10 24  1 12 56\n  11 32  1  1 32 19  1 35]\n [56  8 34  5 10 11 10  0 12 12 56  1 47  0 56 27 22  1 55 10  7 27 10 25\n  19 47 51 12 20  4 10 32]\n [ 1  1 19 22 25 12  5 32 63 47  4 10 43 43  1 10  1 47 47  1  0  1 30 27\n  24  1 10 35 16  6  1  1]]\nInput length: 15, Label lengths: [1, 3, 1]\nToken distribution (Batch 31): {1: 3, 56: 1, 32: 1, 11: 1, 34: 1, 7: 1}\nBatch 80, Gradient norm: 27.3061\nEpoch 14, Batch 80/91, Loss: 30.3027\nAvg Blank Probability: 0.0179\nSample predictions: ['3jv-Hfav3e', 'lUia2HAraFa', 'UaU']\nGround Truth (first 3): ['6JT6A', '*ukzOg', 'ks']\nRaw outputs (first 3): [[56 12 47 34 47  1  1  0 42  1 42 47  1 19 25 32  6 56 61  0 19  1  1  1\n  13 34 50 30 22 48  6  1]\n [10 47  1 10 30  1 48 47 63  1  1  4  1 61 42 12  1 42 56  4  1  1 47 42\n  42 43  0 42 27 10  6  1]\n [22  9  1  1 33  1  4 10  6 24 11 32 32 20  3  4  1  1 35 43 10 11 11 32\n  21  4 47 50  1 10  4 56]]\nInput length: 15, Label lengths: [5, 6, 2]\nToken distribution (Batch 15): {23: 1, 1: 3, 35: 1, 4: 1}\nBatch 90, Gradient norm: 16.4050\nEpoch 14, Batch 90/91, Loss: 24.7138\nAvg Blank Probability: 0.0180\nSample predictions: ['FdyFU-sUDa', 'kjPjnv', 'jad-V']\nGround Truth (first 3): ['b3OhG', 'yn*', 'rOq']\nRaw outputs (first 3): [[32 11 10 47 42 32 34 10 13 48 33 22 30 11 10 23]\n [ 4 10 10 19 34 25 10  1 34 47  4 50  7  6 30  1]\n [25 42  1  4  4 48 47 47 10 32 34  1  0  4  1 35]]\nInput length: 15, Label lengths: [5, 3, 3]\nEpoch 14/20, Loss: 28.0504\nToken distribution (Batch 19): {1: 14}\nValidation Loss: 27.9411\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['exRVivK', '1', 'zLD', 'ALMJ', '32']\nCurrent Learning Rate: 6.290067270632257e-07\nEpoch 15, Filtered data size: 3620, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {42: 1, 12: 1, 1: 4, 6: 2, 4: 1, 25: 1}\nBatch 0, Gradient norm: 103.3236\nEpoch 15, Batch 0/91, Loss: 27.8831\nAvg Blank Probability: 0.0181\nSample predictions: ['3vjH', 'dlaHXv8VaAFd', 'a3J']\nGround Truth (first 3): ['Ub', '7VLzPb', '-k']\nRaw outputs (first 3): [[56  4  1 47 35 47 47 19  1 24 42 63 35 56 12 12  1  1  1 34 10 63 47 11\n   4 56  1 33 34  1  1 42]\n [22 12  1 12 32 24 29  1 22 47  0 35 42 48 47 12  0  1 27  4 35  1 30 42\n  10 24  1 22 36 34 10 12]\n [10  1 56 25 16 12  1 11 22 25  1  1 33  1 56 32 11 43  0  1 61 25  5  1\n  35  1  6 34  0  1 47  1]]\nInput length: 15, Label lengths: [2, 6, 2]\nToken distribution (Batch 31): {22: 2, 43: 1, 34: 1, 1: 2, 19: 1, 48: 1}\nBatch 10, Gradient norm: 19.6096\nEpoch 15, Batch 10/91, Loss: 26.8564\nAvg Blank Probability: 0.0183\nSample predictions: ['-vFagxajU', 'la3ra', 'H4lI']\nGround Truth (first 3): ['HlfFN', '5hb', 'Hl']\nRaw outputs (first 3): [[63 12 34 30 22  0  1  1 63  1 47 50  4 32  1 10 11  5 13  6 35  1  9  1\n  18 47  4  4  1 50 56 22]\n [22  1 57 10 44  4  8  1  6  1 11  1  1  4 10 47 43 34 27 47 27  1 20 54\n  48 11 22 35  1  4  1 43]\n [32  1 12  1 10 14  0  1  1 56 32  1 22  1  6 34  4  1 10  0 10  6 22  0\n  48 50 35 42 56 35 47 34]]\nInput length: 15, Label lengths: [5, 3, 2]\nToken distribution (Batch 31): {47: 1, 22: 1, 12: 1, 1: 3, 19: 2, 40: 1, 10: 1, 5: 1, 35: 1, 27: 1, 6: 1}\nBatch 20, Gradient norm: 570.6018\nEpoch 15, Batch 20/91, Loss: 27.1012\nAvg Blank Probability: 0.0183\nSample predictions: ['aHzyjeyXaHQf', 'aldaFHls', '-a3axayH']\nGround Truth (first 3): ['7Ifh9Q', 'UuGt', 'W4WB']\nRaw outputs (first 3): [[ 1  1 63  1 32 19  5 34 50 32 42 57  0  1 10 63  1 19  1  1 11 42  1  1\n  32 10 42  1 11  1 43 47]\n [ 0 12  1 35 11  1  6 28 55  4 25  1 19  5 13 48  6 47  0 11 12 62 34  1\n  32 20  4  1 22 35 11  0]\n [26  4 56 42 22 34 43 10 47 22 27  1 63 40 34 13 24 12 34  0 10 11 63 10\n  10 12  1 10 11  0 20 12]]\nInput length: 15, Label lengths: [6, 4, 4]\nToken distribution (Batch 31): {22: 1, 30: 1}\nBatch 30, Gradient norm: 24.7426\nEpoch 15, Batch 30/91, Loss: 31.1988\nAvg Blank Probability: 0.0185\nSample predictions: ['aUda2Ha', 'a3jXdkd', 'a']\nGround Truth (first 3): ['TA9pm', 'EItm', 'C']\nRaw outputs (first 3): [[ 1  1  1 22 19 11 27  1  1 10 47  1 27 11 32 33  0 42 10 12  4 48 11 10\n  35  1 11 24 32 22  4 22]\n [ 1 56  1 56  1 10 34 22  1 47 30 48  4 35 47 12 24  6 34 47  1 34 43 11\n  11 34 32  4 57  4  1 30]\n [47 10  1 11  1 56 56  0 10  1 27  1 32  6  6 12 22 47 25 12  1  1  1  1\n  22  1  1  0 47 34 10 30]]\nInput length: 15, Label lengths: [5, 4, 1]\nToken distribution (Batch 31): {5: 1, 10: 1, 27: 2}\nBatch 40, Gradient norm: 664.3641\nEpoch 15, Batch 40/91, Loss: 28.3345\nAvg Blank Probability: 0.0186\nSample predictions: ['aHpHadaHFaej', 'F3FaUH', 'fdSkU']\nGround Truth (first 3): ['ViIigG', '9k0', 'PCa']\nRaw outputs (first 3): [[ 1 32  6  1 34 10 43  1 30 12 16  4  1  4 63  6  1 43 32 61 16 50 63  1\n  10 34 30 63 22  1  1  5]\n [34 56  4  1  1  0 19 63 63 56  1 22  4 34  0 34  6 55 30  1 50 50  1  0\n   0 11  5 61 22 11  1 10]\n [16 32 45 12 16 34 10 21 32 33 10  1 42 12 19 27  1  1 19 35  1 11  1 56\n   5  4 12  0 10  1 50 27]]\nInput length: 15, Label lengths: [6, 3, 3]\nToken distribution (Batch 31): {1: 2, 47: 1, 4: 1, 32: 1, 42: 2, 22: 1, 10: 2}\nBatch 50, Gradient norm: 21.0614\nEpoch 15, Batch 50/91, Loss: 30.1029\nAvg Blank Probability: 0.0189\nSample predictions: ['pj', '3k', 'dAUjakgvAQUeF']\nGround Truth (first 3): ['v', 'u', 'cCNy0u1']\nRaw outputs (first 3): [[16 56  4 48 63  1 10 42 35 48 24  1  4 12  1 24  0  4 11  1  6 13 47 63\n  25  4 22  1  4 63  1  1]\n [10 11 27 34 32 34 22  1 34  1 22  1 56 34 22  4 30  4  1 29  9  1 11  1\n  14  4 48  6  1 10 12 47]\n [47 48 47  6 10 35 12  4 32 27 27 27 32  1 42 47  1 24 27 56  0  0  1 56\n   0 48  0  5 57  1 34  4]]\nInput length: 15, Label lengths: [1, 1, 7]\nToken distribution (Batch 31): {12: 1, 33: 1, 57: 1, 10: 2, 1: 2, 35: 1, 56: 3, 6: 1, 32: 1, 27: 1}\nBatch 60, Gradient norm: 20.9186\nEpoch 15, Batch 60/91, Loss: 29.1985\nAvg Blank Probability: 0.0191\nSample predictions: ['afUHyaHC', 'CUjF-f', 'pXFgHaFgAHl3fA']\nGround Truth (first 3): ['n3jVe', 'Sbl', 'HEu9kyT']\nRaw outputs (first 3): [[ 1 29  0  5  1  1 56 56 12 56 63 42 13  1 56  4 47 25  0 32  1  1  1  1\n  42  1 19  1  1 19 56 12]\n [ 6 47 50 32  6 11 10 19  4 47 10 11 63 20  1 10  1  0  1  1 56 47 34 22\n  19 35 34 34  1 32  0 33]\n [ 0 10 32  1  6 34 12 47 32  1 46  0 12 24 59 34 57 34 12 35  0 50 47 36\n  63  1 47 22 24 27 24 57]]\nInput length: 15, Label lengths: [5, 3, 7]\nToken distribution (Batch 31): {4: 1, 12: 1, 56: 1, 22: 1}\nBatch 70, Gradient norm: 19.0341\nEpoch 15, Batch 70/91, Loss: 28.1393\nAvg Blank Probability: 0.0196\nSample predictions: ['ve-dHafI', 'valvk3dP', 'jwAY3']\nGround Truth (first 3): ['uwYu', 'ZEvd7', 'N94']\nRaw outputs (first 3): [[22 22 10 63  1 56 10  6  1  6  1  1 10  4 32 10 10  1 34 19 12 19 11  1\n  24  5 48 34 19 63 11  4]\n [ 5  1 10 32 47 12 22 25 48  1 22 47 43  0 48 42  1 47  1  1  4  1 30 11\n   1 56  1  1  5  0 50 12]\n [ 0  1 23 12  1 34  1 16 10 34 27  0 35  0 34 50 47 27 35  1 11  4 42 48\n   4 32 29  1  1  1 32 56]]\nInput length: 15, Label lengths: [4, 5, 3]\nToken distribution (Batch 31): {42: 1, 47: 3, 9: 1, 14: 1, 35: 1, 10: 1, 1: 1, 4: 1}\nBatch 80, Gradient norm: 418.5671\nEpoch 15, Batch 80/91, Loss: 31.3383\nAvg Blank Probability: 0.0198\nSample predictions: ['vFUa', 'fXavHQ', 'dAXF']\nGround Truth (first 3): ['Zg', 'Uw0', 'fA']\nRaw outputs (first 3): [[22  6  4 15 47 63  1 12 34  0 47 19 61 63 32 10  1 10 19 11 19 63  0 11\n  12 10 34 34 43 10 63 42]\n [32 50 27  0  1  1  0  0  1 44  1 10  6 27 47 10  1  6 27 34  1 35 35 35\n   1 27 42 63  1 47 11 47]\n [47  1  0 32  1  0  7  1 56  1 19  1 10  0 34 11  1  0 47  1  1  0 56 48\n  10  0 20 11 10  1 47 47]]\nInput length: 15, Label lengths: [2, 3, 2]\nToken distribution (Batch 15): {35: 1, 10: 1}\nBatch 90, Gradient norm: 20.4310\nEpoch 15, Batch 90/91, Loss: 28.5817\nAvg Blank Probability: 0.0198\nSample predictions: ['FaIVF', 'vHUFadHdQd', 'aj4lHF']\nGround Truth (first 3): ['6Ki', 'uVaQJ', 'cqS']\nRaw outputs (first 3): [[32 22  1 11  0 10 10  0 12 19 35  1  0 63 32 35]\n [ 1 34 10 35 22 32 50  5 50 14 10 63  1  1 11 10]\n [35 47 57 34 48  0 19  1 32  1 28 32 34 11 35 10]]\nInput length: 15, Label lengths: [3, 5, 3]\nEpoch 15/20, Loss: 27.4494\nToken distribution (Batch 19): {1: 14}\nValidation Loss: 29.4206\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['G', 'Wa131', 'q', 'SdH', 'mSQ']\nCurrent Learning Rate: 7.363961030678927e-07\nEpoch 16, Filtered data size: 5120, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {6: 1, 1: 3, 32: 1, 47: 1, 19: 1, 7: 1}\nBatch 0, Gradient norm: 17.6072\nEpoch 16, Batch 0/128, Loss: 24.8882\nAvg Blank Probability: 0.0198\nSample predictions: ['ak', 'dFdaHlfFjds', 'H2a']\nGround Truth (first 3): ['v', 'xpYZA5', 'Ub']\nRaw outputs (first 3): [[ 1  4 34 50 32 16 35 47  4 10  5 11  1  0 12  0 27 57  1 35 63 47 34 10\n  16 47  0 27 12  1  1  6]\n [11  4  0  6 10  1  1  0 63 42  1  1  7 47  1 34 11 63 63  0  1 20 48 10\n   6 12  6  0  0 35 24  1]\n [10 32  0  0 32  0  6 34 11  4  1 22 47 11 48 23  0 56  5  0  7 35 32 63\n  47  0 19 34  1 55 11 32]]\nInput length: 15, Label lengths: [1, 6, 2]\nToken distribution (Batch 31): {12: 1, 42: 1, 46: 1, 10: 2, 22: 1, 1: 1, 9: 1, 50: 1, 23: 1}\nBatch 10, Gradient norm: 9.7773\nEpoch 16, Batch 10/128, Loss: 20.1727\nAvg Blank Probability: 0.0200\nSample predictions: ['kaPtseFAlkea', 'kLHUXas', 'jIFa']\nGround Truth (first 3): ['ubsoqa', 'blCQ', 'pX']\nRaw outputs (first 3): [[11 11 10  1  1 34  6 12 25  4 22 10 35  6 34 63 27 12 12 24  1  6 20  4\n   1 34  1 30  0  0 47 12]\n [ 1 38 35 56  1  0  5  5 10 10 34 22 11  1  1  0  6 12 32  1  1  1 19  4\n   1  1 25 13  6  1 20 42]\n [42 34 32 48  1 47 12 42 10 42 42 34 11 27 10 11  6  1 56  1 12 55 47 43\n  19  1 18 12  0  0  1  0]]\nInput length: 15, Label lengths: [6, 4, 2]\nToken distribution (Batch 31): {16: 1, 4: 2, 47: 1, 10: 1, 27: 1}\nBatch 20, Gradient norm: 36.0358\nEpoch 16, Batch 20/128, Loss: 21.4010\nAvg Blank Probability: 0.0207\nSample predictions: ['fDnPaU', 'j2jeAGjf', 'ta-IaHjAf']\nGround Truth (first 3): ['2JJ', 'ZGrO', 'xFfxJd']\nRaw outputs (first 3): [[ 6 10 20 10 25  6 11  1  1  4 42  1 11  6  0  1  1 11 32 35  0 56 48 48\n  10  0  0 11  1 10 47 16]\n [30 55  1 35 11 32  1 12 47  4 32  0  1 10 35 29 50  0  1 47  4 12 12  1\n  42 22  0 47  0 10  5  4]\n [14 10  1  1 27  1 10  7 51  1  1 27  0  0  5 34  1 23 32 22 29  1  0  0\n  47 19 25  0  5  1  0 47]]\nInput length: 15, Label lengths: [3, 4, 6]\nToken distribution (Batch 31): {34: 2, 35: 1, 1: 2, 16: 1, 22: 2, 63: 1, 10: 1}\nBatch 30, Gradient norm: 14.9507\nEpoch 16, Batch 30/128, Loss: 23.8097\nAvg Blank Probability: 0.0204\nSample predictions: ['jVaAdaAXiPae', 'vI-d', 'k-FUXkXakFa']\nGround Truth (first 3): ['xXf5uZ', 'lw', 'I0kNxv']\nRaw outputs (first 3): [[10 22 11  4 11  1  1 42  1 19  1 27  1 42  6 11 42  1 11 22  0 11 10  1\n  34 34 47  4  4  4 12 34]\n [ 0  0 63  5 25  5 34  0 19 43 47 12  1  1 10  1 47  1 47  1  6  0 47  4\n   6 12  1  6  5 10  1 35]\n [ 1 63 32 10 45  5  4  0  6  1  1  1 35  0 33  1 22 43 34 32  1 34  1  1\n   1 47 50 42 56 50 12  1]]\nInput length: 15, Label lengths: [6, 2, 6]\nToken distribution (Batch 31): {1: 2, 32: 3, 34: 3, 11: 2, 61: 1, 56: 1, 10: 1, 7: 1, 6: 1}\nBatch 40, Gradient norm: 22.4775\nEpoch 16, Batch 40/128, Loss: 21.5049\nAvg Blank Probability: 0.0206\nSample predictions: ['UjFaUHQHla2ka', 'kalsvjasjaeF', 'IHlAHFea']\nGround Truth (first 3): ['Y1amuTnSp', 'w2kXVHIec', 'BahV']\nRaw outputs (first 3): [[47 11 35 12 20 30 12  1 10 10 56 48 12 11  4  6  1 30 34  1 61  0  1  1\n  12  1 12 12  4  0 25  1]\n [10  1 34  0  1 10  0 35  1 10 43 32  0 48 38 11 57 34  4 24 32  1 35 43\n  42  1  1 34 32 55 10  1]\n [32 12 12  1 10 63 55 63  5 19  5  0 19 19  1  0  0  0 55  1 56 22  1 10\n   1 47 21 25 47  0  1 32]]\nInput length: 15, Label lengths: [9, 9, 4]\nToken distribution (Batch 31): {22: 1, 35: 1}\nBatch 50, Gradient norm: 572.5732\nEpoch 16, Batch 50/128, Loss: 24.7045\nAvg Blank Probability: 0.0211\nSample predictions: ['PjszAaQFaPJad-e', 'aL', 'ay2FaFAyeU']\nGround Truth (first 3): ['V90V682C', 'L', 'QUXKSN']\nRaw outputs (first 3): [[42  1  1 27 11 56 10  1 19 12 12  1  1  1  1  4 19 43  1 24 35  1 22  4\n  11 32 11  0 34  0  0 22]\n [ 0 38  0 50 25 48  4  1  1  6 20  1  1 22  0 25  5 10 30  1 36 36 32 11\n   1  1 47 12 43 22 47 35]\n [19 11 25  1 56 32 24  0 34  0 51  0 27  1 34  1  0  1 10  0 50 32  1 29\n   0 47 22 43 19  0  1 11]]\nInput length: 15, Label lengths: [8, 1, 6]\nToken distribution (Batch 31): {11: 1, 1: 2, 57: 1, 34: 1, 22: 1, 47: 1, 50: 1, 56: 2, 30: 1, 10: 1, 5: 1, 32: 1}\nBatch 60, Gradient norm: 20.3797\nEpoch 16, Batch 60/128, Loss: 23.4301\nAvg Blank Probability: 0.0214\nSample predictions: ['d3IjajHaFa', 'dUjQatavxgQAaV', 'aFaVQaTHa3s']\nGround Truth (first 3): ['oPE*cz', 'RlxA*QNSli', 'fWbbc6']\nRaw outputs (first 3): [[ 4  4  1 47  1  0  6 19  4 32  1 32 10 42  4 50 32 42  0 56 12 35 27 10\n  33  6 10 56  1 19  0 11]\n [56 47 32  0 56 47  0 41  6 42 32  1 63 13 11 11  1 56 56 47  1  0 22  0\n  30  6  1  0 56 12 20  1]\n [35 10  1 47  1 10  0  0  0 63  7 12  4 32 16  5  0 10  7  6 47  0 23 35\n  10 10  1  4  0  1  0 57]]\nInput length: 15, Label lengths: [6, 10, 6]\nToken distribution (Batch 31): {24: 1, 56: 1, 47: 3, 13: 1, 32: 1, 1: 1, 19: 1, 43: 1, 50: 1, 34: 1}\nBatch 70, Gradient norm: 16.0625\nEpoch 16, Batch 70/128, Loss: 23.6601\nAvg Blank Probability: 0.0220\nSample predictions: ['ajl', 'jValNXHfaFsaHe', 'adagaGUAFa']\nGround Truth (first 3): ['56', 'v*LHo0TY', 'lSPYJWf']\nRaw outputs (first 3): [[ 1 10  1  1  6  6  0  0 20 10 27 32 56 34 35 10  4  0 63  1 25  4 30 50\n  61  1  1 13 19 63  6 24]\n [10 48  1  1 47  1 11  0 10  0  7 10 63  0  6 34 34 47 22 48  6 10 10 47\n  47  1  1 35  4 27  4 56]\n [10  0  0 29 50 32  1 35  1  1 22 13  0  5  0 48 32  8  0  1 55  0  0  4\n   0 42  0  1  6 43  0 47]]\nInput length: 15, Label lengths: [2, 8, 7]\nToken distribution (Batch 31): {11: 1, 10: 3, 5: 1, 56: 1, 19: 1, 24: 1}\nBatch 80, Gradient norm: 15.6460\nEpoch 16, Batch 80/128, Loss: 23.0859\nAvg Blank Probability: 0.0221\nSample predictions: ['ja', 'kjk3U', 'jFaQtaPpAHepP']\nGround Truth (first 3): ['iA', 'Yp5', '5rxkXtyka']\nRaw outputs (first 3): [[10 11 10 11 19 10  6 34 42  0 42  1  1  4 35 12 10  1  4  1  1  5  0 14\n  11 56 16 56  6 48 10  0]\n [ 1  0  0 24 50 11  1  1 10 12  1 27  0 24  1 32  1  4 19 47  1 12 27 19\n  34 10 11 11 24 10  0 10]\n [ 1 10  1  0  1 63  0  2  0  1 47  4 43  1 19 32 47  0  1  4  0 12  1  1\n  12 34 32 34 29 24  1 10]]\nInput length: 15, Label lengths: [2, 3, 9]\nToken distribution (Batch 31): {47: 2, 1: 2, 32: 1, 4: 1, 34: 1, 24: 1, 5: 1, 12: 2, 10: 1}\nBatch 90, Gradient norm: 15.3641\nEpoch 16, Batch 90/128, Loss: 22.8326\nAvg Blank Probability: 0.0223\nSample predictions: ['FsvFsf', '3sajaBj', 'asal']\nGround Truth (first 3): ['tkg', 'Ocf0', 'Qi']\nRaw outputs (first 3): [[32 56  1  1 34  0 47 11 47 11 12  0  1  6  1 20  0 34  0 11 47 12 14 34\n  48 22  1 50  0  0 47 47]\n [19  0 19  0  0  0 21  0  1 48 61 47 56  0 27 32 19 34 34  0 47  4 43 50\n  63  0  1  0 10  0 19  1]\n [22  1  1  1  0  0  0 12 45 11 35  1 22 12  1  1  1  0  0 11 12 22 34  0\n   0 50 35  0 29 35  1 32]]\nInput length: 15, Label lengths: [3, 4, 2]\nToken distribution (Batch 31): {22: 1, 27: 1, 1: 3, 10: 2, 12: 1}\nBatch 100, Gradient norm: 536.7051\nEpoch 16, Batch 100/128, Loss: 21.1584\nAvg Blank Probability: 0.0229\nSample predictions: ['jsdHAFdUa3jg3jF', 'deljek2H', 'a3dalFj-aj3xXa']\nGround Truth (first 3): ['EqtUXBUD', 'RMii', 'rQVG7a8bAn']\nRaw outputs (first 3): [[10  4  0  0  4 27 48 42 32 43 10  4 34  0 10  5 12  0 35  5 56 11 12 34\n   6  1 20  4 10  1 11 22]\n [19  5 56 11 11  0  5  0  1 34  5 32  0  0 47  0 63 47 12 32 11  0 63 19\n  34 11  1  0  1 42  0  0]\n [ 0 12  4 34 35 47 42  0 10 11  4  0  1  0 27  5  0  1  1  6 63 11 11  6\n   0  0  0  0 29  6  0  0]]\nInput length: 15, Label lengths: [8, 4, 10]\nToken distribution (Batch 31): {34: 1, 19: 1}\nBatch 110, Gradient norm: 44.2985\nEpoch 16, Batch 110/128, Loss: 26.8574\nAvg Blank Probability: 0.0229\nSample predictions: ['jUeaHakXd', 'l3xj', 'vafvkxeaHUF3Xj']\nGround Truth (first 3): ['eMBEWR', 'xd', 'YiJn5tka6z']\nRaw outputs (first 3): [[10 12 22  1 47  0  0 57  6 12  0 32  0 12  1  5 22 34 34 34  6 19 25 32\n   1  1  1 22 24 10  4  0]\n [47 56  1  0  0 32  0  0 35 27  0 13  1  1  4  5 47  0  1  0 50  0 56  0\n  34 21 47 32  0 22 19  0]\n [ 5 24  0  0  1  0  1  6  1  0 47 13  1  1  0 10  1  0  1  4 34  0 27 19\n   5 34 28  1 47 22 50 34]]\nInput length: 15, Label lengths: [6, 2, 10]\nToken distribution (Batch 31): {32: 2, 47: 1, 20: 1, 7: 1, 48: 1, 46: 1, 56: 1, 35: 1, 63: 1}\nBatch 120, Gradient norm: 40.8471\nEpoch 16, Batch 120/128, Loss: 25.2893\nAvg Blank Probability: 0.0234\nSample predictions: ['F-Hvtas3ua2vaPH', 'fa', 'jUsXUf6alAFf3y']\nGround Truth (first 3): ['UKi-iSUyo', 'Q', 'ooEkgjnB']\nRaw outputs (first 3): [[32  6 10  0  1  6  6 12 47 35 10  5 11  0 10 63  1  1  1  0  0 20 10 51\n   0 47 22 11  0 11 24 32]\n [63  1 47 27  1  0 47  1  4 28  0  0 35 42  1  0  1 22  0 24  1 34 19 47\n  35 28  0 22  0 10  0 47]\n [ 0 56  0 11  1  0  0  1  1  0 43  0  1 47 10  0 34  0  0 55  1 63 62 19\n  12 10  0  0 12  4  0  0]]\nInput length: 15, Label lengths: [9, 1, 8]\nEpoch 16/20, Loss: 23.4352\nToken distribution (Batch 31): {1: 4}\nValidation Loss: 23.7841\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['5N0ju', 'MDVk', 'PbuH2h-L38', 'rdC-', '0bL-p5o']\nCurrent Learning Rate: 8.281152949374526e-07\nEpoch 17, Filtered data size: 5120, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {47: 2, 7: 2, 33: 2, 21: 1, 1: 1, 34: 2, 6: 1, 10: 2, 27: 1, 11: 1}\nBatch 0, Gradient norm: 48.7032\nEpoch 17, Batch 0/128, Loss: 23.9057\nAvg Blank Probability: 0.0238\nSample predictions: ['aAsQ', 'yaIderazVa', 'ad8AjaFVzkjs3']\nGround Truth (first 3): ['xc', 'RkYgh', 'b33h*xc-']\nRaw outputs (first 3): [[ 0 25  0 47 56 12 32 19  1 24  0 56 29  0 11  1 42  0 35 24  6  1  0 32\n   8 12  0 34 32 24  1 47]\n [ 0  0  4 12  5  0 12  0 25  0 47  0 12 19 13  0 10  0 33 50 47  1  0 22\n  10 43  0 47  0  1  1  0]\n [19 35  0  1 34 12 35  1  1 34  0  0  0 27 10  0 43  1  0  0  6 34  6  0\n   0 11  0  0 42 23 35  7]]\nInput length: 15, Label lengths: [2, 5, 8]\nToken distribution (Batch 31): {22: 1, 55: 1}\nBatch 10, Gradient norm: 20.7369\nEpoch 17, Batch 10/128, Loss: 24.3549\nAvg Blank Probability: 0.0242\nSample predictions: ['Ha', 'QadHUaIaixi', 'ajkFjcmaAHipIvd']\nGround Truth (first 3): ['S', 'NJlcyoqK', 'nkX7OoRR9E']\nRaw outputs (first 3): [[34 43  1 11 35 56 11 34  1  1  0 10  0 57  0  4  1  9 63  0  4 32 24 56\n   4 10 10 10  1 50  1 22]\n [ 1  1  0  0 47 24  1 13  1  4 43 32  0  0  4 24  6 10  0  0 19  1 22 19\n  27  0  1  0  1 25 32 55]\n [ 1  1 11  6  0 43  0  6  6  0 35 32  0  1 11  0  5 34  1 32  1  0  0  1\n   1  0 47  0  1  0 36  0]]\nInput length: 15, Label lengths: [1, 8, 10]\nToken distribution (Batch 31): {32: 2, 42: 1, 1: 3, 2: 1, 6: 1, 27: 2, 43: 1, 50: 1, 34: 1, 47: 1, 10: 1}\nBatch 20, Gradient norm: 11.9787\nEpoch 17, Batch 20/128, Loss: 20.2851\nAvg Blank Probability: 0.0244\nSample predictions: ['Hfvgc', 'xjvaFa3gvFaYHU', 'UnvdAUSvAk']\nGround Truth (first 3): ['-Bs', 'LJI8DCME', 'yuDw3']\nRaw outputs (first 3): [[34 24 47  1 34 63  6  1 11  0  1 56 34 63 20 27 36  6 47 34  1  0 20 34\n  32 11 20 47 25 10  0  0]\n [ 0 10  0 47 32  0 47 32 54  0  0  4 32  1  0  0 10 21 10 10 19  0  0  1\n   0  0  0  1  0 10  4 42]\n [22  0 22  0 27  0 12 35  0  9  1  0 32 10  1  0  0  0  1  0 34 18  0  0\n   1 42 56  1  0 24  0  1]]\nInput length: 15, Label lengths: [3, 8, 5]\nToken distribution (Batch 31): {19: 2, 47: 1, 56: 1, 1: 1, 55: 1}\nBatch 30, Gradient norm: 17.2795\nEpoch 17, Batch 30/128, Loss: 23.7334\nAvg Blank Probability: 0.0244\nSample predictions: ['HFUekuAvsI', 'ajaf', 'eFHlaI3HUF4fVUd']\nGround Truth (first 3): ['K7ebq', 'dP', '7FqjaQiPG']\nRaw outputs (first 3): [[34  1  0  0 11  1  1  4 10 47 10 42 63  6  0  6 34 63 35 16  1  0 11  1\n  16  4 29 56  0 47 11 19]\n [32  0 32  1 55 35  0  0  0 34 10  1 24  1  0 50 32  0  0 11  0 11  6 25\n   0  1  6  0  4 42 56  0]\n [ 0  1 34  0  0 42  1  0  0 32  0 32 50 34  0 32 11 10  0 11  1 34 47  0\n   0  0 47  1  0  5  1  0]]\nInput length: 15, Label lengths: [5, 2, 9]\nToken distribution (Batch 31): {34: 1, 10: 1, 1: 3, 56: 1, 47: 1, 21: 1, 25: 1, 16: 1}\nBatch 40, Gradient norm: 8.7123\nEpoch 17, Batch 40/128, Loss: 18.0574\nAvg Blank Probability: 0.0249\nSample predictions: ['HPfdBjdIl', 'jFaUAVsH', 'aviga']\nGround Truth (first 3): ['gZ9rU', 'jAh4', 'kXK']\nRaw outputs (first 3): [[ 0 10  0 35 10 32  0 34 10 11  0 12  1 50 19 10  0 11  1 10  1 12  0  1\n  12 57 63  0  1  1  6 34]\n [ 0 32 22 56 10 35  1  1 19  5  0 27 11  0 34  0 63  0  1  0  0 10  0  0\n   0 10  0  0 32  1  0 10]\n [ 6  1  9  0 12 34  1  0  0  0 32 27  0  0  0  0  1  0 47  1  0 47  0  0\n   0  5 32  0 20 33  0  1]]\nInput length: 15, Label lengths: [5, 4, 3]\nToken distribution (Batch 31): {10: 2, 1: 3, 34: 1, 12: 1, 47: 2, 5: 1, 22: 1, 32: 1, 6: 1, 56: 1, 11: 1}\nBatch 50, Gradient norm: 36.5297\nEpoch 17, Batch 50/128, Loss: 26.5463\nAvg Blank Probability: 0.0258\nSample predictions: ['fjd32aI2jaFeF', 'Hx', 'avHaIlFHa']\nGround Truth (first 3): ['HkIUAN8CPh', '6', 'WOr3O']\nRaw outputs (first 3): [[ 6 34  1  5  0 32  1  0  1 22 56  0  0 10 32 24 32  0  0  0  1 34  0  0\n   0  1 11 11  5 14  0 10]\n [ 0 24 22  6 10 10  0 56 36 25  1  1  0  1  0 12  0  0  0 20  0 35  4 13\n  50 10  0 11  0  1  0  0]\n [ 4 47 34  0  0  0  0  1  0 27 10  0  0 47  0 22  0  1  1  0  1  0 25  0\n   0  0 10  4  0  0 10 10]]\nInput length: 15, Label lengths: [10, 1, 5]\nToken distribution (Batch 31): {35: 1, 1: 1, 27: 2, 42: 1, 50: 1}\nBatch 60, Gradient norm: 25.6742\nEpoch 17, Batch 60/128, Loss: 27.6817\nAvg Blank Probability: 0.0257\nSample predictions: ['UQXUjtFyPfTaH', 'F-P-sk', 'ia']\nGround Truth (first 3): ['wCG6wX7fc', '76rX', 'w']\nRaw outputs (first 3): [[47 32  0 43 10 11  0  0  0  0 10 21  0  0  0 43  0  0  0 10 56  0 42  1\n   1 16  4  0 24  6 22  0]\n [43 32  0  6 32  0  0 35 61  1  4 36 12 12 19 22  0 55  0  1 19  0  6  1\n   1 63  1  0 34  0  0  0]\n [ 0 63  0  1  1 47 22 32  0 32  0 34 34  0  0 32  0  0  1  0 60  0 19 34\n   0  0 34  0  1  0 27  0]]\nInput length: 15, Label lengths: [9, 4, 1]\nToken distribution (Batch 31): {4: 2, 13: 1, 19: 1, 9: 1, 1: 1, 50: 2, 28: 1, 27: 1, 32: 1, 35: 1, 6: 1, 47: 1, 11: 1}\nBatch 70, Gradient norm: 14.3764\nEpoch 17, Batch 70/128, Loss: 20.4491\nAvg Blank Probability: 0.0265\nSample predictions: ['jpl3aj28LaFe', 'dQIkUliJ', 'adesdaejF']\nGround Truth (first 3): ['p1TWXUAoWG', 'VNbV', '*dgl1']\nRaw outputs (first 3): [[10  4  1 53 11  0 63  0  1  1 34  0 43 10  0  4  4 43  1  6  0 24 11 56\n   0 56 10  0 10  0  0  4]\n [ 0 43  0  4  1 56  0  4  0  1  0 50  0  6  0  0  0  0 43 32  0  0  1  0\n   0  0 19 42  5  0  0 13]\n [ 0  0  0  1  0 35 56  1 42 32  0 34  0  1  0 40  0 32  0 26  0  0 19  0\n  48  1 11 13  0  0  0  4]]\nInput length: 15, Label lengths: [10, 4, 5]\nToken distribution (Batch 31): {1: 4, 34: 4, 35: 1, 6: 1, 7: 1, 5: 1, 56: 1, 10: 1, 32: 1}\nBatch 80, Gradient norm: 16.4614\nEpoch 17, Batch 80/128, Loss: 21.6096\nAvg Blank Probability: 0.0269\nSample predictions: ['adeaHyVIzgAasas', 'UaIaBVdvaJaUdj4', 'v2Uav']\nGround Truth (first 3): ['9KxJ3uEnv4', '7ONq2*yVPG', 'LQY']\nRaw outputs (first 3): [[ 1 47 22  0 50  0 11  0  0  1 41  0  7 47 11  0  0  0 34 34 63  0  1 10\n  42 22  0  1  0 48 35  1]\n [ 0  0  0  0  0  9 19  0  0  0 32  0  0  0  1  0  0 11  0  0 32  1  0 20\n  11  1  0 32  0  0  0  0]\n [ 5  0  0  0  0  0  0  0  0  0  0  0  0  0 24  1 47  0  0  1 12  0  1 47\n   0 32 35  1  0 56  0  0]]\nInput length: 15, Label lengths: [10, 10, 3]\nToken distribution (Batch 31): {43: 1, 1: 2, 10: 1, 12: 2, 34: 1, 6: 1, 50: 1, 0: 1, 7: 1, 11: 1}\nBatch 90, Gradient norm: 19.1581\nEpoch 17, Batch 90/128, Loss: 23.1888\nAvg Blank Probability: 0.0269\nSample predictions: ['AGXF', 'XyeaAasa2aVaiQ', 'Ij']\nGround Truth (first 3): ['p9', 'Aofdh5RsDS', 'q']\nRaw outputs (first 3): [[ 0 50 35  0  1 19  0 34 24 47  6  0  0 27  0 47  1  1 11 56 34  1  0  4\n  51 48 19  0 50  0  0 43]\n [33 25 10 12  0  0  0  0  0  1  0  1  0  0  0  0 42  0 12 25 11 12  0  3\n   0 11 12  0 50 24 12  1]\n [50  0  6  0  1 25  0  0  1  0  4 42 12  1 57  0  1  0  0  0  0  4  0  0\n   0 55 38  0  0 59  0  0]]\nInput length: 15, Label lengths: [2, 10, 1]\nToken distribution (Batch 31): {6: 1, 20: 1, 1: 1, 56: 1}\nBatch 100, Gradient norm: 18.3882\nEpoch 17, Batch 100/128, Loss: 22.7323\nAvg Blank Probability: 0.0279\nSample predictions: ['vOUiAUPlzp32', 'lvDjFxFg', 'aAsafPFHaQ3f']\nGround Truth (first 3): ['NNv8U8', '60ko', '97Vu2R']\nRaw outputs (first 3): [[22 12  0 50  0 43 11 36  1  4 34 11 25 11  0 24 32  0 16  0  4 12  1 10\n   0  0 35  0 50  0 42  6]\n [ 0  0  0  0  0 32 25  0  0  1  4  1 30 10  0  0  1  0 20 34  0  0 23  0\n   4 19  0  0  0 16  0  0]\n [ 0 30  0 55  0  0  0  0 11 32  0  0  0  0  0  0  0  0  0  1  0 34  0  0\n  56  0  0 32  0  0  0  1]]\nInput length: 15, Label lengths: [6, 4, 6]\nToken distribution (Batch 31): {22: 1, 34: 1}\nBatch 110, Gradient norm: 14.1784\nEpoch 17, Batch 110/128, Loss: 20.8077\nAvg Blank Probability: 0.0290\nSample predictions: ['IaUFafFaHCaPHA', 'jFYgfljkL', 'ImglaaDQYFl3F']\nGround Truth (first 3): ['Z5bX87Rpgi', 'bVwNB', '607MvwXKzK']\nRaw outputs (first 3): [[35  0 35  0  0  0  8  0 23 47  0 56 63 11  1 12  0  7  0 19 34  0  0  6\n   6 32 30  0  0 12  0 22]\n [ 1  0 13  0 35  4  0  0  0  0  1 11  0 10  1  0  0  0 32  0  0  0  0  0\n   0 19  0  0  0 47 34 34]\n [ 0 51  0  0 33  0  1 11  0  0  0  0  0  0  0  5  0 32  0 34  0  0  0  0\n   0  0  0  1  0  0  0  0]]\nInput length: 15, Label lengths: [10, 5, 10]\nToken distribution (Batch 31): {12: 2, 25: 1, 27: 2, 1: 3, 35: 2, 32: 1, 0: 1, 4: 1, 19: 1}\nBatch 120, Gradient norm: 21.6222\nEpoch 17, Batch 120/128, Loss: 24.1575\nAvg Blank Probability: 0.0293\nSample predictions: ['av', '-fdX', 'kFfHaFskH2']\nGround Truth (first 3): ['Q', 'io', 'Y5jwp']\nRaw outputs (first 3): [[ 0 63  0  0  0 12  1 11  0  0  0  0 10  0 47  0  0 10  1  0  0  0  0  0\n   0 34  0 32 19  1 47  0]\n [22  6 32  0  0  0  0 11  0  0  0  0  1  0  0  0  0  0  1  0  6 27  0  0\n   0  0 47  0  0  0  0 25]\n [ 0  4  6  0 63  0  0 19  6  0  0  0  0  0  1  0  0  0 25  0  0 28  0  1\n   0  0  0  0 27  0 32  0]]\nInput length: 15, Label lengths: [1, 2, 5]\nEpoch 17/20, Loss: 22.9689\nToken distribution (Batch 31): {1: 15}\nValidation Loss: 23.4731\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['rn3tWG', 'Cg0k4r', 'Yp5', 'kPzmE48bf0', '8AIjG']\nCurrent Learning Rate: 9.01905871769531e-07\nEpoch 18, Filtered data size: 5120, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {1: 2}\nBatch 0, Gradient norm: 21.7888\nEpoch 18, Batch 0/128, Loss: 22.2376\nAvg Blank Probability: 0.0296\nSample predictions: ['akajsI', 'adsajFaUesjAH', 'PUlGIaAFjIsaHQ']\nGround Truth (first 3): ['yzB', 'MFC1jnHEBt', '7FqjaQiPG']\nRaw outputs (first 3): [[ 1  1 42 11  0  0 35  0  0 19  0 13  0 12  0  0  0 63 34 11  1  0  0 50\n  47  0 47 22  0 10  0  0]\n [11  4  0  0  0  0  1  0  0  0 47  0  0  0 11  0  0  4  0 63  0  0  1  0\n  47  0 36  0 11 32  0  1]\n [ 0  0  0  0 35  0  1 34  0  0  1  0  0  0  0  0  0  0  0  0  0 34 32  0\n   0 50  0  0 11  0  0  0]]\nInput length: 15, Label lengths: [3, 10, 9]\nToken distribution (Batch 31): {5: 1, 1: 2, 10: 1, 19: 1, 22: 1, 48: 1, 34: 1, 14: 1, 50: 1}\nBatch 10, Gradient norm: 24.7098\nEpoch 18, Batch 10/128, Loss: 25.7463\nAvg Blank Probability: 0.0298\nSample predictions: ['FeI8V3sHksaeAs', 'majnlaAuIH', 'FDFAHzp']\nGround Truth (first 3): ['8SCvKN0S', 'JwDvNN', '4oAo']\nRaw outputs (first 3): [[ 0 13 32  1 10 22  0  0  0  0  0 12  0  0  0 12  0 34 25 10  0 50 19  0\n  27  0  1 32  0  0 25  5]\n [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 27  0  0  1  0 61  0  0\n  12  0  0  0  0  0 63  1]\n [ 0  0  0  0  0  1  4  4  1  0 11 27  0  0  1  0  0  0  0  0  0  0  0  0\n   0  0  1  0 27  0  0  0]]\nInput length: 15, Label lengths: [8, 6, 4]\nToken distribution (Batch 31): {1: 1, 34: 1, 35: 1, 50: 1, 4: 1, 0: 2, 32: 2, 11: 1}\nBatch 20, Gradient norm: 16.6639\nEpoch 18, Batch 20/128, Loss: 19.3644\nAvg Blank Probability: 0.0308\nSample predictions: ['kdUklav0ax', 'hlklas', 'k9Hdav']\nGround Truth (first 3): ['KtQhCC', 'k1Z', 'rf2o']\nRaw outputs (first 3): [[ 0  0 11  0 11  1  1  0  0  0 23 19  0  0 63 19 47  0 27  0  0 11 12  1\n  33  1 12  0  0  0  0  0]\n [ 0  0  0 10  0  0  0  0  0  6  0  5  0  0  0  0  0  0  0  0 27  0  0  0\n   0 32 11  0  0 11  0  0]\n [ 0  0  0  0  0  0  0 32  0 10 42  0  0 32  0  0  0  0  0  0 34  0 32  0\n   0  0  0  0  0  0  0 35]]\nInput length: 15, Label lengths: [6, 3, 4]\nToken distribution (Batch 31): {11: 1, 24: 1, 1: 1, 47: 1}\nBatch 30, Gradient norm: 25.7107\nEpoch 18, Batch 30/128, Loss: 22.4643\nAvg Blank Probability: 0.0310\nSample predictions: ['3lPHeelajaXAp', 'U-l32', 'FUA4Fg']\nGround Truth (first 3): ['PwC8ai3', 'zBv', 'K0b']\nRaw outputs (first 3): [[56 47 32 16  1  1 63  0  6  0 32 34  0  0 48  0  0 10 42 34  0  0  0  0\n   0 48  0 35  1 34  0  0]\n [ 0 63 47  4  1  0  0 10  0  0  0 34  0  0  0  0  0  0  0  0  0  0  0  0\n  10 13 32  0 34 35  0 24]\n [42  0  0  1 32  0  0 20 32 11  1  0  0  0 32  0  0  0  0 19  0  0  0  0\n   0  0 10  0  0  0 34  0]]\nInput length: 15, Label lengths: [7, 3, 3]\nToken distribution (Batch 31): {11: 1, 0: 2, 22: 2, 45: 1, 49: 1, 27: 2, 34: 1, 25: 1, 1: 1}\nBatch 40, Gradient norm: 22.4131\nEpoch 18, Batch 40/128, Loss: 22.6024\nAvg Blank Probability: 0.0319\nSample predictions: ['dAUlXU', 'aIfaxHeavf', 'aeafjdsjAxaj']\nGround Truth (first 3): ['TOI', 'bVwNB', 'IsX3zLd']\nRaw outputs (first 3): [[ 0  1  1 48  0  0  0 48  0  0 25  0  0 43  0 10  0  0  1  0  0 34  0  0\n   0 12  1  0 10  0  0 11]\n [ 0  0  0 35  0  0  0  0 27  0  0 27  0  0  0  0 22  0  5  0  0  0  0  1\n   0  0  0  0  0  0  0  0]\n [47  6  1  0  0  0  0 32  0  0  0  0  0  0 32  0  0 47 48  1  0  0  0  0\n   0  0 47  0  0  0  0  0]]\nInput length: 15, Label lengths: [3, 5, 7]\nToken distribution (Batch 31): {12: 1, 11: 1, 1: 4, 19: 1, 32: 2, 4: 1, 34: 1, 27: 1, 56: 1, 10: 1}\nBatch 50, Gradient norm: 20.2393\nEpoch 18, Batch 50/128, Loss: 21.5471\nAvg Blank Probability: 0.0328\nSample predictions: ['aBUefgPkal7a2', 'dUFayAkfUelA', 'lHktsS3yXPea']\nGround Truth (first 3): ['WpNtD7cz', 'E6HnJZsVV', 'eQ8pMyQp']\nRaw outputs (first 3): [[ 0  0  0  0  0  0 34  0  1  0 11  1  0 34  0  0  0  0  0  1  0  0  0  0\n  36  1  0  0  1  0  0  0]\n [ 0  0  0  0  0  0 11  1  4  5  0  1 34  0  0  0  0  0  0  0  0  0  0 47\n  27  0 10 50  0  0  0  0]\n [ 0  0  0  0 47  0  1  1 44  0  0 11  0  0  0  0  0  0  0 63  0  1  0  0\n   0  0  0  0  0  0 32  0]]\nInput length: 15, Label lengths: [8, 9, 8]\nToken distribution (Batch 31): {12: 1, 42: 1, 51: 1, 1: 1, 61: 1, 34: 1}\nBatch 60, Gradient norm: 19.0235\nEpoch 18, Batch 60/128, Loss: 20.3455\nAvg Blank Probability: 0.0334\nSample predictions: ['iaHfdasHPuva', 'sHvX', 'lfga']\nGround Truth (first 3): ['5yccyJ', 'Bq', '0x']\nRaw outputs (first 3): [[ 0  0 12 10 11  0  0  0  0 25  1  0 11  0 56  0 12  0  0  0  4  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 1  0  0  0  0  0  0  0  0  0 56  0  0  0 34  0 34  0 11 47 32  0  0  0\n   0  0 47  0  0  0  0 42]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 43  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [6, 2, 2]\nToken distribution (Batch 31): {10: 2, 0: 2, 32: 2, 12: 1, 1: 1, 6: 1, 11: 1, 9: 1, 43: 1, 34: 1, 30: 1}\nBatch 70, Gradient norm: 35.4483\nEpoch 18, Batch 70/128, Loss: 27.3234\nAvg Blank Probability: 0.0344\nSample predictions: ['Rjcdas', 'xalUIUaHaesd', 'afIUaUUavkgjAH']\nGround Truth (first 3): ['JfCY', 'CZfOCe9FV', '4yILIwOF']\nRaw outputs (first 3): [[ 0  0  0  0  0  1  1 34 33  0  0  0  0  0  0  0  0  0 11  0  6  0  0 12\n   0  0  1  0 55  1 33  0]\n [ 0  0  6  0  1  0 35  0  0  0 56  0  0  0  0  0  0  0  0  1 34  0  0  0\n   0  1  0  0 48  0  0 10]\n [ 0  0 35  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0 25  0  0  0  1\n   0  1  0  0  0 50  0  0]]\nInput length: 15, Label lengths: [4, 9, 8]\nToken distribution (Batch 31): {27: 1, 22: 2, 10: 1}\nBatch 80, Gradient norm: 19.7661\nEpoch 18, Batch 80/128, Loss: 21.6335\nAvg Blank Probability: 0.0350\nSample predictions: ['HyazUFAyAyF', '3aH8axH', 'Fg3vXRFjHP']\nGround Truth (first 3): ['kAWIPaZw4', '7lDV', 'zninSN1y7G']\nRaw outputs (first 3): [[ 0 56 32  0  0  0  0 11  0 10 32  1 36 11  0  0 27  0  0  1  0  0  0  0\n   0  0  0  0  0  1  0  0]\n [ 0  1  0  1  1  0  4  0  6  0  0  0  4  0  0  1  0 56  0  0  0  1 10  0\n   0  0  0  0  0 11  0  0]\n [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 34  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [9, 4, 10]\nToken distribution (Batch 31): {22: 1, 35: 1, 1: 5, 0: 1, 25: 1, 34: 1}\nBatch 90, Gradient norm: 17.5581\nEpoch 18, Batch 90/128, Loss: 20.5978\nAvg Blank Probability: 0.0360\nSample predictions: ['XIaFXUakNetAPd', 'kjaz', 'ilHd2vV']\nGround Truth (first 3): ['3JuRA61mc', '2f', 'P7QbB']\nRaw outputs (first 3): [[50  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 47 10\n  27  1  0  0  1  0 24 22]\n [ 0  0  0  0  0  0  0  0  0  0  0 63  0  0  1  0  0  0  1  0  0 34  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0 32  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  1]]\nInput length: 15, Label lengths: [9, 2, 5]\nToken distribution (Batch 31): {20: 1, 47: 1, 32: 1, 0: 1}\nBatch 100, Gradient norm: 106.5834\nEpoch 18, Batch 100/128, Loss: 21.7559\nAvg Blank Probability: 0.0364\nSample predictions: ['vHfjkaHf', 'ajXiVXerFkjU', 'aFa']\nGround Truth (first 3): ['2UiKEQ', '5JsDVGajf', '56']\nRaw outputs (first 3): [[ 0  1  0  0  0  0  4  0  0  0  0  0  0  6  0 11  0  0  0  0  0  0 50  0\n   0  6  0  0 59  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0\n   0 50  0 11  0  0  0 47]\n [ 0  0  0 32  0  0  0  1  0  0  0  0  0 56  0  0  0 27  0  0  0  0  0  0\n   0  0  0 25  0  0  0  0]]\nInput length: 15, Label lengths: [6, 9, 2]\nToken distribution (Batch 31): {34: 3, 32: 1, 0: 2, 50: 1, 1: 1}\nBatch 110, Gradient norm: 21.3185\nEpoch 18, Batch 110/128, Loss: 19.6803\nAvg Blank Probability: 0.0373\nSample predictions: ['HIvfa0afeG', 'aUlHHlidU', 'Fk20a']\nGround Truth (first 3): ['b005xtkb', 'X9rqrpSp', 'zOxS']\nRaw outputs (first 3): [[34  1  0  0  0  0  0  0  0  0  0  0  0 10  0 11  0 12  0  0  0  1  0  0\n  47  0 27  0  0 34  0 34]\n [ 0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0 12 20  0\n   0  0  0  0  0  0  0 32]\n [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 34  0  0  0  0  0\n  25  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [8, 8, 4]\nToken distribution (Batch 31): {32: 1, 1: 3, 7: 1, 29: 1, 56: 2, 0: 1, 4: 1, 19: 1, 30: 1, 9: 1, 6: 1, 12: 1}\nBatch 120, Gradient norm: 65.2942\nEpoch 18, Batch 120/128, Loss: 19.0698\nAvg Blank Probability: 0.0378\nSample predictions: ['aLUl', 'jAUaHuUHaHFke', 'BHbaxFdzH']\nGround Truth (first 3): ['r5y8', 'JHJlmh0i', 'NS7KJL6']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0 10 59  0  0  0 11  0  0  0  0  0  0  5  0  1  0 28\n   0  0  0  0  0 11 47  0]\n [ 0  0  0  1  0  1  0  0  0  0  0  0  0  0  0  1  0 41  0  0  1  1  0  0\n   0  0  0  0  0  0  0  0]\n [47  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11 63  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [4, 8, 7]\nEpoch 18/20, Loss: 22.2289\nToken distribution (Batch 31): {1: 15}\nValidation Loss: 23.4005\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['nq', 'fxHGS', '9IIwuwWAr', 'nwEPlz6V', '4rz']\nCurrent Learning Rate: 9.559508646656382e-07\nEpoch 19, Filtered data size: 5120, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {6: 1, 1: 4, 0: 3, 10: 1, 20: 1}\nBatch 0, Gradient norm: 23.6818\nEpoch 19, Batch 0/128, Loss: 22.5246\nAvg Blank Probability: 0.0388\nSample predictions: ['iF', 'J32IXsa', 'avAv']\nGround Truth (first 3): ['Y', 'vpIY', 'AfNS6']\nRaw outputs (first 3): [[ 0  0  0  0  0  2  0  0  0  0  0  0  1  6  0 34  0  0  0  1  0  0  0  0\n   0  0  0  0  0  0 12  6]\n [32  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [50  0  0  0  0  1  0  0  0  0  0  0  0  0  0 34  0  0  0  0  0  0  0  0\n   0  0  0  0  0 56  0  0]]\nInput length: 15, Label lengths: [1, 4, 5]\nToken distribution (Batch 31): {50: 1, 25: 1}\nBatch 10, Gradient norm: 46.6971\nEpoch 19, Batch 10/128, Loss: 25.0451\nAvg Blank Probability: 0.0400\nSample predictions: ['PAVFsaaAaP', 'lfFIlIlUas', 'a8H3lXaAd']\nGround Truth (first 3): ['rMdg2h0uii', 'M*li4jM', 'KFJJ7Egd']\nRaw outputs (first 3): [[42 12  1  0  0  0  0  4  1  0  0  0  1  0 29  0  0 12  0  0  0  0  0  0\n   0  0  0  0 50  0 11 50]\n [ 0  0  0  0  0 11  0  0  0  0 34  0  0  0  6  0  0 43  0  0  0  0  0  0\n   0  0  0 34 35  0  0  0]\n [ 0 32  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  1  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [10, 7, 8]\nToken distribution (Batch 31): {19: 2, 36: 2, 32: 1, 34: 2, 1: 4, 47: 1, 8: 1, 6: 1, 4: 1}\nBatch 20, Gradient norm: 27.5125\nEpoch 19, Batch 20/128, Loss: 23.7628\nAvg Blank Probability: 0.0406\nSample predictions: ['lGGdlai', 'aFXIaIa', 'UA2UaHsaXF']\nGround Truth (first 3): ['CYefHF', '1BaHucs7', '45t061hgf9']\nRaw outputs (first 3): [[ 0  0  0 22  0  0 33 10  0  0  0 56 27  0  1  0  0  0  0  4  0  0  0  0\n   0  0  0 42  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [6, 8, 10]\nToken distribution (Batch 31): {1: 2, 0: 9, 34: 1, 27: 1, 12: 1}\nBatch 30, Gradient norm: 23.2918\nEpoch 19, Batch 30/128, Loss: 20.3585\nAvg Blank Probability: 0.0435\nSample predictions: ['jHAIF', 'ka3kaHT', 'DasfiEaJ3aQd']\nGround Truth (first 3): ['uduag5', 'fr1jAmXu', 'RMaR5*7p']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0 34  0  0  0  0  0  0  0 50  0  0  0  0\n   0  0  0  0 19  0 10  1]\n [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [6, 8, 8]\nToken distribution (Batch 31): {42: 1, 59: 1}\nBatch 40, Gradient norm: 152.7151\nEpoch 19, Batch 40/128, Loss: 20.2017\nAvg Blank Probability: 0.0437\nSample predictions: ['HaY', 'sjXmfTFae', 'AamH']\nGround Truth (first 3): ['7zV', '-i6LwZrz47', 'lj1']\nRaw outputs (first 3): [[ 0  0 27  0  1  0  0  0  0 35  0  0  0  0 32  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0 10  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n   5  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [3, 10, 3]\nToken distribution (Batch 31): {12: 1, 0: 4, 35: 1, 21: 1, 1: 4, 48: 1, 22: 1, 62: 1, 47: 1}\nBatch 50, Gradient norm: 91.1311\nEpoch 19, Batch 50/128, Loss: 27.0448\nAvg Blank Probability: 0.0452\nSample predictions: ['V', 'UQIaQ', 'f2']\nGround Truth (first 3): ['1', '0pQUIWd', '4RpW']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0 10 30  0 12  0  0  0  0  0  0  0  0  0  0  0 63\n   0  0  0  4  0  0 32  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  34 42  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0 12  0  0  0  0]]\nInput length: 15, Label lengths: [1, 7, 4]\nToken distribution (Batch 31): {32: 1, 35: 2, 43: 1, 0: 7, 5: 1, 47: 1, 14: 1}\nBatch 60, Gradient norm: 21.9290\nEpoch 19, Batch 60/128, Loss: 20.2330\nAvg Blank Probability: 0.0445\nSample predictions: ['vPad', 'xnjQUd', 'akA3jj']\nGround Truth (first 3): ['NkE9', 'GRgo5', 'MRrU']\nRaw outputs (first 3): [[ 0 24  0  0  0  0  0  0  0  0  0  0  0  0 47 19  0  0  0  0 63  0  0  0\n   0  0  0  0  0  0  0 32]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  1  0  0  0  0  0  0  0 34  0  0  1  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [4, 5, 4]\nToken distribution (Batch 31): {1: 3, 12: 1, 0: 7, 32: 1, 47: 1, 10: 1}\nBatch 70, Gradient norm: 35.7211\nEpoch 19, Batch 70/128, Loss: 20.5811\nAvg Blank Probability: 0.0485\nSample predictions: ['a', 'UiP', 'j']\nGround Truth (first 3): ['waV', 'Mx', 'yn*']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0 47\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0 43  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [3, 2, 3]\nToken distribution (Batch 31): {27: 2, 6: 1, 12: 2, 11: 1, 0: 3, 43: 1, 1: 1, 4: 1}\nBatch 80, Gradient norm: 66.1150\nEpoch 19, Batch 80/128, Loss: 24.3402\nAvg Blank Probability: 0.0490\nSample predictions: ['v', 'fsaXl4', 'laEa']\nGround Truth (first 3): ['O', 'C5Wdy4c', 'WLe']\nRaw outputs (first 3): [[ 0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [1, 7, 3]\nToken distribution (Batch 31): {4: 1, 0: 1}\nBatch 90, Gradient norm: 27.9712\nEpoch 19, Batch 90/128, Loss: 22.2370\nAvg Blank Probability: 0.0498\nSample predictions: ['FI', 'SadaFa3', 'da8UicHHF']\nGround Truth (first 3): ['lZ2TUT', 'q9zklSaiuC', 'AXtKCJ05k']\nRaw outputs (first 3): [[ 0  0  0  0  0 47  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0\n  19  0  0 11  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [6, 10, 9]\nToken distribution (Batch 31): {1: 4, 0: 7, 34: 1, 28: 1, 27: 1, 24: 1}\nBatch 100, Gradient norm: 28.7379\nEpoch 19, Batch 100/128, Loss: 21.8866\nAvg Blank Probability: 0.0519\nSample predictions: ['ua0ia', 'FUjua', 'I']\nGround Truth (first 3): ['P5-Gz9K', 'zYARCOeb', '2j']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0 47  0  0  0  0  0  6  0  0 32  0  0  0  0  0 34  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [7, 8, 2]\nToken distribution (Batch 31): {56: 1, 3: 1, 0: 8, 9: 1, 27: 1, 57: 1, 34: 1, 47: 1}\nBatch 110, Gradient norm: 22.0632\nEpoch 19, Batch 110/128, Loss: 20.0251\nAvg Blank Probability: 0.0536\nSample predictions: ['alak', 'av', 'lH']\nGround Truth (first 3): ['hACa', 'g', 'kOnkX']\nRaw outputs (first 3): [[ 0  0  0  0  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [4, 1, 5]\nToken distribution (Batch 31): {3: 1, 35: 1, 42: 1, 0: 4, 27: 1}\nBatch 120, Gradient norm: 21.6873\nEpoch 19, Batch 120/128, Loss: 19.1026\nAvg Blank Probability: 0.0543\nSample predictions: ['fd', 'jI', 'HklFaHl3']\nGround Truth (first 3): ['**GKC5p', 'MI', 'Ql1pa--3']\nRaw outputs (first 3): [[ 6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0\n   0  0  0  0  0  1  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [7, 2, 8]\nEpoch 19/20, Loss: 21.3404\nToken distribution (Batch 31): {1: 14}\nValidation Loss: 22.8048\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['Tn', 'zypb', 'U6LgEHC8oW', 'c', 'NXr']\nCurrent Learning Rate: 9.889195065356238e-07\nEpoch 20, Filtered data size: 5120, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {43: 1, 0: 11, 55: 1, 12: 1}\nBatch 0, Gradient norm: 33.0218\nEpoch 20, Batch 0/128, Loss: 23.5026\nAvg Blank Probability: 0.0550\nSample predictions: ['asa3P', 'sHYFe', 'Iaej']\nGround Truth (first 3): ['PDeSdwlOT', 'kPAyIFQu', 'fForlf']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0 32  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [9, 8, 6]\nToken distribution (Batch 31): {63: 1, 0: 11, 27: 1, 22: 1, 42: 1}\nBatch 10, Gradient norm: 222.0476\nEpoch 20, Batch 10/128, Loss: 18.8017\nAvg Blank Probability: 0.0587\nSample predictions: ['AlF', 'maga', 'P-']\nGround Truth (first 3): ['pOTlc0P5pw', 'u6XUi', 'n']\nRaw outputs (first 3): [[ 0 13  0  0  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  25  0  0  0  0  0  0  0]\n [ 0  0  0  0 47  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [10, 5, 1]\nToken distribution (Batch 31): {4: 1, 0: 3}\nBatch 20, Gradient norm: 19.4357\nEpoch 20, Batch 20/128, Loss: 18.0102\nAvg Blank Probability: 0.0600\nSample predictions: ['<empty>', 'U', 'I']\nGround Truth (first 3): ['6', '7N7d', 'g']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 4, 1]\nToken distribution (Batch 31): {1: 1, 0: 11, 11: 1, 32: 1, 34: 1}\nBatch 30, Gradient norm: 134.0172\nEpoch 20, Batch 30/128, Loss: 21.6583\nAvg Blank Probability: 0.0612\nSample predictions: ['a', 'IF', 's']\nGround Truth (first 3): ['T6', 'AE', 'q']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 2, 1]\nToken distribution (Batch 31): {10: 1, 0: 7}\nBatch 40, Gradient norm: 19.9861\nEpoch 20, Batch 40/128, Loss: 17.9644\nAvg Blank Probability: 0.0663\nSample predictions: ['aA', 'Ae', 'ela']\nGround Truth (first 3): ['MmvXqd05', '55kxoPw', 'K9']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n   0  0  0 34  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [8, 7, 2]\nToken distribution (Batch 31): {11: 1, 0: 7}\nBatch 50, Gradient norm: 149.2832\nEpoch 20, Batch 50/128, Loss: 20.6494\nAvg Blank Probability: 0.0672\nSample predictions: ['IJJ', 'Vlai', 'P']\nGround Truth (first 3): ['9KaMuuhtgy', 'RQz0Sj', '8']\nRaw outputs (first 3): [[ 0  0  0 32  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  1  0  0  0  0]]\nInput length: 15, Label lengths: [10, 6, 1]\nToken distribution (Batch 31): {0: 15}\nBatch 60, Gradient norm: 149.0585\nEpoch 20, Batch 60/128, Loss: 20.6029\nAvg Blank Probability: 0.0675\nSample predictions: ['<empty>', 'Ak', 'aF']\nGround Truth (first 3): ['Q', '1qwdH4orZZ', 'b0sr']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 47  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [1, 10, 4]\nToken distribution (Batch 31): {0: 15}\nBatch 70, Gradient norm: 29.2040\nEpoch 20, Batch 70/128, Loss: 20.0768\nAvg Blank Probability: 0.0722\nSample predictions: ['Aak', 'l', 'aUla']\nGround Truth (first 3): ['zapD0Ga3q', 'hjpH', 'H9Ih-81']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [9, 4, 7]\nToken distribution (Batch 31): {35: 1, 34: 1, 0: 13}\nBatch 80, Gradient norm: 2627.8518\nEpoch 20, Batch 80/128, Loss: 19.3326\nAvg Blank Probability: 0.0739\nSample predictions: ['q', 'a', 'eH']\nGround Truth (first 3): ['bUNq', '*m4W', 'BGcfsHl0j6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 4, 10]\nToken distribution (Batch 31): {27: 1, 21: 1}\nBatch 90, Gradient norm: 26.6961\nEpoch 20, Batch 90/128, Loss: 19.0946\nAvg Blank Probability: 0.0797\nSample predictions: ['la', '<empty>', '<empty>']\nGround Truth (first 3): ['1', 'OWs', '2UiKEQ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 3, 6]\nToken distribution (Batch 31): {34: 1, 0: 13, 33: 1}\nBatch 100, Gradient norm: 430.4269\nEpoch 20, Batch 100/128, Loss: 20.1181\nAvg Blank Probability: 0.0787\nSample predictions: ['<empty>', '<empty>', '-']\nGround Truth (first 3): ['09Vsfm3', 'k1Z', 'A8Be2f']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 3, 6]\nToken distribution (Batch 31): {0: 2}\nBatch 110, Gradient norm: 45.4444\nEpoch 20, Batch 110/128, Loss: 22.7099\nAvg Blank Probability: 0.0791\nSample predictions: ['<empty>', 'j', 'jk']\nGround Truth (first 3): ['uBJcLx', 'l', '*mfyDLwx']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 1, 8]\nToken distribution (Batch 31): {1: 1, 0: 3}\nBatch 120, Gradient norm: 35.4654\nEpoch 20, Batch 120/128, Loss: 21.0230\nAvg Blank Probability: 0.0864\nSample predictions: ['n', '<empty>', '<empty>']\nGround Truth (first 3): ['UtXibJFR', 'GMTm', '65GcR']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 4, 5]\nEpoch 20/20, Loss: 19.8967\nToken distribution (Batch 31): {12: 1, 1: 6, 0: 8}\nValidation Loss: 23.3559\nValidation Predictions: ['la', 'laH', 'a', 'la', 'la']\nGround Truth: ['K7ebq', 'GXX3PhE', 'kuG', 'Bw', 'DV14']\nCurrent Learning Rate: 1e-06\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"def zip_folder_with_shutil(source_folder, output_path):\n    '''Function for zip dir data'''\n    shutil.make_archive(output_path, 'zip', source_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:49:17.541325Z","iopub.execute_input":"2025-03-08T11:49:17.541623Z","iopub.status.idle":"2025-03-08T11:49:17.545986Z","shell.execute_reply.started":"2025-03-08T11:49:17.541595Z","shell.execute_reply":"2025-03-08T11:49:17.545124Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/backgrounds', '/kaggle/working/backgrounds')\nzip_folder_with_shutil('/kaggle/working/synthetic_data', '/kaggle/working/synthetic_data')\nzip_folder_with_shutil('/kaggle/working/model_dir', '/kaggle/working/model_dir')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:49:17.546780Z","iopub.execute_input":"2025-03-08T11:49:17.546989Z","iopub.status.idle":"2025-03-08T11:49:20.650421Z","shell.execute_reply.started":"2025-03-08T11:49:17.546970Z","shell.execute_reply":"2025-03-08T11:49:20.649453Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/runs', '/kaggle/working/runs')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T12:18:37.592760Z","iopub.execute_input":"2025-03-08T12:18:37.593140Z","iopub.status.idle":"2025-03-08T12:18:37.599756Z","shell.execute_reply.started":"2025-03-08T12:18:37.593110Z","shell.execute_reply":"2025-03-08T12:18:37.598821Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"#!tensorboard --logdir=/kaggle/working/runs --port 6006","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:49:20.651475Z","iopub.execute_input":"2025-03-08T11:49:20.651827Z","iopub.status.idle":"2025-03-08T11:49:20.655668Z","shell.execute_reply.started":"2025-03-08T11:49:20.651782Z","shell.execute_reply":"2025-03-08T11:49:20.654739Z"}},"outputs":[],"execution_count":27}]}