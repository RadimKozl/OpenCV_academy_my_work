{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10951507,"sourceType":"datasetVersion","datasetId":6783030}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---------------\n\n# **<font style=\"color:Black\">Create OCR by PyTorch</font>**\n-------------------\n-----------------","metadata":{}},{"cell_type":"code","source":"#!pip install tensorboard\n!tensorboard --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:51:32.663238Z","iopub.execute_input":"2025-03-11T16:51:32.663473Z","iopub.status.idle":"2025-03-11T16:51:53.213904Z","shell.execute_reply.started":"2025-03-11T16:51:32.663450Z","shell.execute_reply":"2025-03-11T16:51:53.212434Z"}},"outputs":[{"name":"stdout","text":"2025-03-11 16:51:37.378104: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-11 16:51:37.644480: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-11 16:51:37.724914: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2.17.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport random\nfrom PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter\nimport numpy as np\nimport cv2\n\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F  # Add this import\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:51:53.215885Z","iopub.execute_input":"2025-03-11T16:51:53.216287Z","iopub.status.idle":"2025-03-11T16:52:04.549184Z","shell.execute_reply.started":"2025-03-11T16:51:53.216246Z","shell.execute_reply":"2025-03-11T16:52:04.548091Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Hyperparameters</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"seed = 3\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:04.551523Z","iopub.execute_input":"2025-03-11T16:52:04.552184Z","iopub.status.idle":"2025-03-11T16:52:04.565783Z","shell.execute_reply.started":"2025-03-11T16:52:04.552149Z","shell.execute_reply":"2025-03-11T16:52:04.564702Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x79314eb62dd0>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"OUTPUT_DIR = os.path.join('/kaggle','working','synthetic_data','images')\nTENSORBOARD_DIR = os.path.join('/kaggle','working','runs')\nMODEL_DIR = os.path.join('/kaggle','working','model_dir')\nLABELS_FILE = os.path.join('/kaggle','working','synthetic_data','labels.txt')\nNUM_SAMPLES = 5120  # Number of images generated\nIMG_WIDTH = 128\nIMG_HEIGHT = 32\nBATCH_SIZE = 32\nEPOCHS = 20\nLEARNING_RATE = 3e-7 \nWEIGHT_DECAY = 1e-4  \nWARMUP_STEPS = 500\nENTROPY_WEIGHT = 1.0\nTEMPERATURE = 0.3\nDROPOUT = 0.3\nBEAM_WIDTH = 5\nLABEL_SMOOTHING = 0.1\nBLANK_PENALTY_WEIGHT = 1.0\nMAX_SEQ_LENGTH = None\nCHARSET = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-*\"  # Group characters\nMAX_TEXT_LENGTH = 12  # Maximum length of text in an image\nMIN_TEXT_LENGTH = 4  # Minimum length of text in an image\nFONT_DIR = os.path.join('/kaggle','input','google-fonts','GoogleFontScripts') # Folder with TrueType fonts (.ttf)\nBACKGROUND_DIR = os.path.join('/kaggle','working','backgrounds')  # New folder for background (optional)\nNUMBER_BACKGROUND_IMAGE = 1000","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:04.567447Z","iopub.execute_input":"2025-03-11T16:52:04.567821Z","iopub.status.idle":"2025-03-11T16:52:04.583132Z","shell.execute_reply.started":"2025-03-11T16:52:04.567774Z","shell.execute_reply":"2025-03-11T16:52:04.581543Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Utils support functions</font>**\n-------------------","metadata":{}},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Create output folders</font>**","metadata":{}},{"cell_type":"code","source":"os.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(BACKGROUND_DIR, exist_ok=True)\nos.makedirs(TENSORBOARD_DIR, exist_ok=True)\n\n# Creates a new file\nwith open(LABELS_FILE, 'w') as fp:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:04.584142Z","iopub.execute_input":"2025-03-11T16:52:04.584497Z","iopub.status.idle":"2025-03-11T16:52:04.603516Z","shell.execute_reply.started":"2025-03-11T16:52:04.584468Z","shell.execute_reply":"2025-03-11T16:52:04.602461Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load the font list (add the paths to the .ttf files to the \"fonts\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"font_files = [\n    os.path.join(FONT_DIR, f) for f in os.listdir(FONT_DIR) \n    if f.endswith('.ttf') and os.path.isfile(os.path.join(FONT_DIR, f))\n]\nif not font_files:\n    raise FileNotFoundError(\"No fonts found in 'fonts' folder. Add .ttf files!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:04.604730Z","iopub.execute_input":"2025-03-11T16:52:04.605134Z","iopub.status.idle":"2025-03-11T16:52:11.190882Z","shell.execute_reply.started":"2025-03-11T16:52:04.605088Z","shell.execute_reply":"2025-03-11T16:52:11.189969Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generating a simple gradient background</font>**","metadata":{}},{"cell_type":"code","source":"def generate_gradient_background(filename, size=(128, 32)):\n    img = Image.new('L', size, color=230)  # Lighter gray as a base\n    draw = ImageDraw.Draw(img)\n    for y in range(size[1]):\n        # Soft gradient with low contrast\n        color = int(230 - 20 * (y / size[1]))  # From light gray to slightly darker\n        draw.line([(0, y), (size[0], y)], fill=color)\n    # Background blur\n    img = img.filter(ImageFilter.GaussianBlur(radius=2))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:11.191919Z","iopub.execute_input":"2025-03-11T16:52:11.192279Z","iopub.status.idle":"2025-03-11T16:52:11.198756Z","shell.execute_reply.started":"2025-03-11T16:52:11.192243Z","shell.execute_reply":"2025-03-11T16:52:11.197420Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generate a background with noise (paper texture)</font>**","metadata":{}},{"cell_type":"code","source":"def generate_paper_texture(filename, size=(128, 32)):\n    img = Image.new('L', size, color=220)  # Lighter gray\n    noise = np.random.normal(0, 5, size).astype(np.uint8)  # Less noise\n    noise_img = Image.fromarray(noise)\n    img.paste(noise_img, (0, 0), noise_img)\n    # Blur for a softer effect\n    img = img.filter(ImageFilter.GaussianBlur(radius=1.5))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:11.200032Z","iopub.execute_input":"2025-03-11T16:52:11.200392Z","iopub.status.idle":"2025-03-11T16:52:11.220292Z","shell.execute_reply.started":"2025-03-11T16:52:11.200364Z","shell.execute_reply":"2025-03-11T16:52:11.219202Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Creating multiple backgrounds</font>**","metadata":{}},{"cell_type":"code","source":"for i in range(NUMBER_BACKGROUND_IMAGE):\n    generate_gradient_background(f\"gradient_{i}.png\")\n    generate_paper_texture(f\"paper_{i}.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:11.224186Z","iopub.execute_input":"2025-03-11T16:52:11.224483Z","iopub.status.idle":"2025-03-11T16:52:12.408728Z","shell.execute_reply.started":"2025-03-11T16:52:11.224458Z","shell.execute_reply":"2025-03-11T16:52:12.407690Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load backgrounds (optional, add images to the \"backgrounds\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"background_files = (\n    [os.path.join(BACKGROUND_DIR, f) for f in os.listdir(BACKGROUND_DIR) \n     if f.endswith(('.png', '.jpg', '.jpeg'))] if os.path.exists(BACKGROUND_DIR) else []\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.410431Z","iopub.execute_input":"2025-03-11T16:52:12.410827Z","iopub.status.idle":"2025-03-11T16:52:12.419814Z","shell.execute_reply.started":"2025-03-11T16:52:12.410786Z","shell.execute_reply":"2025-03-11T16:52:12.418884Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Random text generation function</font>**","metadata":{}},{"cell_type":"code","source":"def generate_random_text(min_length, max_length, charset=CHARSET):\n    \"\"\"\n    Generates random text of length between min_length and max_length from the given character set.\n    \n    Args:\n        min_length (int): Minimum length of the generated text.\n        max_length (int): Maximum length of the generated text.\n        charset (str): Character set from which characters are selected (default is global CHARSET).\n    \n    Returns:\n        str: Random text of length between min_length and max_length.\n    \"\"\"\n    # Verifying that min_length is not greater than max_length\n    if min_length > max_length:\n        raise ValueError(f\"min_length ({min_length}) must be less than or equal to max_length ({max_length})\")\n    \n    # Choosing a random length between min_length and max_length\n    length = random.randint(min_length, max_length)\n    \n    # Generating text using random.choice from charset\n    return ''.join(random.choice(charset) for _ in range(length))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.420873Z","iopub.execute_input":"2025-03-11T16:52:12.421195Z","iopub.status.idle":"2025-03-11T16:52:12.428759Z","shell.execute_reply.started":"2025-03-11T16:52:12.421171Z","shell.execute_reply":"2025-03-11T16:52:12.427688Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Functions for adding noise and distortions</font>**","metadata":{}},{"cell_type":"code","source":"def add_noise_and_distortion(img):\n    img_array = np.array(img)\n    # Mild Gaussian noise with lower intensity\n    if random.random() > 0.5:  # 50% šance\n        noise = np.random.normal(0, random.randint(5, 15), img_array.shape).astype(np.uint8)\n        img_array = cv2.add(img_array, noise)\n    # Subtle perspective distortion\n    rows, cols = img_array.shape\n    src_points = np.float32([[0, 0], [cols-1, 0], [0, rows-1], [cols-1, rows-1]])\n    dst_points = np.float32([\n        [random.uniform(0, 3), random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), random.uniform(0, 3)],\n        [random.uniform(0, 3), rows-1-random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), rows-1-random.uniform(0, 3)]\n    ])\n    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n    img_array = cv2.warpPerspective(img_array, matrix, (cols, rows))\n    return Image.fromarray(img_array)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.430099Z","iopub.execute_input":"2025-03-11T16:52:12.430456Z","iopub.status.idle":"2025-03-11T16:52:12.455737Z","shell.execute_reply.started":"2025-03-11T16:52:12.430428Z","shell.execute_reply":"2025-03-11T16:52:12.454605Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Improved image generation feature</font>**","metadata":{}},{"cell_type":"code","source":"def generate_synthetic_image(text, font_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n    # Background\n    if background_files:\n        bg_path = random.choice(background_files)\n        img = Image.open(bg_path).convert('L').resize(img_size)\n    else:\n        img = Image.new('L', img_size, color=230)\n        draw = ImageDraw.Draw(img)\n        for y in range(img_size[1]):\n            color = int(230 - 20 * (y / img_size[1]))\n            draw.line([(0, y), (img_size[0], y)], fill=color)\n        img = img.filter(ImageFilter.GaussianBlur(radius=2))\n\n    draw = ImageDraw.Draw(img)\n\n    # Iterative font and text editing\n    font_size = random.randint(20, min(IMG_HEIGHT-2, 28))\n    max_attempts = 5  # Limiting the number of attempts\n    for attempt in range(max_attempts):\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n        if text_width <= IMG_WIDTH - 10:  # Text will fit\n            break\n        elif len(text) > 1:  # Shorten the text if it is too long.\n            text = text[:len(text)//2]\n        else:  # Reduce font size\n            font_size = max(10, font_size - 5)  # Minimum size 10\n\n    # If that doesn't work, use a minimal font and single-letter text.\n    if text_width > IMG_WIDTH - 10:\n        text = text[0]  # Use the first letter\n        font_size = 10\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n    # Text position\n    x = random.randint(5, max(5, IMG_WIDTH - text_width - 5))\n    y = random.randint(5, max(5, IMG_HEIGHT - text_height - 5))\n\n    # Highlighting text\n    text_color = random.randint(0, 50)\n    outline_color = 200\n    for offset_x in [-1, 0, 1]:\n        for offset_y in [-1, 0, 1]:\n            if offset_x != 0 or offset_y != 0:\n                draw.text((x + offset_x, y + offset_y), text, font=font, fill=outline_color)\n    draw.text((x, y), text, font=font, fill=text_color)\n\n    # Noise and distortion\n    img = add_noise_and_distortion(img)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.456932Z","iopub.execute_input":"2025-03-11T16:52:12.457267Z","iopub.status.idle":"2025-03-11T16:52:12.477200Z","shell.execute_reply.started":"2025-03-11T16:52:12.457241Z","shell.execute_reply":"2025-03-11T16:52:12.476318Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function for splitting labels</font>**","metadata":{}},{"cell_type":"code","source":"def split_labels(labels, label_lengths):\n    \"\"\"Split a flat tensor of labels into a list of label sequences based on lengths.\"\"\"\n    split_labels = []\n    start = 0\n    for length in label_lengths:\n        split_labels.append(labels[start:start + length])\n        start += length\n    return split_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.478243Z","iopub.execute_input":"2025-03-11T16:52:12.478632Z","iopub.status.idle":"2025-03-11T16:52:12.501544Z","shell.execute_reply.started":"2025-03-11T16:52:12.478573Z","shell.execute_reply":"2025-03-11T16:52:12.500440Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function of Beam search decoding</font>**","metadata":{}},{"cell_type":"code","source":"def beam_search_decode(output, idx_to_char, target_lengths=None, beam_width=20, blank_penalty=-1.0, length_penalty=-0.5, global_step=None):\n    probs = output.softmax(2).cpu().numpy()\n    T, B, C = probs.shape\n    predictions = []\n\n    for b in range(B):\n        sequence_probs = [(0.0, [], 1.0)]  # (log_prob, sequence, probability)\n        max_length = target_lengths[b].item() * 2 if target_lengths is not None else min(T, 16)\n        for t in range(T):\n            new_sequences = []\n            for log_prob, seq, prob in sequence_probs:\n                if len(seq) >= max_length:\n                    new_sequences.append((log_prob, seq, prob))\n                    continue\n                top_k_probs, top_k_idx = torch.topk(torch.tensor(probs[t, b]), beam_width)\n                for k_prob, k_idx in zip(top_k_probs, top_k_idx):\n                    new_seq = seq + [k_idx.item()] if k_idx.item() != 0 else seq  # We only add non-blank tokens\n                    new_prob = prob * k_prob.item()\n                    new_log_prob = log_prob + np.log(k_prob.item() + 1e-10)  # Prevention logs(0)\n                    if k_idx.item() == 0:\n                        new_log_prob += blank_penalty\n                    new_log_prob += length_penalty * len(new_seq)\n                    new_sequences.append((new_log_prob, new_seq, new_prob))\n            sequence_probs = sorted(new_sequences, key=lambda x: x[0], reverse=True)[:beam_width]\n\n        best_seq = sequence_probs[0][1]\n        if all(token == 0 for token in best_seq):  # If all tokens are blank\n            decoded = \"\"\n        else:\n            decoded = []\n            prev = -1\n            for idx in best_seq:\n                if idx != 0 and idx != prev:\n                    decoded.append(idx_to_char.get(idx, ''))\n                prev = idx\n            decoded = ''.join(decoded)\n        predictions.append(decoded if decoded else '<empty>')\n\n        token_counts = Counter(best_seq)\n        pred_length = len(best_seq)\n        for token, count in token_counts.items():\n            writer.add_scalar(f'Token_Distribution/token_{token}', count, global_step)\n        writer.add_scalar('Prediction_Length/mean_length', pred_length, global_step)\n        print(f\"Token distribution (Batch {b}): {dict(token_counts)}, Pred length: {pred_length}\")\n\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.502641Z","iopub.execute_input":"2025-03-11T16:52:12.503036Z","iopub.status.idle":"2025-03-11T16:52:12.524292Z","shell.execute_reply.started":"2025-03-11T16:52:12.502998Z","shell.execute_reply":"2025-03-11T16:52:12.523172Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Custom collate function</font>**","metadata":{}},{"cell_type":"code","source":"def custom_collate_fn(batch):\n    images, labels, label_lengths = zip(*batch)\n    # Stack images (all same size)\n    images = torch.stack(images, dim=0)\n    # Concatenate labels into a flat tensor\n    labels = torch.cat(labels, dim=0)\n    # Convert label_lengths to tensor\n    label_lengths = torch.tensor(label_lengths, dtype=torch.long)\n    return images, labels, label_lengths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.525308Z","iopub.execute_input":"2025-03-11T16:52:12.525689Z","iopub.status.idle":"2025-03-11T16:52:12.550942Z","shell.execute_reply.started":"2025-03-11T16:52:12.525657Z","shell.execute_reply":"2025-03-11T16:52:12.549557Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Analyze dataset char frequency</font>**","metadata":{}},{"cell_type":"code","source":"def analyze_dataset_char_frequency(labels_file, charset):\n    \"\"\"\n    Analyzes the character frequency in the generated dataset and displays a progress bar.\n    \n    Args:\n        labels_file (str): Path to the labels file (e.g., LABELS_FILE).\n        charset (str): String containing all possible characters (e.g., CHARSET).\n    \n    Returns:\n        dict: Dictionary with character frequencies.\n    \"\"\"\n    if not os.path.exists(labels_file):\n        print(f\"Error: Labels file '{labels_file}' does not exist!\")\n        return {}\n\n    # Read labels and extract texts\n    with open(labels_file, 'r') as f:\n        labels = [line.split('\\t')[1].strip() for line in f if '\\t' in line]\n\n    if not labels:\n        print(\"Error: No valid labels found in the file!\")\n        return {}\n\n    # Count character frequencies\n    all_chars = ''.join(labels)\n    char_counts = Counter(all_chars)\n\n    # Prepare data for the bar plot\n    chars = list(charset)\n    frequencies = [char_counts.get(char, 0) for char in chars]\n\n    # Create a progress bar (bar plot)\n    plt.figure(figsize=(12, 6))\n    plt.bar(chars, frequencies, color='skyblue')\n    plt.xlabel('Characters')\n    plt.ylabel('Frequency')\n    plt.title('Character Frequency in Dataset')\n    plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n    plt.tight_layout()\n\n    # Display the plot\n    plt.show()\n\n    # Print summary\n    total_chars = sum(frequencies)\n    print(f\"Total characters analyzed: {total_chars}\")\n    print(\"Character frequencies:\", dict(char_counts))\n\n    return dict(char_counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.551989Z","iopub.execute_input":"2025-03-11T16:52:12.552363Z","iopub.status.idle":"2025-03-11T16:52:12.574780Z","shell.execute_reply.started":"2025-03-11T16:52:12.552323Z","shell.execute_reply":"2025-03-11T16:52:12.573784Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generování datasetu</font>**","metadata":{}},{"cell_type":"code","source":"def create_synthetic_dataset(num_samples):\n    \"\"\"\n    Creates a synthetic dataset with images and corresponding labels.\n    \n    Args:\n        num_samples (int): Number of images to generate.\n    \n    Notes:\n        It uses global variables: OUTPUT_DIR, LABELS_FILE, font_files, MAX_TEXT_LENGTH, MIN_TEXT_LENGTH.\n        It assumes the existence of the generate_synthetic_image functions and access to font_files.\n    \"\"\"\n    labels = []\n    for i in range(num_samples):\n        # Generating text with minimum and maximum length\n        text = generate_random_text(MIN_TEXT_LENGTH, MAX_TEXT_LENGTH)\n        if not text:\n            continue  # Skip if text is empty (which should not happen with min_length=3)\n        \n        # Random font selection\n        font_path = random.choice(font_files)\n        \n        # Image generation\n        img = generate_synthetic_image(text, font_path)\n        img_name = f\"img_{i:05d}.png\"\n        img_path = os.path.join(OUTPUT_DIR, img_name)\n        img.save(img_path)\n        \n        # Saving a label\n        labels.append(f\"{img_name}\\t{text}\")  # Using the tab as a separator\n        \n        # Progress report\n        if i % 100 == 0:\n            print(f\"Generated {i}/{num_samples} images\")\n\n    # Saving labels to a file\n    if labels:\n        with open(LABELS_FILE, 'w') as f:\n            f.write(\"\\n\".join(labels))\n        print(f\"Dataset generated! Images saved in '{OUTPUT_DIR}', labels in '{LABELS_FILE}'\")\n        \n        # Analyze and display character frequency\n        analyze_dataset_char_frequency(LABELS_FILE, CHARSET)\n    else:\n        print(\"No labels generated!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.576190Z","iopub.execute_input":"2025-03-11T16:52:12.576803Z","iopub.status.idle":"2025-03-11T16:52:12.599161Z","shell.execute_reply.started":"2025-03-11T16:52:12.576759Z","shell.execute_reply":"2025-03-11T16:52:12.598164Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Mapping characters to indices and back</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"char_to_idx = {char: idx + 1 for idx, char in enumerate(CHARSET)}  # 0 is reserved for blank (CTC)\nidx_to_char = {idx: char for char, idx in char_to_idx.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.600153Z","iopub.execute_input":"2025-03-11T16:52:12.600413Z","iopub.status.idle":"2025-03-11T16:52:12.622296Z","shell.execute_reply.started":"2025-03-11T16:52:12.600390Z","shell.execute_reply":"2025-03-11T16:52:12.621134Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom dataset</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRDataset(Dataset):\n    def __init__(self, image_dir, labels_file):\n        self.image_dir = image_dir\n        self.labels_file = labels_file\n        self.data = []\n        with open(labels_file, 'r') as f:\n            for line in f:\n                if not line.strip():  # Skip empty lines\n                    continue\n                image_path, label = line.strip().split('\\t')\n                label_length = len(label)\n                self.data.append((image_path, label, label_length))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_path, label, label_length = self.data[idx]\n        image = Image.open(os.path.join(self.image_dir, image_path)).convert('L')\n        image = transforms.ToTensor()(image)\n        label_encoded = torch.tensor([char_to_idx[c] for c in label], dtype=torch.long)\n        return image, label_encoded, label_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.623458Z","iopub.execute_input":"2025-03-11T16:52:12.623798Z","iopub.status.idle":"2025-03-11T16:52:12.643798Z","shell.execute_reply.started":"2025-03-11T16:52:12.623758Z","shell.execute_reply":"2025-03-11T16:52:12.642571Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom CTC Loss with Blank Penalty</font>**\n-------------------\n> CTC Loss with Entropy Regularization","metadata":{}},{"cell_type":"code","source":"class CTCLossWithBlankPenalty(nn.Module):\n    def __init__(self, blank=0, zero_infinity=True, blank_penalty_weight=1.0, entropy_weight=0.1, label_smoothing=0.1):\n        super().__init__()\n        self.ctc_loss = nn.CTCLoss(blank=blank, zero_infinity=zero_infinity)\n        self.blank_penalty_weight = blank_penalty_weight\n        self.entropy_weight = entropy_weight\n        self.label_smoothing = label_smoothing\n\n    def forward(self, log_probs, targets, input_lengths, target_lengths):\n        ctc_loss = self.ctc_loss(log_probs, targets, input_lengths, target_lengths)\n        blank_probs = log_probs[:, :, 0].exp().mean()\n        blank_penalty = torch.clamp(-torch.log(1 - blank_probs + 1e-6) * self.blank_penalty_weight, max=1.0)  # Clipping\n        probs = log_probs.exp()\n        entropy = -torch.sum(probs * log_probs, dim=-1).mean()\n        total_loss = ctc_loss + blank_penalty + self.entropy_weight * entropy\n        return total_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.645079Z","iopub.execute_input":"2025-03-11T16:52:12.645467Z","iopub.status.idle":"2025-03-11T16:52:12.671067Z","shell.execute_reply.started":"2025-03-11T16:52:12.645422Z","shell.execute_reply":"2025-03-11T16:52:12.670022Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Model definition (CNN + RNN + CTC)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRModel(nn.Module):\n    def __init__(self, num_chars):\n        super(OCRModel, self).__init__()\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.rnn = nn.LSTM(128 * (IMG_HEIGHT // 4), 256, num_layers=2, bidirectional=True, dropout=DROPOUT)\n        self.fc = nn.Linear(256 * 2, num_chars)\n        self.dropout = nn.Dropout(DROPOUT)\n\n    def forward(self, x, max_length=None):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        batch, channels, height, width = x.size()\n        x = x.view(batch, channels * height, width).permute(2, 0, 1)\n        if max_length is not None:\n            x = x[:max_length]\n        x, _ = self.rnn(x)\n        x = self.dropout(x)\n        x = self.fc(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.672120Z","iopub.execute_input":"2025-03-11T16:52:12.672407Z","iopub.status.idle":"2025-03-11T16:52:12.694282Z","shell.execute_reply.started":"2025-03-11T16:52:12.672383Z","shell.execute_reply":"2025-03-11T16:52:12.693047Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Training</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, device, epoch, warmup_steps=WARMUP_STEPS):\n    model.train()\n    total_loss = 0\n    global_step = epoch * len(train_loader)\n    \n    for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n        imgs, labels = imgs.to(device), labels.to(device)\n        label_lengths = label_lengths.to(device)\n\n        if global_step < warmup_steps:\n            lr_scale = min(1.0, float(global_step + 1) / warmup_steps)\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = LEARNING_RATE * lr_scale\n\n        optimizer.zero_grad()\n        # Dynamické nastavení MAX_SEQ_LENGTH\n        max_label_length = min(label_lengths.max().item() * 2, 16)\n        outputs = model(imgs, max_length=max_label_length)\n        outputs = outputs / TEMPERATURE\n        outputs = outputs.log_softmax(2)\n\n        batch_size = imgs.size(0)\n        seq_length = outputs.size(0)\n        input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n\n        loss = criterion(outputs, labels, input_lengths, label_lengths)\n        if torch.isnan(loss) or torch.isinf(loss):\n            print(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n            continue\n\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Sníženo\n        optimizer.step()\n        total_loss += loss.item()\n        global_step += 1\n\n        if batch_idx % 10 == 0:\n            with torch.no_grad():\n                pred_texts = beam_search_decode(outputs, idx_to_char, label_lengths, global_step=global_step)\n                raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n                blank_probs = outputs[:, :, 0].exp().mean().item()\n                \n                # Average entropy as a measure of diversity\n                probs = outputs.exp()\n                entropy = -torch.sum(probs * outputs, dim=-1).mean().item()\n                \n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:3]]\n                pred_lengths = [len(p) for p in pred_texts]\n                avg_pred_length = sum(pred_lengths) / len(pred_lengths) if pred_lengths else 0\n                \n                writer.add_scalar('Loss/train_batch', loss.item(), global_step)\n                writer.add_scalar('Blank_Probability/train_batch', blank_probs, global_step)\n                writer.add_scalar('Gradient_Norm/train_batch', grad_norm.item(), global_step)\n                writer.add_scalar('Entropy/train_batch', entropy, global_step)  \n                writer.add_scalar('Prediction_Length/avg_length', avg_pred_length, global_step)\n                \n                print(f\"Batch {batch_idx}, Gradient norm: {grad_norm.item():.4f}\")\n                print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n                print(f\"Avg Blank Probability: {blank_probs:.4f}\")\n                print(f\"Sample predictions: {pred_texts[:3]}\")\n                print(f\"Ground Truth (first 3): {ground_truth}\")\n                print(f\"Raw outputs (first 3): {raw_outputs}\")\n                print(f\"Avg Pred Length: {avg_pred_length:.2f}, Input length: {seq_length}, Label lengths: {label_lengths[:3].tolist()}\")\n\n    avg_loss = total_loss / len(train_loader)\n    writer.add_scalar('Loss/train_epoch', avg_loss, epoch)\n    return avg_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.695422Z","iopub.execute_input":"2025-03-11T16:52:12.695886Z","iopub.status.idle":"2025-03-11T16:52:12.721010Z","shell.execute_reply.started":"2025-03-11T16:52:12.695852Z","shell.execute_reply":"2025-03-11T16:52:12.719954Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Inference (prediction)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def decode_prediction(output, idx_to_char):\n    probs = output.softmax(2)\n    max_probs, preds = probs.max(dim=2)\n    preds = preds.cpu().numpy()\n    max_probs = max_probs.cpu().numpy()\n    texts = []\n    for i, (pred, prob) in enumerate(zip(preds.T, max_probs.T)):\n        print(f\"Raw prediction {i} (pre-filter): {pred}, Max probs: {prob}\")\n        # Dynamic threshold: 75th percentile of max probs in this sequence\n        threshold = np.percentile(prob, 75)\n        print(f\"Dynamic threshold for prediction {i}: {threshold:.4f}\")\n        pred_text = []\n        prev = -1\n        for idx, p in zip(pred, prob):\n            if idx != 0 and idx != prev and p > threshold:\n                pred_text.append(idx_to_char.get(idx, ''))\n            prev = idx\n        decoded = ''.join(pred_text)\n        texts.append(decoded if decoded else '<empty>')\n    return texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.722206Z","iopub.execute_input":"2025-03-11T16:52:12.722503Z","iopub.status.idle":"2025-03-11T16:52:12.744676Z","shell.execute_reply.started":"2025-03-11T16:52:12.722464Z","shell.execute_reply":"2025-03-11T16:52:12.743469Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Main launch</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Inicializace TensorBoard writeru\n    log_dir = \"runs/ocr_experiment\"\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    writer = SummaryWriter(log_dir)\n\n    if not font_files:\n        print(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n    else:\n        create_synthetic_dataset(NUM_SAMPLES)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    full_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n\n    for i in range(5):\n        img, label, length = full_dataset[i]\n        plt.imshow(img.squeeze(), cmap='gray')\n        plt.title(''.join([idx_to_char.get(idx.item(), '') for idx in label[:length]]))\n        plt.show()\n    \n    if len(full_dataset) == 0:\n        print(\"Dataset is empty! Check labels.txt or image directory.\")\n    else:\n        # Curriculum phases with pre-filtering\n        model = OCRModel(num_chars=len(CHARSET)).to(device)\n        criterion = CTCLossWithBlankPenalty(\n            blank=0, zero_infinity=True, blank_penalty_weight=BLANK_PENALTY_WEIGHT,\n            entropy_weight=ENTROPY_WEIGHT, label_smoothing=LABEL_SMOOTHING\n        )\n        \n        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n\n        best_loss = float('inf')\n        \n        for epoch in range(EPOCHS):\n            # Filter full dataset based on curriculum phase\n            if epoch < 5:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 5]\n                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]  # lbl je řetězec\n                print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n            elif epoch < 10:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 7]\n                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]\n                print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n            else:\n                filtered_data = full_dataset.data\n                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]\n                print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n\n            # Create a new dataset with filtered data\n            curr_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n            curr_dataset.data = filtered_data  # Overwrite with filtered data\n\n            # Split into train and validation\n            train_size = int(0.8 * len(curr_dataset))\n            val_size = len(curr_dataset) - train_size\n            train_dataset, val_dataset = torch.utils.data.random_split(curr_dataset, [train_size, val_size])\n            print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n            \n            # Create data loaders\n            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n            val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n            \n            # Training with TensorBoard logging\n            model.train()\n            total_loss = 0\n            global_step = epoch * len(train_loader)\n            for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n                imgs, labels = imgs.to(device), labels.to(device)\n                label_lengths = label_lengths.to(device)\n\n                if global_step < WARMUP_STEPS:\n                    lr_scale = min(1.0, float(global_step + 1) / WARMUP_STEPS)\n                    for param_group in optimizer.param_groups:\n                        param_group['lr'] = LEARNING_RATE * lr_scale\n\n                optimizer.zero_grad()\n                outputs = model(imgs)\n                outputs = outputs / TEMPERATURE\n                outputs = outputs.log_softmax(2)\n\n                batch_size = imgs.size(0)\n                seq_length = outputs.size(0)\n                input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n\n                loss = criterion(outputs, labels, input_lengths, label_lengths)\n                if torch.isnan(loss) or torch.isinf(loss):\n                    print(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n                    continue\n\n                loss.backward()\n                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n                optimizer.step()\n                total_loss += loss.item()\n                global_step += 1\n\n                if batch_idx % 10 == 0:\n                    with torch.no_grad():\n                        pred_texts = beam_search_decode(outputs, idx_to_char, label_lengths)\n                        raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n                        blank_probs = outputs[:, :, 0].exp().mean().item()\n                        label_sequences = split_labels(labels, label_lengths)\n                        ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                        for label_seq in label_sequences[:3]]\n                        \n                        # Logging into TensorBoard\n                        writer.add_scalar('Loss/train_batch', loss.item(), global_step)\n                        writer.add_scalar('Blank_Probability/train_batch', blank_probs, global_step)\n                        writer.add_scalar('Gradient_Norm/train_batch', grad_norm.item(), global_step)\n                        writer.add_histogram('Logits/train_probs', outputs.exp().flatten(), global_step)\n\n                        # Adding raw outputs\n                        writer.add_histogram('Raw_Outputs/train_argmax', raw_outputs.flatten(), global_step)\n                        writer.add_text('Raw_Outputs/train_text', f\"Raw train outputs (argmax):\\n{str(raw_outputs)}\", global_step)\n\n                        # Token frequency calculation and logging\n                        token_counts = Counter(raw_outputs.flatten())\n                        writer.add_text(\n                            'Raw_Outputs/train_token_counts',\n                            f\"Token counts: {token_counts}\",\n                            global_step\n                        )\n                        \n                        print(f\"Batch {batch_idx}, Gradient norm: {grad_norm.item():.4f}\")\n                        print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n                        print(f\"Avg Blank Probability: {blank_probs:.4f}\")\n                        print(f\"Sample predictions: {pred_texts[:3]}\")\n                        print(f\"Ground Truth (first 3): {ground_truth}\")\n                        print(f\"Raw outputs (first 3): {raw_outputs}\")\n                        print(f\"Input length: {seq_length}, Label lengths: {label_lengths[:3].tolist()}\")\n\n            avg_loss = total_loss / len(train_loader)\n            writer.add_scalar('Loss/train_epoch', avg_loss, epoch)\n            print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.4f}\")\n\n            # Validation with TensorBoard logging\n            model.eval()\n            val_loss = 0\n            val_blank_probs = 0\n            with torch.no_grad():\n                for batch_idx, (imgs, labels, label_lengths) in enumerate(val_loader):\n                    imgs, labels = imgs.to(device), labels.to(device)\n                    label_lengths = label_lengths.to(device)\n                    outputs = model(imgs)\n                    outputs = outputs.log_softmax(2)\n                    seq_length = outputs.size(0)\n                    input_lengths = torch.full((imgs.size(0),), seq_length, dtype=torch.long).to(device)\n                    val_loss += criterion(outputs, labels, input_lengths, label_lengths).item()\n                    val_blank_probs += outputs[:, :, 0].exp().mean().item()\n\n                    # Logging raw outputs for the first batch\n                    if batch_idx == 0:  # We only log the first batch to save space\n                        # 1. Histogram of the distribution of predicted tokens (argmax)\n                        raw_outputs = outputs.argmax(2).cpu().numpy()  # [seq_length, batch_size]\n                        writer.add_histogram(\n                            'Raw_Outputs/val_argmax', \n                            raw_outputs.flatten(),  # We convert to a 1D array for the histogram\n                            global_step=epoch\n                        )\n            \n                        # 2. Text listing of raw outputs (first 5 sequences)\n                        raw_outputs_text = str(raw_outputs[:5])  # First 5 sequences as text\n                        writer.add_text(\n                            'Raw_Outputs/val_text',\n                            f\"Raw validation outputs (argmax) for first batch:\\n{raw_outputs_text}\",\n                            global_step=epoch\n                        )\n\n                        # 3. Calculating token frequency and logging to TensorBoard\n                        token_counts = Counter(raw_outputs.flatten())\n                        writer.add_text(\n                            'Raw_Outputs/val_token_counts',\n                            f\"Token counts: {token_counts}\",\n                            global_step=epoch\n                        )\n            \n                        # 4. (Optional) Logit histogram for specific tokens (e.g. first time step)\n                        logits_first_step = outputs[0].cpu().numpy()  # [batch_size, num_chars]\n                        writer.add_histogram(\n                            'Raw_Outputs/val_logits_first_step',\n                            logits_first_step.flatten(),\n                            global_step=epoch\n                        )\n                        \n                        logits_first_step = outputs[0].cpu().numpy()\n                        writer.add_histogram('Logits/val_probs', torch.softmax(outputs[0], dim=-1).flatten(), global_step)\n                \n                val_loss /= len(val_loader)\n                val_blank_probs /= len(val_loader)\n                pred_texts = beam_search_decode(outputs, idx_to_char, label_lengths)\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:5]]\n                \n                # Validation logging to TensorBoard\n                writer.add_scalar('Loss/val_epoch', val_loss, epoch)\n                writer.add_scalar('Blank_Probability/val_epoch', val_blank_probs, epoch)\n                writer.add_text('Predictions/val', f\"Validation Predictions: {pred_texts[:5]}\", epoch)\n                writer.add_text('Ground_Truth/val', f\"Ground Truth: {ground_truth}\", epoch)\n                print(f\"Validation Loss: {val_loss:.4f}\")\n                print(\"Validation Predictions:\", pred_texts[:5])\n                print(\"Ground Truth:\", ground_truth)\n\n            scheduler.step()\n            print(f\"Current Learning Rate: {optimizer.param_groups[0]['lr']}\")\n\n            if val_loss < best_loss:\n                best_loss = val_loss\n                torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'best_ocr_model.pth'))\n\n        torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'final_ocr_model.pth'))\n    \n    # Closing the TensorBoard writer\n    writer.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:52:12.746026Z","iopub.execute_input":"2025-03-11T16:52:12.746384Z","iopub.status.idle":"2025-03-11T17:19:08.435859Z","shell.execute_reply.started":"2025-03-11T16:52:12.746353Z","shell.execute_reply":"2025-03-11T17:19:08.434754Z"}},"outputs":[{"name":"stdout","text":"Generated 0/5120 images\nGenerated 100/5120 images\nGenerated 200/5120 images\nGenerated 300/5120 images\nGenerated 400/5120 images\nGenerated 500/5120 images\nGenerated 600/5120 images\nGenerated 700/5120 images\nGenerated 800/5120 images\nGenerated 900/5120 images\nGenerated 1000/5120 images\nGenerated 1100/5120 images\nGenerated 1200/5120 images\nGenerated 1300/5120 images\nGenerated 1400/5120 images\nGenerated 1500/5120 images\nGenerated 1600/5120 images\nGenerated 1700/5120 images\nGenerated 1800/5120 images\nGenerated 1900/5120 images\nGenerated 2000/5120 images\nGenerated 2100/5120 images\nGenerated 2200/5120 images\nGenerated 2300/5120 images\nGenerated 2400/5120 images\nGenerated 2500/5120 images\nGenerated 2600/5120 images\nGenerated 2700/5120 images\nGenerated 2800/5120 images\nGenerated 2900/5120 images\nGenerated 3000/5120 images\nGenerated 3100/5120 images\nGenerated 3200/5120 images\nGenerated 3300/5120 images\nGenerated 3400/5120 images\nGenerated 3500/5120 images\nGenerated 3600/5120 images\nGenerated 3700/5120 images\nGenerated 3800/5120 images\nGenerated 3900/5120 images\nGenerated 4000/5120 images\nGenerated 4100/5120 images\nGenerated 4200/5120 images\nGenerated 4300/5120 images\nGenerated 4400/5120 images\nGenerated 4500/5120 images\nGenerated 4600/5120 images\nGenerated 4700/5120 images\nGenerated 4800/5120 images\nGenerated 4900/5120 images\nGenerated 5000/5120 images\nGenerated 5100/5120 images\nDataset generated! Images saved in '/kaggle/working/synthetic_data/images', labels in '/kaggle/working/synthetic_data/labels.txt'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Total characters analyzed: 41046\nCharacter frequencies: {'q': 645, 'V': 645, '8': 651, 'i': 640, 'b': 655, 'H': 685, 'M': 611, 'd': 598, 'I': 629, '1': 649, 'X': 648, 'S': 663, '0': 662, 'D': 624, 'R': 634, 'J': 636, 't': 626, 'c': 621, 'L': 664, '2': 708, 'e': 644, 'z': 642, 'f': 628, 'O': 636, 'U': 685, 'r': 682, 'W': 688, 'h': 674, 'Q': 578, '7': 642, 'T': 674, 'n': 652, 'N': 620, 'C': 631, 'E': 663, 'P': 608, 'x': 637, '3': 630, 'y': 610, '9': 641, 'g': 685, 'p': 626, 'v': 654, 'a': 698, '-': 626, 'Z': 603, 'F': 648, 'u': 619, 'j': 617, '*': 632, '6': 615, 's': 652, 'l': 681, 'm': 617, 'B': 646, 'w': 625, 'G': 605, 'A': 611, '5': 639, 'o': 645, 'Y': 634, '4': 649, 'K': 631, 'k': 629}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAh8AAAC+CAYAAACVgm2zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7XklEQVR4nO2de3RW1Zn/n3ALWCSRW0KEACKKolgEwYhTFVMFLaKiVkSJ1VVHJ1AQWwXvWigunaptx8LUsdKKoNIRVKbiQhCQGS4SwYqOeEMEIaBYCCDX5Pz+6I939v684ey8Mb5J4PtZK2vlyXnPOXs/+/LunO9znp0RRVFkQgghhBBpokFtF0AIIYQQRxZafAghhBAirWjxIYQQQoi0osWHEEIIIdKKFh9CCCGESCtafAghhBAirWjxIYQQQoi0osWHEEIIIdKKFh9CCCGESCtafAgh0s5nn31mGRkZNmXKlNouihCiFtDiQwhRJaZMmWIZGRmWkZFhixcvTjoeRZF16NDBMjIy7Ec/+lHK17///vstIyPDvvrqK+/vr7/+up133nnWunVry87Otj59+tgzzzxT7XoIIWofLT6EECnRtGlTmzZtWtLfFy5caBs2bLDMzMwau9fLL79sF1xwge3bt8/uv/9+mzBhgjVr1syGDx9ujz32WI3dRwiRXrT4EEKkxEUXXWQzZsywAwcOeH+fNm2a9erVy3Jzc2vsXv/2b/9m7dq1s/nz59uIESOsuLjY5s2bZ126dJFkI0Q9RosPIURKDB061LZu3Wpz585N/G3fvn32l7/8xa655pqkz2/bts2uv/56y8rKsuzsbCsqKrJt27ZV6V5lZWV2zDHHeE9TGjVqZK1bt7ZmzZp967oIIWoHLT6EECnRqVMnKygosOnTpyf+9uqrr9r27dvt6quv9j4bRZENHjzYnnnmGbv22mtt/PjxtmHDBisqKqrSvc4991x777337J577rGPP/7YPvnkE/vlL39pK1assNtvv71G6yWESB+NarsAQoj6xzXXXGPjxo2z3bt3W7NmzezZZ5+1c845x/Ly8rzPvfzyy7Zo0SJ7+OGH7Re/+IWZmd1yyy123nnnVek+99xzj61du9YmTJhg48ePNzOzo446yv7zP//TBg8eXLOVEkKkDT35EEKkzFVXXWW7d++22bNn244dO2z27NmVSi5//etfrVGjRnbLLbck/tawYUMbOXJkle6TmZlpJ5xwgl1xxRU2ffp0mzp1qvXu3duuvfZaW7p0aY3VRwiRXvTkQwiRMm3atLHCwkKbNm2affPNN1ZeXm5XXHFF0ufWrVtn7dq1s+bNm3t/P/HEE6t0nxEjRtjSpUvt7bfftgYN/vG/0lVXXWXdu3e3UaNG2bJly759ZYQQaUdPPoQQ1eKaa66xV1991SZPnmwDBw607OzsGr3+vn377KmnnrKLL744sfAwM2vcuLENHDjQVqxYYfv27avRewoh0oMWH0KIanHZZZdZgwYNbOnSpZVKLmZmHTt2tE2bNtnOnTu9v69ZsyZ4/a1bt9qBAwesvLw86dj+/futoqKi0mNCiLqPFh9CiGrRvHlzmzRpkt1///02aNCgSj9z0UUX2YEDB2zSpEmJv5WXl9vvfve74PXbtm1r2dnZNnPmTO8Jx86dO+2VV16xbt266XVbIeopivkQQlSb0CuzgwYNsn79+tnYsWPts88+s5NPPtlefPFF2759e/DaDRs2tJ///Od2991325lnnmnDhw+38vJye+qpp2zDhg02derUmqqGECLNaPEhhPjOaNCggb388ss2evRomzp1qmVkZNgll1xiv/71r61nz57B8++66y7r3Lmz/eY3v7EHHnjA9u7daz169LC//OUvNmTIkDTUQAjxXZARRVFU24UQQgghxJGDYj6EEEIIkVa0+BBCCCFEWtHiQwghhBBpRYsPIYQQQqQVLT6EEEIIkVa+s8XHE088YZ06dbKmTZta3759bfny5d/VrYQQQghRj/hOXrV9/vnnbfjw4TZ58mTr27evPf744zZjxgxbs2aNtW3bNvbciooK27hxox199NGWkZFR00UTQgghxHdAFEW2Y8cOy8vL8/ZjOtSHa5w+ffpExcXFCbu8vDzKy8uLJk6cGDx3/fr1kZnpRz/60Y9+9KOfevizfv364Hd9jWc43bdvn5WUlNi4ceMSf2vQoIEVFhbakiVLkj6/d+9e27t3b8KOqvAghttzP/jgg4f87IEDBzy7UaP4Kn/zzTee3bBhQ8/mRlZHHXVU7PVSuTZt1jOOHTt2eDb92KJFi9jzd+/e7dn79+/3bO6h0bhx48Tv3DSMPv7e974Xe5zs2rXrkPcy89ugadOm3jGWhbC9uDrnLqlZWVmx13OpqKjwbPowMzMz9nx+nmVxz9+zZ493jO0dagPWm30vlXJyjDVp0iSla7PNeL02bdpU+VqpjndCP27bti3xO3129NFHe3aovVkW9nPeO27fGo5Xfpb3Zn9hWeL8xLmlVatWns1U+WwjXjs077n9PrR3j/vdYZY8Bnk+25C224b0GecCnrt169bYsnIOZr3d+3HO4zzHvsLP8zjbMO76HI/s51999ZVn9+/f3wjPqYwaX3x89dVXVl5ebjk5Od7fc3Jy7IMPPkj6/MSJE+2BBx5I6R6UY+I6aKqTETtvaPGRysZWoWuzbKlcm/UMDcIQLFvc4oM+CdWDHZ+w7HGLD147tMspPx+aCFNZXNb04oNlcScIjoHQZBRadKXyJc1FUWjxkeqY4/XchVO6Fx9uXekzLuhSXXwQ+iGu77EsocVHaK6JKxvLxX+K6PNUFx887i4oQuOP54Z8mMriI/TPIM/lYoXw/Dg/pLr44Jjj8dD8EPf9wIVEqJ5myfNTZdT63i7jxo2zMWPGJOyysjLr0KFD7DnHHnusZ990002J3/l0IfRlw87q/qdT2fG4JwqhLxc2GsvKyYyr+riBws7J/4xatmzp2Vzd8vOhDufWO7Tw4bXZMfkfBb/c6Ce3bGxPfgGwvXg89CXMNnDLzsmE1w49EQr5mH5w78dFFn1MQk86vs0imv9VsT9wXPB8Tpw87vZt1oM+5pcNj4eeAPLe7n+zxxxzjHeMfYv1pk/ZP9i3+Hm3/dne9Bm/TEKL07///e+eTb+4fXXz5s2HPGZm1qNHj9h7lZWVeTb9SJ/HPb3kXBF6Uh7yA8vm9h/6qHXr1p7NJwCsF+MbWRbW223j0D9onBNDT4D4/eA+TTTz25Q+CY2Z6lLji4/WrVtbw4YNkzrs5s2bLTc3N+nzmZmZwS9tIYQQQhw+1Pirtk2aNLFevXrZvHnzEn+rqKiwefPmWUFBQU3fTgghhBD1jO9EdhkzZowVFRVZ7969rU+fPvb444/brl277Cc/+cl3cTshhBBC1CO+k8XHj3/8Y/vyyy/t3nvvtdLSUvv+979vc+bMSQpCrS7Ur1wtjVo29SvqqtROqeOHNMVUAtooL1HTDwUNMR7FhVp4KPCS92LMQJyPWZbs7GzvGLXS0Js31CepXzI2wm1j6uz0Kf0QCjBlf4mLCWGUP+sViuGhn3gvtoF7nPXkuakEylZGXNwNxxDbh36hfk29mho/+5PbPxhfwvbl+A29Mca+xzZxdXzGbLBejNnh59kmHIPsH65fQueG4Bikj+NyMjA+gHMBfRaKN+BbIXHzAcdn6G220AsC9Fvc22yM2eC9Q8dp02+cu9w2CMUDsj+k2tdYltLS0sTv7CvsGxzf1eU7CzgdMWKEjRgx4ru6vBBCCCHqKdrbRQghhBBpRYsPIYQQQqSVWs/zUR2oEcYlhqEOSw2Q2hd13NA7zu71Qu9HU0sLJSliBkS+Rx6XyIW6ayg+gTZ1XGrELtThWS7GBDCegH6gHfduPrVNtjf7A8sSp7uaJcf0uMcZ+8B7s/1CuTZCfnLrHXo9nedSdw/B811YburTjLNgLAP7GvsPYwLc/hRKMPjll196NsdzXD82i08MForv4rUZR8X+wLKzL7rxCLw3+xrryTYK6fbse+7nQwmjGDfB2DTOucyXwb7m1oX1ZhxFKKaD9eL14pJxhfKwhPKTcByEYsDc/sL24hjhtVhPtgFtxvG48Sscz/Qpy1Jd9ORDCCGEEGlFiw8hhBBCpBUtPoQQQgiRVuplzAf1TFdLpf7IHRipq1KXDelbjDFwtVNemzos7a+//tqzqUeGdlR1dTz6JBSrQh2X5/N43F4ioTiKUA4R7pEQ0uVd4vZHMAtr36GYAOqybtwFtVGWhfEDoZgO9oe4HDShTczo81AMD/Vs6tXu+aF9gVgWXovns58zHsH1c2hfGN6bbcRrczyzTVybcwHbk/EDHEOhjcjidH7Wm+Ob54byl4R2aHXZtGmTZ9PH7IuM6WCsS1w+E7PUctSwDVi20Pwd1970MWOReG/GYbB9QxvwuW1CH4XyTTGmg+OZ8YJxO2hzTqQPt2zZEluWqqInH0IIIYRIK1p8CCGEECKtaPEhhBBCiLRSL2M++I6yq71Ry6IeTc2PcRbUaakJUlN0Ywx4bep2jHVo2bKlZ1PXo2ZI3HpTyw7l9Ug17wf94h6P04vNkuvFe1O3Z72pObp+pG6aaj4L1iuURyKV67PvMaaDhGJnXM2Z7RPSaUN9k36MyxtBDZ9xVTyX7U+Nn/EIxx577CHPZ7nZXqG9XKjLs414vquls+1ZFsYbse+E/MK5y7XZN1hu2qEYEeYkisuHEcpHEsoDwmuzbIw/cq/HmJ24+dcsOfYhtJ9WXJxGKDaJ7cV60m9sI/rNrSv7Bvsa783vEs6hof14cnNzE7/H5dkxS26/6qInH0IIIYRIK1p8CCGEECKt1EvZJU464SOhUDpdSgaUAHivuG3QQ+nS+Ugw1TTjfNzpPlrn40fafJQWepQaSt/sPpLkq3W8Fglt0U14b/eRMdNps31DrxDzcTQf8/LxtNsf+Jg1tKV26NVM9g8ed8saes03JOnx8+wfHDfuuMjJyfGOUU7ia330A/sL25B1cx/LU05iX2O9OAbZH0IyjSspheYWPlbno3KWleOfZXH7C69NqSKU8p5+S6X/0IeU2Tgnsr05p4ZerXXlLY790OurITmSbULcvhkan7w2yxLqe3HzXiiNPAlJ/CGZzfUr2zdUj+qiJx9CCCGESCtafAghhBAirWjxIYQQQoi0Ui9jPqhnufpYKM1w3BbKZsk6XOh1OBdqn6EtmKmN8xVG6rTUM12NmPpjSMtmPUOpf6lvu20QSvVNvXLDhg2eTc2XmiPb2y077x2qdyimg+ezzdzz6TPWk7oq68n2pY4fF7/CvkVCejXLwnFDDTnu1Wq2N48ztoH1DqV2d/3K9mP8CGFfol/Yhiy763OOCcYf0GfsOzyfZef1XL8y5oPQLxyvbAPCGCF3jIX6Co+H4s9CaefdujL2gWOE96aPeW/6mPEocXAe4rmhmB+Ok9D2Gy4cM6wn/cT2jtuqobLzXehDpkqoLnryIYQQQoi0osWHEEIIIdKKFh9CCCGESCv1MuaDaW7dfBjUuqgvUnejTXg+dTlXS4tLE2wWH7tgllx26vTU5dx60yfUH3ltfp7adyh/gns96q4sJ69FPzFuI7R9tKtnU4+k9h3SoxnzQb9RW3Wvxzws9BFt5sNgm4RSnLtlp+7KejHWIbTdNzV/Xt+tS0jDD6VAZ5uwL/J8t73ZNxhnxTHGuBv2tVBOCresoX7J2BXGMoS2IYjb7p19gz4K5eXhuEglNiK0xUQo/oDH6SfW2703j3EuiesrZsntGcq14Y5/9qXQXMM2YHvz/Lh0+/Qxr816cN5i2Wnzu4Vzsgt9ynpXFz35EEIIIURa0eJDCCGEEGlFiw8hhBBCpJV6GfNBray0tDTxOzVCfvarr77ybOqP1HWp03FfC5dQDgnei3k7qE8yD0CchhjKZ0LdNi5+xCy8V4R77y1btnjHWM/QtdhGzHfCurl+jYv/MQvHk/De7D+8nntvlpN6dKiezPNCXZdt5PYX1pt9LZVYJbNk7TwuT0io37I/tG/f3rNZT+rPcfuYhPL0sP1SjQkI5TtxCeUEitsXyCx5XLCvuueH9nnitULxCjyfPnfbiH2H7UWf8vM8zvHMfu4eZ/uwHoyNCMV8sW/GzQf0CcsdiuFh2ULxJ27Z+VnOqexboT2N2N483z3Ocodi26qLnnwIIYQQIq1o8SGEEEKItJLy4mPRokU2aNAgy8vLs4yMDJs1a5Z3PIoiu/fee61du3bWrFkzKywstI8++qimyiuEEEKIek7KMR+7du2y0047zW644Qa7/PLLk44//PDD9tvf/tb+9Kc/WefOne2ee+6xCy+80N5///0kHbK6UJNyNeFQDAe1sFBuBuq61CddTTik6TPuwo1VMUvOtx/af8U9vnXrVu8Y8xtQQ2Q9qMvy3sT1M31MTZ9tQg2RsJ9Qx3Xbm5outUyWhTB+gW3E813NmT4K7bfC4+yLrDfb2/089WaWhddm+zKWgT5m33VjpVhO9mOOT44p5ubguOH57r4WoWuz/RiXw/YO6fhu3w7FxfBa9Dnbk2MyriyMP+D4DuXt4L1C+5LE7eUTyuNC2LfYRmx/d34I1YvljpsjzVLbq4v3Zl9iGzBXRtxeLZWVxW2TUN4W+pBtxHpx7onbq4vty2sxX1F1SXnxMXDgQBs4cGClx6Iosscff9zuvvtuGzx4sJmZ/fnPf7acnBybNWuWXX311d+utEIIIYSo99RozMfatWuttLTUCgsLE3/Lysqyvn372pIlSyo9Z+/evVZWVub9CCGEEOLwpUYXHwcfv/J11JycnKRHsweZOHGiZWVlJX46dOhQk0USQgghRB2j1vN8jBs3zsaMGZOwy8rKggsQ5g1w9SzGPsRpepUdp25HXY96mKvFUYfj/hiM6WjXrp1nh95/p+1CfdLVyVlOs2Ttm8dDOq9bFpabMR28dtx+CmbJMQEsq1tX+jguHqgqxMV4mPlaKfVlaqH0If3C/kB4bxe2L8tCvzBOg/lujj32WM+O25+DWnVozyKWlfXiOOBxau0uoZgP9j32Y36euP2JPo77rFl4HyH6jbq8W+9QDAD7UmivD14vLkcN25PxQIRzKmM+6Ke4+DT2Y9Y71P6EuZM+++wzz3bHaG5urneM7cm+xDgafhdx3LDe7twS2i+H9eBx5gHavHmzZ/P67pzLvsL2ZrxIdanRJx8HG4sV3bx5c1JDHiQzM9NatGjh/QghhBDi8KVGFx+dO3e23NxcmzdvXuJvZWVltmzZMisoKKjJWwkhhBCinpLy85OdO3faxx9/nLDXrl1rq1atspYtW1p+fr6NHj3axo8fb127dk28apuXl2eXXnppTZZbCCGEEPWUlBcfK1assPPOOy9hH4zXKCoqsilTptjtt99uu3btsptuusm2bdtmZ599ts2ZM6fGcnyYJet6rr5JnZ1aKHVV6tHUN0P6s6vzhd7jD2nCjHVgXZjTwr1fKF8J600f0mZ8AsvqloXnUtsMvatPm2Wntura1LZDGn+qMUBxe6SwfXluyIehPB/UVl2dnu3JvkOou7Ns9GOc1h7Kd+D+c2KWPMZYL5aFPo/TmEP7a7Bv0g/0eVxsBONk6HO2CWPT2Dfp41atWnm22z+o4XMu4X4rbCOOybg9a8zi4+hWrlzp2YyrOuGEE2KPs83i2pdzAeOq2J4dO3b07NmzZ3v2BRdc4Nlz5szx7DZt2iR+P/74471jXbt29WyWm/2cbcb25nzgHud45Esc7It5eXme/eWXX1ocvJ7bP/g9xr61adOm2GtXlZQXH+eee25SR3bJyMiwBx980B588MFvVTAhhBBCHJ5obxchhBBCpBUtPoQQQgiRVmo9z0d1YB4QV6OixhvS+PlqLzVE6lvUt93YB+qsIa2b8lVo3wKe75YlLieEWbLOSi2VOh+PUwt3NWPemzEebAPmO6DmH8pJ4F6Pn2UcBvVK9o/QHhhxsRH0UZwcaZb6vkJxsFyhPB8hQnlB3BiDUN6GUCwMdXg3I7KZWY8ePQ55fV6L+Q14b44ZxmXw8xzDbnLE1157zTu2atUqz+YYu/vuu2PvRajju/2J5WIsG9uEYzC05xX73pYtWxK///d//7d3jON3wIABns14A8YXPPnkk57NmBD35QTOobw34zJuvPFGz/7DH/7g2fTjsmXLPPu2225L/P7AAw94xy677DLPHjp0qGfT5+x7LVu29Gz6yZ3POU8x1oUxHqnu7cR5z70+xz5zirCe1UVPPoQQQgiRVrT4EEIIIURa0eJDCCGEEGmlXsZ8xOn0offZQ7k0Qnkj4vJjhPaBYbmprVF3pW7H67vaWyimgzZ1emqCIb+4x0N7VFDrjovhqKxsfF/e9SO171C9+flQvhPiloU+Ce3VwuPUr9k3ud+Kq39Tu2bfogbMvhiKu+H14urGuBqOGe5o3alTJ89esWKFZ1PHd9uE/ZT3YgwIY7pYL7Y3/fLhhx8mfmcsCsv9ySefePb777/v2awXc1Kwzdz+wP01Qv2cNmNCGGfBvuy2KfN8hOJqOHcsWLDAs9944w3P7t+/v2d/+umnid9PPPFE71hJSYlnuzEaZmYzZ870bPYPlmX06NGe7cZlMLaQfmDeJcKYDvYt+smdWzgeOTcwBiSUS4X9h2Vzz+f8yzEVyilUVfTkQwghhBBpRYsPIYQQQqQVLT6EEEIIkVbqZcwHYwpc/apt27beMWrjoTgL6l0hXc/V1kJ7nLAs1GEZ08GysKzuvfk+PD/Ld8xZVt4rlLPCPU59kTZ1duqwoTwgLJsbv0Cfhfa04bVCOUXop7h9KJhrIxSXQRifQD+6WjvjA9iXqPFSp+U+Ijyf/d4dY6EcEmzf44477pDXMjPr2bOnZ69fv96zXd2f9Y7LR2IWjn1gLAvnj88++yzx+9tvv+0dKyoq8uxJkyZ5NuvNWJdQm7ljjHE1LGdubu4hzzVL7oup7EN10UUXecfefPNNz2acxVlnneXZvXr18uwXXnjBs9mf3DbmGJg8ebJnz50717MXL17s2X379vXsU0891bM5DtauXZv4fezYsd4x5jsZPHiwZ48aNcqzWW/m5uCc7daVcwHjLthXvvjiC89mvFgoj5ObY4Y+Z/twjqwuevIhhBBCiLSixYcQQggh0kq9lF34SMl9RBjajpuPiPmKGV/r5PlMgew+9udjVD7q4qNsyg18VMp783VJNyU278XHcqE083zUlsprvnztK1RuPvJjm9EPlGHc83kuYbkpfbCsfIzP1+vc/hP3emJl0A+ppil2y8J+zFftWJaQvET5gY/pXfmJfYOP7Okzvlp5/vnne/YZZ5zh2XFp5tk32AYsN/3E/kKbdXFTaFO6Yr3Gjx/v2WwD9mP2RcpRrrTCx+osN/sS70V5ITRu3NdMn3nmGe/YtGnTPPtnP/uZZ1Pi/dOf/uTZP/rRjzx7w4YNnu3OXaz3nDlzPJv9mNLW5s2bPTs/P9+zOW+efPLJid/p05UrVx6ynGbJWxRwnFDCjZPZOKe2a9fOs0Nbd7AsbBOmTHc/z+8pvvbL74rqoicfQgghhEgrWnwIIYQQIq1o8SGEEEKItFIvYz6ob7t6NbWvNm3aeDY1QOpboVcr415Doq7O16OoZVPz5WuCjFeg5uyeT12O5ea9QymxqYXyeFw5U41toI4furd7fbZHKq/pVlY2auFxrzeznIybYN+iThtKx75p0ybPdvVt+iQuLsYsOZaJ8QWsN/uTez51dvZ7phXn51nW++67z7P5iuIPf/jDxO+hVw4Z48HxzL66ceNGz54+fbpnr1q1KvH7/fff7x3r0qWLZ9MPfDXX3aa+ss/TdscwU7ET9ge2J9OKM4aAMSFubNugQYO8Y+z3oVeGOcbGjBnj2UOGDPFsNy6DsQvuq89mZrNmzfLs4uJiz2Z/YV/kGHO/WzgGevfu7dk/+MEPPJvjmfUObbfhfjcxNoVzB1/FZZuwniE/uLFOjHti+/Ja1UVPPoQQQgiRVrT4EEIIIURa0eJDCCGEEGmlXsZ8UBt1dTtqo9TZ+O41tS/mDeC94raH57WpP1M7C6XbJtT13FiJUJ4HxoBQn6SfGIdB7dWNAaDezHOpu1OvZCwLz49LFc9jrFcoJoT34vksa2lpaeJ31ov5Z+hz2iwL45Oo27vxCtSAGdPBvsZ+zPf+2V9Yb/c4xwy3OX/llVc8m1uTd+/e3bP/53/+x7PpFxe2N9uAY4q6vdt+ZslpyplXwj2fcTLPP/+8Z995552ezdgV5rNgum22mQvr7caimJm9+OKLnv3AAw94NvOf/Nd//ZdnDxs2zLNdP3JOZFpxxjaxnrw3403at2/v2W6c1pVXXukdY46Qbt26eXYololjkPEprr169Wrv2L//+797dmFhoWdzmwD6hWOOfdEd3/QZY9f4XcP5n7l2GG/EOdude0L3Yn+oLnryIYQQQoi0osWHEEIIIdKKFh9CCCGESCv1MuaDsRSuVsbYBepT1ICplfG9b2qG3NvFhZoedXhq5dSneZx23NblrDd1O8ZVUG+mdk6djzEGbqxEKI8Hj1OPZBwN/cKyuVpqaE8LxjqwvamFMuaDeyy45zNehPXKycmJLUvofOrRrp4dih8KbakeGgfMf+FCLbtfv36evW7dOs9mvgu22a9//WvPZn/45JNPEr+numcF4w94PuNsGPvSv3//xO8FBQXeMcZNXHDBBZ49b948z2Z/oI8Zf+LGBHz88cfesUceecSzL7/8cs/+8MMPPZt5PNw9TMzMRo4c6dldu3ZN/D5gwADvGHNrXH311Z7NGA6256OPPurZ7OfuHMx6nHPOOZ7NuAzOc249zMJ5ntz+smbNGu9Y586dPZvxhRxzLAvjzxh34fohtE8U4XzN8c05lPOc+z3HuYXfJanGKh4KPfkQQgghRFpJafExceJEO+OMM+zoo4+2tm3b2qWXXpq0OtyzZ48VFxdbq1atrHnz5jZkyJCk1aYQQgghjlxSWnwsXLjQiouLbenSpTZ37lzbv3+/XXDBBd4j3VtvvdVeeeUVmzFjhi1cuNA2btyY9EhQCCGEEEcuKcV8zJkzx7OnTJlibdu2tZKSEvvBD35g27dvt6eeesqmTZuW0EqffvppO+mkk2zp0qV25plnVquQ1JzidHhq/tS+QvtpUM+i9sb37V14b96LMRzU2devXx9bFmqMbjwL9cQ4Tc8sOT8/y0Ldj1q6G39ADZ86PGMd+C4+25f34vvwrk4byl/CejMGiDo8Y0DoJ/d6ubm53jFquGw/avzUxllWPjF0YwKYh4M+ZVlYT96LMUO8vns9xkWxnkVFRZ7NmBD21RUrVnj2pEmTPNuNGeA/Mscff7xn08es13HHHefZ1MJPOOEEz3b382Dswr/+67/G3pvxCBxjZNmyZZ799NNPJ35nDpnbbrvNs0888UTP5lzTqVMnz2YMF8eFG9/w7rvvese4vwrHL+PJmJ/ozTff9Gzm7nBjJ9hXBg4c6Nnsp+w77r5AZsnjm+PC3VOF9Ro+fLhnc95j3AW/KxgDwhgfd65hHAxhv+a1Q3t9cX5w/cxyh/byqS7fKubjYPDWwS+bkpIS279/v5d8pVu3bpafn29Lliz5NrcSQgghxGFCtd92qaiosNGjR1u/fv3slFNOMbN//IfapEmTpBV+Tk5O0n+vB9m7d6+3iovLbiiEEEKI+k+1n3wUFxfb6tWr7bnnnvtWBZg4caJlZWUlfpiKWQghhBCHF9V68jFixAibPXu2LVq0yNOtc3Nzbd++fbZt2zbv6cfmzZuT9PGDjBs3zsaMGZOwy8rKkhYgzJfBGAJXk6JeRZsxHHxKw3tRd4/bE4Pn8ikOdXba1AypOcbtUxDKGcHjzBlCv1Bz5L1dqAFSb+S53NshtD8LtVW3/VlPtg9jIdhGcfkszJLbwPULc0hQn2bsCnV4nk/9mddz25saLscM83qsXbvWs0N5PpgXwtWjOZapuz/55JOezfajxk8/nX766Z7txkKwXow/YWwD4w8efvhhz545c6Znz5gxw7PdWAv2488//9yzr7vuOs+eP3++ZzPegOOA8Sj/9E//lPid+Ul4b8ausN9yHuP4du9l5seEXHHFFd6xUBwdxyRjBv72t795NvdEcecmjle2N/O0MJZhwYIFns04K/YPN2dU6Cl8aE6lzXmOY9htI8bghPZioo9D8YWMX3LHaCh2jfEm1SWlJx9RFNmIESNs5syZNn/+/KSkK7169bLGjRt7yXXWrFljn3/+eVKCnoNkZmZaixYtvB8hhBBCHL6k9OSjuLjYpk2bZi+99JIdffTRiTiOrKwsa9asmWVlZdmNN95oY8aMsZYtW1qLFi1s5MiRVlBQUO03XYQQQghxeJHS4uPga0znnnuu9/enn37arr/+ejMze+yxx6xBgwY2ZMgQ27t3r1144YX2+9//vkYKK4QQQoj6T0qLD2pcldG0aVN74okn7Iknnqh2oSq7pgu1V1db494rfJea76hTh6O+Re2UepirxVH7/OKLLzybeiOh5h/aG8D1CzVg6nLUl6kZhjRG4taVPmK9qfmzLCG4/4LbD5nzhfEnvFdc3ExlsD+49+Mx3ov1ZjwC24i6LWOA4uC1GAPQpUsXz2bsBOMR4vYRYvwA78UxxWvz3iw7x4kbj3Daaad5x0LjmSxdutSze/To4dmcP+Jyc9x3332eTZ+F+j1jChgL4c4HjNFguWizX3PuYNkYO+Fmrma5+D3AuYT35pgbO3asZzN/lJu7heVkDAivfdFFF3k25yLC/uL2xe7du3vHGJs0d+5cz2ZfCu2Jwrq44z2U24oxG8xHRNg3Od+7Y5J9id9DjOmpLtrbRQghhBBpRYsPIYQQQqQVLT6EEEIIkVaqneE0nfD1W+p0rl7F/AQhDZiaId+PplbK425MCbVQliUEY0aYoyJurw9qeIxN4bv51LapRzP/BY+7Wip1WZaF+iTbhNlveZz3dvfAcfdiMEvWRqk/M46CNnVd+s0llLcllNeD12b+DJZl3bp1id/pU8boMH6E7c3Ps+/F5cPhfiocIzfffLNnf/zxx57NuBzWZcCAAZ791FNPJX6ntk1tnP2BnHzyyZ5dXFzs2WwDt58zVoWxaIw3oMbPerOvLl682LPdGIKTTjrJO8Y5kf2YPg3tM8W4HTc+ifMQ24Dnsj/Qb5MnT/Zs7tfixie8+OKL3jGOCe71w/gExtGx3qyL26aMNSMvvfSSZ3N/HcZO8PuBe3m5c5Wbb8QsHE/EstLnnA/YN928LuxL/B5LJRYtDj35EEIIIURa0eJDCCGEEGlFiw8hhBBCpJWMqCrJO9JIWVlZ0vvPvXr18my+F+7qXdQ6mWOAWhdzClAr4zvNzBviuo+6G2MX+F5/aC8Yxm3weq6+yVwJ7p4UlV2beQN4L2qjjMtw4xuokzPnSMgv1GUPtQPyQdw247UY20CNmO/9sz/QptYat/EhtVCWhdemJuzqrmbJfnX7GuNLOIzZ3tTCGSvBNmI8ihuvwFiFUA4KxgAxhoBlpx/dsv35z3/2jn3/+9/37BNOOMGz2ZcY+8Dxzm0g3DZhX7v77rs9e9CgQZ7NOA22Gf3I/XfcfUeYI4aaP8c/60nYN5nnwz1/6tSp3jHGthD6iTE/jCdiP3dtxp4xbobzMX3MeAXGUjCOzv3+YCyLm/vELDnuhjloeG3OHR999JFnu+OA7ccxxvZjWTjXMA4nbhsTzv2MbaJP2Z5m/9iLKLRVip58CCGEECKtaPEhhBBCiLSixYcQQggh0kq9yPNB/ZnauKsxUj+m9sUYAGqEjBmhVsZ7x8V88N58p5zvXodyjFDfdK/v6sNm4b1aGONB6AfGxrh+o/7csWNHz6a2zbwd9FMqeT4Y20KddtOmTZ5N7Zx+YoxQ3H48LCevxb7IsrLe1FYZp+H2j1DuG8aq0E41/417PnOn0GeffPKJZ2/fvt2zuQcGxzev58ZtjB492ju2ZMkSz2buhPHjx3v2yJEjPZvtG7cvDccE6/HMM8949k033RR7r0WLFnn2Bx984NluDhLG6DD2gWOQ44DHGUPAvrd8+fLE75w72JfYvozhYAzQQw895Nn//M//7NluHM4LL7zgHeP8ffHFF3s2/cQxyDmW7e36jfMzYzroQ/qYfmGbHHfccYcsK+Oe+N3BuYRzLGNC2CYsmzsGeS1+D3Geqy568iGEEEKItKLFhxBCCCHSihYfQgghhEgr9SLmg/o2dT9XS6NWxlwa1EoZ+8D35Xk+tTI3DoMaIT9L/ZH14jvorAtzVLi6POtB3Zz1Jiw73zOnz+Og7krNmHEYjGUhfI/cjQFhHgDGUYRiW6hfsyzMSeH2B+aAYZwE43Co24bygDDGgLYL+wp1W2rb7IuhfYncccFyMP/B0qVLPZv5DZibg35k7JRbFvathx9+2LOHDRvm2cy9cfbZZ3s2+w/L4vqVmn2/fv08u6SkxLMZq8ScIqeccopnn3POOZ7t5gnheGZfYntxPNOnjH1grMzMmTMTv992223esUceecSzR40a5dmffvqpZ7/++uuePXjwYM9mvgs3NoZ5V95++23PDuW/4HGOE7apa7Pf/sd//Idnv/baa5798ssve3b37t09m+Obfc+9H+OqOE8Rzte06Rd+18TNk5z7+R1ZXfTkQwghhBBpRYsPIYQQQqSVeiG78LEPH0lR3nDh40U+vuJjVn6ej6/4uMqVQvjomuXkI0DKKHzlkJIPX+VyX5/iY1a+HkXpg1IGU5zTp3zU5konrHco3XboXvw8r+e2UeiVUZaNn+djWMpTPN99PMnXE9kGvBf7A8/nI2BKQO75LDfvFXrczLKEHqW6dePjY8pLfAzPfs560+dxqeOZLv3KK6/0bI5fpgKnfMFXEHm+O/fw1WdXmmA5K4NzB1/75lyzYMGCxO8ffvihd+zUU0/17NC253zEzzmV6dWHDx+e+J3jkfIS249zzfvvv+/Z7mu8ZmbXXXedZ7v9hf2YMgxTv//whz/0bM5zlKsoN7htsnDhQu/YT3/6U8++9dZbPZtyI32an5/v2exrrnzJesdt62GWXM/Q1hwck+73Ba9Nmbym0JMPIYQQQqQVLT6EEEIIkVa0+BBCCCFEWqkXMR/U0qlBua/+hXR0xlVQG2OcBc9nalnq3S6M0aBNHY6xD9QMqb26+jfT7VJ35auXvBZftaNf2Abu/fgaF19Ppc5KGIdDvTMuloY6KmMXuLU8fcx0+YyViUuZTF2dr05Th6Wf6FO2N18rdfser81yEh4PxSfQLy6M2ZkyZYpnM+U1xyTjTTim+Epq165dE79z2/kbbrjBszds2ODZjE8JpcSOewWZ9abNV0Y55kJjkq+oun5iLMM777zj2Yzp4Pg9/fTTPfuPf/yjZ7/77rue/eijjyZ+v/32271jTzzxROy96UPWmyny+aq2O7cwLoLtyWuxbzEOY/Xq1Z7dv3//Q54/bdo071jfvn09e/HixZ7NuYjjmW1y/PHHe7ZbN9aDcIywH9NPoa0c3HmN12a9ago9+RBCCCFEWtHiQwghhBBpRYsPIYQQQqSVehHzQX2K+pWrMVIjpP7IGABqZZs3b449Tt3O1at5jLo5NUDGlzAPQFy+A9qMq2BMAGM8mLOA+Q6Y/4R5Adx4FeYnoMbLGBDmBWBsA6EG6V6P9eK1QluLc5tz9o+4eBVeiz5nP6WOy/7CGBLGp7j9gfVke6aajpnjJi61O+/FWJaXXnrJsxkbwZTnHBf0o1tvlptjgn0lNMYYr8C4HXcMs5yMbWHeDvqQ8WGM+WAMkBsT8Oabb3rHpk+f7tkjR470bKb6/v3vf+/ZTEs/dOhQz3b9xliWsWPHevbPf/5zz6aP77zzTs9m+3J+d/s2Y7DYPswZMm/ePM9+4YUXLI7Jkyd7tjsGn3zySe8Yc8RwTly1apVnh2Il4uLP2M8Jx2sI5vVgbJzrV+bS4bxUU+jJhxBCCCHSSkqLj0mTJlmPHj2sRYsW1qJFCysoKLBXX301cXzPnj1WXFxsrVq1subNm9uQIUOSniQIIYQQ4sgmpcVH+/bt7aGHHrKSkhJbsWKF9e/f3wYPHmzvvfeemf0j3ewrr7xiM2bMsIULF9rGjRvt8ssv/04KLoQQQoj6SUYUeuE/QMuWLe2RRx6xK664wtq0aWPTpk2zK664wszMPvjgAzvppJNsyZIlduaZZ1bpemVlZUk67bhx4zybWzy7UG8k1BAZV0EdjjEAzBPiauvUcKn5Uoen3syyM56BsRKuLsgnTMwhwjwg1OmZa4ExBevWrfNsty6hXCmhmA/GBFDP5OfdNqGPUtVC2d6h4eCWJbR3C6/N+BOezzgb9k03hoR9he3Hfks/sZ6hXCxu3diezBHBXBvu1vBmZl26dPFs+oVlccdcKLaFPiT0KbVvtokbh8HYBPa1kM3zWU/GfLg+59zCMcF5icdD+Y54PO5YaD8lIbZv354Un0OqHfNRXl5uzz33nO3atcsKCgqspKTE9u/fb4WFhYnPdOvWzfLz823JkiWHvM7evXutrKzM+xFCCCHE4UvKi493333XmjdvbpmZmXbzzTfbzJkz7eSTT7bS0lJr0qRJpTuYMnrWZeLEiZaVlZX46dChQ8qVEEIIIUT9IeXFx4knnmirVq2yZcuW2S233GJFRUVJWyanwrhx42z79u2JH6b5FkIIIcThxbeO+SgsLLQuXbrYj3/8Yzv//PPt73//u/f0o2PHjjZ69Gi79dZbq3S9ymI+Onbs6NlxcR3UTUkoJoB6JrX0OM2YrqSeHCLVzwshhBB1je805uMgFRUVtnfvXuvVq5c1btzYS/KyZs0a+/zzz62goODb3kYIIYQQhwkpZTgdN26cDRw40PLz823Hjh02bdo0W7Bggb322muWlZVlN954o40ZM8ZatmxpLVq0sJEjR1pBQUGV33QRQgghxOFPSouPLVu22PDhw23Tpk2WlZVlPXr0sNdeey2x3fNjjz1mDRo0sCFDhtjevXvtwgsvTErrG6IyFYhSCNNWV/VYZdcKHacdl/I8Lv25EEIIcSRQle++bx3zUdNs2LBBb7wIIYQQ9ZT169cn7ZtF6tzio6KiwjZu3GhRFFl+fr6tX78+GLgi/o+ysjLr0KGD/JYC8ln1kN9SRz6rHvJb6tSGz6Iosh07dlheXl5SQk9S53a1bdCggbVv3z6RbOzgPjIiNeS31JHPqof8ljryWfWQ31In3T7j26qHQrvaCiGEECKtaPEhhBBCiLRSZxcfmZmZdt999yVtcCbikd9SRz6rHvJb6shn1UN+S5267rM6F3AqhBBCiMObOvvkQwghhBCHJ1p8CCGEECKtaPEhhBBCiLSixYcQQggh0kqdXXw88cQT1qlTJ2vatKn17dvXli9fXttFqjNMnDjRzjjjDDv66KOtbdu2dumll9qaNWu8z+zZs8eKi4utVatW1rx5cxsyZIht3ry5lkpc93jooYcsIyPDRo8enfibfFY5X3zxhV177bXWqlUra9asmZ166qm2YsWKxPEoiuzee++1du3aWbNmzaywsNA++uijWixx7VJeXm733HOPde7c2Zo1a2ZdunSxX/7yl0n7QB3pPlu0aJENGjTI8vLyLCMjw2bNmuUdr4qPvv76axs2bJi1aNHCsrOz7cYbb7SdO3emsRbpJ85v+/fvtzvuuMNOPfVU+973vmd5eXk2fPhw27hxo3eNOuG3qA7y3HPPRU2aNIn++Mc/Ru+9917005/+NMrOzo42b95c20WrE1x44YXR008/Ha1evTpatWpVdNFFF0X5+fnRzp07E5+5+eabow4dOkTz5s2LVqxYEZ155pnRWWedVYulrjssX7486tSpU9SjR49o1KhRib/LZ8l8/fXXUceOHaPrr78+WrZsWfTpp59Gr732WvTxxx8nPvPQQw9FWVlZ0axZs6J33nknuuSSS6LOnTtHu3fvrsWS1x4TJkyIWrVqFc2ePTtau3ZtNGPGjKh58+bRb37zm8Rn5LMo+utf/xrddddd0YsvvhiZWTRz5kzveFV8NGDAgOi0006Lli5dGr355pvR8ccfHw0dOjTNNUkvcX7btm1bVFhYGD3//PPRBx98EC1ZsiTq06dP1KtXL+8adcFvdXLx0adPn6i4uDhhl5eXR3l5edHEiRNrsVR1ly1btkRmFi1cuDCKon90wMaNG0czZsxIfOZ///d/IzOLlixZUlvFrBPs2LEj6tq1azR37tzonHPOSSw+5LPKueOOO6Kzzz77kMcrKiqi3Nzc6JFHHkn8bdu2bVFmZmY0ffr0dBSxznHxxRdHN9xwg/e3yy+/PBo2bFgURfJZZfBLtCo+ev/99yMzi956663EZ1599dUoIyMj+uKLL9JW9tqkskUbWb58eWRm0bp166Ioqjt+q3Oyy759+6ykpMQKCwsTf2vQoIEVFhbakiVLarFkdZft27ebmVnLli3NzKykpMT279/v+bBbt26Wn59/xPuwuLjYLr74Ys83ZvLZoXj55Zetd+/eduWVV1rbtm2tZ8+e9uSTTyaOr1271kpLSz2/ZWVlWd++fY9Yv5111lk2b948+/DDD83M7J133rHFixfbwIEDzUw+qwpV8dGSJUssOzvbevfunfhMYWGhNWjQwJYtW5b2MtdVtm/fbhkZGZadnW1mdcdvdW5jua+++srKy8stJyfH+3tOTo598MEHtVSquktFRYWNHj3a+vXrZ6eccoqZmZWWllqTJk0Sne0gOTk5VlpaWgulrBs899xz9vbbb9tbb72VdEw+q5xPP/3UJk2aZGPGjLE777zT3nrrLfvZz35mTZo0saKiooRvKhuvR6rfxo4da2VlZdatWzdr2LChlZeX24QJE2zYsGFmZvJZFaiKj0pLS61t27be8UaNGlnLli3lx//Pnj177I477rChQ4cmNperK36rc4sPkRrFxcW2evVqW7x4cW0XpU6zfv16GzVqlM2dO9eaNm1a28WpN1RUVFjv3r3tV7/6lZmZ9ezZ01avXm2TJ0+2oqKiWi5d3eSFF16wZ5991qZNm2bdu3e3VatW2ejRoy0vL08+E2lj//79dtVVV1kURTZp0qTaLk4SdU52ad26tTVs2DDpLYPNmzdbbm5uLZWqbjJixAibPXu2vfHGG9a+ffvE33Nzc23fvn22bds27/NHsg9LSkpsy5Ytdvrpp1ujRo2sUaNGtnDhQvvtb39rjRo1spycHPmsEtq1a2cnn3yy97eTTjrJPv/8czOzhG80Xv+PX/ziFzZ27Fi7+uqr7dRTT7XrrrvObr31Vps4caKZyWdVoSo+ys3NtS1btnjHDxw4YF9//fUR78eDC49169bZ3LlzE089zOqO3+rc4qNJkybWq1cvmzdvXuJvFRUVNm/ePCsoKKjFktUdoiiyESNG2MyZM23+/PnWuXNn73ivXr2scePGng/XrFljn3/++RHrw/PPP9/effddW7VqVeKnd+/eNmzYsMTv8lky/fr1S3qN+8MPP7SOHTuamVnnzp0tNzfX81tZWZktW7bsiPXbN998Yw0a+FNrw4YNraKiwszks6pQFR8VFBTYtm3brKSkJPGZ+fPnW0VFhfXt2zftZa4rHFx4fPTRR/b6669bq1atvON1xm9pC21Ngeeeey7KzMyMpkyZEr3//vvRTTfdFGVnZ0elpaW1XbQ6wS233BJlZWVFCxYsiDZt2pT4+eabbxKfufnmm6P8/Pxo/vz50YoVK6KCgoKooKCgFktd93Dfdoki+awyli9fHjVq1CiaMGFC9NFHH0XPPvtsdNRRR0VTp05NfOahhx6KsrOzo5deein629/+Fg0ePPiIe23UpaioKDr22GMTr9q++OKLUevWraPbb7898Rn57B9vnq1cuTJauXJlZGbRo48+Gq1cuTLxVkZVfDRgwICoZ8+e0bJly6LFixdHXbt2PexftY3z2759+6JLLrkkat++fbRq1Srv+2Hv3r2Ja9QFv9XJxUcURdHvfve7KD8/P2rSpEnUp0+faOnSpbVdpDqDmVX68/TTTyc+s3v37uhf/uVfomOOOSY66qijossuuyzatGlT7RW6DsLFh3xWOa+88kp0yimnRJmZmVG3bt2iP/zhD97xioqK6J577olycnKizMzM6Pzzz4/WrFlTS6WtfcrKyqJRo0ZF+fn5UdOmTaPjjjsuuuuuu7zJXz6LojfeeKPSeayoqCiKoqr5aOvWrdHQoUOj5s2bRy1atIh+8pOfRDt27KiF2qSPOL+tXbv2kN8Pb7zxRuIadcFvGVHkpN0TQgghhPiOqXMxH0IIIYQ4vNHiQwghhBBpRYsPIYQQQqQVLT6EEEIIkVa0+BBCCCFEWtHiQwghhBBpRYsPIYQQQqQVLT6EEEIIkVa0+BBCCCFEWtHiQwghhBBpRYsPIYQQQqQVLT6EEEIIkVb+H4e/dH6b3bWdAAAAAElFTkSuQmCC\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAh8AAAC+CAYAAACVgm2zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABASElEQVR4nO2de5xP1f7/XzOYGRlGbjMGg9IXRXGIRroaob5J0cVRdP+qGZd860id0lHS5dRBSed0ik6RcpTo5HZGSLlOKEeJkkvMSGLcyazfH/3s71qvD3vNaHxm4vV8PObx+Lxn7c/ea6+19p49+/Va7xVjjDEQQgghhIgSsSVdASGEEEKcWujhQwghhBBRRQ8fQgghhIgqevgQQgghRFTRw4cQQgghoooePoQQQggRVfTwIYQQQoiooocPIYQQQkQVPXwIIYQQIqro4UMIcUoSExODxx57rKSrIcQpiR4+hDgJ2b17NwYPHoyOHTuiSpUqiImJwdixY51ttm7diipVquDyyy+P+P6hQ4fQtGlT1KtXD3v27Al+/8UXX6Bbt26oW7cuEhISUKtWLbRv3x4vvPBCxD4+/fRTtG3bFqeddhpSUlLQt29f7N6929lm7NixiImJCX4SEhKQmpqKDh06YOTIkdi1a1fEfh977DHnO+XKlUO9evXQt29f7Nix4/gazKrL0qVLj3sfQojCUbakKyCEKH62bduGIUOGIC0tDeeddx7mzJkTsU2NGjXw9NNP4+6778brr7+OXr16BWXPPfccVq5cialTp6JChQoAfnmYuOyyy5CWloa77roLKSkp2LhxIxYuXIgRI0agT58+wfeXL1+Odu3aoXHjxnj++eexadMm/PnPf8aaNWswbdq0iLoMGTIE9evXx6FDh5Cbm4s5c+agf//+eP755zFlyhSce+65Ed8ZPXo0EhMTsWfPHmRnZ+OFF17AZ599hvnz5xdDCwohTihGCHHSsX//frNlyxZjjDFLliwxAMyYMWMitisoKDBt27Y11apVM9u2bTPGGPPtt9+a8uXLm+uuu87Z9sorrzTVq1c3P/30U8R+8vLynLhTp06mZs2aZufOncHvXnnlFQPAzJgxI/jdmDFjDACzZMmSiH1mZ2eb8uXLm7p165q9e/cGvx88eLABYH744Qdn+xtvvNEAMIsWLTpGq7gAMIMHDy5UXYQQxYtkFyFOQuLj45GSkuLdLiYmBi+//DJ27tyJ+++/HwBw7733omzZshg5cqSz7TfffINzzjkHlStXjthPjRo1gs/5+fmYNWsWbr75ZlSqVCn4fc+ePZGYmIh33nmnUOdw+eWX45FHHsH69evx5ptvere/6KKLgnraHDhwAPfddx+qV6+OihUronPnzti0aVOh6iCEODHo4UOIU5xzzjkH999/P8aOHYu+ffti+vTpeOKJJ1CrVi1nu7p16yInJwcrV64M3d8XX3yBn3/+GS1btnR+HxcXh2bNmmHZsmWFrtstt9wCAJg5c6Z32++++w4AcPrppzu/v/POOzF8+HBcccUVeOqpp1CuXDlcddVVha6DEKL40cOHEAKPPPIIzjjjDLzwwgto0aIFMjMzI7a5//77sXfvXjRr1gxt2rTBwIEDMXPmTBw6dMjZbsuWLQCAmjVrRuyjZs2a2Lx5c6HrVbt2bSQlJUW8zQCA7du3Y9u2bVi/fj3GjBmDUaNGoXr16rj44ouDbVasWIE333wT9957L8aNG4fMzExMmjQJTZo0KXQdhBDFjx4+hBCIi4tDUlISAKBdu3YoU6ZMxDbt27fHggUL0LlzZ6xYsQLPPPMMOnTogFq1amHKlCnBdvv27QPwi/TDJCQkBOWFJTEx8aizXho2bIjq1aujXr16uP3229GgQQNMmzYNp512WrDNhx9+CADo27ev893+/fsXqQ5CiOJFDx9CCIwYMQLLli1DkyZNMHLkSKxdu/ao251//vl499138dNPP2Hx4sUYNGgQdu3ahW7dumHVqlUAgPLlywP4xWvB7N+/PygvLLt370bFihUjfj9p0iTMmjUL48ePxwUXXICtW7dG7Hv9+vWIjY3FmWee6fy+YcOGRaqDEKJ40cOHEKc4GzduxODBg9GlSxfMnDkTcXFxR5VdbOLi4nD++efjySefxOjRo3Ho0CFMnDgRwP/JLUfkF5stW7YgNTW10HXbtGkTdu7ciQYNGkSUXXzxxcjIyED37t0xa9YslC9fHj169EBBQUGh9y+EKBn08CHEKU5WVhYAYOTIkahZsyaGDh2KmTNnYsKECYX6/hFj6ZGHjSZNmqBs2bIRyboOHjyI5cuXo1mzZoWu2xtvvAEA6NChQ+h2iYmJGDx4MJYvX+7Mpqlbty4KCgoiPCOrV68udB2EEMWPHj6EOIV57733MGXKFAwZMgR16tQB8MtU2xYtWmDAgAHIz88Ptv3oo49gjInYxxFfxREpIykpCRkZGXjzzTcdr8Ybb7yB3bt34/rrry9U3WbPno3HH38c9evXR48ePbzb9+jRA7Vr18bTTz8d/K5Tp04AEDFtePjw4YWqgxDixKAMp0KcpLz44ovYsWNHMLtk6tSpQX6LPn36IDY2Fn379kXz5s0dQ2ZsbCxefvlltG7dGg8//HCQOr1Pnz7Yu3cvrr32WjRq1AgHDx7Ep59+irfffhv16tXDbbfdFuxj6NChaNOmDS655BLcfffd2LRpE5577jlcccUV6NixY0Rdp02bhq+++go///wz8vLyMHv2bMyaNQt169bFlClTkJCQ4D3fcuXKoV+/fnjggQcwffp0dOzYEc2aNUP37t3x0ksvYefOnWjTpg2ys7OP6WkRQkSJks5yJoQ4MdStW9cAOOrPunXrTL9+/UxsbKxZvHjxUb+flZVlYmNjzdKlS40xxkybNs3cfvvtplGjRiYxMdHExcWZBg0amD59+kRkODXGmI8//ti0adPGJCQkmOrVq5vMzEyTn5/vbHMkq+iRn7i4OJOSkmLat29vRowYEbG9McfOcGqMMTt37jRJSUnmkksuCX63b98+07dvX1O1alVToUIFc/XVV5uNGzdGZDh97bXXDADz2WefFaZ5hRC/ghhjjvIeVQghTjFGjhyJfv36Ye3atRGzY4QQxYs8H0IIAWDJkiWoUKEC6tatW9JVEeKkR54PIcQpzaRJkzBnzhyMGzcOd955J8qW1W1RiBONZBchxClN/fr1sWvXLlx77bUYPnw4KlSoUNJVEuKkRw8fQgghhIgq8nwIIYQQIqqcsIePUaNGoV69ekhISEDr1q2xePHiE3UoIYQQQvyGOCGyy9tvv42ePXsGiYqGDx+OiRMnYvXq1ahRo0bodwsKCrB582ZUrFgRMTExxV01IYQQQpwAjDHYtWsXUlNTERvrebdxIpKHtGrVymRmZgbx4cOHTWpqqhk2bJj3u0eS/+hHP/rRj370o5/f3s/GjRu9f+uLfU7ZwYMHkZOTg0GDBgW/i42NRUZGBhYsWBCx/YEDB5ylt438r0IIIUShiY+P/1XlYcsXcNn27dudePfu3RHfqVixYujxgBPg+di2bRsOHz6M5ORk5/fJycnIzc2N2H7YsGFISkoKftLS0oq7SkIIIcRJS0xMzK/6iY2NLfQPf/dY9fFR4tl0Bg0ahAEDBgRxfn5+sLqmECczvsXSuNx+K8hlfLFz+eHDh53Y958Q57qw91/Uehdn+a9pM+CXxedsuF0qVarkxPZb2TJlyjhlhfnvLgyuK/eJXc7/XVauXNmJ7XoCv6wsbMOJ0/hYvvFjc+jQISfmduF9cZsnJiaGHsvus4MHDzplfF78XV/dON67d68T2/3PbVZQUBC6L/Yz8vZbt251Ym4H2yPBY6uoie+4Hfg8uf/tmK8Z9m78/ve/d+IJEyYUqW5HKPaHj2rVqqFMmTLIy8tzfp+Xl4eUlJSI7ePj4703QiGEEEKcPBS77BIXF4cWLVogOzs7+F1BQQGys7ORnp5e3IcTQgghxG+MEyK7DBgwAL169ULLli3RqlUrDB8+HHv27MFtt912Ig4nhBBCiN8QJ+Th48Ybb8QPP/yARx99FLm5uWjWrBmmT58eYUINo3r16oHWdOWVVzplrPPZehhr1axfccz6JOtwHDNh2ijrdPv373di1pdZGy1fvnzosW0dj3W5MD3xaMfmurGmzJqhfW6sbXIf+OoWFxfnxD///LMTc7vYbc71ZmrVquXEP/30kxNzH7EH4PTTT3diW0vdt2/fMet1NFi/DhvHQGS77ty5M/jMbchtxG24Z8+e0HLuA47Dyvga4nbhcj4vLmct3T4eX7/c/7wv3r6o523vn/d12mmnOTH3L7cDX8/5+flOXKVKFSe2rxveltuQ682aP4+1sPME3D7wbXu02Q423E68Pz43+9jsfeB7CR+bj8Xl3Idh7cLXDPtq+Dy4v9lOwOfCfVStWrXgM7cJ35d851HU2S32ufJ58N8KLj9eTpjhNCsrC1lZWSdq90IIIYT4jaK1XYQQQggRVfTwIYQQQoioUuJ5Po7F2WefHWjgL774olPG+petf7IOx9uynsw6LcP+BdblbQ2ZfRFcFy5nWMdnbZU1Q/u8WQNmbds3d9s37581SLsdWGdlWCtlHdbnT+HY7kP2cPB5cruwrs7jg4/F5WHnzcdiWPPnsciw5mz7OrheHPv8RdwnrAHv2rXLiW2dl71b3Ob8XW4Xvob4GuSxWLVqVRwLPm/2vvCx+Vg89nhs2tcca/Q89riNeXz46haWmInvQ7428917eHzwuA/LK8H15PPkunAfcd3ZXxZWLyYsHw0QeR/kct6/Xc779vn/+Fh8HXA55wWxj8314rHDY9GXW8XnAbHPjc+T7/0+j09h0ZsPIYQQQkQVPXwIIYQQIqro4UMIIYQQUaXUej5sfPn6bXzaFmtjRd2e9S9b52VNnzV7zhnB2tmOHTucmLXuML3Sp9my7sr48qFwH9jlvMoha9nsJ+B24PPidgvLf8H9x+3Auivr8tzmvHYEz2m3PQDcpjw2+Lz42Iwv34V9rnbOj6Nt6/PR+HKUcF3t77NmzzF/15dbg+vC52J7K3zrq/C49Xk8eKzyNWmX83lxm/F58LF81xiPH9uXY+eAAML9QEDkNcMxb8/tGua18PnqfL4rvpeEeafYq8Lb8r64//g8eCxy3e1y7k8+b/aE8HlyG/P44WvY3j4szw7g93zwefvyW4Xhy19zvOjNhxBCCCGiih4+hBBCCBFV9PAhhBBCiKhSaj0fFSpUCDQwXz4EW0vLy8tzyqpXr+7ErJWyZswaI+t2rOPm5uYGn9mjwXqib30N9kL4cpLYGjFrfKwZcl4H9kr4fDVhuRY4ZwC3oS+/CR/Lp8vax/OtxcI5BHxaKeu2YevrcJv71nbxaeHcDqxv233oy63ia1Mex9wOnMPCLud6+3JM+DwCYflrANe3w/3h0655e/Y+cJ/w+Akbu3wePs8Hnxf7ONifZOekYS8Dj+uwvBxA5L3Ht65UGHwNsVeF98U+Kp/Pzh6r3Cbcn9w/PO7Zl8EeLx4/9jXM13PYuAQi28U3lviatPuU6+W7P3PM2/vyXYXlEOJxzPU+XvTmQwghhBBRRQ8fQgghhIgqpVZ2OXz4cPBa2/eKyX5NxK8y+VWo73U1vxL88ccfnZhfb9qv9bjM99qN68KvgBl+fW2/OvV9l1+l8Xn6XhGHTc30LRXvmwbme40fltKexwK/VvVNteTY9yrdrqtPJvEt/86vRn3Lh9uxbyo1v2bncn4VzvDrbfsVM7/y96Ww5v71LRsQlvKex9bWrVudmMu5jX3T18NkGa4Xv3b3yUtc15o1azox94ndh9xGLMPwsXyyCo/dH374wYnt/vctI8BtyPc5Hot8ffP+7T5k2ZyP5Zsaz23uS1Nutwvvy3cf80lXPLZ4vNjt6luygMt9Ke19sntR5GXe1/GiNx9CCCGEiCp6+BBCCCFEVNHDhxBCCCGiSqn1fCQkJAQaGmtlrNPZGiNrWTzVivVm1ul8S42H1cW3pLpPd/XVjTVHO/al4/VNb2MN0Zfi3N7eN32V9WrGN12Oy219kuvJ7cBtyNop+xe4D1g7tfVp9jpwzGOH68rn5Zs2bLcLa/S+lPbsEeDz5OskLHU09y/7bHjf3J/8ffblcNppuy4+nd031hhut7BpwHye7Nnga4jHA/vR7Gn6AJCSkuLE3AfHqldh4HHO48e3VICNL10615vrytdBmLfCN8WYYe8CjyX2woSlJODz4v5krwrvm/+W8PXO7RSWtpzPm/uArwtuNz5Pvj/Y/e2bWsvT8I8XvfkQQgghRFTRw4cQQgghoooePoQQQggRVUqt5yM+Pj7Qc1lLZZ3X1rt86Xf5uz6fBcN1CZsXzrCWxrCG6EsdbdeVdTnfXHzWBFmX9XlEbN2W9URfal/WfFmvZH8Jt0tYzomw3BhHi7dt2+bErMOyNmqPF1+qb9ZGeV/c5pxThrHblf0D27dvd2LOf8BeF86fELaEOuDWnffF/evzADF8jYalfmffRY0aNUKPzdtzOY9zbge7v305YXx+Mb4mffvbvHlz8Jn9P757iQ/uf75/2Pc5Hlvchgz3J/e/b5kBO2YfBV+vvG8eD3w9s5eFrxO7br7+C8vTAUT+LbHT5fOxAPdcfGPL93eN9x02rnl7n9dFeT6EEEII8ZtEDx9CCCGEiCp6+BBCCCFEVCm1no+yZcsGOhZra6zj2r4L1qdYG2Otk7UvhrUz9iPY+rdv7jXnO2DPgM+PELYMMut07IXg+e6sdbMPg88lTOdjTwb3l+882PvA32d/iq3T8r62bNnixKwB8758embYUuXchrxv3hePNT42jwdelyI5OTn4zFo3r1nC1KpVK3TfnGMiLP8Fl3H/c8xjz+fTCPMA8Hn71qxgb4zvWPx9+/rnbTk/CX+Xz5t1fL5GwzwA7PEo6nn44Lra58b3JfZh8Ljm65fPy7cuiQ23GV8zvvPkcp+fwa47/53xefJ4LPrWJGP4Hmzj8yb6vEy+8WLfU7l/bO8R4Pc2Fha9+RBCCCFEVNHDhxBCCCGiSpEfPubNm4err74aqampiImJweTJk51yYwweffRR1KxZE+XLl0dGRgbWrFlTXPUVQgghxG+cIns+9uzZg/POOw+33347rrvuuojyZ555BiNHjsTrr7+O+vXr45FHHkGHDh2watWqiHnTYcTFxQX6my9nhe0ZYO2S51azdsbzvH3wmgi29saaPedD4DnmrCnyebFOF7bODGt8rD9yG7KXwZezgr///fffH/NYvvVSfOuv+NbIsTVozqXB62341lsJWz8DCM+Pwr4J1oT5WKxfcx9wedj6KjwOeV+s07OvhtuF+4j9K7YOzNcM9wHvm+Fxzxoya+P2eOGx5csh4suXwMficvZ12Pg8XtxO7D9jjZ/rYvepb+0lvlewB8iXx4W3t8c2tzm3iS//BV8XDNc9zGfjW7uLt+exGZYjCnDHPY8tn/+Er0GfRyjsfuH7W8LH4nbhY/H44T6y24HHKbdR2DVRFIr88NGpUyd06tTpqGXGGAwfPhx//OMfcc011wAA/vGPfyA5ORmTJ0/GTTfd9OtqK4QQQojfPMXq+Vi3bh1yc3ORkZER/C4pKQmtW7fGggULjvqdAwcOID8/3/kRQgghxMlLsT58HFki2p4SeCTm5aOPMGzYMCQlJQU/derUKc4qCSGEEKKUUeJ5PgYNGoQBAwYEcX5+PurUqYPY2NhAa+I1L1h7s+fA+9YdYB2PdTufDsvamq3N8b7Zb8Jamc/zwQ9i/H27XbhNWG/mfXOb8nmxR4A1Q9tbwf4APhZ7H/i8+fus44bp8r41bdhPwPkSWOP3zZe3z4WP5fOXcF24j/j7rLXa+jVrtjzW2Pvky4fBfcJ1sz0hPA65nj7NmNs4TH8G3P7n65O1b94X15XHJm9flLwPvnsJ9wmPY99YtfuAj8X9w9/l65WvMb4OuNxuV5/vgo9d1PWyeHu7nbh/+N7gG3t8DXIf8Piw24HbyHcv4bHI15zP28b3cBu+H7MHhNuJ24HLuR3sPvCtpebLjVVYivXNx5FERXl5ec7v8/LyIpIYHSE+Ph6VKlVyfoQQQghx8lKsDx/169dHSkoKsrOzg9/l5+dj0aJFSE9PL85DCSGEEOI3SpFll927d2Pt2rVBvG7dOixfvhxVqlRBWloa+vfvjyeeeAJnnXVWMNU2NTUVXbp0Kc56CyGEEOI3SpEfPpYuXYrLLrssiI/4NXr16oWxY8fiD3/4A/bs2YO7774bO3bsQNu2bTF9+vQi5fgAftGFj+icrJ3x2hC2Dsx6FetqXM7aOGtlRdErWZdlbZTjsHn9QKQeybE9/571aN6XLx8Cb88x798+F9Yqt2/f7sQ8n923LgFvH6Zfs+bLMWvErNtym/ryPtjtwm3Kx2Jt1Nf/rOPy2LXH/caNG50yzsXA58nl7EfgY3N/233M+jPvm2escRv6xiL3oT1euM3YA8Ix50vw5Tvhutl14XHpy2fC45rvNb68IDa+scFt7vMIsF+Bz8XuUy7z+Q147HE7cB/y9R2Wk8S3XkpRc1Dw3yW7//lvAdfTl++Ex5Jv3Ntwm/E9k+vC8Fjl+znfm+xrlL97omagFvnh49JLLw098ZiYGAwZMgRDhgz5VRUTQgghxMmJ1nYRQgghRFTRw4cQQgghokqJ5/k4FhUrVgw0ctZCw7wQrLuxtsXaF2ufrF/61i2wY9Y6GdYnWVtjz4BPv7TP7fTTT3fKiuqx2bRpkxOztMZ9YGvrvlwL7HVgTZfbmHMOsKekWrVqwedt27YhDNZOed8+bTRMj/blEOBy9sL4xiZr7WFyJ58Xjx3eF8e+vC72/nxr8/j8Jz5tnPvM7n+fR4c9Hjz2GD7PMK2d981auG89JG5zn/fJ/j73r29s+NY0CVtPBXDPzXe98r59Hi+ue1jeGN+aRWEeHSDyvPheEnY/9+XG4XHtW9uFr3ceT2F5PsI8GkDk3w6fx4O9UXY78ba8jlRxoTcfQgghhIgqevgQQgghRFTRw4cQQgghokqp9XyULVs20K1Yl2P909art2zZ4pT55keHrSsAROqR/H1b9+N98Xc5P4kvT4Bv/ry9PgvvO6yegF+n57VfwvbH9fR5GVjbDNM6gUjt1Ia1Tt93uU9Yx/WtBWKPNd9aLNzGXFf2gPjyhNhjm3NG8HnYvhgg0n/Cmi9fN2FauS/3DevRvGSCL0cBn5t9vXN+Eh577MPYunVr6PYcM3afchuzD4rHGo8HvsZ4rIXlz/CtacOeL75++dhMWG4evgbYJ8fjlMcxjweG92cfj+8NXBcu5z7y5U5iP4N93fB58L757xDD23Pd+Z5s9z8f25enxefL4XsV/52zy/m8fL6640VvPoQQQggRVfTwIYQQQoiooocPIYQQQkSVUuv5sHVCnpPOcW5ubvC5Tp06Tpkvx4AvHwLDWlteXl7wmfXFRYsWOTGv7FurVi0nXr16tRN///33Tvxf//VfTvzNN98En1l/Zt2c55RzeWpqqhOzdm6fJ+DqmaybLly40IkvvvhiJ05LSwutC68rwudt99k//vEPp4y1UdaEeV/169d34uXLlztx27Ztndj2O7D3gXVXbhfW5VNSUpyY684+HltbHz9+vFPG47J3794IgzVlzgvBHpBGjRoFn7lNub/4+mS/wZo1a5yYPQMNGzZ04q+//jr4zGOFt2VvC/cJ69d8bPan8LnY+LxLnO+Cj833Bx4PF1xwQfCZ+2f+/PlO7PO2JScnO/Ell1yCMOw+5TatWrWqE/MaKL41q3zr89jt6OtPxudH4nK+L9q+jM8//9wp4/sWX0Nc13Xr1jkx+4tq1qzpxPbY5vvQOeecE1pv/jvny38TlpOG/wb6cuUcL3rzIYQQQoiooocPIYQQQkSVUiu7VKhQIXjdw691+ZWi/TqMX137XsPxq07fdDkut6fycYryFStWOPETTzzhxPwqbdCgQU58xhlnOPGf//xnJ+7SpUvwedq0aU7ZFVdc4cT8yp9fX/MrYX61ylPxbPnizTffdMpeeuklJ+ZXxhdddJET8yvBs88+24n5deXvf//74PPQoUOdsltuucWJedrYDTfc4MT8ypdfR06cONGJ7am27du3d8rq1avnxNyGPJb4te6CBQucODs724lHjx4dfJ40aZJTdu6556IocF1YAuQpqnZd7HEHhE+FBoB33nnHiV944QUn7tmzpxM3bdrUiW0Zb8KECU4Zj41bb701tG5Tpkxx4m7dujnxNddc48T2/YSlSJa6+F4zZ84cJ/7uu++cmGWZZ5991oltCYivid/97ndOPHnyZCe+8847nfjVV191Yh4vw4cPd+Jhw4YFn215F4gcO77p6b57MMsV9r2JZS+WAPj65ZglP1/d+/fvH3xmCZ/H6fr1652YZRme7j5z5kwn5vve5ZdfHnxmCY9lUP7b4EtDz/tjWSZsmRAe98WF3nwIIYQQIqro4UMIIYQQUUUPH0IIIYSIKqXW82GnV2fdLmzqD2tbrIWxfsXlPKWUdb9Zs2Y58bhx44LPvpS2PI3v8ccfd2L2snB8/fXXO/HDDz8cfGYfRadOnZyY24U9IKzxcxufeeaZTmxPceU246m2rMvzlGL2SvTq1cuJX3vtNSf+61//Gnx+9NFHnTKezszt4lvunXVcnu587bXXBp95bPCUQ9a6uR1Yp3/wwQedePr06U5se0jYH8LT+rKyskLrVrt2bSfmduL92+3MU4i//PJLJ/7Xv/7lxNxOtmcH8HsC7LHLqbrZT8TlrJVnZGQ4MffvjTfe6MT2Nde6dWunjMcxe0DYK2F7doBI78zf/vY3J/73v/8dfF65cqVT5puC2qxZMye+5557QusycOBAJ7avfzuVARA5rZ+njPI9lX1XXHfuf/v77B/hmH0T7Pnjsblq1SonZk+X7X27//77nTJO7T979mwnfv31152Yrzn2/HTs2NGJ7fH0ySefOGUdOnRwYvbgcd0YXzva+K7H4kJvPoQQQggRVfTwIYQQQoiooocPIYQQQkSVUuv5OP300wNtkPVM1hRt/Yr1SM4Rwt9l2KexYcMGJ2Ydl9N7h9G9e3cn/uKLL5zY9hMAkbk4WCu1vRGcY4TryX6TsNS+QGQ6ZvYULF68OPjcvHlzp4zbjOe7s89i6dKlTmzPtQciPSSXXXZZ8Pkvf/kLigJ7XxjWp9mfYOdmYI8P+w147E2dOtWJ2a/CvPvuu8fcP/tHOKdIZmamE4ctoQ1E5jto0KCBE9s5TTi/CeegYP8Q5xBh/Zq9Ehs3bnRiOyfFW2+95ZTxWFq7dq0Tsz+F25TLuV2+/fbb4HPjxo2dMs6N8/e//92JP/30Uydu166dE7OHi6/v8847L/jMaf7ZJ8VeJx57n332mRNzDqK+ffs6sd1Ol156qVPG91Dub25DPi+OGdsrwR6O6tWrOzF7Hew8PEc7Fud14uvmmWeeCT77cgDxdcD75rH54YcfOjH7z3788cfgM7dx3bp1nZj9gJs3b3Zi9uzx9c33QdvnwX9v+W9DcaE3H0IIIYSIKnr4EEIIIURU0cOHEEIIIaJKqfV8lClTJtC9WFtnndbWjFmv4rnWrLOxFsZaGc95vvrqq53Y9giwjsb+E96XvWQ2EJmDhOvGc9qbNGkSfOY55x999JET/8///I8Tc44C/j6vv8FrCdi+DF5amv0FnIthyJAhTsw6Pbcbr+dhw2s/8LFYO+U25fU1uI15f3Yf8nLsfN62hgtErivCy8HbazsAkedm51Nhzw6Pc87jwr4K9ivweOAl2zt37hx8vummm5wy1uG5P9lnwWtg2PsGIrV2u135GuPrlb0R9hpEQOT6HDw+7DVN+Hjcprw+CufW4XHL9yauG5+b7aXhscZji8ctez4aNWrkxHxPnTdvnhPb457vBexVYq8D+0nYK8Ntzvcqe3v2HnEbco4hPi++TnwekNTU1OBz/fr1Q4/N45SvA3tfgH89HjsnzXXXXeeUsX+EvS1872GPH3sC2b9i74/vO3yvKC705kMIIYQQUaVIDx/Dhg3D+eefj4oVK6JGjRro0qVLxH9M+/fvR2ZmJqpWrYrExER07do14ulUCCGEEKcuRXr4mDt3LjIzM7Fw4ULMmjULhw4dwhVXXOG8frrvvvswdepUTJw4EXPnzsXmzZsjXiEJIYQQ4tSlSJ4PXmti7NixqFGjBnJycnDxxRdj586dePXVVzF+/PhAvx4zZgwaN26MhQsXRngcQitmre3CuRd4bratd7H2zRofa6e8Pet6NWrUcGKewx4G5/q/6667nJj1SM7Xz7oc63i2JtmnTx+n7Mknn3Rizkfy/PPPOzHn4mA4h4U9z5z1RtZdOW7atKkTs0eAj8U+Hfvc2LPB64iwB4B1WtY3uc25LjxebFgb5XVDWHd96KGHnJjXU2F/ip3TgP1D7JNhTwDXm306PK5Z77Y9Bfy2k30xvIYFa9+s+XMeAb5GbV8HnyfnO+DzZB8Ft8v777/vxIsWLXJi+7riewHvm68D9sawp4tj9m3YcP/wuOXvcp4ebhe+btj7YLfroEGDnDI+b/Z4cN6X3r17O/Hy5cudmK9vO3fPn/70J6eMc2vwWON24DVtZsyY4cRPP/20E19zzTXBZ+5Pvn75WOzLYN8Ur7dz8803O7F97+E29vnLON8Jqw38t4a/b1+TPC55rBUXv8rzceSmceTEc3JycOjQIWfxpkaNGiEtLS3ixiqEEEKIU5Pjnu1SUFCA/v3748ILLwxmXeTm5iIuLi7iSTY5OTliZcQjHDhwwPnvkp+6hBBCCHFycdxvPjIzM7Fy5crQaZCFYdiwYUhKSgp++LW5EEIIIU4ujuvNR1ZWFj744APMmzcPtWvXDn6fkpKCgwcPYseOHc7bj7y8vAhN8QiDBg3CgAEDgjg/Px916tRBXFxcsH4Fa8Tsy7D1MdbK2B/CawVwzMfi/fG6JbaHgPMZfPDBB058yy23ODHnDeD58PwWyJ4HDrh+BNbl2C8wdOhQJ+b1Uy6++GIn5vU4WO/mt1s2rIVyjokrrrjCiVnHZXjdCfst2oMPPnjMMiByTYtLLrnEiVlLZy2cPSC2L4f9IOybYX2Z9z1w4MDQuvCaGfZ6LpzfwjeOuQ+4Lqwpjx8/3om7dOkSfLZ1cQB45ZVXnHjOnDlOzOvjcDuxpyvMx8H+IR733CfMuHHjnJj/2WndurUT233C62dwLg32trDvgj1b3Ge8f/vew9cUj0tuQ74+2W/A+TP4Pvm///u/wec77rjDKeN1ZDjnhG98cJvzvSorKyv4vGbNGqeMJy/wGkavvvqqE/O6U3xdcH/b/hS+33L/8npX7KvhtbtGjhzpxOwR6dGjR/D5v//7v50y9mj4rnefxyMMvg9xPYuLIr35MMYgKysL7733HmbPnh1hSmvRogXKlSuH7Ozs4HerV6/Ghg0bIgbsEeLj41GpUiXnRwghhBAnL0V685GZmYnx48fj/fffR8WKFYP/MpOSklC+fHkkJSXhjjvuwIABA1ClShVUqlQJffr0QXp6epFmugghhBDi5KVIDx+jR48GELnE8pgxY3DrrbcC+GWaVGxsLLp27YoDBw6gQ4cOeOmll4qlskIIIYT47VOkhw/WYo9GQkICRo0ahVGjRh13pYBftNwjOhbr0ZxPwdY7bV0ciMzrwD4L1h953jjD61LY/hNe6+Gxxx5z4pycHCfm9uR8CayNc44DW/edNWuWU8YPfPfee68Ts47HEhrnXuC62vIYl7G+yDp8y5YtnZjbnNe84D775JNPgs/sVWED9KpVq5yY57/zmjWs41522WVObI9F1lVZd7/qqquc2F6LB4jMl8EaM+fysHV59j7wtpzHg68LXh+J+4C9FLa/gccG9y/7argNeRxz3fhcbE8AjzWuJ3th2JfB58nnwv4Fe5yzB4vXPOnWrZsTX3nllQiDz5OvG7suXMb3RG5Tzm/E/T1p0iQn5lQIdq4NziHB+S54rSb2XbDng/OGfPzxx05sr6/D/TF37lwnHjNmjBNfeOGFTsz3PR/2eGKflO/vH+cvYp8Nn/eIESOc2D4eH5s9Pzxu2afBHsuNGzc6MXuGbM8IWx/4+iwutLaLEEIIIaKKHj6EEEIIEVX08CGEEEKIqHLcGU5PNImJiUEuAs45wdqrrV+xl4E1YNZKWa/m/Ae8FkRYXgHWRvm7vtwLrLXxvHH2BNh5IJYtW+aUzZ4924lZGw1bNwQAvv32WyeuV6+eE9vzzNmDw3PQWdvmPmrYsKET81ovZ511lhPbOQy4Tdh3c/311zsx9x9r6f/85z+dmKeI2x4R7k/2k/hyKcycOdOJuV3OPPPMY9ad/SXsi+FcOAx7QlgDZv+CvWTC4sWLnTLOZ3DnnXc6caNGjZyYfVg8Ftm/YOv+vnw2PI45TwTnmGGfFefHsMc9exO4f9mrxO3C44P7kP1nttbO/cMeDs5vw+fBmj+vYcPjxV5/hT1afF87MhHhCJzv6IEHHnBi9qOwR8j2lPCx6tat68R2nikg0p/A9yLf2k32PZj9Juyz4r8VnAPKl8+E/YP2/YH7g+8N7Pngv3Pr1693Yj5PvrfwvcyG611c6M2HEEIIIaKKHj6EEEIIEVX08CGEEEKIqFJqPR8HDhwIdC/WnFh7s7Uy9knwtr71GFgzZM2RsbU49pOwf4B1dJ6bzXXjY3/99ddO/PbbbwefWdPlNSxYf2YPCOcFYQ2Z16mwYb2Q9WbWeNmnwbk12IfB7WB7ZXhfnBuFtdOlS5c6MeuuDH/fPlee988+GfYEsIbM+RH4WBzb7cIaL2u6vCaRb22Xe+65x4mnTZvmxPbY5jbkdSjatm3rxHzerF+zJ4h1evvc+LzY68LXL+vwrIWzl4nX+rA9BnzN8LGmTp3qxHzNcX4M9h+wN8IeT+wXYZ/VwoULnZjz13To0MGJb7rpJidmL4193nzf4fwU3C6XX365E/N5c93CPGK8ppRv3ZHXX3/didln5VsjxV6Xhu9bfL2zv4i9THwsew0zIPJeZfcJXzPs8eB7A4/FsPs1EDn27Ps9X4889ooLvfkQQgghRFTRw4cQQgghoooePoQQQggRVUqt5+Pw4cOBvst6dpiPgzVA9h+wDsfaGefQZ02Z/Qd2ToIZM2aE1pPnfbPXgT0DH374oROzPp2VlRV85nVCmMaNGzsx+0/YV7N582Yn5nazvTKsXbL3xc5HAkTmM2HPiC/evn178Jk1XdY+7W2ByJwxnOehd+/eTsyeEPvceN+sjXL/s/+A27hFixZOzHkg7HNlzZbhce3LOcPtyJqzrSHzmkWsjc+bN8+JeU0b3zUYtr4Kwz4pvn45zwev/cExt7lN9+7dnZh9F8w333zjxDw27dwpAPD99987sd0OnPtmxYoVTszXHOfOuOiii5yY76m8tpM9ltlvwGvWsA+D8zBxn/C9hsee3Qd8fbKXgfuLPWDcTpzfgvvfbnM+D4b9Q+yF4rVdHnroIScO81LwuOZrgGNuBx737PFiD5jtreHrsTBruh0PevMhhBBCiKiihw8hhBBCRBU9fAghhBAiqpRaz0etWrUCnYr1atbhw3LPs7bF+iRr55wvw7cuiT3nnde8ePXVV52Y9Uj2cLBmOGvWLCe+9957nbhNmzbBZ55zzm3CeSHOPvtsJ+a5+KNGjXJiXiPlvPPOCz6vWrXKKcvJyXFi1m1ZC+W5/Ly2B/sT7HVJWI/mNUtYV+U2fuedd5yY5/2/8sorTmxrraxV81jhtVtefPFFJ+ZcC3Z/ApF9ZsMaL+e34XbhPrJzxABA586dnZjXyFm5cmXw+eGHH3bKOH8B+6TY88PXHOfuYK3d9jPw9cv+EfZ42b4oIPI64WuM+9QeixMnTnTK7rjjDifmXBl33323E/N587jm3Dq2/4CvV64n7+vSSy91Yh6b3G7cB3Y7cxmvK8PrSHFOER6L3E6Mfd7cZjzO2bvC9xpeb4fvPWE5aNirwt4mjtkD1LNnTyfmNXL++Mc/OrHdzuz54HHv89mwx4PXwGE/mu3zYI8H/80rLvTmQwghhBBRRQ8fQgghhIgqpVZ2+fnnn4NXSyxP8BTVlJSU4DO/MuJXfPw6ilMH83S46tWrR9TLxk5DzK/0eSomv/Jj+LX7M888E7o/+9U7v6KvWbOmE/OrUm5Tfg3Xq1cvJ548ebIT26+jWQJo2LChEw8bNsyJu3bt6sRPP/10aN06derkxJ9++mnwmaf9+aaUsaTDdfHJcrbk9+WXX4Yei2UXfq0+adIkJ+Ypyzwt0JaUvvvuO6eMUzt/9dVXTszLCPBrfFtWASJfEbdr1y74fMEFFzhljz76qBNzevX27ds78X/+8x8n5utiyZIlx9zfJ5984pRlZ2eH1uXmm292YpaE+Brj1/hvvPFG8JmvCZZ/eezwvYSlDn6dzRKA/Vqfxy1POeVl7P/61786MfcJp0Dn87bvsTzln2U0nqY7f/58J+Z06nyefM+2pRWWPng6MssNfA9lqZvlaJZ87brxlFO+F7DEw33A2z/77LNOzFKZvT++j7GczGOH24nHC0/F5u/b9y6+n/umHB8vevMhhBBCiKiihw8hhBBCRBU9fAghhBAiqpRaz0f58uUD3Yu1NdazbHzTwljzY12O/Qa8PU9JtadyduzY0Snj6Yo8VZanZrFu17dvXye2p7cCrmbIOiqnauf06mHnAUTq1+wpsKdqshbObWjr5kDktC9OBcw6LdfVTkvOUyu5DVmXv+GGG5yYp1azV4Z1WRseO+np6U7M/c++mgYNGjgxp8jn9Ov2dFn2OvBYYS/MW2+95cTs2zjnnHOcmP0rTzzxRPCZvUecRvzGG2904vvuu8+J+TzZ28Jpq+1rkKfGTpgwwYm5T6ZPn+7EvtTR/H2eqmnD6bJtXwwQ6T/gsckxjz1ba+dxyl60q6++2onZX8BLzfN97bLLLnNi+37BfiAeG/xd9uXY6QiO9n2O7SnoPD2dp8L379/fidnbsmzZMifmKcd8Tdr3ZL6n8v2ap/0OHDjQidnzw3Xne6rt+eJteVyyJ4T/7vG+2cfB48f2kPE9U+nVhRBCCHFSoIcPIYQQQkQVPXwIIYQQIqrEmBMl6Bwn+fn5SEpKQosWLYJ58axPccxz1G14fjSnxOU8IL68Hjy/3oZ1NT42l/P8eC7nvACcGtrWFNkHwz4ZTsfMOSW4Xdgrwynu7XPjIcR5GzhVMC9rzxox5xHg/dueA16GnjV69o9wPhSOuX/DPALsVWGNmDVhbkPOf8DHmjNnjhPb+jXXk9Np87FY42efBV9DPHb/+c9/Bp+vu+46p2zKlClOzDlIeFxzzoHnnnvOif/+9787sd2HtvcEiFxanNmwYYMTc14HzmHAuVjsfCisu3PM+UsYHmvsJ2I/go3vXvD+++87MafP59xIffr0cWJOBW7fP9gPxuPcznUERKZT52Xt+Z7L/gR7++bNmztljz32mBNz/iG+Zngcs9eJ62Jfg+xNmzdvnhOPHTvWiXkJCr7GeGzZ+akAdzyxH4h9MXxe/HeKz4v7jK93+xrjv4EXXnihE3/++efwsXPnTu+1qTcfQgghhIgqRXr4GD16NM4991xUqlQJlSpVQnp6OqZNmxaU79+/H5mZmahatSoSExPRtWvXiKdmIYQQQpzaFOnho3bt2njqqaeQk5ODpUuX4vLLL8c111wTvG687777MHXqVEycOBFz587F5s2bI17RCiGEEOLU5ld7PqpUqYJnn30W3bp1Q/Xq1TF+/Hh069YNwC/rSzRu3BgLFiyI0NqOxRHPhxAnAtbd2evCWitjb88eDYbn+XPM3+e6sE8jzOPDa5awBsx+Av5+mG8KcP0J7Ddh7wJ7PBjuA153hnMYcLuElXHM/hNf/3O+BNvzwb4Jbgc+Dz72WWed5cSswzN2nhfW+NkvwMfiXCzsX2Bdn9vB/j57sNh/wG3KHi/2m3322WdOzGPVPpdWrVo5Zf/617+cmNdm+vjjj52YPSNNmjRxYn4zb7cD511ZuHChE7Ovpk6dOk7Mf/P4GuXr3+7jovgagch7C/9Z5zbm/dkeIs7bw/mrOIfU0Tihno/Dhw9jwoQJ2LNnD9LT05GTk4NDhw4hIyMj2KZRo0ZIS0vDggULjrmfAwcOID8/3/kRQgghxMlLkR8+vvjiCyQmJiI+Ph69e/fGe++9h7PPPhu5ubmIi4uLyDiZnJwc4fK1GTZsGJKSkoIffnoUQgghxMlFkR8+GjZsiOXLl2PRokW455570KtXLyftc1EZNGgQdu7cGfxwGmEhhBBCnFwUeW2XuLi4YE2KFi1aYMmSJRgxYgRuvPFGHDx4EDt27HDefuTl5UXokzbx8fERmqEQJwrWOjnmHAVCnAqw58O+J/P6J2HbHm179vBwDgrOl2Lvn70MvO8PP/zQidl/NH78eCdm/wn7Luzvs0eD7w2cS4e9TmvXrnVi9u0wtu+CvWfc5nzf4u25T9jOwOV23ifOu8LrzBQXvzrPR0FBAQ4cOIAWLVqgXLlyzoJXq1evxoYNGyIW3BJCCCHEqUuR3nwMGjQInTp1QlpaGnbt2oXx48djzpw5mDFjBpKSknDHHXdgwIABqFKlCipVqoQ+ffogPT290DNdhBBCCHHyU6SHj61bt6Jnz57YsmULkpKScO6552LGjBlo3749AOAvf/kLYmNj0bVrVxw4cAAdOnTASy+9VKQKlbJs70IIcdLD91075jKWPn5tzLKLPd2Zpz7zd3kKKcOySlg6dcA9V57qzt/lY/P23G4sCTH2sgPcJrwvPhbD7bRv377QcnspCN+2haEwf8dL3doumzZt0owXIYQQ4jfKxo0bI3LLMKXu4aOgoACbN2+GMQZpaWnYuHGjN1mJ+D/y8/NRp04dtVsRUJsdH2q3oqM2Oz7UbkWnJNrMGINdu3YhNTXVm4SxyLNdTjSxsbGoXbt24M49so6MKBpqt6KjNjs+1G5FR212fKjdik6026ywGcq1qq0QQgghoooePoQQQggRVUrtw0d8fDwGDx6sBGRFRO1WdNRmx4fareiozY4PtVvRKe1tVuoMp0IIIYQ4uSm1bz6EEEIIcXKihw8hhBBCRBU9fAghhBAiqujhQwghhBBRpdQ+fIwaNQr16tVDQkICWrdujcWLF5d0lUoNw4YNw/nnn4+KFSuiRo0a6NKlC1avXu1ss3//fmRmZqJq1apITExE165dkZeXV0I1Ln089dRTiImJQf/+/YPfqc2Ozvfff4+bb74ZVatWRfny5dG0aVMsXbo0KDfG4NFHH0XNmjVRvnx5ZGRkYM2aNSVY45Ll8OHDeOSRR1C/fn2UL18eZ555Jh5//PGI9VJO9TabN28err76aqSmpiImJgaTJ092ygvTRtu3b0ePHj1QqVIlVK5cGXfccUfE0vYnG2HtdujQIQwcOBBNmzZFhQoVkJqaip49e2Lz5s3OPkpFu5lSyIQJE0xcXJx57bXXzH/+8x9z1113mcqVK5u8vLySrlqpoEOHDmbMmDFm5cqVZvny5ebKK680aWlpZvfu3cE2vXv3NnXq1DHZ2dlm6dKl5oILLjBt2rQpwVqXHhYvXmzq1atnzj33XNOvX7/g92qzSLZv327q1q1rbr31VrNo0SLz7bffmhkzZpi1a9cG2zz11FMmKSnJTJ482axYscJ07tzZ1K9f3+zbt68Ea15yDB061FStWtV88MEHZt26dWbixIkmMTHRjBgxIthGbWbMhx9+aB5++GHz7rvvGgDmvffec8oL00YdO3Y05513nlm4cKH5+OOPTYMGDUz37t2jfCbRJazdduzYYTIyMszbb79tvvrqK7NgwQLTqlUr06JFC2cfpaHdSuXDR6tWrUxmZmYQHz582KSmppphw4aVYK1KL1u3bjUAzNy5c40xvwzAcuXKmYkTJwbbfPnllwaAWbBgQUlVs1Swa9cuc9ZZZ5lZs2aZSy65JHj4UJsdnYEDB5q2bdses7ygoMCkpKSYZ599Nvjdjh07THx8vHnrrbeiUcVSx1VXXWVuv/1253fXXXed6dGjhzFGbXY0+I9oYdpo1apVBoBZsmRJsM20adNMTEyM+f7776NW95LkaA9tzOLFiw0As379emNM6Wm3Uie7HDx4EDk5OcjIyAh+Fxsbi4yMDCxYsKAEa1Z62blzJwCgSpUqAICcnBwcOnTIacNGjRohLS3tlG/DzMxMXHXVVU7bAGqzYzFlyhS0bNkS119/PWrUqIHmzZvjlVdeCcrXrVuH3Nxcp92SkpLQunXrU7bd2rRpg+zsbHz99dcAgBUrVmD+/Pno1KkTALVZYShMGy1YsACVK1dGy5Ytg20yMjIQGxuLRYsWRb3OpZWdO3ciJiYGlStXBlB62q3ULSy3bds2HD58GMnJyc7vk5OT8dVXX5VQrUovBQUF6N+/Py688EI0adIEAJCbm4u4uLhgsB0hOTkZubm5JVDL0sGECRPw2WefYcmSJRFlarOj8+2332L06NEYMGAAHnroISxZsgR9+/ZFXFwcevXqFbTN0a7XU7XdHnzwQeTn56NRo0YoU6YMDh8+jKFDh6JHjx4AoDYrBIVpo9zcXNSoUcMpL1u2LKpUqaJ2/P/s378fAwcORPfu3YPF5UpLu5W6hw9RNDIzM7Fy5UrMnz+/pKtSqtm4cSP69euHWbNmISEhoaSr85uhoKAALVu2xJNPPgkAaN68OVauXImXX34ZvXr1KuHalU7eeecdjBs3DuPHj8c555yD5cuXo3///khNTVWbiahx6NAh3HDDDTDGYPTo0SVdnQhKnexSrVo1lClTJmKWQV5eHlJSUkqoVqWTrKwsfPDBB/joo49Qu3bt4PcpKSk4ePAgduzY4Wx/KrdhTk4Otm7dit/97ncoW7YsypYti7lz52LkyJEoW7YskpOT1WZHoWbNmjj77LOd3zVu3BgbNmwAgKBtdL3+Hw888AAefPBB3HTTTWjatCluueUW3HfffRg2bBgAtVlhKEwbpaSkYOvWrU75zz//jO3bt5/y7XjkwWP9+vWYNWtW8NYDKD3tVuoePuLi4tCiRQtkZ2cHvysoKEB2djbS09NLsGalB2MMsrKy8N5772H27NmoX7++U96iRQuUK1fOacPVq1djw4YNp2wbtmvXDl988QWWL18e/LRs2RI9evQIPqvNIrnwwgsjpnF//fXXqFu3LgCgfv36SElJcdotPz8fixYtOmXbbe/evYiNdW+tZcqUQUFBAQC1WWEoTBulp6djx44dyMnJCbaZPXs2CgoK0Lp166jXubRw5MFjzZo1+Pe//42qVas65aWm3aJmbS0CEyZMMPHx8Wbs2LFm1apV5u677zaVK1c2ubm5JV21UsE999xjkpKSzJw5c8yWLVuCn7179wbb9O7d26SlpZnZs2ebpUuXmvT0dJOenl6CtS592LNdjFGbHY3FixebsmXLmqFDh5o1a9aYcePGmdNOO828+eabwTZPPfWUqVy5snn//ffN559/bq655ppTbtqoTa9evUytWrWCqbbvvvuuqVatmvnDH/4QbKM2+2Xm2bJly8yyZcsMAPP888+bZcuWBbMyCtNGHTt2NM2bNzeLFi0y8+fPN2edddZJP9U2rN0OHjxoOnfubGrXrm2WL1/u/H04cOBAsI/S0G6l8uHDGGNeeOEFk5aWZuLi4kyrVq3MwoULS7pKpQYAR/0ZM2ZMsM2+ffvMvffea04//XRz2mmnmWuvvdZs2bKl5CpdCuGHD7XZ0Zk6dapp0qSJiY+PN40aNTJ/+9vfnPKCggLzyCOPmOTkZBMfH2/atWtnVq9eXUK1LXny8/NNv379TFpamklISDBnnHGGefjhh52bv9rMmI8++uio97FevXoZYwrXRj/++KPp3r27SUxMNJUqVTK33Xab2bVrVwmcTfQIa7d169Yd8+/DRx99FOyjNLRbjDFW2j0hhBBCiBNMqfN8CCGEEOLkRg8fQgghhIgqevgQQgghRFTRw4cQQgghoooePoQQQggRVfTwIYQQQoiooocPIYQQQkQVPXwIIYQQIqro4UMIIYQQUUUPH0IIIYSIKnr4EEIIIURU0cOHEEIIIaLK/wN7dRHre4JL+QAAAABJRU5ErkJggg==\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1, Filtered data size: 1083, Sample labels: ['MdI8', '0tcL2', 'eyOxJ']\nTrain size: 866, Val size: 217\nToken distribution (Batch 0): {4: 1, 1: 7, 10: 2}, Pred length: 10\nToken distribution (Batch 1): {1: 7, 32: 1, 42: 2}, Pred length: 10\nToken distribution (Batch 2): {1: 4, 10: 4, 32: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 3): {4: 1, 10: 1, 1: 8}, Pred length: 10\nToken distribution (Batch 4): {1: 5, 10: 2, 22: 1, 47: 2}, Pred length: 10\nToken distribution (Batch 5): {32: 1, 1: 7, 11: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 6): {1: 9, 11: 1}, Pred length: 10\nToken distribution (Batch 7): {35: 1, 19: 1, 1: 5, 10: 1, 32: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 8): {1: 6, 10: 1, 50: 1}, Pred length: 8\nToken distribution (Batch 9): {34: 1, 1: 4, 10: 1, 43: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 10): {1: 6, 4: 1, 35: 1, 32: 2}, Pred length: 10\nToken distribution (Batch 11): {1: 8, 47: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 12): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 13): {1: 4, 34: 1, 10: 2, 35: 1, 32: 1, 6: 1}, Pred length: 10\nToken distribution (Batch 14): {1: 3, 48: 1, 10: 2, 34: 1, 43: 1}, Pred length: 8\nToken distribution (Batch 15): {1: 7, 4: 1, 6: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 16): {22: 1, 1: 4, 10: 2, 4: 1, 34: 1, 11: 1}, Pred length: 10\nToken distribution (Batch 17): {1: 6, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 18): {1: 7, 34: 2, 47: 1}, Pred length: 10\nToken distribution (Batch 19): {34: 1, 1: 5, 10: 2, 32: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 6, 11: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 21): {22: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 22): {10: 4, 4: 1, 56: 1, 1: 3, 27: 1}, Pred length: 10\nToken distribution (Batch 23): {1: 8, 10: 1, 42: 1}, Pred length: 10\nToken distribution (Batch 24): {1: 8, 4: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 25): {10: 2, 42: 1, 1: 6, 27: 1}, Pred length: 10\nToken distribution (Batch 26): {1: 6, 10: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 27): {1: 5, 10: 3}, Pred length: 8\nToken distribution (Batch 28): {1: 4, 47: 1, 19: 1, 11: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 29): {1: 7, 47: 1, 43: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 4, 34: 3, 10: 2, 11: 1}, Pred length: 10\nToken distribution (Batch 31): {1: 6, 32: 1, 10: 2, 42: 1}, Pred length: 10\nBatch 0, Gradient norm: 15.6032\nEpoch 1, Batch 0/28, Loss: 28.7089\nAvg Blank Probability: 0.0147\nSample predictions: ['dajaj', 'aFPaPa', 'ajFjada']\nGround Truth (first 3): ['-OuOj', 'wb8Ww', 'iaesP']\nRaw outputs (first 3): [[ 4  1  1  4  1 32  1 35  1 34  1  1  1  1  1  1 22  1  1 34  1 22 10  1\n   1 10  1  1  1  1  1  1]\n [ 1  1  1 10 10  1  1 19  1  1  1  1  1 34 48  1  1  1  1  1  1  1  4  1\n   1 42  1  1  1 47 34  1]\n [ 1  1 10  1  1  1  1  1  1  1  1 47  1 10 10  1  1 10  1  1 11  1 56  1\n   4 10  1 10 47  1  1  1]]\nInput length: 32, Label lengths: [5, 5, 5]\nToken distribution (Batch 0): {1: 6, 11: 1, 32: 1, 6: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 1): {1: 8, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 2): {11: 1, 1: 6, 10: 2, 5: 1}, Pred length: 10\nToken distribution (Batch 3): {1: 10}, Pred length: 10\nToken distribution (Batch 4): {1: 8, 32: 1, 50: 1}, Pred length: 10\nToken distribution (Batch 5): {10: 2, 32: 2, 1: 3, 34: 1}, Pred length: 8\nToken distribution (Batch 6): {10: 4, 1: 2, 32: 1, 42: 1}, Pred length: 8\nToken distribution (Batch 7): {1: 5, 12: 1, 32: 2}, Pred length: 8\nToken distribution (Batch 8): {1: 6, 19: 1, 27: 1}, Pred length: 8\nToken distribution (Batch 9): {63: 1, 1: 6, 47: 1}, Pred length: 8\nToken distribution (Batch 10): {1: 7, 11: 1}, Pred length: 8\nToken distribution (Batch 11): {1: 7, 6: 1}, Pred length: 8\nToken distribution (Batch 12): {11: 1, 1: 7, 34: 2}, Pred length: 10\nToken distribution (Batch 13): {1: 5, 32: 1, 47: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 14): {1: 7, 32: 1, 47: 1, 19: 1}, Pred length: 10\nToken distribution (Batch 15): {1: 10}, Pred length: 10\nToken distribution (Batch 16): {1: 6, 34: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 17): {34: 1, 1: 3, 6: 2, 35: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 18): {32: 2, 1: 5, 5: 1, 22: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 19): {56: 1, 1: 6, 22: 1}, Pred length: 8\nToken distribution (Batch 20): {1: 4, 22: 1, 34: 1, 32: 1, 47: 2, 4: 1}, Pred length: 10\nToken distribution (Batch 21): {1: 5, 10: 3, 22: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 22): {1: 8, 11: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 23): {1: 7, 32: 1, 27: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 24): {1: 5, 10: 3, 34: 1, 11: 1}, Pred length: 10\nToken distribution (Batch 25): {1: 4, 47: 2, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 26): {1: 5, 47: 3, 34: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 27): {1: 6, 4: 2, 22: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 28): {10: 3, 1: 6, 22: 1}, Pred length: 10\nToken distribution (Batch 29): {10: 2, 1: 7, 56: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 6, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 31): {1: 4, 22: 1, 35: 1, 10: 1, 32: 1}, Pred length: 8\nBatch 10, Gradient norm: 17.5333\nEpoch 1, Batch 10/28, Loss: 29.8283\nAvg Blank Probability: 0.0147\nSample predictions: ['akFaf3a', 'ajaF', 'kajae']\nGround Truth (first 3): ['e6df2', 'PBDnU', 'yAKoI']\nRaw outputs (first 3): [[ 1  1 11  1  1 10 10  1  1 63  1  1 11  1  1  1  1 34 32 56  1  1  1  1\n   1  1  1  1 10 10  1  1]\n [11  1  1  1  1 32 10 12  1  1  1  6  1  1  1  1 34  1  1  1 22 10  1  1\n   1  1  1  4 10  1 10 22]\n [32  1  1  1  1 10  1 32  1 47  1  1  1  1 32  1  1  1  1  1  1  1  1  1\n   1  1 47  1  1  1  1 35]]\nInput length: 32, Label lengths: [5, 5, 5]\nToken distribution (Batch 0): {4: 1, 1: 6, 32: 1}, Pred length: 8\nToken distribution (Batch 1): {1: 6, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 2): {1: 7, 47: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 7, 6: 1, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 4): {1: 7, 10: 2, 32: 1}, Pred length: 10\nToken distribution (Batch 5): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 6): {4: 1, 1: 5, 10: 2, 47: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 7): {10: 2, 32: 2, 1: 3, 34: 1}, Pred length: 8\nToken distribution (Batch 8): {6: 1, 1: 6, 10: 1}, Pred length: 8\nToken distribution (Batch 9): {1: 5, 4: 1, 32: 2, 10: 2}, Pred length: 10\nToken distribution (Batch 10): {1: 6, 19: 1, 34: 2, 10: 1}, Pred length: 10\nToken distribution (Batch 11): {1: 8}, Pred length: 8\nToken distribution (Batch 12): {6: 1, 1: 5, 10: 2, 34: 2}, Pred length: 10\nToken distribution (Batch 13): {11: 2, 1: 5, 10: 1}, Pred length: 8\nToken distribution (Batch 14): {1: 8, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 15): {1: 7, 56: 2, 32: 1}, Pred length: 10\nToken distribution (Batch 16): {1: 7, 22: 1}, Pred length: 8\nToken distribution (Batch 17): {1: 5, 10: 1, 32: 1, 50: 1}, Pred length: 8\nToken distribution (Batch 18): {1: 4, 10: 3, 27: 1}, Pred length: 8\nToken distribution (Batch 19): {1: 8, 47: 1, 43: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 6, 32: 2}, Pred length: 8\nToken distribution (Batch 21): {10: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 22): {42: 1, 1: 6, 32: 1, 10: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 23): {1: 7, 56: 1}, Pred length: 8\nToken distribution (Batch 24): {1: 5, 4: 1, 32: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 25): {10: 2, 1: 5, 34: 1}, Pred length: 8\nToken distribution (Batch 26): {10: 1, 1: 6, 42: 1}, Pred length: 8\nToken distribution (Batch 27): {1: 7, 32: 3}, Pred length: 10\nToken distribution (Batch 28): {1: 8}, Pred length: 8\nToken distribution (Batch 29): {10: 3, 1: 2, 34: 1, 22: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 30): {1: 7, 10: 1, 11: 1, 35: 1}, Pred length: 10\nToken distribution (Batch 31): {1: 8, 10: 1, 32: 1}, Pred length: 10\nBatch 20, Gradient norm: 17.6862\nEpoch 1, Batch 20/28, Loss: 30.5458\nAvg Blank Probability: 0.0147\nSample predictions: ['daFa', 'ajF', 'aU']\nGround Truth (first 3): ['EEXE', 'k2OY', '20RQ']\nRaw outputs (first 3): [[ 4  1  1  1  1  1  4 10  6  1  1  1  6 11  1  1  1  1  1  1  1 10 42  1\n   1 10 10  1  1 10  1  1]\n [ 1  1  1  1  1  1  1 10  1  1  1  1  1  1  1 56  1  1  1  1  1  1  1  1\n   1  1  1  1  1 10  1 10]\n [ 1  1  1  1 10  1 10 32  1  4 19  1  1  1  1  1 22 10 10  1  1  1  1  1\n   1 34  1  1  1  1 10  1]]\nInput length: 32, Label lengths: [4, 4, 4]\nEpoch 1/20, Loss: 30.1757\nToken distribution (Batch 0): {1: 8}, Pred length: 8\nToken distribution (Batch 1): {1: 10}, Pred length: 10\nToken distribution (Batch 2): {1: 10}, Pred length: 10\nToken distribution (Batch 3): {1: 8}, Pred length: 8\nToken distribution (Batch 4): {1: 8}, Pred length: 8\nToken distribution (Batch 5): {1: 8}, Pred length: 8\nToken distribution (Batch 6): {1: 8}, Pred length: 8\nToken distribution (Batch 7): {1: 10}, Pred length: 10\nToken distribution (Batch 8): {1: 8}, Pred length: 8\nToken distribution (Batch 9): {1: 8}, Pred length: 8\nToken distribution (Batch 10): {1: 8}, Pred length: 8\nToken distribution (Batch 11): {1: 8}, Pred length: 8\nToken distribution (Batch 12): {1: 10}, Pred length: 10\nToken distribution (Batch 13): {1: 8}, Pred length: 8\nToken distribution (Batch 14): {1: 8}, Pred length: 8\nToken distribution (Batch 15): {1: 8}, Pred length: 8\nToken distribution (Batch 16): {1: 10}, Pred length: 10\nToken distribution (Batch 17): {1: 10}, Pred length: 10\nToken distribution (Batch 18): {1: 10}, Pred length: 10\nToken distribution (Batch 19): {1: 10}, Pred length: 10\nToken distribution (Batch 20): {1: 10}, Pred length: 10\nToken distribution (Batch 21): {1: 10}, Pred length: 10\nToken distribution (Batch 22): {1: 8}, Pred length: 8\nToken distribution (Batch 23): {1: 10}, Pred length: 10\nToken distribution (Batch 24): {1: 10}, Pred length: 10\nValidation Loss: 30.1823\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['tdjc', 'ehjAC', 'zYs28', '*Ill', 'Mg5e']\nCurrent Learning Rate: 2.2852411763430247e-08\nEpoch 2, Filtered data size: 1083, Sample labels: ['MdI8', '0tcL2', 'eyOxJ']\nTrain size: 866, Val size: 217\nToken distribution (Batch 0): {1: 7, 32: 1, 34: 2}, Pred length: 10\nToken distribution (Batch 1): {12: 1, 10: 2, 1: 4, 34: 3}, Pred length: 10\nToken distribution (Batch 2): {1: 3, 34: 1, 11: 1, 6: 1, 10: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 8, 25: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 4): {1: 7, 4: 1, 22: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 5): {1: 7, 10: 2, 12: 1}, Pred length: 10\nToken distribution (Batch 6): {1: 8, 34: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 7): {1: 6, 32: 2}, Pred length: 8\nToken distribution (Batch 8): {1: 4, 11: 1, 47: 1, 10: 3, 22: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 5, 47: 1, 34: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 10): {42: 1, 1: 4, 10: 2, 35: 1}, Pred length: 8\nToken distribution (Batch 11): {10: 2, 1: 5, 5: 1}, Pred length: 8\nToken distribution (Batch 12): {1: 9, 11: 1}, Pred length: 10\nToken distribution (Batch 13): {10: 2, 1: 3, 6: 1, 27: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 14): {10: 1, 1: 6, 32: 1, 4: 2}, Pred length: 10\nToken distribution (Batch 15): {1: 10}, Pred length: 10\nToken distribution (Batch 16): {1: 6, 19: 2}, Pred length: 8\nToken distribution (Batch 17): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 18): {1: 6, 10: 2, 32: 2}, Pred length: 10\nToken distribution (Batch 19): {1: 7, 11: 1}, Pred length: 8\nToken distribution (Batch 20): {1: 7, 11: 1, 56: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 21): {63: 1, 1: 7, 10: 2}, Pred length: 10\nToken distribution (Batch 22): {1: 8}, Pred length: 8\nToken distribution (Batch 23): {1: 6, 19: 1, 22: 1, 35: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 24): {10: 3, 1: 7}, Pred length: 10\nToken distribution (Batch 25): {1: 8, 27: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 26): {1: 8, 10: 1, 42: 1}, Pred length: 10\nToken distribution (Batch 27): {10: 1, 1: 6, 4: 1}, Pred length: 8\nToken distribution (Batch 28): {1: 7, 10: 2, 32: 1}, Pred length: 10\nToken distribution (Batch 29): {4: 1, 47: 1, 1: 6, 22: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 7, 10: 1, 34: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 31): {1: 3, 10: 1, 19: 1, 32: 3}, Pred length: 8\nBatch 0, Gradient norm: 17.7114\nEpoch 2, Batch 0/28, Loss: 29.3360\nAvg Blank Probability: 0.0147\nSample predictions: ['aFHaH', 'ljaHaH', 'aHkfjd']\nGround Truth (first 3): ['xQdQf', 'hLrX3', 'TZJ7']\nRaw outputs (first 3): [[ 1 12  1  1  1  1  1  1  1  1 42 10  1 10 10  1  1  1  1  1  1 63  1  1\n  10  1  1 10  1  4  1  1]\n [ 1 10  1  1  1 10  1  1 11 47  1  1 11  1  1  1  1  1  1 11  1  1  1  1\n   1  1  1  1  1 47  1 10]\n [ 1 10  1  1  1  1  1 32 47  1  1  1  1  6  1  1  1  1  1  1  1  1  1  1\n  10  1  1  1  1  1  1  1]]\nInput length: 32, Label lengths: [5, 5, 4]\nToken distribution (Batch 0): {34: 1, 32: 1, 1: 5, 10: 1}, Pred length: 8\nToken distribution (Batch 1): {1: 7, 27: 1, 22: 1, 12: 1}, Pred length: 10\nToken distribution (Batch 2): {6: 1, 1: 8, 22: 1}, Pred length: 10\nToken distribution (Batch 3): {10: 2, 11: 1, 1: 4, 56: 1}, Pred length: 8\nToken distribution (Batch 4): {1: 6, 34: 2}, Pred length: 8\nToken distribution (Batch 5): {1: 3, 35: 1, 11: 1, 10: 1, 4: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 6): {1: 6, 47: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 7): {32: 1, 35: 1, 1: 6, 10: 2}, Pred length: 10\nToken distribution (Batch 8): {1: 5, 56: 2, 10: 1, 22: 1, 19: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 6, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 10): {34: 1, 1: 9}, Pred length: 10\nToken distribution (Batch 11): {12: 1, 1: 6, 48: 1, 10: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 12): {1: 6, 34: 1, 56: 1, 32: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 13): {1: 7, 10: 2, 11: 1}, Pred length: 10\nToken distribution (Batch 14): {10: 3, 34: 1, 42: 1, 32: 1, 1: 4}, Pred length: 10\nToken distribution (Batch 15): {1: 7, 32: 1, 22: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 16): {12: 1, 1: 6, 11: 1}, Pred length: 8\nToken distribution (Batch 17): {11: 1, 1: 6, 10: 1}, Pred length: 8\nToken distribution (Batch 18): {1: 7, 5: 1, 10: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 6, 11: 1, 47: 1, 34: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 5, 22: 1, 10: 2}, Pred length: 8\nToken distribution (Batch 21): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 22): {1: 8}, Pred length: 8\nToken distribution (Batch 23): {1: 8}, Pred length: 8\nToken distribution (Batch 24): {1: 5, 4: 2, 32: 1}, Pred length: 8\nToken distribution (Batch 25): {1: 5, 34: 1, 10: 1, 4: 1, 6: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 26): {1: 5, 56: 1, 24: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 27): {56: 1, 1: 3, 27: 1, 10: 1, 34: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 28): {1: 9, 32: 1}, Pred length: 10\nToken distribution (Batch 29): {1: 8, 32: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 7, 34: 1, 10: 1, 6: 1}, Pred length: 10\nToken distribution (Batch 31): {10: 1, 1: 7}, Pred length: 8\nBatch 10, Gradient norm: 18.1550\nEpoch 2, Batch 10/28, Loss: 30.1554\nAvg Blank Probability: 0.0147\nSample predictions: ['HFaja', 'aAval', 'fav']\nGround Truth (first 3): ['d0wH', '4s670', '4saPp']\nRaw outputs (first 3): [[34  1  6 10  1  1  1 32  1  1 34 12  1  1 10  1 12 11  1  1  1  1  1  1\n   1  1  1 56  1  1  1 10]\n [32  1  1 10  1 35  1 35  1  1  1  1  1 10 34  1  1  1  1  1  1 10  1  1\n   1 34  1  1  1  1  1  1]\n [ 1  1  1 11  1 11 47  1 56  1  1  1  1  1 42  1 11  1  5  1  1  1  1  1\n   1 10  1  1  1  1  1  1]]\nInput length: 32, Label lengths: [4, 5, 5]\nToken distribution (Batch 0): {1: 7, 11: 1, 47: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 1): {1: 7, 6: 1}, Pred length: 8\nToken distribution (Batch 2): {1: 6, 10: 2, 11: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 3): {1: 6, 12: 1, 10: 1, 32: 2}, Pred length: 10\nToken distribution (Batch 4): {11: 1, 1: 4, 10: 3, 32: 2}, Pred length: 10\nToken distribution (Batch 5): {12: 1, 1: 3, 32: 1, 10: 1, 6: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 6): {1: 7, 34: 2, 10: 1}, Pred length: 10\nToken distribution (Batch 7): {11: 1, 1: 6, 35: 1, 47: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 8): {34: 1, 10: 1, 1: 7, 19: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 5, 22: 1, 10: 2, 24: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 10): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 11): {1: 8, 27: 1, 5: 1}, Pred length: 10\nToken distribution (Batch 12): {1: 4, 35: 1, 10: 1, 11: 1, 42: 1, 22: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 13): {63: 1, 1: 5, 34: 1, 35: 1}, Pred length: 8\nToken distribution (Batch 14): {6: 1, 1: 5, 34: 1, 11: 1}, Pred length: 8\nToken distribution (Batch 15): {10: 1, 1: 5, 34: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 16): {11: 1, 1: 6, 10: 1}, Pred length: 8\nToken distribution (Batch 17): {6: 2, 1: 5, 43: 1}, Pred length: 8\nToken distribution (Batch 18): {56: 1, 1: 5, 47: 1, 19: 1, 10: 2}, Pred length: 10\nToken distribution (Batch 19): {1: 6, 32: 2, 10: 2}, Pred length: 10\nToken distribution (Batch 20): {1: 7, 34: 1, 32: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 21): {56: 2, 10: 2, 32: 1, 6: 1, 34: 1, 1: 1}, Pred length: 8\nToken distribution (Batch 22): {1: 8, 4: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 23): {1: 4, 32: 1, 10: 2, 11: 1}, Pred length: 8\nToken distribution (Batch 24): {1: 5, 32: 2, 55: 1}, Pred length: 8\nToken distribution (Batch 25): {4: 1, 1: 5, 27: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 26): {4: 1, 1: 8, 43: 1}, Pred length: 10\nToken distribution (Batch 27): {1: 7, 32: 1, 11: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 28): {1: 5, 32: 1, 19: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 29): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 30): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 31): {1: 6, 19: 1, 10: 3}, Pred length: 10\nBatch 20, Gradient norm: 16.8452\nEpoch 2, Batch 20/28, Loss: 29.9265\nAvg Blank Probability: 0.0147\nSample predictions: ['akaUaja', 'afa', 'ajkjava']\nGround Truth (first 3): ['f5Ins', 'Hhye', 'aeRKp']\nRaw outputs (first 3): [[ 1  1  1  1 11 12  1 11 34  1  1  1  1 63  6 10 11  6 56  1  1 56  1  1\n   1  4  4  1  1  1  1  1]\n [ 1  1 10 12  1  1 34  1 10  1  1  1  1  1  1  1  1  1  1  1  1 10  1  1\n  32  1  1  1  1  1  1 19]\n [ 1  1 11  1 10  1  1  1  1 22  1 27 35 34 34  1  1 43  1 32  1 56  1 32\n   1 27  1  1 32  1  1 10]]\nInput length: 32, Label lengths: [5, 4, 5]\nEpoch 2/20, Loss: 30.1145\nToken distribution (Batch 0): {1: 10}, Pred length: 10\nToken distribution (Batch 1): {1: 8}, Pred length: 8\nToken distribution (Batch 2): {1: 8}, Pred length: 8\nToken distribution (Batch 3): {1: 10}, Pred length: 10\nToken distribution (Batch 4): {1: 10}, Pred length: 10\nToken distribution (Batch 5): {1: 8}, Pred length: 8\nToken distribution (Batch 6): {1: 10}, Pred length: 10\nToken distribution (Batch 7): {1: 8}, Pred length: 8\nToken distribution (Batch 8): {1: 8}, Pred length: 8\nToken distribution (Batch 9): {1: 8}, Pred length: 8\nToken distribution (Batch 10): {1: 10}, Pred length: 10\nToken distribution (Batch 11): {1: 8}, Pred length: 8\nToken distribution (Batch 12): {1: 10}, Pred length: 10\nToken distribution (Batch 13): {1: 8}, Pred length: 8\nToken distribution (Batch 14): {1: 10}, Pred length: 10\nToken distribution (Batch 15): {1: 10}, Pred length: 10\nToken distribution (Batch 16): {1: 10}, Pred length: 10\nToken distribution (Batch 17): {1: 10}, Pred length: 10\nToken distribution (Batch 18): {1: 10}, Pred length: 10\nToken distribution (Batch 19): {1: 10}, Pred length: 10\nToken distribution (Batch 20): {1: 8}, Pred length: 8\nToken distribution (Batch 21): {1: 8}, Pred length: 8\nToken distribution (Batch 22): {1: 10}, Pred length: 10\nToken distribution (Batch 23): {1: 8}, Pred length: 8\nToken distribution (Batch 24): {1: 10}, Pred length: 10\nValidation Loss: 29.9655\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['-X3*-', 'pf6j', 'S6bq', '77iEA', 'XxVx9']\nCurrent Learning Rate: 5.1410133651488365e-08\nEpoch 3, Filtered data size: 1083, Sample labels: ['MdI8', '0tcL2', 'eyOxJ']\nTrain size: 866, Val size: 217\nToken distribution (Batch 0): {34: 2, 1: 5, 10: 1}, Pred length: 8\nToken distribution (Batch 1): {10: 1, 1: 6, 43: 1}, Pred length: 8\nToken distribution (Batch 2): {1: 9, 32: 1}, Pred length: 10\nToken distribution (Batch 3): {4: 1, 1: 7, 11: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 4): {1: 4, 4: 2, 34: 2, 22: 1, 12: 1}, Pred length: 10\nToken distribution (Batch 5): {1: 6, 56: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 6): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 7): {1: 5, 10: 3}, Pred length: 8\nToken distribution (Batch 8): {1: 4, 4: 1, 56: 1, 11: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 9): {1: 4, 47: 1, 5: 1, 35: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 10): {1: 7, 27: 1, 10: 2}, Pred length: 10\nToken distribution (Batch 11): {1: 7, 10: 2, 47: 1}, Pred length: 10\nToken distribution (Batch 12): {6: 1, 1: 6, 32: 1, 4: 2}, Pred length: 10\nToken distribution (Batch 13): {1: 5, 10: 2, 11: 1}, Pred length: 8\nToken distribution (Batch 14): {1: 7, 47: 1}, Pred length: 8\nToken distribution (Batch 15): {10: 1, 34: 2, 1: 6, 4: 1}, Pred length: 10\nToken distribution (Batch 16): {1: 9, 12: 1}, Pred length: 10\nToken distribution (Batch 17): {10: 1, 1: 6, 6: 1}, Pred length: 8\nToken distribution (Batch 18): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 19): {1: 4, 47: 1, 10: 3, 34: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 8, 22: 1, 48: 1}, Pred length: 10\nToken distribution (Batch 21): {1: 8, 4: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 22): {1: 5, 22: 1, 32: 1, 35: 1}, Pred length: 8\nToken distribution (Batch 23): {1: 6, 11: 1, 56: 1, 32: 1, 19: 1}, Pred length: 10\nToken distribution (Batch 24): {34: 1, 1: 6, 48: 1}, Pred length: 8\nToken distribution (Batch 25): {1: 7, 34: 1}, Pred length: 8\nToken distribution (Batch 26): {1: 8, 43: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 27): {1: 7, 4: 1}, Pred length: 8\nToken distribution (Batch 28): {10: 3, 47: 2, 1: 5}, Pred length: 10\nToken distribution (Batch 29): {1: 6, 6: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 30): {34: 1, 1: 4, 35: 1, 32: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 31): {1: 6, 56: 1, 4: 2, 6: 1}, Pred length: 10\nBatch 0, Gradient norm: 16.6162\nEpoch 3, Batch 0/28, Loss: 30.2782\nAvg Blank Probability: 0.0146\nSample predictions: ['HajaH', 'jaQa', 'aFa']\nGround Truth (first 3): ['b21F', 'RjHo', 'f0mrF']\nRaw outputs (first 3): [[34 10  1  4  1  1  1  1  1  1  1  1  6  1  1 10  1 10  1  1  1  1  1  1\n  34  1  1  1 10  1 34  1]\n [ 1  1 32  1  4  1  1  1  4 47  1 10  1  1 47 34  1  1  1 47  1  1  1 11\n   1  1  1  4 47  6  1  1]\n [10  1  1 11  4  1  1  1 56  1  1 47  1  1  1  1  1  1  1 10  1  1  1  1\n   1  1  1  1 10  1 35 56]]\nInput length: 32, Label lengths: [4, 4, 5]\nToken distribution (Batch 0): {1: 7, 10: 2, 22: 1}, Pred length: 10\nToken distribution (Batch 1): {1: 6, 10: 2}, Pred length: 8\nToken distribution (Batch 2): {1: 6, 10: 1, 5: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 3, 6: 1, 4: 1, 10: 2, 32: 1}, Pred length: 8\nToken distribution (Batch 4): {1: 7, 22: 1, 56: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 5): {4: 1, 1: 3, 10: 2, 11: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 6): {1: 5, 10: 1, 11: 2}, Pred length: 8\nToken distribution (Batch 7): {10: 3, 1: 3, 34: 1, 5: 2, 6: 1}, Pred length: 10\nToken distribution (Batch 8): {10: 1, 1: 7, 19: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 5, 32: 2, 34: 1, 19: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 10): {1: 6, 10: 3, 32: 1}, Pred length: 10\nToken distribution (Batch 11): {1: 8, 34: 2}, Pred length: 10\nToken distribution (Batch 12): {1: 7, 34: 1, 4: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 13): {1: 5, 10: 1, 22: 1, 42: 1}, Pred length: 8\nToken distribution (Batch 14): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 15): {1: 6, 42: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 16): {12: 1, 1: 8, 32: 1}, Pred length: 10\nToken distribution (Batch 17): {1: 5, 34: 1, 10: 2, 11: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 18): {1: 5, 32: 4, 27: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 6, 10: 2, 6: 1, 19: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 4, 11: 1, 19: 1, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 21): {12: 1, 10: 3, 5: 1, 1: 3, 11: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 22): {1: 7, 47: 1, 32: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 23): {1: 6, 47: 2}, Pred length: 8\nToken distribution (Batch 24): {10: 1, 1: 7, 11: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 25): {10: 1, 1: 6, 5: 1}, Pred length: 8\nToken distribution (Batch 26): {10: 1, 1: 5, 34: 2}, Pred length: 8\nToken distribution (Batch 27): {1: 5, 10: 1, 50: 1, 6: 1, 27: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 28): {6: 1, 1: 6, 56: 1}, Pred length: 8\nToken distribution (Batch 29): {1: 5, 10: 3}, Pred length: 8\nToken distribution (Batch 30): {10: 1, 1: 7, 22: 1, 6: 1}, Pred length: 10\nToken distribution (Batch 31): {34: 2, 10: 2, 1: 5, 47: 1}, Pred length: 10\nBatch 10, Gradient norm: 16.8872\nEpoch 3, Batch 10/28, Loss: 29.7646\nAvg Blank Probability: 0.0147\nSample predictions: ['ajvaja', 'ajaja', 'aje']\nGround Truth (first 3): ['f0CXH', 'aJ6y', 'oMqs']\nRaw outputs (first 3): [[ 1  1  1  1  1  4  1 10 10  1  1  1  1  1  1  1 12  1  1  1  1 12  1  1\n  10 10 10  1  6  1 10 34]\n [ 1  1  1  1  1  1  1  1  1 32  1  1  1  1  1  1  1 34  1  1 11 10  1  1\n   1  1  1  1  1  1  1 10]\n [ 1  1  1  1  1 10 10 34  1 34  1 34 34  1 32  1  1  1 32  1  1  5  1  1\n   1  1  1  1  1 10  1  1]]\nInput length: 32, Label lengths: [5, 4, 4]\nToken distribution (Batch 0): {1: 6, 42: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 1): {10: 2, 1: 8}, Pred length: 10\nToken distribution (Batch 2): {1: 8, 55: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 3): {1: 8, 10: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 4): {1: 4, 34: 1, 4: 1, 19: 1, 43: 1}, Pred length: 8\nToken distribution (Batch 5): {1: 5, 10: 2, 47: 2, 19: 1}, Pred length: 10\nToken distribution (Batch 6): {34: 1, 10: 3, 1: 4}, Pred length: 8\nToken distribution (Batch 7): {6: 1, 10: 2, 1: 5}, Pred length: 8\nToken distribution (Batch 8): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 9): {10: 1, 1: 5, 11: 2, 32: 2}, Pred length: 10\nToken distribution (Batch 10): {1: 8, 11: 1, 42: 1}, Pred length: 10\nToken distribution (Batch 11): {56: 1, 1: 5, 47: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 12): {10: 1, 1: 6, 22: 1}, Pred length: 8\nToken distribution (Batch 13): {1: 7, 47: 1, 32: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 14): {34: 2, 1: 5, 10: 1, 48: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 15): {1: 5, 19: 1, 32: 1, 6: 1, 35: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 16): {1: 10}, Pred length: 10\nToken distribution (Batch 17): {34: 2, 1: 3, 56: 1, 11: 1, 4: 1, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 18): {1: 4, 4: 1, 42: 1, 32: 2, 56: 2}, Pred length: 10\nToken distribution (Batch 19): {1: 3, 11: 1, 32: 2, 34: 1, 56: 1}, Pred length: 8\nToken distribution (Batch 20): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 21): {34: 1, 10: 2, 47: 1, 1: 4}, Pred length: 8\nToken distribution (Batch 22): {12: 1, 1: 4, 5: 1, 10: 2}, Pred length: 8\nToken distribution (Batch 23): {1: 4, 10: 3, 47: 1}, Pred length: 8\nToken distribution (Batch 24): {1: 4, 63: 1, 16: 1, 32: 1, 34: 1, 47: 2}, Pred length: 10\nToken distribution (Batch 25): {63: 1, 10: 2, 1: 6, 32: 1}, Pred length: 10\nToken distribution (Batch 26): {11: 2, 1: 6, 56: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 27): {1: 4, 22: 1, 11: 1, 10: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 28): {1: 8}, Pred length: 8\nToken distribution (Batch 29): {1: 8, 10: 2}, Pred length: 10\nToken distribution (Batch 30): {1: 6, 32: 1, 11: 1}, Pred length: 8\nToken distribution (Batch 31): {1: 7, 42: 1, 22: 1, 10: 1}, Pred length: 10\nBatch 20, Gradient norm: 18.1879\nEpoch 3, Batch 20/28, Loss: 29.7737\nAvg Blank Probability: 0.0147\nSample predictions: ['aPaja', 'jaja', 'a2ada']\nGround Truth (first 3): ['qChT', 'dnQZt', 'cl0di']\nRaw outputs (first 3): [[ 1 10  1  1  1  1 34  6  1 10  1 56 10  1 34  1  1 34  1  1  1 34 12  1\n   1 63 11  1  1  1  1  1]\n [ 1  1  1  1 34 10 10 10  1  1  1  1  1  1 34  1  1  1  4 11 10 10  1  1\n   1 10 11  1  1  1 32  1]\n [42  1  1  1  4  1  1  1  1  1  1  1  1  1  1 19  1  1 42  1  1 47  5 10\n  63  1  1  1  1  1 11  1]]\nInput length: 32, Label lengths: [4, 5, 5]\nEpoch 3/20, Loss: 30.2666\nToken distribution (Batch 0): {1: 10}, Pred length: 10\nToken distribution (Batch 1): {1: 10}, Pred length: 10\nToken distribution (Batch 2): {1: 8}, Pred length: 8\nToken distribution (Batch 3): {1: 8}, Pred length: 8\nToken distribution (Batch 4): {1: 8}, Pred length: 8\nToken distribution (Batch 5): {1: 10}, Pred length: 10\nToken distribution (Batch 6): {1: 10}, Pred length: 10\nToken distribution (Batch 7): {1: 8}, Pred length: 8\nToken distribution (Batch 8): {1: 8}, Pred length: 8\nToken distribution (Batch 9): {1: 10}, Pred length: 10\nToken distribution (Batch 10): {1: 8}, Pred length: 8\nToken distribution (Batch 11): {1: 8}, Pred length: 8\nToken distribution (Batch 12): {1: 10}, Pred length: 10\nToken distribution (Batch 13): {1: 8}, Pred length: 8\nToken distribution (Batch 14): {1: 8}, Pred length: 8\nToken distribution (Batch 15): {1: 8}, Pred length: 8\nToken distribution (Batch 16): {1: 10}, Pred length: 10\nToken distribution (Batch 17): {1: 8}, Pred length: 8\nToken distribution (Batch 18): {1: 8}, Pred length: 8\nToken distribution (Batch 19): {1: 10}, Pred length: 10\nToken distribution (Batch 20): {1: 8}, Pred length: 8\nToken distribution (Batch 21): {1: 8}, Pred length: 8\nToken distribution (Batch 22): {1: 10}, Pred length: 10\nToken distribution (Batch 23): {1: 8}, Pred length: 8\nToken distribution (Batch 24): {1: 10}, Pred length: 10\nValidation Loss: 29.7764\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['PxNEF', 'b1ppE', '-382', 'oGDK', 'uS*F']\nCurrent Learning Rate: 7.962697114529786e-08\nEpoch 4, Filtered data size: 1083, Sample labels: ['MdI8', '0tcL2', 'eyOxJ']\nTrain size: 866, Val size: 217\nToken distribution (Batch 0): {1: 6, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 1): {1: 4, 56: 1, 10: 1, 12: 1, 34: 2, 11: 1}, Pred length: 10\nToken distribution (Batch 2): {10: 2, 1: 3, 32: 1, 35: 1, 6: 1}, Pred length: 8\nToken distribution (Batch 3): {10: 3, 12: 1, 1: 3, 35: 1}, Pred length: 8\nToken distribution (Batch 4): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 5): {11: 1, 1: 6, 50: 1}, Pred length: 8\nToken distribution (Batch 6): {1: 6, 32: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 7): {1: 7, 22: 1}, Pred length: 8\nToken distribution (Batch 8): {1: 8, 34: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 8, 50: 1, 6: 1}, Pred length: 10\nToken distribution (Batch 10): {1: 6, 10: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 11): {1: 6, 11: 1, 10: 1, 12: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 12): {1: 4, 11: 1, 10: 2, 32: 1}, Pred length: 8\nToken distribution (Batch 13): {1: 5, 32: 2, 34: 1, 10: 2}, Pred length: 10\nToken distribution (Batch 14): {1: 5, 10: 3, 32: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 15): {1: 7, 4: 1, 10: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 16): {1: 5, 12: 1, 42: 1, 48: 1, 32: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 17): {32: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 18): {1: 7, 10: 3}, Pred length: 10\nToken distribution (Batch 19): {10: 1, 19: 1, 1: 7, 11: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 6, 27: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 21): {1: 6, 10: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 22): {1: 7, 19: 1}, Pred length: 8\nToken distribution (Batch 23): {1: 6, 32: 2, 34: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 24): {1: 6, 10: 1, 6: 1, 56: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 25): {1: 9, 47: 1}, Pred length: 10\nToken distribution (Batch 26): {1: 4, 43: 1, 19: 1, 47: 1, 56: 1}, Pred length: 8\nToken distribution (Batch 27): {1: 7, 11: 1, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 28): {1: 6, 10: 1, 5: 1}, Pred length: 8\nToken distribution (Batch 29): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 8, 27: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 31): {1: 7, 27: 1, 11: 1, 47: 1}, Pred length: 10\nBatch 0, Gradient norm: 18.4186\nEpoch 4, Batch 0/28, Loss: 29.6874\nAvg Blank Probability: 0.0147\nSample predictions: ['ajaF', 'a3jlHkaH', 'jaFjIfa']\nGround Truth (first 3): ['OKsw', 'W4Iwe', 'wnUT']\nRaw outputs (first 3): [[ 1  1 10 10  1 11  1  1  1  1  1  1  1  1  1  1  1 32  1 10  1  1  1  1\n   1  1  1  1  1  1  1  1]\n [ 1  1  1 12  1  1 32  1  1  1  1  1  1 32 10  1 12  1  1 19  1  1 19 32\n   1  1  1  1 10  1  1  1]\n [ 1 56 32 10  1  1 22  1  1 50 10  1  1  1  1  4  1  1 10  1  1  1  1  1\n   1  1 43  1  1  1  1  1]]\nInput length: 32, Label lengths: [4, 5, 4]\nToken distribution (Batch 0): {1: 4, 47: 2, 19: 1, 11: 1, 35: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 1): {1: 9, 4: 1}, Pred length: 10\nToken distribution (Batch 2): {10: 2, 4: 2, 1: 4}, Pred length: 8\nToken distribution (Batch 3): {1: 4, 47: 1, 6: 1, 22: 1, 19: 1}, Pred length: 8\nToken distribution (Batch 4): {34: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 5): {34: 1, 1: 6, 32: 2, 10: 1}, Pred length: 10\nToken distribution (Batch 6): {1: 6, 34: 1, 10: 2, 22: 1}, Pred length: 10\nToken distribution (Batch 7): {25: 1, 1: 4, 19: 1, 34: 2, 10: 1, 35: 1}, Pred length: 10\nToken distribution (Batch 8): {1: 6, 5: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 9): {1: 4, 10: 1, 22: 1, 6: 1, 27: 1}, Pred length: 8\nToken distribution (Batch 10): {1: 8, 10: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 11): {1: 8, 56: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 12): {1: 4, 34: 2, 11: 1, 5: 1}, Pred length: 8\nToken distribution (Batch 13): {34: 2, 1: 1, 10: 3, 32: 1, 56: 1}, Pred length: 8\nToken distribution (Batch 14): {1: 8, 35: 1, 5: 1}, Pred length: 10\nToken distribution (Batch 15): {1: 8, 32: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 16): {1: 5, 12: 1, 32: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 17): {1: 5, 47: 1, 4: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 18): {1: 7, 47: 1, 27: 2}, Pred length: 10\nToken distribution (Batch 19): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 5, 35: 1, 47: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 21): {1: 4, 6: 1, 47: 1, 19: 1, 55: 1}, Pred length: 8\nToken distribution (Batch 22): {1: 5, 6: 1, 10: 1, 47: 1, 32: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 23): {1: 9, 22: 1}, Pred length: 10\nToken distribution (Batch 24): {1: 7, 34: 1}, Pred length: 8\nToken distribution (Batch 25): {10: 3, 1: 5, 22: 1, 5: 1}, Pred length: 10\nToken distribution (Batch 26): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 27): {22: 1, 34: 1, 10: 1, 1: 4, 6: 1}, Pred length: 8\nToken distribution (Batch 28): {63: 1, 1: 5, 10: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 29): {1: 5, 10: 1, 4: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 30): {1: 4, 10: 1, 32: 1, 22: 2}, Pred length: 8\nToken distribution (Batch 31): {34: 1, 1: 7, 56: 1, 32: 1}, Pred length: 10\nBatch 10, Gradient norm: 17.3120\nEpoch 4, Batch 10/28, Loss: 30.1642\nAvg Blank Probability: 0.0147\nSample predictions: ['aUskIHaU', 'ada', 'jdajda']\nGround Truth (first 3): ['gH2tX', 'iH2Kv', 'C0Wa']\nRaw outputs (first 3): [[ 1  1 10  1 34 34  1 25  1  1  1  1  1 34  1  1  1  1  1  1  1  1  1  1\n   1 10  1 22 63  1  1 34]\n [ 1  1  4 47  1  1 34  1  1  1  1  1  1  1  1  1  1  1  1  1  1  6  1  1\n   1  1  1 34  1  1  1  1]\n [ 1  1  1  1  1  1 10  1  5 10  1  1 34 10  1  1  1 47 47  1  1  1  1  1\n  34 10 10 10  1 10 10 56]]\nInput length: 32, Label lengths: [5, 5, 4]\nToken distribution (Batch 0): {1: 4, 32: 2, 22: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 1): {16: 1, 1: 7, 32: 2}, Pred length: 10\nToken distribution (Batch 2): {1: 7, 63: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 6, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 4): {10: 1, 1: 6, 32: 3}, Pred length: 10\nToken distribution (Batch 5): {1: 8, 27: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 6): {1: 6, 10: 2}, Pred length: 8\nToken distribution (Batch 7): {1: 9, 4: 1}, Pred length: 10\nToken distribution (Batch 8): {1: 7, 47: 1, 35: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 7, 10: 2, 34: 1}, Pred length: 10\nToken distribution (Batch 10): {47: 2, 1: 4, 32: 2, 10: 2}, Pred length: 10\nToken distribution (Batch 11): {1: 5, 10: 3, 47: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 12): {34: 2, 6: 1, 11: 1, 1: 6}, Pred length: 10\nToken distribution (Batch 13): {10: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 14): {1: 9, 19: 1}, Pred length: 10\nToken distribution (Batch 15): {10: 2, 1: 5, 32: 1}, Pred length: 8\nToken distribution (Batch 16): {1: 7, 12: 1}, Pred length: 8\nToken distribution (Batch 17): {10: 2, 1: 5, 11: 1, 6: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 18): {1: 7, 47: 1}, Pred length: 8\nToken distribution (Batch 19): {19: 1, 47: 2, 1: 6, 32: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 8}, Pred length: 8\nToken distribution (Batch 21): {22: 1, 32: 2, 10: 3, 1: 2}, Pred length: 8\nToken distribution (Batch 22): {1: 5, 34: 1, 10: 1, 12: 1, 35: 1, 6: 1}, Pred length: 10\nToken distribution (Batch 23): {34: 1, 1: 5, 10: 2}, Pred length: 8\nToken distribution (Batch 24): {1: 4, 10: 3, 4: 1}, Pred length: 8\nToken distribution (Batch 25): {34: 1, 1: 5, 10: 2}, Pred length: 8\nToken distribution (Batch 26): {32: 2, 10: 1, 42: 1, 1: 4}, Pred length: 8\nToken distribution (Batch 27): {11: 1, 1: 5, 32: 1, 34: 1, 10: 2}, Pred length: 10\nToken distribution (Batch 28): {1: 5, 47: 1, 32: 2}, Pred length: 8\nToken distribution (Batch 29): {1: 5, 32: 2, 50: 1, 22: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 8, 10: 2}, Pred length: 10\nToken distribution (Batch 31): {1: 4, 34: 3, 32: 1}, Pred length: 8\nBatch 20, Gradient norm: 17.8683\nEpoch 4, Batch 20/28, Loss: 30.1926\nAvg Blank Probability: 0.0148\nSample predictions: ['aFvjaF', 'paFa', 'a-a']\nGround Truth (first 3): ['yquw', 'ocXXc', 'YJg3']\nRaw outputs (first 3): [[ 1 16  1  1 10  1  1  1  1  1 47  1 34 10  1 10  1 10  1 19  1 22  1 34\n   1 34 32 11  1  1  1  1]\n [ 1  1 63  1  1  1 10  4  1  1  1  1  6  1  1 10 12  1  1 47  1 32  1  1\n  10  1 10  1  1  1  1  1]\n [ 1 32  1  1  1  1  1  1 47  1 32  1 11  1  1  1  1  1 47  1  1 32 34  1\n  10  1 42 32  1 32  1 34]]\nInput length: 32, Label lengths: [4, 5, 4]\nEpoch 4/20, Loss: 30.0703\nToken distribution (Batch 0): {1: 8}, Pred length: 8\nToken distribution (Batch 1): {1: 10}, Pred length: 10\nToken distribution (Batch 2): {1: 8}, Pred length: 8\nToken distribution (Batch 3): {1: 8}, Pred length: 8\nToken distribution (Batch 4): {1: 8}, Pred length: 8\nToken distribution (Batch 5): {1: 10}, Pred length: 10\nToken distribution (Batch 6): {1: 8}, Pred length: 8\nToken distribution (Batch 7): {1: 10}, Pred length: 10\nToken distribution (Batch 8): {1: 8}, Pred length: 8\nToken distribution (Batch 9): {1: 8}, Pred length: 8\nToken distribution (Batch 10): {1: 10}, Pred length: 10\nToken distribution (Batch 11): {1: 10}, Pred length: 10\nToken distribution (Batch 12): {1: 8}, Pred length: 8\nToken distribution (Batch 13): {1: 10}, Pred length: 10\nToken distribution (Batch 14): {1: 8}, Pred length: 8\nToken distribution (Batch 15): {1: 8}, Pred length: 8\nToken distribution (Batch 16): {1: 10}, Pred length: 10\nToken distribution (Batch 17): {1: 10}, Pred length: 10\nToken distribution (Batch 18): {1: 10}, Pred length: 10\nToken distribution (Batch 19): {1: 10}, Pred length: 10\nToken distribution (Batch 20): {1: 10}, Pred length: 10\nToken distribution (Batch 21): {1: 10}, Pred length: 10\nToken distribution (Batch 22): {1: 10}, Pred length: 10\nToken distribution (Batch 23): {1: 10}, Pred length: 10\nToken distribution (Batch 24): {1: 10}, Pred length: 10\nValidation Loss: 30.0164\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['-382', 'zGkn7', '4rXg', 'fmjx', 'dZY4']\nCurrent Learning Rate: 1.0764398177990635e-07\nEpoch 5, Filtered data size: 1083, Sample labels: ['MdI8', '0tcL2', 'eyOxJ']\nTrain size: 866, Val size: 217\nToken distribution (Batch 0): {10: 1, 1: 4, 5: 1, 47: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 1): {1: 2, 32: 2, 10: 1, 56: 1, 22: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 2): {1: 2, 63: 1, 10: 3, 42: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 4): {1: 3, 10: 2, 11: 1, 27: 1, 50: 1}, Pred length: 8\nToken distribution (Batch 5): {32: 2, 1: 6, 10: 1, 19: 1}, Pred length: 10\nToken distribution (Batch 6): {1: 6, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 7): {47: 1, 1: 6, 32: 1}, Pred length: 8\nToken distribution (Batch 8): {1: 7, 10: 1, 4: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 6, 32: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 10): {10: 2, 1: 5, 22: 1}, Pred length: 8\nToken distribution (Batch 11): {1: 5, 11: 1, 10: 1, 56: 1}, Pred length: 8\nToken distribution (Batch 12): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 13): {1: 7, 47: 1}, Pred length: 8\nToken distribution (Batch 14): {10: 2, 1: 4, 32: 1, 50: 1}, Pred length: 8\nToken distribution (Batch 15): {1: 6, 6: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 16): {1: 8, 5: 1, 42: 1}, Pred length: 10\nToken distribution (Batch 17): {1: 6, 10: 1, 56: 1, 32: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 18): {10: 2, 1: 5, 47: 1, 32: 1, 11: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 6, 47: 1, 27: 1}, Pred length: 8\nToken distribution (Batch 20): {1: 5, 19: 1, 47: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 21): {10: 1, 1: 6, 34: 1}, Pred length: 8\nToken distribution (Batch 22): {10: 2, 35: 1, 1: 4, 34: 1}, Pred length: 8\nToken distribution (Batch 23): {1: 5, 56: 1, 19: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 24): {1: 6, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 25): {1: 5, 32: 3, 19: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 26): {34: 1, 56: 1, 1: 5, 10: 1}, Pred length: 8\nToken distribution (Batch 27): {10: 1, 1: 5, 32: 1, 11: 1}, Pred length: 8\nToken distribution (Batch 28): {1: 6, 43: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 29): {10: 1, 1: 5, 12: 2}, Pred length: 8\nToken distribution (Batch 30): {1: 7, 6: 1, 27: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 31): {1: 10}, Pred length: 10\nBatch 0, Gradient norm: 18.6455\nEpoch 5, Batch 0/28, Loss: 31.7315\nAvg Blank Probability: 0.0148\nSample predictions: ['jaeUaHa', 'aFaj3vU', 'a-jPjaF']\nGround Truth (first 3): ['OKsw', 'af5v', 'xm0f']\nRaw outputs (first 3): [[10  1  1  1  1 32  1 47  1  1 10  1  1  1 10  1  1  1 10  1  1 10 10  1\n   1  1 34 10  1 10  1  1]\n [ 1 32 63  1 10  1  1  1 10  1 10  1  1  1  1  1  1 10  1 47  1  1 35  1\n  10  1 56  1  1  1  1  1]\n [ 5 32 10  1  1 32  1  1  4  1  1 11  1  1  1  1  1  1  1  1 19  1  1 56\n   1 32  1  1  1 12  6  1]]\nInput length: 32, Label lengths: [4, 4, 4]\nToken distribution (Batch 0): {1: 5, 47: 2, 34: 1, 10: 2}, Pred length: 10\nToken distribution (Batch 1): {1: 4, 34: 2, 11: 1, 56: 1}, Pred length: 8\nToken distribution (Batch 2): {1: 6, 34: 1, 6: 1, 10: 2}, Pred length: 10\nToken distribution (Batch 3): {1: 4, 10: 1, 6: 1, 34: 1, 27: 1, 7: 1, 50: 1}, Pred length: 10\nToken distribution (Batch 4): {1: 9, 32: 1}, Pred length: 10\nToken distribution (Batch 5): {1: 6, 10: 1, 47: 2, 56: 1}, Pred length: 10\nToken distribution (Batch 6): {1: 5, 12: 1, 10: 2}, Pred length: 8\nToken distribution (Batch 7): {1: 3, 10: 1, 47: 1, 43: 1, 5: 1, 22: 1, 11: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 8): {34: 1, 1: 6, 22: 1, 50: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 6, 42: 1, 10: 2, 11: 1}, Pred length: 10\nToken distribution (Batch 10): {24: 1, 1: 6, 32: 1, 10: 1, 19: 1}, Pred length: 10\nToken distribution (Batch 11): {10: 2, 1: 7, 47: 1}, Pred length: 10\nToken distribution (Batch 12): {11: 2, 27: 1, 1: 4, 10: 1}, Pred length: 8\nToken distribution (Batch 13): {10: 2, 1: 7, 32: 1}, Pred length: 10\nToken distribution (Batch 14): {1: 4, 34: 1, 10: 1, 12: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 15): {1: 5, 11: 1, 32: 1, 10: 2, 47: 1}, Pred length: 10\nToken distribution (Batch 16): {1: 7, 47: 1, 32: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 17): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 18): {1: 5, 43: 2, 10: 1, 4: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 5, 19: 1, 10: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 20): {42: 1, 1: 6, 25: 1}, Pred length: 8\nToken distribution (Batch 21): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 22): {1: 5, 11: 1, 19: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 23): {56: 1, 1: 4, 32: 2, 10: 2, 34: 1}, Pred length: 10\nToken distribution (Batch 24): {1: 5, 11: 1, 22: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 25): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 26): {1: 5, 19: 1, 4: 2}, Pred length: 8\nToken distribution (Batch 27): {1: 4, 22: 1, 56: 1, 10: 2}, Pred length: 8\nToken distribution (Batch 28): {1: 8, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 29): {1: 8, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 7, 27: 1}, Pred length: 8\nToken distribution (Batch 31): {1: 7, 32: 1}, Pred length: 8\nBatch 10, Gradient norm: 34.0304\nEpoch 5, Batch 10/28, Loss: 29.7530\nAvg Blank Probability: 0.0148\nSample predictions: ['aUaUHj', 'aHkaHa3', 'aHafja']\nGround Truth (first 3): ['uwNaz', '6*h1', '*2Hap']\nRaw outputs (first 3): [[ 1  1  1  1  1  1  1  1 34  1 24 10 11 10  1  1  1  1  1  1 42  1  1 56\n   1  1  1  1  1  1  1  1]\n [ 1 34  1 10  1 10 12  1  1  1  1  1 27  1  1 11 47  1 43 19  1  1  1  1\n   1  1  1  1  1 10  1 32]\n [ 1 11 34  1  1  1  1 10  1 42  1 10  1  1 34 32 32  1  1 10  1  1  1 32\n   1  1 19 22  1  1  1  1]]\nInput length: 32, Label lengths: [5, 4, 5]\nToken distribution (Batch 0): {1: 7, 6: 1}, Pred length: 8\nToken distribution (Batch 1): {1: 5, 10: 4, 47: 1}, Pred length: 10\nToken distribution (Batch 2): {1: 4, 10: 1, 32: 3, 19: 1, 42: 1}, Pred length: 10\nToken distribution (Batch 3): {4: 1, 1: 6, 19: 1}, Pred length: 8\nToken distribution (Batch 4): {10: 1, 1: 5, 6: 1, 27: 1, 32: 2}, Pred length: 10\nToken distribution (Batch 5): {1: 2, 34: 2, 6: 2, 32: 1, 10: 2, 27: 1}, Pred length: 10\nToken distribution (Batch 6): {34: 1, 56: 1, 1: 5, 22: 1}, Pred length: 8\nToken distribution (Batch 7): {10: 4, 19: 2, 1: 2}, Pred length: 8\nToken distribution (Batch 8): {1: 4, 6: 1, 22: 1, 27: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 9): {1: 8, 10: 1, 12: 1}, Pred length: 10\nToken distribution (Batch 10): {10: 2, 1: 8}, Pred length: 10\nToken distribution (Batch 11): {1: 8, 10: 2}, Pred length: 10\nToken distribution (Batch 12): {34: 1, 11: 1, 1: 4, 32: 2}, Pred length: 8\nToken distribution (Batch 13): {1: 5, 27: 2, 32: 1}, Pred length: 8\nToken distribution (Batch 14): {6: 1, 1: 6, 32: 1}, Pred length: 8\nToken distribution (Batch 15): {1: 6, 10: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 16): {1: 5, 32: 1, 10: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 17): {1: 4, 34: 2, 47: 1, 27: 1, 19: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 18): {34: 3, 4: 1, 1: 4, 10: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 19): {12: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 20): {63: 1, 1: 4, 10: 2, 47: 1, 34: 2}, Pred length: 10\nToken distribution (Batch 21): {1: 6, 34: 2}, Pred length: 8\nToken distribution (Batch 22): {1: 4, 19: 1, 35: 1, 32: 1, 6: 1}, Pred length: 8\nToken distribution (Batch 23): {1: 6, 32: 2, 34: 1, 6: 1}, Pred length: 10\nToken distribution (Batch 24): {1: 10}, Pred length: 10\nToken distribution (Batch 25): {1: 3, 25: 1, 34: 2, 11: 2, 32: 1, 19: 1}, Pred length: 10\nToken distribution (Batch 26): {1: 8}, Pred length: 8\nToken distribution (Batch 27): {10: 1, 19: 1, 32: 1, 1: 4, 12: 1}, Pred length: 8\nToken distribution (Batch 28): {1: 6, 10: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 29): {1: 5, 47: 1, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 30): {1: 3, 42: 1, 12: 1, 10: 2, 11: 1}, Pred length: 8\nToken distribution (Batch 31): {1: 6, 32: 1, 10: 1}, Pred length: 8\nBatch 20, Gradient norm: 18.2987\nEpoch 5, Batch 20/28, Loss: 30.7443\nAvg Blank Probability: 0.0148\nSample predictions: ['af', 'ajUajaja', 'ajFaFsPFa']\nGround Truth (first 3): ['ZSZ1', 'RhAem', 'Sy1pI']\nRaw outputs (first 3): [[ 1  1  1  4 10  1 34 10  1  1 10  1 34  1  6  1  1  1 34 12 63  1  1  1\n   1  1  1 10  1  1  1  1]\n [ 1 10  1  1  1 34 56 10  1 10  1 10 11  1  1 10 32 34  4  1  1 34  1  1\n   1 25  1 19  1  1 42  1]\n [ 1 10 10  1  6  6  1 19  1 12  1  1  1  1  1  1 10  1  1  1  1  1 19  1\n   1  1  1 32  1 47  1  1]]\nInput length: 32, Label lengths: [4, 5, 5]\nEpoch 5/20, Loss: 30.1788\nToken distribution (Batch 0): {1: 10}, Pred length: 10\nToken distribution (Batch 1): {1: 10}, Pred length: 10\nToken distribution (Batch 2): {1: 10}, Pred length: 10\nToken distribution (Batch 3): {1: 10}, Pred length: 10\nToken distribution (Batch 4): {1: 10}, Pred length: 10\nToken distribution (Batch 5): {1: 8}, Pred length: 8\nToken distribution (Batch 6): {1: 10}, Pred length: 10\nToken distribution (Batch 7): {1: 10}, Pred length: 10\nToken distribution (Batch 8): {1: 8}, Pred length: 8\nToken distribution (Batch 9): {1: 10}, Pred length: 10\nToken distribution (Batch 10): {1: 8}, Pred length: 8\nToken distribution (Batch 11): {1: 8}, Pred length: 8\nToken distribution (Batch 12): {1: 8}, Pred length: 8\nToken distribution (Batch 13): {1: 10}, Pred length: 10\nToken distribution (Batch 14): {1: 8}, Pred length: 8\nToken distribution (Batch 15): {1: 10}, Pred length: 10\nToken distribution (Batch 16): {1: 8}, Pred length: 8\nToken distribution (Batch 17): {1: 8}, Pred length: 8\nToken distribution (Batch 18): {1: 8}, Pred length: 8\nToken distribution (Batch 19): {1: 10}, Pred length: 10\nToken distribution (Batch 20): {1: 10}, Pred length: 10\nToken distribution (Batch 21): {1: 10}, Pred length: 10\nToken distribution (Batch 22): {1: 8}, Pred length: 8\nToken distribution (Batch 23): {1: 10}, Pred length: 10\nToken distribution (Batch 24): {1: 10}, Pred length: 10\nValidation Loss: 29.9858\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['TD7Er', '4roDw', 'QZa-T', 'zYs28', 'jfC0p']\nCurrent Learning Rate: 1.3560247558250752e-07\nEpoch 6, Filtered data size: 2287, Sample labels: ['qV8ib8H', 'MdI8', '0tcL2']\nTrain size: 1829, Val size: 458\nToken distribution (Batch 0): {1: 5, 11: 1, 43: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 1): {6: 2, 1: 2, 56: 2, 32: 2}, Pred length: 8\nToken distribution (Batch 2): {1: 6, 56: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 10, 32: 1, 10: 1, 35: 1, 4: 1}, Pred length: 14\nToken distribution (Batch 4): {1: 6, 34: 1, 32: 1, 10: 2}, Pred length: 10\nToken distribution (Batch 5): {32: 2, 1: 9, 10: 1, 27: 1, 6: 1}, Pred length: 14\nToken distribution (Batch 6): {1: 6, 6: 1, 4: 1, 10: 2}, Pred length: 10\nToken distribution (Batch 7): {1: 7, 34: 1}, Pred length: 8\nToken distribution (Batch 8): {1: 5, 10: 2, 27: 1}, Pred length: 8\nToken distribution (Batch 9): {1: 10, 10: 2, 11: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 10): {10: 2, 34: 1, 1: 3, 5: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 11): {10: 2, 32: 1, 1: 3, 42: 1, 34: 1, 4: 2}, Pred length: 10\nToken distribution (Batch 12): {4: 2, 11: 1, 1: 6, 5: 1}, Pred length: 10\nToken distribution (Batch 13): {6: 1, 43: 1, 1: 7, 34: 1, 10: 3, 4: 1}, Pred length: 14\nToken distribution (Batch 14): {1: 10, 19: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 15): {1: 5, 10: 1, 56: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 16): {1: 5, 12: 1, 4: 1, 25: 1, 34: 3, 32: 1}, Pred length: 12\nToken distribution (Batch 17): {10: 3, 1: 7, 32: 1, 19: 1, 47: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 18): {1: 5, 32: 1, 11: 1, 6: 1}, Pred length: 8\nToken distribution (Batch 19): {1: 9, 10: 3, 4: 1, 43: 1}, Pred length: 14\nToken distribution (Batch 20): {1: 9, 4: 1, 10: 1, 19: 1, 32: 1, 22: 1}, Pred length: 14\nToken distribution (Batch 21): {34: 1, 1: 5, 5: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 22): {10: 2, 1: 8, 32: 1, 22: 2, 19: 1}, Pred length: 14\nToken distribution (Batch 23): {10: 4, 1: 5, 34: 1}, Pred length: 10\nToken distribution (Batch 24): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 25): {34: 1, 1: 8, 27: 1, 22: 1, 6: 1, 47: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 26): {1: 11, 32: 1, 10: 1, 56: 1}, Pred length: 14\nToken distribution (Batch 27): {1: 8}, Pred length: 8\nToken distribution (Batch 28): {10: 2, 42: 1, 1: 8, 12: 1}, Pred length: 12\nToken distribution (Batch 29): {4: 1, 1: 6, 10: 4, 19: 1, 50: 1, 55: 1}, Pred length: 14\nToken distribution (Batch 30): {1: 7, 4: 1, 34: 1, 32: 2, 10: 1}, Pred length: 12\nToken distribution (Batch 31): {19: 2, 1: 7, 10: 4, 32: 1}, Pred length: 14\nBatch 0, Gradient norm: 21.9380\nEpoch 6, Batch 0/58, Loss: 25.8237\nAvg Blank Probability: 0.0148\nSample predictions: ['akaQav', 'fa3FfF', 'a3aj']\nGround Truth (first 3): ['EPL7', 'mNkU', 'KNzX']\nRaw outputs (first 3): [[ 1  6  1  1  1 32  1  1  1  1 10 10  4  6  1  1  1 10  1  1  1 34 10 10\n   1 34  1  1 10  4  1 19]\n [ 1  1 56  1  1  1  6  1  1 10 34 32  4 43  1 10 12  1  1  1  1  1  1  1\n   1  1  1  1 42  1  1  1]\n [11  1  1  1  1  1  4  1  1  1  1 10 11  1  1  1  4  1  1 10  1  5 10  1\n   1  1  1  1  1 10  1  1]]\nInput length: 32, Label lengths: [4, 4, 4]\nToken distribution (Batch 0): {1: 4, 32: 1, 5: 1, 42: 1, 34: 2, 19: 1}, Pred length: 10\nToken distribution (Batch 1): {1: 8}, Pred length: 8\nToken distribution (Batch 2): {1: 11, 47: 1, 19: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 3): {1: 6, 32: 1, 10: 2, 4: 1}, Pred length: 10\nToken distribution (Batch 4): {56: 1, 1: 8, 6: 1, 11: 1, 34: 2, 32: 1}, Pred length: 14\nToken distribution (Batch 5): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 6): {11: 1, 34: 2, 1: 7, 4: 1, 27: 1, 6: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 7): {1: 10, 10: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 8): {1: 4, 4: 1, 34: 1, 10: 1, 27: 1}, Pred length: 8\nToken distribution (Batch 9): {10: 1, 1: 7, 32: 1, 12: 1, 27: 2}, Pred length: 12\nToken distribution (Batch 10): {11: 1, 10: 2, 1: 5}, Pred length: 8\nToken distribution (Batch 11): {1: 9, 10: 2, 32: 1, 34: 2}, Pred length: 14\nToken distribution (Batch 12): {1: 6, 11: 1, 35: 1}, Pred length: 8\nToken distribution (Batch 13): {1: 6, 10: 3, 34: 1, 32: 1, 4: 1}, Pred length: 12\nToken distribution (Batch 14): {1: 9, 47: 1, 34: 2}, Pred length: 12\nToken distribution (Batch 15): {1: 5, 35: 1, 47: 1, 27: 1}, Pred length: 8\nToken distribution (Batch 16): {1: 8, 35: 1, 34: 1, 10: 1, 4: 1}, Pred length: 12\nToken distribution (Batch 17): {10: 2, 1: 5, 47: 1}, Pred length: 8\nToken distribution (Batch 18): {63: 1, 43: 1, 1: 3, 32: 2, 10: 1}, Pred length: 8\nToken distribution (Batch 19): {1: 6, 10: 3, 47: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 8, 32: 1, 43: 1}, Pred length: 10\nToken distribution (Batch 21): {10: 3, 6: 1, 47: 1, 22: 1, 1: 8}, Pred length: 14\nToken distribution (Batch 22): {1: 6, 32: 1, 47: 1, 22: 1, 6: 1}, Pred length: 10\nToken distribution (Batch 23): {1: 7, 11: 1, 12: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 24): {1: 8, 32: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 25): {24: 1, 1: 4, 47: 1, 34: 2}, Pred length: 8\nToken distribution (Batch 26): {1: 9, 10: 3}, Pred length: 12\nToken distribution (Batch 27): {34: 1, 4: 1, 30: 1, 47: 1, 35: 1, 1: 3}, Pred length: 8\nToken distribution (Batch 28): {1: 8, 34: 2, 19: 1, 56: 1, 27: 1, 35: 1}, Pred length: 14\nToken distribution (Batch 29): {1: 9, 34: 1, 32: 1, 11: 1}, Pred length: 12\nToken distribution (Batch 30): {1: 6, 47: 1, 19: 2, 6: 1, 32: 1, 10: 3}, Pred length: 14\nToken distribution (Batch 31): {1: 8, 10: 3, 32: 1}, Pred length: 12\nBatch 10, Gradient norm: 18.6161\nEpoch 6, Batch 10/58, Loss: 26.3270\nAvg Blank Probability: 0.0149\nSample predictions: ['aFaePHsHa', 'a', 'aUsaFa']\nGround Truth (first 3): ['qnWbe', 'CBN6', 'Fmh3uhn']\nRaw outputs (first 3): [[ 1  1  1  1 56  1 11  1  1 10 11  1  1  1  1  1  1 10 63  1  1 10  1  1\n   1 24  1 34  1  1  1  1]\n [ 1  1  1  1  1  1 34  1  4  1 10 10  1  1  1  1  1  1 43  1  1  6  1  1\n   1  1  1  4  1  1 47  1]\n [32  1  1 32  1  1  1  1 34  1  1  1  1  1  1  1 35 10  1 10  1 47  1  1\n   1 47  1 30 34  1  1  1]]\nInput length: 32, Label lengths: [5, 4, 7]\nToken distribution (Batch 0): {1: 4, 47: 2, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 1): {4: 1, 1: 5, 11: 1, 47: 1, 32: 2}, Pred length: 10\nToken distribution (Batch 2): {1: 8, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 3): {1: 12, 10: 2}, Pred length: 14\nToken distribution (Batch 4): {1: 7, 6: 2, 10: 1}, Pred length: 10\nToken distribution (Batch 5): {10: 2, 1: 6, 34: 2, 32: 2, 6: 1, 56: 1}, Pred length: 14\nToken distribution (Batch 6): {1: 9, 27: 1, 4: 1, 32: 2, 56: 1}, Pred length: 14\nToken distribution (Batch 7): {1: 6, 56: 1, 34: 1, 4: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 8): {6: 1, 1: 7, 34: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 7, 48: 1, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 10): {1: 6, 32: 2, 19: 1, 34: 1, 35: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 11): {1: 3, 32: 2, 56: 1, 42: 1, 12: 1}, Pred length: 8\nToken distribution (Batch 12): {1: 9, 4: 1}, Pred length: 10\nToken distribution (Batch 13): {1: 5, 34: 1, 35: 1, 42: 1, 47: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 14): {10: 1, 1: 2, 32: 2, 6: 2, 4: 1}, Pred length: 8\nToken distribution (Batch 15): {1: 6, 10: 2, 11: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 16): {10: 3, 1: 9, 5: 1, 22: 1}, Pred length: 14\nToken distribution (Batch 17): {1: 8, 10: 2, 11: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 18): {1: 5, 4: 1, 10: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 19): {1: 11, 10: 2, 47: 1}, Pred length: 14\nToken distribution (Batch 20): {35: 1, 1: 7, 47: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 21): {1: 10, 10: 2}, Pred length: 12\nToken distribution (Batch 22): {1: 7, 56: 1}, Pred length: 8\nToken distribution (Batch 23): {1: 11, 11: 1, 10: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 24): {10: 3, 1: 6, 32: 1}, Pred length: 10\nToken distribution (Batch 25): {10: 6, 11: 1, 47: 1, 19: 1, 1: 4, 34: 1}, Pred length: 14\nToken distribution (Batch 26): {47: 1, 1: 9}, Pred length: 10\nToken distribution (Batch 27): {1: 5, 47: 1, 10: 2}, Pred length: 8\nToken distribution (Batch 28): {56: 1, 1: 6, 4: 1, 6: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 29): {1: 6, 47: 1, 19: 1}, Pred length: 8\nToken distribution (Batch 30): {1: 8, 10: 2}, Pred length: 10\nToken distribution (Batch 31): {32: 2, 10: 1, 1: 5}, Pred length: 8\nBatch 20, Gradient norm: 63.1730\nEpoch 6, Batch 20/58, Loss: 26.6166\nAvg Blank Probability: 0.0149\nSample predictions: ['aUaUjFa', 'dakUaF', 'ajaFa']\nGround Truth (first 3): ['iRPV', 'qiegN', 'YPm*R']\nRaw outputs (first 3): [[ 1  4  1  1  1 10  1  1  6  1  1  1  1  1 10  1 10  1  1  1 35  1  1  1\n  10 10 47  1 56  1  1 32]\n [ 1  1  1  1  1  1  1 56  1  1  1 32  1 34  1  1  1  1  1  1  1  1 56 11\n   1 11  1 47  1  1 10 32]\n [47  1  1  1  6  1  1 34  1  1 32  1  1  1 32  1  1 10  1 10  1 10  1  1\n  10 10  1  1  1 47  1 10]]\nInput length: 32, Label lengths: [4, 5, 5]\nToken distribution (Batch 0): {1: 6, 34: 3, 6: 1}, Pred length: 10\nToken distribution (Batch 1): {1: 8, 56: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 2): {10: 2, 1: 7, 25: 1, 22: 1, 56: 1}, Pred length: 12\nToken distribution (Batch 3): {63: 1, 10: 6, 32: 1, 1: 3, 12: 1}, Pred length: 12\nToken distribution (Batch 4): {63: 1, 1: 9, 47: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 5): {1: 6, 47: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 6): {10: 2, 1: 4, 34: 1, 6: 1}, Pred length: 8\nToken distribution (Batch 7): {1: 6, 10: 1, 32: 2, 12: 1}, Pred length: 10\nToken distribution (Batch 8): {1: 4, 27: 1, 10: 2, 56: 1}, Pred length: 8\nToken distribution (Batch 9): {1: 7, 32: 1, 10: 3, 22: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 8, 47: 1, 10: 4, 6: 1}, Pred length: 14\nToken distribution (Batch 11): {1: 7, 19: 1, 11: 1, 47: 1, 32: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 12): {1: 4, 56: 1, 19: 1, 4: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 13): {1: 12}, Pred length: 12\nToken distribution (Batch 14): {34: 1, 32: 1, 1: 8, 22: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 15): {1: 7, 19: 1}, Pred length: 8\nToken distribution (Batch 16): {1: 10, 12: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 17): {1: 5, 32: 2, 10: 5}, Pred length: 12\nToken distribution (Batch 18): {1: 10, 55: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 19): {34: 1, 10: 2, 1: 5, 19: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 8, 42: 1, 10: 1, 34: 2, 11: 1, 5: 1}, Pred length: 14\nToken distribution (Batch 21): {10: 3, 1: 6, 32: 2, 34: 1}, Pred length: 12\nToken distribution (Batch 22): {1: 11, 42: 1, 34: 2}, Pred length: 14\nToken distribution (Batch 23): {1: 8, 10: 4, 35: 1, 25: 1}, Pred length: 14\nToken distribution (Batch 24): {1: 8, 22: 2}, Pred length: 10\nToken distribution (Batch 25): {10: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 26): {1: 11, 22: 1, 56: 1, 6: 1}, Pred length: 14\nToken distribution (Batch 27): {1: 6, 35: 1, 56: 1, 25: 1, 34: 1, 10: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 28): {34: 1, 1: 3, 10: 3, 32: 1}, Pred length: 8\nToken distribution (Batch 29): {10: 1, 1: 6, 32: 2, 34: 1}, Pred length: 10\nToken distribution (Batch 30): {10: 1, 1: 4, 11: 1, 4: 1, 32: 2, 34: 1}, Pred length: 10\nToken distribution (Batch 31): {1: 5, 34: 2, 32: 1}, Pred length: 8\nBatch 30, Gradient norm: 14.5471\nEpoch 6, Batch 30/58, Loss: 25.8168\nAvg Blank Probability: 0.0150\nSample predictions: ['aHafa', 'a3aj', 'jayva3ja']\nGround Truth (first 3): ['OoPE*', 'Jl-e8', 'du7vbm']\nRaw outputs (first 3): [[ 1  1 10 63 63  1 10  1  1  1  1  1  1  1 34  1  1  1  1 34  1 10  1  1\n   1 10  1  1 34 10 10  1]\n [34  1  1 10  1  1  1  1 27 32  1  1 56  1 32  1  1  1  1 10 42  1  1 10\n   1  1  1  1  1  1  1 34]\n [34  1  1 10  1  1  1  1 10  1 47  1 19  1  1  1  1 32  1  1 10 32 42 10\n   1  1  1  1 10  1  1 34]]\nInput length: 32, Label lengths: [5, 5, 6]\nToken distribution (Batch 0): {1: 10, 6: 1, 10: 1, 27: 1, 22: 1}, Pred length: 14\nToken distribution (Batch 1): {1: 7, 6: 1, 22: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 2): {1: 7, 42: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 6, 32: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 4): {1: 5, 63: 1, 34: 2, 32: 1, 11: 1, 10: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 5): {1: 8, 34: 1, 10: 1, 19: 1, 30: 1}, Pred length: 12\nToken distribution (Batch 6): {1: 8, 10: 2, 35: 1, 32: 1, 11: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 7): {1: 5, 10: 2, 5: 1}, Pred length: 8\nToken distribution (Batch 8): {1: 6, 10: 2, 35: 2, 56: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 9): {1: 4, 10: 3, 47: 1, 12: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 10): {1: 7, 32: 2, 27: 1}, Pred length: 10\nToken distribution (Batch 11): {24: 1, 1: 6, 32: 1}, Pred length: 8\nToken distribution (Batch 12): {1: 8, 32: 1, 6: 1, 56: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 13): {1: 10, 32: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 14): {1: 7, 34: 1, 10: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 15): {10: 4, 1: 4, 11: 1, 34: 1, 42: 1, 43: 1}, Pred length: 12\nToken distribution (Batch 16): {1: 6, 10: 3, 48: 1}, Pred length: 10\nToken distribution (Batch 17): {1: 7, 22: 1, 34: 1, 35: 1}, Pred length: 10\nToken distribution (Batch 18): {34: 1, 32: 2, 1: 8, 22: 1}, Pred length: 12\nToken distribution (Batch 19): {1: 10, 56: 1, 4: 1}, Pred length: 12\nToken distribution (Batch 20): {1: 8, 27: 1, 10: 1, 22: 1, 55: 1}, Pred length: 12\nToken distribution (Batch 21): {35: 1, 47: 1, 1: 5, 10: 1}, Pred length: 8\nToken distribution (Batch 22): {56: 1, 1: 9, 11: 1, 19: 1, 10: 1, 16: 1}, Pred length: 14\nToken distribution (Batch 23): {1: 9, 47: 1, 19: 1, 25: 1}, Pred length: 12\nToken distribution (Batch 24): {1: 5, 47: 1, 10: 4, 27: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 25): {1: 6, 12: 1, 24: 1}, Pred length: 8\nToken distribution (Batch 26): {1: 12, 6: 1, 11: 1}, Pred length: 14\nToken distribution (Batch 27): {1: 13, 10: 1}, Pred length: 14\nToken distribution (Batch 28): {1: 7, 19: 1, 47: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 29): {19: 1, 32: 1, 1: 8, 34: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 30): {1: 6, 32: 1, 56: 1}, Pred length: 8\nToken distribution (Batch 31): {56: 1, 1: 7, 47: 1, 6: 1}, Pred length: 10\nBatch 40, Gradient norm: 262.3102\nEpoch 6, Batch 40/58, Loss: 25.6499\nAvg Blank Probability: 0.0150\nSample predictions: ['afajAva', 'afavU', 'aPa']\nGround Truth (first 3): ['sIhW35-', 'h1sQr', '2EKq']\nRaw outputs (first 3): [[ 1  1  1  1  1  1  1  1  1  1  1 24  1  1  1 10  1  1 34  1  1 35 56  1\n   1  1  1  1  1 19  1 56]\n [ 1  1 42  1  1  1 10 10  1 10  1  1  1  1  1  1  1  1 32  1  1 47  1  1\n   1  1  1  1  1 32 32  1]\n [ 1  1  1  1 63  1  1 10  1  1  1  1 32  1  1 11  1  1  1 56  1  1  1  1\n  47 12  1  1  1  1 56 47]]\nInput length: 32, Label lengths: [7, 5, 4]\nToken distribution (Batch 0): {10: 3, 42: 1, 34: 2, 19: 1, 1: 2, 32: 1}, Pred length: 10\nToken distribution (Batch 1): {34: 1, 1: 12, 4: 1}, Pred length: 14\nToken distribution (Batch 2): {1: 11, 10: 1, 32: 1, 27: 1}, Pred length: 14\nToken distribution (Batch 3): {34: 2, 1: 5, 10: 1, 47: 1, 35: 1, 6: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 4): {4: 1, 6: 1, 1: 8, 19: 1, 27: 1, 42: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 5): {1: 7, 34: 1}, Pred length: 8\nToken distribution (Batch 6): {24: 1, 1: 9}, Pred length: 10\nToken distribution (Batch 7): {1: 5, 47: 1, 10: 1, 6: 1, 22: 1, 32: 1, 27: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 8): {56: 1, 47: 1, 1: 5, 11: 2, 32: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 9, 4: 1, 10: 1, 27: 1, 19: 2}, Pred length: 14\nToken distribution (Batch 10): {10: 2, 1: 6, 34: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 11): {1: 9, 10: 4, 27: 1}, Pred length: 14\nToken distribution (Batch 12): {10: 1, 1: 9, 32: 2, 34: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 13): {34: 3, 11: 2, 10: 2, 1: 4, 56: 1}, Pred length: 12\nToken distribution (Batch 14): {1: 8, 35: 1, 10: 2, 32: 2, 55: 1}, Pred length: 14\nToken distribution (Batch 15): {1: 5, 11: 1, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 16): {56: 1, 1: 9, 10: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 17): {1: 6, 10: 3, 32: 3}, Pred length: 12\nToken distribution (Batch 18): {11: 1, 10: 1, 1: 6, 56: 1, 42: 1}, Pred length: 10\nToken distribution (Batch 19): {10: 1, 1: 10, 32: 3}, Pred length: 14\nToken distribution (Batch 20): {34: 1, 1: 5, 4: 1, 19: 1, 32: 2}, Pred length: 10\nToken distribution (Batch 21): {10: 1, 32: 2, 1: 9, 47: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 22): {1: 8, 11: 1, 10: 2, 32: 1, 47: 2}, Pred length: 14\nToken distribution (Batch 23): {1: 6, 32: 3, 10: 3, 56: 1, 19: 1}, Pred length: 14\nToken distribution (Batch 24): {1: 8, 32: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 25): {1: 5, 22: 1, 4: 2}, Pred length: 8\nToken distribution (Batch 26): {1: 8, 10: 2, 56: 1, 11: 1, 6: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 27): {63: 1, 1: 5, 4: 1, 19: 1, 34: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 28): {1: 6, 4: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 29): {1: 4, 42: 1, 32: 1, 10: 1, 11: 1, 34: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 10, 10: 2}, Pred length: 12\nToken distribution (Batch 31): {1: 5, 35: 1, 10: 2}, Pred length: 8\nBatch 50, Gradient norm: 20.3807\nEpoch 6, Batch 50/58, Loss: 24.4775\nAvg Blank Probability: 0.0152\nSample predictions: ['jPHsjaHjFa', 'Hada', 'ajaFaAa']\nGround Truth (first 3): ['pNdnX', 'rz1iKMQ', '*Ch-ala']\nRaw outputs (first 3): [[10 34  1 34  4  1 24  1 56  1 10  1 10 34  1  1 56  1 11 10 34 10  1  1\n   1  1  1 63  1  1  1  1]\n [42  1 10 34  6  1  1  1 47  4  1  1  1 11  1 11  1  1 10  1  1 32  1 32\n   1 22  1  1  1  1  1 35]\n [34  1  1  1  1  1  1 47  1 10 10 10  1 11  1 10  1 10  1  1  4  1 11  1\n   1  1 10  1  4 42  1  1]]\nInput length: 32, Label lengths: [5, 7, 7]\nEpoch 6/20, Loss: 25.4498\nToken distribution (Batch 0): {1: 12}, Pred length: 12\nToken distribution (Batch 1): {1: 14}, Pred length: 14\nToken distribution (Batch 2): {1: 8}, Pred length: 8\nToken distribution (Batch 3): {1: 12}, Pred length: 12\nToken distribution (Batch 4): {1: 14}, Pred length: 14\nToken distribution (Batch 5): {1: 8}, Pred length: 8\nToken distribution (Batch 6): {1: 14}, Pred length: 14\nToken distribution (Batch 7): {1: 10}, Pred length: 10\nToken distribution (Batch 8): {1: 14}, Pred length: 14\nToken distribution (Batch 9): {1: 14}, Pred length: 14\nValidation Loss: 25.3688\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['wuI06C', 'EBg7n0T', 'uS*F', 'DFNF4M', 'PZ8JfWD']\nCurrent Learning Rate: 2.641024536610256e-07\nEpoch 7, Filtered data size: 2287, Sample labels: ['qV8ib8H', 'MdI8', '0tcL2']\nTrain size: 1829, Val size: 458\nToken distribution (Batch 0): {1: 7, 34: 1, 10: 3, 22: 1, 4: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 1): {1: 6, 4: 1, 6: 1, 10: 2}, Pred length: 10\nToken distribution (Batch 2): {1: 10}, Pred length: 10\nToken distribution (Batch 3): {1: 7, 19: 1, 4: 1, 10: 1, 11: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 4): {32: 1, 1: 11, 47: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 5): {1: 8, 22: 1, 32: 1, 56: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 6): {1: 10}, Pred length: 10\nToken distribution (Batch 7): {1: 6, 32: 2, 10: 2, 34: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 8): {11: 1, 1: 5, 32: 2}, Pred length: 8\nToken distribution (Batch 9): {1: 9, 34: 1, 10: 1, 27: 1, 47: 1, 5: 1}, Pred length: 14\nToken distribution (Batch 10): {10: 2, 1: 6, 6: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 11): {1: 9, 32: 1, 56: 1, 6: 1}, Pred length: 12\nToken distribution (Batch 12): {4: 1, 32: 1, 1: 5, 34: 1, 22: 2, 56: 1, 10: 2, 42: 1}, Pred length: 14\nToken distribution (Batch 13): {4: 1, 1: 5, 22: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 14): {1: 5, 34: 3}, Pred length: 8\nToken distribution (Batch 15): {1: 7, 50: 1}, Pred length: 8\nToken distribution (Batch 16): {42: 2, 10: 1, 1: 8, 34: 3}, Pred length: 14\nToken distribution (Batch 17): {11: 1, 1: 8, 19: 1, 10: 2, 47: 1, 27: 1}, Pred length: 14\nToken distribution (Batch 18): {11: 3, 32: 1, 1: 5, 10: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 4, 32: 2, 19: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 20): {34: 1, 10: 2, 1: 8, 32: 2, 19: 1}, Pred length: 14\nToken distribution (Batch 21): {6: 1, 1: 11, 22: 1, 19: 1}, Pred length: 14\nToken distribution (Batch 22): {1: 6, 10: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 23): {1: 6, 42: 1, 32: 1, 34: 2, 56: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 24): {10: 2, 32: 2, 1: 5, 47: 1}, Pred length: 10\nToken distribution (Batch 25): {1: 11, 32: 1, 10: 1, 6: 1}, Pred length: 14\nToken distribution (Batch 26): {10: 1, 1: 6, 22: 1}, Pred length: 8\nToken distribution (Batch 27): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 28): {1: 7, 10: 2, 22: 1}, Pred length: 10\nToken distribution (Batch 29): {1: 8, 6: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 31): {1: 2, 32: 1, 34: 2, 63: 1, 47: 1, 10: 2, 22: 1}, Pred length: 10\nBatch 0, Gradient norm: 15.8734\nEpoch 7, Batch 0/58, Loss: 25.8763\nAvg Blank Probability: 0.0152\nSample predictions: ['aHajvdjaFa', 'adfjaja', 'a']\nGround Truth (first 3): ['kKbVPzU', '86ybD', 'rYopn']\nRaw outputs (first 3): [[ 1  1  1  1 32  1  1  1 11  1 10  1  4  4  1  1 42 11 11  1 34  6  1  1\n  10  1 10  1  1  1  1  1]\n [ 1  1  1  1  1  1  1 32  1  1  1  1 32  1 34 50 42  1 11  1 10  1  1  1\n  32  1  1  1  1  1  1  1]\n [ 1  1  1 19  1  1  1 32  1 34  6  1  1  1  1  1 10 19 32 32  1  1  1  1\n   1  1  1  1  1  6  1 32]]\nInput length: 32, Label lengths: [7, 5, 5]\nToken distribution (Batch 0): {1: 5, 22: 1, 47: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 1): {1: 7, 32: 1, 35: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 2): {1: 6, 34: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 3): {10: 6, 1: 5, 32: 1}, Pred length: 12\nToken distribution (Batch 4): {1: 7, 11: 1, 34: 1, 32: 1, 10: 2}, Pred length: 12\nToken distribution (Batch 5): {1: 8, 10: 2}, Pred length: 10\nToken distribution (Batch 6): {1: 6, 10: 1, 27: 1}, Pred length: 8\nToken distribution (Batch 7): {11: 1, 1: 8, 34: 1, 4: 1, 6: 1}, Pred length: 12\nToken distribution (Batch 8): {1: 12, 10: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 9): {1: 11, 32: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 7, 10: 2, 32: 1, 56: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 11): {1: 11, 34: 1, 10: 1, 35: 1}, Pred length: 14\nToken distribution (Batch 12): {10: 1, 1: 10, 22: 1}, Pred length: 12\nToken distribution (Batch 13): {1: 9, 32: 2, 22: 1}, Pred length: 12\nToken distribution (Batch 14): {1: 10, 10: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 15): {1: 5, 10: 3, 22: 1, 63: 1}, Pred length: 10\nToken distribution (Batch 16): {1: 5, 32: 1, 12: 1, 47: 2, 10: 1}, Pred length: 10\nToken distribution (Batch 17): {1: 7, 63: 1, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 18): {1: 14}, Pred length: 14\nToken distribution (Batch 19): {6: 1, 10: 1, 1: 4, 24: 1, 56: 1}, Pred length: 8\nToken distribution (Batch 20): {1: 4, 32: 1, 10: 4, 27: 1}, Pred length: 10\nToken distribution (Batch 21): {10: 3, 1: 9}, Pred length: 12\nToken distribution (Batch 22): {11: 1, 1: 8, 19: 1, 10: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 23): {1: 7, 47: 1, 42: 1, 5: 1}, Pred length: 10\nToken distribution (Batch 24): {1: 8, 34: 1, 4: 1, 10: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 25): {1: 10, 4: 1, 27: 1, 32: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 26): {1: 5, 4: 2, 34: 3, 11: 1, 22: 1, 6: 1, 5: 1}, Pred length: 14\nToken distribution (Batch 27): {1: 7, 35: 1, 10: 2, 34: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 28): {1: 8, 10: 1, 25: 1, 47: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 29): {1: 8, 11: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 30): {34: 2, 1: 10, 19: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 31): {1: 11, 34: 1}, Pred length: 12\nBatch 10, Gradient norm: 15.0117\nEpoch 7, Batch 10/58, Loss: 24.5901\nAvg Blank Probability: 0.0152\nSample predictions: ['avUH', 'aFaIaj', 'aHaja']\nGround Truth (first 3): ['i6-V', 'JYhiG', 'atLM']\nRaw outputs (first 3): [[ 1  1  1 10  1  1  1 11  1  1  1  1 10  1  1  1  1  1  1  6  1 10 11  1\n   1  1  1  1  1  1 34  1]\n [ 1  1  1 10  1 10  1  1  1  1 10  1  1 32  1  1  1 63  1 10  1 10  1  1\n   1  4  4  1 10 11  1  1]\n [ 1  1  1  1  1 10  1  1  1  1 32 34  1  1  1 10 32 10  1  1 32  1 19 47\n   1  1  1  1 25  1  1  1]]\nInput length: 32, Label lengths: [4, 5, 4]\nToken distribution (Batch 0): {10: 2, 1: 5, 12: 1}, Pred length: 8\nToken distribution (Batch 1): {1: 7, 56: 1, 4: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 2): {1: 8, 32: 1, 34: 2, 22: 2, 10: 1}, Pred length: 14\nToken distribution (Batch 3): {43: 1, 19: 1, 1: 9, 10: 1}, Pred length: 12\nToken distribution (Batch 4): {10: 1, 1: 10, 27: 1, 19: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 5): {6: 1, 10: 1, 1: 5, 11: 1}, Pred length: 8\nToken distribution (Batch 6): {42: 1, 1: 12, 32: 1}, Pred length: 14\nToken distribution (Batch 7): {1: 9, 32: 1, 34: 1, 56: 1}, Pred length: 12\nToken distribution (Batch 8): {10: 1, 1: 5, 22: 2}, Pred length: 8\nToken distribution (Batch 9): {10: 2, 1: 10, 6: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 10): {32: 2, 1: 8, 6: 1, 35: 1}, Pred length: 12\nToken distribution (Batch 11): {1: 5, 10: 2, 19: 1, 34: 3, 11: 1}, Pred length: 12\nToken distribution (Batch 12): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 13): {1: 13, 10: 1}, Pred length: 14\nToken distribution (Batch 14): {1: 8, 10: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 15): {32: 2, 47: 1, 1: 6, 34: 1, 22: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 16): {63: 1, 1: 7, 32: 2}, Pred length: 10\nToken distribution (Batch 17): {10: 1, 1: 8, 47: 1}, Pred length: 10\nToken distribution (Batch 18): {1: 4, 10: 2, 32: 1, 23: 1, 47: 1, 19: 1, 11: 1, 56: 1}, Pred length: 12\nToken distribution (Batch 19): {1: 12, 19: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 20): {1: 8, 10: 3, 11: 2, 32: 1}, Pred length: 14\nToken distribution (Batch 21): {10: 1, 1: 9, 35: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 22): {1: 11, 42: 1, 32: 1, 27: 1}, Pred length: 14\nToken distribution (Batch 23): {6: 2, 1: 7, 10: 3, 35: 1, 11: 1}, Pred length: 14\nToken distribution (Batch 24): {11: 1, 1: 7, 27: 2, 10: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 25): {1: 7, 10: 2, 19: 1, 4: 2, 11: 1, 27: 1}, Pred length: 14\nToken distribution (Batch 26): {1: 8, 10: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 27): {11: 1, 47: 1, 43: 1, 1: 4, 10: 1}, Pred length: 8\nToken distribution (Batch 28): {4: 1, 1: 6, 19: 1, 42: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 29): {11: 1, 1: 5, 32: 2, 34: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 10}, Pred length: 10\nToken distribution (Batch 31): {1: 7, 32: 1, 47: 2, 34: 1, 6: 1}, Pred length: 12\nBatch 20, Gradient norm: 14.4130\nEpoch 7, Batch 20/58, Loss: 24.2624\nAvg Blank Probability: 0.0153\nSample predictions: ['jajala', 'a3daj', 'aFHavHja']\nGround Truth (first 3): ['OjOd', 'tK0IR', 'o9nI10H']\nRaw outputs (first 3): [[10  1  1 43 10  6 42  1 10 10 32  1  1  1  1 32 63 10  1  1  1 10  1  6\n  11  1  1 11  4 11  1  1]\n [ 1  1  1 19  1 10  1  1  1  1  1 10  1  1  1 47  1  1  1  1  1  1  1  1\n   1 10  1 47  1  1  1  1]\n [10  1 32  1  1  1  1  1  1  1  1 19  1  1  1  1  1  1 10  1 10  1 42  1\n   1  1  1 43  1  1  1  1]]\nInput length: 32, Label lengths: [4, 5, 7]\nToken distribution (Batch 0): {4: 1, 1: 8, 10: 2, 19: 1}, Pred length: 12\nToken distribution (Batch 1): {1: 7, 10: 2, 34: 1}, Pred length: 10\nToken distribution (Batch 2): {1: 6, 10: 1, 56: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 5, 47: 1, 34: 1, 43: 1, 4: 1, 10: 1, 42: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 4): {10: 1, 1: 6, 11: 1, 19: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 5): {1: 5, 42: 1, 32: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 6): {1: 10, 10: 3, 32: 1}, Pred length: 14\nToken distribution (Batch 7): {1: 7, 32: 1, 56: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 8): {10: 1, 1: 9}, Pred length: 10\nToken distribution (Batch 9): {11: 3, 1: 6, 10: 3}, Pred length: 12\nToken distribution (Batch 10): {1: 8, 34: 2}, Pred length: 10\nToken distribution (Batch 11): {1: 8}, Pred length: 8\nToken distribution (Batch 12): {32: 1, 1: 7, 10: 3, 27: 1}, Pred length: 12\nToken distribution (Batch 13): {10: 1, 1: 6, 34: 1}, Pred length: 8\nToken distribution (Batch 14): {10: 3, 1: 3, 6: 1, 34: 1, 19: 1, 42: 1}, Pred length: 10\nToken distribution (Batch 15): {1: 7, 10: 5}, Pred length: 12\nToken distribution (Batch 16): {34: 2, 10: 1, 1: 10, 47: 1}, Pred length: 14\nToken distribution (Batch 17): {1: 10, 19: 1, 4: 1}, Pred length: 12\nToken distribution (Batch 18): {10: 2, 1: 9, 25: 1, 32: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 19): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 20): {1: 5, 6: 1, 22: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 21): {10: 3, 56: 1, 1: 5, 32: 1, 43: 1, 48: 1}, Pred length: 12\nToken distribution (Batch 22): {1: 8, 32: 2, 35: 1, 56: 1}, Pred length: 12\nToken distribution (Batch 23): {1: 8, 10: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 24): {1: 7, 11: 1}, Pred length: 8\nToken distribution (Batch 25): {1: 8, 43: 1, 22: 1, 4: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 26): {10: 1, 1: 9, 4: 1, 11: 1, 34: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 27): {30: 1, 1: 4, 43: 1, 10: 4, 32: 1, 11: 1}, Pred length: 12\nToken distribution (Batch 28): {1: 10, 34: 1, 6: 1}, Pred length: 12\nToken distribution (Batch 29): {10: 3, 1: 7, 32: 1, 6: 1}, Pred length: 12\nToken distribution (Batch 30): {1: 11, 35: 1, 34: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 31): {1: 5, 10: 2, 34: 1, 47: 1, 50: 1}, Pred length: 10\nBatch 30, Gradient norm: 16.9749\nEpoch 7, Batch 30/58, Loss: 25.6306\nAvg Blank Probability: 0.0154\nSample predictions: ['dajasj', 'ajHaj', 'aja3a']\nGround Truth (first 3): ['XgEbSn', '1vYi6', 'HW-t']\nRaw outputs (first 3): [[ 4  1  1  1 10  1  1  1 10 11  1  1 32 10 10  1 34  1 10  1  1 10  1  1\n   1  1 10 30  1 10  1  1]\n [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 10  1 10  1  1 10  1  1\n   1 43  1  1  1  1  1 10]\n [ 1  1  1 47  1  1  1  1  1 10  1  1  1  1  6  1  1  1  1  1  6 56  1  1\n   1 22  4 43 34  1  1 34]]\nInput length: 32, Label lengths: [6, 5, 4]\nToken distribution (Batch 0): {1: 13, 10: 1}, Pred length: 14\nToken distribution (Batch 1): {1: 8, 32: 2, 10: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 2): {1: 4, 4: 2, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 11, 34: 1}, Pred length: 12\nToken distribution (Batch 4): {1: 7, 35: 1, 32: 1, 47: 2, 10: 1}, Pred length: 12\nToken distribution (Batch 5): {1: 12, 10: 2}, Pred length: 14\nToken distribution (Batch 6): {1: 6, 10: 1, 47: 1, 32: 1, 25: 1, 11: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 7): {6: 1, 32: 1, 1: 6}, Pred length: 8\nToken distribution (Batch 8): {19: 1, 10: 2, 1: 5, 27: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 10, 4: 1, 10: 1, 22: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 10): {1: 5, 10: 1, 34: 1, 11: 1}, Pred length: 8\nToken distribution (Batch 11): {1: 8, 34: 1, 10: 2, 27: 1, 47: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 12): {1: 10, 47: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 13): {10: 2, 1: 4, 19: 1, 32: 1, 34: 2}, Pred length: 10\nToken distribution (Batch 14): {1: 8, 47: 1, 10: 2, 50: 1, 34: 1, 19: 1}, Pred length: 14\nToken distribution (Batch 15): {1: 7, 10: 3, 6: 1, 32: 3}, Pred length: 14\nToken distribution (Batch 16): {1: 8, 32: 2, 35: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 17): {34: 1, 1: 5, 11: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 18): {63: 1, 47: 1, 1: 6, 32: 1, 11: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 9, 32: 2, 22: 1}, Pred length: 12\nToken distribution (Batch 20): {1: 10, 32: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 21): {1: 10, 34: 1, 10: 2, 32: 1}, Pred length: 14\nToken distribution (Batch 22): {1: 5, 10: 1, 42: 1, 11: 2, 55: 1, 32: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 23): {1: 9, 47: 1, 6: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 24): {10: 1, 1: 5, 34: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 25): {1: 11, 11: 1}, Pred length: 12\nToken distribution (Batch 26): {1: 9, 34: 2, 10: 2, 32: 1}, Pred length: 14\nToken distribution (Batch 27): {1: 7, 6: 1, 34: 2}, Pred length: 10\nToken distribution (Batch 28): {47: 1, 1: 9, 10: 1, 4: 1}, Pred length: 12\nToken distribution (Batch 29): {1: 9, 11: 1, 22: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 30): {1: 6, 4: 2, 6: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 31): {1: 9, 47: 1}, Pred length: 10\nBatch 40, Gradient norm: 14.0689\nEpoch 7, Batch 40/58, Loss: 24.4299\nAvg Blank Probability: 0.0154\nSample predictions: ['aja', 'aFajFaU', 'adjaF']\nGround Truth (first 3): ['pWKS6fp', '1C49cr', 'XAW2']\nRaw outputs (first 3): [[ 1  1  1  1  1  1  1  6 19  1  1  1  1 10  1  1  1 34 63  1  1  1  1  1\n  10  1  1  1 47  1  1  1]\n [ 1  1  1  1 35  1  1 32 10  1 10 34  1  1  1 10  1  1 47  1  1  1 10 47\n   1  1  1  1  1  1  4  1]\n [ 1  1  4  1 32  1  1  1  1  4  1  1  1  1 47 10 32  1  1  1  1 34  1  1\n   1  1  1  1  1  1  6  1]]\nInput length: 32, Label lengths: [7, 6, 4]\nToken distribution (Batch 0): {1: 2, 19: 2, 10: 2, 6: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 1): {1: 7, 22: 1, 34: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 2): {11: 1, 1: 7, 10: 2}, Pred length: 10\nToken distribution (Batch 3): {1: 9, 47: 2, 32: 1, 27: 1, 19: 1}, Pred length: 14\nToken distribution (Batch 4): {1: 11, 42: 1, 32: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 5): {1: 8, 4: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 6): {1: 4, 10: 2, 47: 1, 7: 1}, Pred length: 8\nToken distribution (Batch 7): {1: 10}, Pred length: 10\nToken distribution (Batch 8): {10: 1, 1: 6, 34: 1}, Pred length: 8\nToken distribution (Batch 9): {1: 7, 10: 3, 42: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 7, 56: 1, 32: 2}, Pred length: 10\nToken distribution (Batch 11): {1: 5, 10: 1, 34: 2}, Pred length: 8\nToken distribution (Batch 12): {1: 13, 32: 1}, Pred length: 14\nToken distribution (Batch 13): {47: 1, 1: 5, 19: 1, 32: 1, 10: 2, 42: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 14): {6: 1, 1: 9, 10: 1, 25: 1}, Pred length: 12\nToken distribution (Batch 15): {1: 9, 56: 1, 27: 2}, Pred length: 12\nToken distribution (Batch 16): {10: 2, 1: 6, 56: 1, 6: 1, 47: 1, 5: 1}, Pred length: 12\nToken distribution (Batch 17): {47: 1, 1: 10, 10: 1}, Pred length: 12\nToken distribution (Batch 18): {10: 2, 1: 5, 34: 1}, Pred length: 8\nToken distribution (Batch 19): {1: 7, 10: 3}, Pred length: 10\nToken distribution (Batch 20): {32: 1, 1: 9, 47: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 21): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 22): {1: 9, 47: 1, 32: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 23): {63: 1, 1: 7, 10: 1, 19: 1, 35: 1, 56: 1}, Pred length: 12\nToken distribution (Batch 24): {10: 4, 1: 7, 43: 2, 5: 1}, Pred length: 14\nToken distribution (Batch 25): {11: 2, 6: 1, 10: 4, 1: 5}, Pred length: 12\nToken distribution (Batch 26): {1: 6, 10: 3, 19: 2, 63: 1}, Pred length: 12\nToken distribution (Batch 27): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 28): {27: 2, 1: 9, 10: 2, 6: 1}, Pred length: 14\nToken distribution (Batch 29): {1: 5, 10: 2, 32: 1}, Pred length: 8\nToken distribution (Batch 30): {1: 9, 32: 1, 5: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 31): {1: 5, 6: 1, 42: 1, 4: 1, 34: 1, 22: 1}, Pred length: 10\nBatch 50, Gradient norm: 15.7373\nEpoch 7, Batch 50/58, Loss: 25.8319\nAvg Blank Probability: 0.0156\nSample predictions: ['asjfFaj', 'avHUa', 'kaja']\nGround Truth (first 3): ['aT2T', '3GoZl', '1nqnE']\nRaw outputs (first 3): [[ 1  1 11  1  1  1  1  1 10  1  1  1  1 47  6  1 10 47 10  1 32  1  1 63\n  10 11  1  1 27  1  1  1]\n [19  1  1  1 42  1 10  1  1 10  1  1  1  1  1  1  1  1 10  1  1  1 47  1\n   1  6  1  1  1  1 32  1]\n [19  1  1  1  1  1 10  1  1  1  1  1  1 19 10  1 10  1  1  1  1  1  1 10\n   1 10 10 32  1 10  1  1]]\nInput length: 32, Label lengths: [4, 5, 5]\nEpoch 7/20, Loss: 25.2853\nToken distribution (Batch 0): {1: 14}, Pred length: 14\nToken distribution (Batch 1): {1: 14}, Pred length: 14\nToken distribution (Batch 2): {1: 14}, Pred length: 14\nToken distribution (Batch 3): {1: 10}, Pred length: 10\nToken distribution (Batch 4): {1: 14}, Pred length: 14\nToken distribution (Batch 5): {1: 10}, Pred length: 10\nToken distribution (Batch 6): {1: 10}, Pred length: 10\nToken distribution (Batch 7): {1: 10}, Pred length: 10\nToken distribution (Batch 8): {1: 12}, Pred length: 12\nToken distribution (Batch 9): {1: 14}, Pred length: 14\nValidation Loss: 25.8480\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['5JyGVvd', 'fqFFV7y', 'PZ8JfWD', 'LCU9C', 'dzSL99R']\nCurrent Learning Rate: 3.0733805946674194e-07\nEpoch 8, Filtered data size: 2287, Sample labels: ['qV8ib8H', 'MdI8', '0tcL2']\nTrain size: 1829, Val size: 458\nToken distribution (Batch 0): {1: 7, 47: 1, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 1): {1: 9, 19: 1, 56: 1, 42: 1}, Pred length: 12\nToken distribution (Batch 2): {1: 11, 10: 2, 27: 1}, Pred length: 14\nToken distribution (Batch 3): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 4): {1: 5, 10: 1, 4: 1, 56: 1}, Pred length: 8\nToken distribution (Batch 5): {1: 6, 12: 1, 27: 1}, Pred length: 8\nToken distribution (Batch 6): {10: 4, 1: 9, 32: 1}, Pred length: 14\nToken distribution (Batch 7): {1: 10, 32: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 8): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 9): {1: 12, 6: 1, 22: 1}, Pred length: 14\nToken distribution (Batch 10): {34: 1, 1: 7, 10: 2, 42: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 11): {1: 7, 4: 1, 22: 1, 32: 1, 47: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 12): {1: 6, 10: 1, 19: 1}, Pred length: 8\nToken distribution (Batch 13): {1: 6, 35: 1, 32: 1, 11: 1, 34: 2, 10: 1}, Pred length: 12\nToken distribution (Batch 14): {1: 11, 34: 1, 10: 1, 56: 1}, Pred length: 14\nToken distribution (Batch 15): {1: 8, 34: 1, 10: 3, 47: 1, 19: 1}, Pred length: 14\nToken distribution (Batch 16): {32: 1, 10: 1, 22: 1, 1: 5, 11: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 17): {4: 1, 1: 9, 6: 1, 35: 1}, Pred length: 12\nToken distribution (Batch 18): {1: 5, 19: 1, 34: 1, 10: 1, 11: 1, 32: 1, 6: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 19): {1: 8, 10: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 21): {1: 4, 32: 1, 10: 2, 47: 1}, Pred length: 8\nToken distribution (Batch 22): {1: 7, 19: 1, 5: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 23): {1: 7, 35: 1, 10: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 24): {4: 1, 1: 5, 34: 1, 50: 1, 19: 2}, Pred length: 10\nToken distribution (Batch 25): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 26): {1: 9, 43: 1, 19: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 27): {1: 9, 32: 1}, Pred length: 10\nToken distribution (Batch 28): {1: 8, 43: 1, 32: 1, 10: 1, 55: 1}, Pred length: 12\nToken distribution (Batch 29): {1: 6, 22: 1, 4: 1, 6: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 9, 47: 1, 35: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 31): {1: 8, 4: 1, 32: 1, 10: 2, 35: 1, 47: 1}, Pred length: 14\nBatch 0, Gradient norm: 14.9593\nEpoch 8, Batch 0/58, Loss: 25.4071\nAvg Blank Probability: 0.0155\nSample predictions: ['aUajFa', 'as3aP', 'ajajaA']\nGround Truth (first 3): ['HOxCf', 'pXkGAC', 'DUE0Jpe']\nRaw outputs (first 3): [[ 1  1  1  1  1  1 10  1  1  1 34  1  1  1  1  1 32  4  1  1  1  1  1  1\n   4  1  1  1  1  1  1  1]\n [ 1  1  1  1  1  1  1  1 10  1  1  4  1  1  1  1 10  1  1  1  1 32  1  1\n   1  1 43  1  1  1  1  4]\n [ 1  1  1  1  1 12  1 32  1  1 10 22 10  1  1  1 22  1  1 10  1  1  1  1\n  34  1  1  1 43 22  1 32]]\nInput length: 32, Label lengths: [5, 6, 7]\nToken distribution (Batch 0): {1: 8, 10: 2, 47: 1, 35: 1}, Pred length: 12\nToken distribution (Batch 1): {1: 8, 10: 2, 32: 1, 50: 1, 34: 2}, Pred length: 14\nToken distribution (Batch 2): {1: 6, 4: 1, 10: 2, 34: 1, 47: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 3): {34: 2, 1: 5, 11: 1, 10: 2}, Pred length: 10\nToken distribution (Batch 4): {1: 5, 43: 1, 4: 2}, Pred length: 8\nToken distribution (Batch 5): {10: 3, 1: 6, 32: 1}, Pred length: 10\nToken distribution (Batch 6): {1: 9, 10: 2, 34: 1}, Pred length: 12\nToken distribution (Batch 7): {1: 3, 32: 1, 10: 1, 47: 1, 22: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 8): {1: 7, 47: 1, 6: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 9, 42: 1, 32: 2, 22: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 10): {1: 7, 34: 1}, Pred length: 8\nToken distribution (Batch 11): {1: 8, 4: 1, 10: 1, 34: 2, 47: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 12): {1: 8}, Pred length: 8\nToken distribution (Batch 13): {1: 9, 22: 1}, Pred length: 10\nToken distribution (Batch 14): {1: 3, 10: 1, 6: 1, 22: 2, 34: 1}, Pred length: 8\nToken distribution (Batch 15): {1: 7, 4: 1, 34: 1, 47: 1, 10: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 16): {1: 7, 10: 2, 27: 1, 32: 1, 22: 2, 19: 1}, Pred length: 14\nToken distribution (Batch 17): {1: 11, 19: 1, 27: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 18): {1: 7, 19: 1, 11: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 5, 10: 1, 34: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 20): {1: 9, 47: 3, 12: 1, 5: 1}, Pred length: 14\nToken distribution (Batch 21): {47: 2, 27: 1, 1: 9}, Pred length: 12\nToken distribution (Batch 22): {32: 1, 1: 7, 11: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 23): {1: 8, 32: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 24): {34: 1, 47: 2, 1: 7, 12: 1, 32: 2, 10: 1}, Pred length: 14\nToken distribution (Batch 25): {35: 1, 1: 7, 10: 3, 55: 1}, Pred length: 12\nToken distribution (Batch 26): {1: 6, 10: 3, 47: 1, 34: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 27): {1: 5, 32: 3, 22: 2, 10: 2, 56: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 28): {1: 6, 32: 1, 56: 1, 50: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 29): {63: 1, 1: 10, 10: 1}, Pred length: 12\nToken distribution (Batch 30): {6: 1, 10: 2, 1: 5, 34: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 31): {10: 1, 1: 7}, Pred length: 8\nBatch 10, Gradient norm: 16.1297\nEpoch 8, Batch 10/58, Loss: 25.4574\nAvg Blank Probability: 0.0157\nSample predictions: ['ajUajaI', 'ajaFajXHaH', 'adjHjaUava']\nGround Truth (first 3): ['2Y09-2', 'NphivvM', 'XgU7oz']\nRaw outputs (first 3): [[ 1  1  1 34  1 10  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 47 32  1\n  34 35  1  1  1 63  6 10]\n [ 1 10  4 34  1 10  1 32 47  1  1  4  1  1 10  1 10  1  1  1 47 47  1  1\n  47  1  1  1 32  1 10  1]\n [ 1  1 10  1 43  1  1  1  6  1  1 10  1  1  6  4 10  1 19  1  1 27 11 32\n   1 10  1 32  1  1  1  1]]\nInput length: 32, Label lengths: [6, 7, 6]\nToken distribution (Batch 0): {10: 1, 1: 5, 32: 2}, Pred length: 8\nToken distribution (Batch 1): {1: 8, 10: 2, 47: 1, 4: 1, 27: 1, 11: 1}, Pred length: 14\nToken distribution (Batch 2): {1: 6, 10: 2}, Pred length: 8\nToken distribution (Batch 3): {1: 6, 10: 2, 19: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 4): {1: 6, 10: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 5): {1: 10, 11: 1, 27: 1, 10: 2}, Pred length: 14\nToken distribution (Batch 6): {1: 8, 47: 1, 19: 1}, Pred length: 10\nToken distribution (Batch 7): {1: 6, 19: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 8): {1: 9, 56: 1, 11: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 9): {4: 1, 1: 8, 5: 2, 10: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 4, 6: 1, 4: 1, 43: 1, 34: 1, 10: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 11): {1: 7, 32: 1, 11: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 12): {1: 10}, Pred length: 10\nToken distribution (Batch 13): {1: 12, 35: 1, 42: 1}, Pred length: 14\nToken distribution (Batch 14): {1: 5, 6: 1, 47: 2, 10: 1, 42: 1}, Pred length: 10\nToken distribution (Batch 15): {10: 1, 47: 1, 11: 1, 56: 1, 1: 3, 4: 1}, Pred length: 8\nToken distribution (Batch 16): {1: 8, 4: 1, 5: 1}, Pred length: 10\nToken distribution (Batch 17): {1: 5, 6: 1, 34: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 18): {1: 5, 22: 1, 34: 1, 10: 2, 47: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 8, 11: 1, 4: 1, 32: 2, 19: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 20): {1: 8, 34: 1, 32: 2, 10: 1}, Pred length: 12\nToken distribution (Batch 21): {1: 8, 10: 2}, Pred length: 10\nToken distribution (Batch 22): {10: 2, 1: 10, 22: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 23): {1: 10, 34: 1, 32: 2, 10: 1}, Pred length: 14\nToken distribution (Batch 24): {1: 8, 10: 1, 32: 1, 19: 1, 4: 1}, Pred length: 12\nToken distribution (Batch 25): {10: 2, 1: 9, 32: 1, 22: 1, 19: 1}, Pred length: 14\nToken distribution (Batch 26): {1: 8, 10: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 27): {34: 2, 1: 7, 42: 1, 10: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 28): {1: 13, 10: 1}, Pred length: 14\nToken distribution (Batch 29): {1: 7, 56: 1, 19: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 30): {34: 2, 1: 8, 56: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 31): {11: 1, 1: 7}, Pred length: 8\nBatch 20, Gradient norm: 18.2086\nEpoch 8, Batch 20/58, Loss: 25.6711\nAvg Blank Probability: 0.0157\nSample predictions: ['jaFa', 'ajaUdaAajak', 'aj']\nGround Truth (first 3): ['62FH', 'uypDKxc', '9*Si']\nRaw outputs (first 3): [[10  1  1  1  1  1  1  1  1  4  1  1  1  1  1 10  1  1  1  1  1  1 10  1\n   1 10  1 34  1  1 34 11]\n [ 1  1  1  1 10  1 47 19  1  1  6  1  1  1  1 47  4  6 22 11  1  1  1  1\n  10  1  1  1  1  1  1  1]\n [ 1 10  1 10  1  1  1  1  1  1  4 32  1  1  1 11  1  1  1  1  1  1  1  1\n   1  1  1  1  1  1  1  1]]\nInput length: 32, Label lengths: [4, 7, 4]\nToken distribution (Batch 0): {10: 2, 1: 4, 56: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 1): {1: 2, 10: 1, 48: 1, 6: 1, 34: 1, 32: 3, 56: 1}, Pred length: 10\nToken distribution (Batch 2): {1: 9, 32: 1}, Pred length: 10\nToken distribution (Batch 3): {32: 1, 34: 2, 1: 10, 25: 1}, Pred length: 14\nToken distribution (Batch 4): {6: 1, 1: 11, 19: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 5): {1: 8, 10: 2, 50: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 6): {10: 2, 25: 1, 1: 5}, Pred length: 8\nToken distribution (Batch 7): {10: 1, 1: 6, 56: 1}, Pred length: 8\nToken distribution (Batch 8): {6: 1, 1: 5, 32: 2, 34: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 5, 11: 1, 10: 1, 34: 1, 56: 2}, Pred length: 10\nToken distribution (Batch 10): {1: 9, 27: 2, 32: 2, 10: 1}, Pred length: 14\nToken distribution (Batch 11): {10: 2, 1: 5, 47: 2, 42: 1}, Pred length: 10\nToken distribution (Batch 12): {1: 6, 43: 1, 34: 1, 19: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 13): {4: 2, 1: 5, 34: 2, 10: 1}, Pred length: 10\nToken distribution (Batch 14): {1: 4, 19: 1, 10: 2, 47: 1}, Pred length: 8\nToken distribution (Batch 15): {10: 3, 47: 1, 1: 3, 32: 1}, Pred length: 8\nToken distribution (Batch 16): {11: 1, 10: 2, 1: 3, 34: 1, 6: 1}, Pred length: 8\nToken distribution (Batch 17): {4: 1, 1: 5, 10: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 18): {63: 1, 1: 6, 10: 2, 32: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 4, 42: 1, 10: 2, 32: 1}, Pred length: 8\nToken distribution (Batch 20): {1: 9, 6: 1, 47: 2, 22: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 21): {1: 7, 47: 1}, Pred length: 8\nToken distribution (Batch 22): {1: 8, 4: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 23): {32: 3, 1: 8, 56: 1, 22: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 24): {1: 7, 10: 2, 34: 1, 32: 2}, Pred length: 12\nToken distribution (Batch 25): {10: 1, 1: 8, 22: 1}, Pred length: 10\nToken distribution (Batch 26): {1: 9, 32: 1}, Pred length: 10\nToken distribution (Batch 27): {1: 7, 10: 2, 47: 1}, Pred length: 10\nToken distribution (Batch 28): {10: 1, 1: 6, 32: 1}, Pred length: 8\nToken distribution (Batch 29): {1: 9, 4: 1}, Pred length: 10\nToken distribution (Batch 30): {10: 1, 1: 6, 19: 1}, Pred length: 8\nToken distribution (Batch 31): {11: 1, 1: 7, 19: 2, 10: 2}, Pred length: 12\nBatch 30, Gradient norm: 26.9394\nEpoch 8, Batch 30/58, Loss: 27.5650\nAvg Blank Probability: 0.0158\nSample predictions: ['jaja3Ua', 'ajVfaHF3', 'aFa']\nGround Truth (first 3): ['NY0Z', 'L2a69', 'vv9k0']\nRaw outputs (first 3): [[10  1  1 32  6  1 10 10  6  1  1 10  1  4  1 10 11  4 63  1 34  1  1 32\n   1 10  1  1 10  1 10 11]\n [ 1 10  1 34  1  1 25  1  1  1  1  1 43  1  1 47 10  1  1  1  1  1  1  1\n  10  1  1  1  1  1  1  1]\n [10 48  1  1  1  1  1  1 32  1  1 47 34  4  1  1 10  1 10 42  1  1  1 32\n   1  1  1  1 32  1  1  1]]\nInput length: 32, Label lengths: [4, 5, 5]\nToken distribution (Batch 0): {1: 10, 10: 2}, Pred length: 12\nToken distribution (Batch 1): {10: 3, 1: 8, 22: 1, 5: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 2): {1: 7, 32: 2, 11: 1}, Pred length: 10\nToken distribution (Batch 3): {1: 5, 10: 4, 34: 1, 32: 1, 11: 1}, Pred length: 12\nToken distribution (Batch 4): {1: 9, 56: 1, 11: 1, 32: 1, 47: 1, 42: 1}, Pred length: 14\nToken distribution (Batch 5): {1: 11, 6: 1}, Pred length: 12\nToken distribution (Batch 6): {1: 8, 6: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 7): {34: 2, 47: 2, 10: 3, 1: 5}, Pred length: 12\nToken distribution (Batch 8): {42: 1, 11: 1, 34: 1, 1: 5, 32: 2}, Pred length: 10\nToken distribution (Batch 9): {1: 10, 35: 1, 4: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 7, 34: 2, 10: 1, 11: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 11): {1: 8, 12: 1, 22: 1, 34: 1, 10: 2, 42: 1}, Pred length: 14\nToken distribution (Batch 12): {1: 5, 11: 1, 10: 2}, Pred length: 8\nToken distribution (Batch 13): {1: 6, 12: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 14): {1: 6, 10: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 15): {1: 12, 11: 1, 19: 1}, Pred length: 14\nToken distribution (Batch 16): {1: 6, 4: 1, 19: 1}, Pred length: 8\nToken distribution (Batch 17): {1: 5, 11: 1, 47: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 18): {1: 9, 56: 1, 32: 1, 10: 2, 4: 1}, Pred length: 14\nToken distribution (Batch 19): {1: 7, 35: 1, 10: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 7, 6: 1, 47: 1, 42: 1}, Pred length: 10\nToken distribution (Batch 21): {11: 2, 1: 10, 5: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 22): {1: 10, 27: 1, 32: 1, 4: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 23): {1: 7, 12: 1}, Pred length: 8\nToken distribution (Batch 24): {1: 5, 35: 1, 32: 2, 10: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 25): {1: 4, 47: 1, 42: 1, 32: 1, 35: 1}, Pred length: 8\nToken distribution (Batch 26): {4: 2, 1: 9, 27: 1}, Pred length: 12\nToken distribution (Batch 27): {11: 1, 1: 11}, Pred length: 12\nToken distribution (Batch 28): {19: 1, 1: 9, 32: 2, 10: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 29): {1: 9, 6: 1, 32: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 30): {1: 6, 10: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 31): {1: 6, 10: 3, 56: 1}, Pred length: 10\nBatch 40, Gradient norm: 19.6015\nEpoch 8, Batch 40/58, Loss: 25.4181\nAvg Blank Probability: 0.0159\nSample predictions: ['ajaj', 'jajaveaHja', 'aFakF']\nGround Truth (first 3): ['8xLIdo', 'GWKm5xJ', 'uTvjj']\nRaw outputs (first 3): [[ 1 10  1  1  1  1  1 34 42  1  1  1  1  1  1  1  1  1  1  1  1 11  1  1\n   1  1  4 11 19  1  1  1]\n [ 1  1  1  1  1  1  1 47 11  1  1 12 11  1 10 11  1  1 56  1  1  1 27 12\n   1 47  1  1  1  1 10 10]\n [ 1 10 32 10 56  1  1 10 34 35 34  1  1 12 34 19  1  1 32  1  6  1 32  1\n   1 42  4  1 32  6  1 10]]\nInput length: 32, Label lengths: [6, 7, 5]\nToken distribution (Batch 0): {1: 6, 10: 2}, Pred length: 8\nToken distribution (Batch 1): {35: 1, 1: 7, 11: 1, 19: 1}, Pred length: 10\nToken distribution (Batch 2): {11: 1, 1: 9, 47: 2, 27: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 3): {34: 1, 1: 5, 11: 1, 47: 2, 56: 1, 5: 1, 12: 1, 10: 1, 22: 1}, Pred length: 14\nToken distribution (Batch 4): {11: 1, 1: 7, 34: 1, 47: 2, 10: 1}, Pred length: 12\nToken distribution (Batch 5): {34: 1, 1: 5, 10: 1, 27: 1}, Pred length: 8\nToken distribution (Batch 6): {34: 1, 1: 7, 10: 1, 11: 1}, Pred length: 10\nToken distribution (Batch 7): {1: 7, 11: 1, 4: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 8): {1: 8, 34: 4, 56: 1, 5: 1}, Pred length: 14\nToken distribution (Batch 9): {1: 5, 32: 1, 6: 1, 11: 1}, Pred length: 8\nToken distribution (Batch 10): {56: 1, 10: 1, 19: 1, 1: 6, 34: 1}, Pred length: 10\nToken distribution (Batch 11): {47: 2, 1: 5, 10: 3, 4: 2, 34: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 12): {1: 8, 11: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 13): {10: 1, 1: 6, 47: 1}, Pred length: 8\nToken distribution (Batch 14): {1: 12}, Pred length: 12\nToken distribution (Batch 15): {25: 1, 1: 5, 10: 4, 34: 3, 35: 1}, Pred length: 14\nToken distribution (Batch 16): {47: 1, 1: 7, 34: 2}, Pred length: 10\nToken distribution (Batch 17): {1: 12, 32: 1, 56: 1}, Pred length: 14\nToken distribution (Batch 18): {1: 9, 43: 1, 10: 2}, Pred length: 12\nToken distribution (Batch 19): {1: 8, 42: 1, 10: 3}, Pred length: 12\nToken distribution (Batch 20): {1: 9, 4: 1, 32: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 21): {1: 5, 22: 1, 43: 1, 10: 1, 34: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 22): {1: 8, 56: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 23): {1: 11, 32: 1}, Pred length: 12\nToken distribution (Batch 24): {10: 1, 32: 3, 1: 3, 4: 1}, Pred length: 8\nToken distribution (Batch 25): {1: 6, 6: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 26): {1: 5, 12: 1, 10: 2, 4: 1, 42: 1, 47: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 27): {10: 4, 1: 7, 34: 1}, Pred length: 12\nToken distribution (Batch 28): {4: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 29): {10: 2, 1: 4, 34: 3, 32: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 7, 11: 1, 27: 1, 32: 1, 47: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 31): {1: 8, 22: 1, 4: 1}, Pred length: 10\nBatch 50, Gradient norm: 16.9165\nEpoch 8, Batch 50/58, Loss: 25.6544\nAvg Blank Probability: 0.0159\nSample predictions: ['ajaj', 'Iakasa', 'kaUaAUja']\nGround Truth (first 3): ['Hd*1', 'PUDVG', 'h7fqynH']\nRaw outputs (first 3): [[ 1 35 11 34 11 34 34  1  1  1 56 47  1 10  1 25 47  1  1  1  1  1  1  1\n  10  1  1 10  4 10  1  1]\n [ 1  1  1  1  1  1  1  1  1  1 10  1  1  1  1  1  1  1 43  1  1 22  1  1\n  32  6 12 10  1  1  1  1]\n [ 1  1  1  1  1  1 10  1 34  1 19 10  1  1  1  1  1  1 10  1  4  1  1  1\n   1  1 10  1  1 34 11  1]]\nInput length: 32, Label lengths: [4, 5, 7]\nEpoch 8/20, Loss: 25.2655\nToken distribution (Batch 0): {1: 14}, Pred length: 14\nToken distribution (Batch 1): {1: 12}, Pred length: 12\nToken distribution (Batch 2): {1: 14}, Pred length: 14\nToken distribution (Batch 3): {1: 8}, Pred length: 8\nToken distribution (Batch 4): {1: 12}, Pred length: 12\nToken distribution (Batch 5): {1: 12}, Pred length: 12\nToken distribution (Batch 6): {1: 12}, Pred length: 12\nToken distribution (Batch 7): {1: 12}, Pred length: 12\nToken distribution (Batch 8): {1: 12}, Pred length: 12\nToken distribution (Batch 9): {1: 14}, Pred length: 14\nValidation Loss: 25.5085\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['CI*V6hg', 'PpHvXw', 'Gqm1iZq', 'Smrs', 'ltc7Qh']\nCurrent Learning Rate: 3.5034880674243335e-07\nEpoch 9, Filtered data size: 2287, Sample labels: ['qV8ib8H', 'MdI8', '0tcL2']\nTrain size: 1829, Val size: 458\nToken distribution (Batch 0): {10: 5, 1: 7}, Pred length: 12\nToken distribution (Batch 1): {1: 10, 34: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 2): {1: 11, 47: 1, 11: 1, 22: 1}, Pred length: 14\nToken distribution (Batch 3): {10: 3, 42: 1, 1: 7, 32: 1}, Pred length: 12\nToken distribution (Batch 4): {63: 1, 1: 5, 6: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 5): {34: 2, 1: 6, 12: 1, 35: 1}, Pred length: 10\nToken distribution (Batch 6): {1: 9, 34: 1, 10: 1, 11: 1, 35: 1, 22: 1}, Pred length: 14\nToken distribution (Batch 7): {1: 9, 4: 1, 10: 2}, Pred length: 12\nToken distribution (Batch 8): {1: 9, 34: 1}, Pred length: 10\nToken distribution (Batch 9): {11: 1, 34: 1, 1: 8, 50: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 5, 34: 2, 47: 1, 32: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 11): {10: 1, 1: 6, 27: 1, 32: 2}, Pred length: 10\nToken distribution (Batch 12): {34: 1, 1: 8, 4: 1}, Pred length: 10\nToken distribution (Batch 13): {10: 4, 1: 6, 6: 1, 11: 1, 34: 2}, Pred length: 14\nToken distribution (Batch 14): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 15): {1: 7, 10: 2, 34: 1, 22: 1, 11: 1}, Pred length: 12\nToken distribution (Batch 16): {1: 7, 4: 1, 34: 1, 10: 2, 56: 1}, Pred length: 12\nToken distribution (Batch 17): {1: 9, 6: 1, 11: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 18): {10: 2, 32: 2, 1: 3, 34: 2, 43: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 6, 10: 1, 19: 1}, Pred length: 8\nToken distribution (Batch 20): {11: 1, 1: 8, 5: 1}, Pred length: 10\nToken distribution (Batch 21): {1: 9, 10: 2, 34: 1}, Pred length: 12\nToken distribution (Batch 22): {1: 5, 47: 1, 25: 1, 56: 1, 34: 2}, Pred length: 10\nToken distribution (Batch 23): {6: 1, 1: 10, 32: 1}, Pred length: 12\nToken distribution (Batch 24): {1: 10, 32: 2}, Pred length: 12\nToken distribution (Batch 25): {1: 10, 32: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 26): {1: 5, 35: 1, 10: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 27): {1: 6, 10: 2, 32: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 28): {10: 2, 1: 8, 19: 1, 22: 1, 32: 1, 50: 1}, Pred length: 14\nToken distribution (Batch 29): {1: 8, 34: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 30): {10: 1, 34: 2, 11: 1, 27: 1, 1: 6, 6: 1}, Pred length: 12\nToken distribution (Batch 31): {1: 8, 34: 2, 47: 1, 32: 2, 4: 1}, Pred length: 14\nBatch 0, Gradient norm: 19.3659\nEpoch 9, Batch 0/58, Loss: 24.7854\nAvg Blank Probability: 0.0160\nSample predictions: ['jajajajaja', 'aHava', 'aUakava']\nGround Truth (first 3): ['W1g7Mm', 'QhCCU0', '*x4ZOlo']\nRaw outputs (first 3): [[10  1  1 10 63 34  1  1  1 11  1 10 34 10  1  1  1  1 10  1 11  1  1  6\n   1  1  1  1 10  1 10  1]\n [ 1  1  1 42  1  1  1  1  1 34 34  1  1 10  1  1  1  1 10  1  1  1 47  1\n   1  1 35 10 10  1 34 34]\n [10  1 47  1  1  1  1  1  1  1 34  1  1 10 10 10  1  6 32 10  1  1 25  1\n   1  1 10  1  1  1 11  1]]\nInput length: 32, Label lengths: [6, 6, 7]\nToken distribution (Batch 0): {1: 7, 30: 1, 11: 2}, Pred length: 10\nToken distribution (Batch 1): {32: 1, 1: 7, 34: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 2): {10: 1, 1: 5, 34: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 10, 35: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 4): {11: 1, 34: 2, 1: 6, 10: 1, 42: 1, 56: 1, 32: 1, 19: 1}, Pred length: 14\nToken distribution (Batch 5): {12: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 6): {1: 6, 34: 1, 10: 1, 19: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 7): {1: 8, 10: 2, 34: 1, 5: 1}, Pred length: 12\nToken distribution (Batch 8): {1: 7, 10: 2, 19: 1, 27: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 9): {1: 12, 19: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 10): {1: 10, 34: 1, 6: 1, 4: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 11): {1: 5, 34: 1, 4: 1, 10: 3}, Pred length: 10\nToken distribution (Batch 12): {1: 9, 10: 2, 32: 2, 4: 1}, Pred length: 14\nToken distribution (Batch 13): {10: 2, 1: 5, 32: 1}, Pred length: 8\nToken distribution (Batch 14): {35: 1, 1: 10, 56: 1, 47: 1, 11: 1}, Pred length: 14\nToken distribution (Batch 15): {10: 4, 47: 1, 1: 9}, Pred length: 14\nToken distribution (Batch 16): {10: 2, 1: 4, 34: 2}, Pred length: 8\nToken distribution (Batch 17): {1: 7, 10: 1, 56: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 18): {1: 7, 47: 1}, Pred length: 8\nToken distribution (Batch 19): {34: 1, 1: 8, 19: 2, 24: 1}, Pred length: 12\nToken distribution (Batch 20): {1: 8}, Pred length: 8\nToken distribution (Batch 21): {1: 10, 35: 1, 5: 1}, Pred length: 12\nToken distribution (Batch 22): {1: 6, 35: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 23): {1: 7, 10: 1, 47: 1, 35: 1, 22: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 24): {1: 9, 4: 1, 56: 1, 12: 1}, Pred length: 12\nToken distribution (Batch 25): {1: 9, 27: 3, 22: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 26): {1: 8, 47: 1, 6: 1}, Pred length: 10\nToken distribution (Batch 27): {6: 1, 1: 5, 34: 2, 10: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 28): {6: 1, 1: 8, 10: 1, 56: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 29): {10: 2, 1: 6, 22: 2}, Pred length: 10\nToken distribution (Batch 30): {1: 13, 6: 1}, Pred length: 14\nToken distribution (Batch 31): {1: 13, 10: 1}, Pred length: 14\nBatch 10, Gradient norm: 20.2535\nEpoch 9, Batch 10/58, Loss: 25.1226\nAvg Blank Probability: 0.0162\nSample predictions: ['aDaka', 'FaHja', 'jaHaFa']\nGround Truth (first 3): ['x5BJD', '5ER9-', '4q1g']\nRaw outputs (first 3): [[ 1 32 10  1 11 12  1  1  1  1  1  1  1 10 35 10 10  1  1 34  1  1  1  1\n  22  1  1  6  6 10  1  1]\n [ 1  1  1  1 34  1  1 10  1  1 34  1  1  1  1 10 10 10  1  1  1  1  1  1\n   1  1 47  1  1  1  1  1]\n [30  1  1  1  1  1  1  1 10  1  1 34 10  1  1 47  1  1  1  1  1  1  1 10\n   4  1  1 34  1  1  1  1]]\nInput length: 32, Label lengths: [5, 5, 4]\nToken distribution (Batch 0): {10: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 1): {22: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 2): {1: 6, 19: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 3): {34: 2, 1: 10, 10: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 4): {1: 6, 47: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 5): {1: 8, 11: 2, 47: 1, 50: 1}, Pred length: 12\nToken distribution (Batch 6): {1: 5, 34: 2, 22: 1, 10: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 7): {32: 1, 1: 11, 11: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 8): {1: 9, 6: 1, 32: 1, 19: 1, 35: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 9): {1: 10, 10: 1, 50: 1, 32: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 10): {1: 7, 32: 1, 10: 1, 42: 1}, Pred length: 10\nToken distribution (Batch 11): {1: 8, 32: 1, 10: 3, 5: 1, 6: 1}, Pred length: 14\nToken distribution (Batch 12): {1: 8, 47: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 13): {1: 6, 34: 1, 32: 1, 6: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 14): {47: 1, 10: 2, 1: 11}, Pred length: 14\nToken distribution (Batch 15): {1: 10, 34: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 16): {56: 1, 10: 1, 1: 5, 6: 1, 34: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 17): {1: 6, 34: 1, 10: 6, 22: 1}, Pred length: 14\nToken distribution (Batch 18): {32: 1, 1: 2, 50: 1, 11: 1, 5: 1, 22: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 19): {34: 1, 22: 1, 1: 4, 35: 1, 56: 1, 4: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 7, 34: 1}, Pred length: 8\nToken distribution (Batch 21): {1: 10, 47: 1, 32: 1, 10: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 22): {1: 5, 34: 1, 19: 1, 4: 1, 32: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 23): {1: 10, 10: 2}, Pred length: 12\nToken distribution (Batch 24): {1: 8, 6: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 25): {10: 2, 1: 3, 30: 1, 5: 1, 34: 2, 32: 1}, Pred length: 10\nToken distribution (Batch 26): {1: 9, 34: 2, 32: 1}, Pred length: 12\nToken distribution (Batch 27): {1: 5, 11: 1, 34: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 28): {1: 13, 6: 1}, Pred length: 14\nToken distribution (Batch 29): {10: 2, 1: 9, 56: 1}, Pred length: 12\nToken distribution (Batch 30): {1: 8, 32: 1, 6: 1, 22: 1, 4: 1}, Pred length: 12\nToken distribution (Batch 31): {1: 8, 10: 3, 32: 1}, Pred length: 12\nBatch 20, Gradient norm: 18.4020\nEpoch 9, Batch 20/58, Loss: 25.2493\nAvg Blank Probability: 0.0162\nSample predictions: ['ja', 'va', 'asUa']\nGround Truth (first 3): ['4qqz', 'CBN6', 'k6H5']\nRaw outputs (first 3): [[10 22  1 34  1  1  1 32  1  1  1  1  1 10 47  1 56  1 32 34  1  1  1  1\n   1 10  1  1  1 10  1  1]\n [ 1  1  1  1  1 11 34  1  6 10 32  1  1  1 10  1 10  1  1 22  1  1 34  1\n   6 10  1 11  1  1  1  1]\n [ 1  1  1  1  1  1  1  1  1  1  1  1 47  1  1  1  1 34  1  1  1 47  1  1\n   1  1  1 34  1  1  1  1]]\nInput length: 32, Label lengths: [4, 4, 4]\nToken distribution (Batch 0): {34: 1, 1: 5, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 1): {1: 7, 32: 1, 10: 1, 34: 1, 19: 1, 6: 1}, Pred length: 12\nToken distribution (Batch 2): {10: 2, 1: 7, 19: 1, 47: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 3): {1: 5, 32: 2, 6: 1, 10: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 4): {1: 6, 6: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 5): {12: 1, 1: 4, 34: 1, 56: 1, 55: 1}, Pred length: 8\nToken distribution (Batch 6): {1: 6, 47: 2, 32: 2, 10: 1, 11: 1}, Pred length: 12\nToken distribution (Batch 7): {1: 7, 32: 1, 47: 1, 55: 1, 42: 1, 19: 2, 25: 1}, Pred length: 14\nToken distribution (Batch 8): {1: 5, 25: 1, 11: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 9): {11: 2, 1: 6, 34: 1, 32: 1, 47: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 7, 47: 1, 10: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 11): {1: 7, 4: 1, 32: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 12): {1: 11, 32: 1}, Pred length: 12\nToken distribution (Batch 13): {10: 4, 1: 8, 34: 1, 56: 1}, Pred length: 14\nToken distribution (Batch 14): {1: 6, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 15): {1: 7, 27: 1}, Pred length: 8\nToken distribution (Batch 16): {4: 1, 1: 7, 10: 2, 11: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 17): {1: 12, 47: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 18): {1: 7, 34: 2, 43: 1}, Pred length: 10\nToken distribution (Batch 19): {10: 2, 1: 4, 32: 1, 11: 1}, Pred length: 8\nToken distribution (Batch 20): {1: 9, 11: 1, 10: 1, 32: 1, 47: 1, 42: 1}, Pred length: 14\nToken distribution (Batch 21): {1: 7, 4: 1, 22: 1, 5: 1}, Pred length: 10\nToken distribution (Batch 22): {1: 8, 4: 3, 19: 1}, Pred length: 12\nToken distribution (Batch 23): {6: 1, 1: 7, 32: 3, 47: 1}, Pred length: 12\nToken distribution (Batch 24): {1: 5, 12: 1, 34: 1, 5: 1}, Pred length: 8\nToken distribution (Batch 25): {34: 1, 1: 6, 10: 2, 47: 1, 5: 1, 11: 1}, Pred length: 12\nToken distribution (Batch 26): {10: 2, 1: 6, 35: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 27): {1: 5, 34: 1, 10: 1, 43: 1}, Pred length: 8\nToken distribution (Batch 28): {1: 9, 10: 1, 6: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 29): {10: 2, 12: 1, 1: 5, 19: 1, 5: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 6, 12: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 31): {1: 4, 6: 1, 5: 1, 32: 4, 35: 1, 10: 2, 34: 1}, Pred length: 14\nBatch 30, Gradient norm: 22.8703\nEpoch 9, Batch 30/58, Loss: 26.2524\nAvg Blank Probability: 0.0163\nSample predictions: ['HajaF', 'aFjaHsafa', 'jasjaUaFa']\nGround Truth (first 3): ['fmjx', '6dOZFh', '*XwSXN']\nRaw outputs (first 3): [[34  1 10  1  1 12  1  1  1 11  1  1  1 10  1  1  4  1  1 10  1  1  1  6\n   1 34 10  1  1 10  1  1]\n [ 1 32  1 32  1  1 47 32 25  1  1  4  1  1  1  1  1  1 34  1 11  4  4  1\n  12  1  1  1  1 12 12  6]\n [ 1 10  1  1  6  1  1 47 11  1 47  1  1  1 10  1  1  1  1 32  1 22  1  1\n   1  1 10 34  1  1 10  5]]\nInput length: 32, Label lengths: [4, 6, 6]\nToken distribution (Batch 0): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 1): {34: 2, 1: 10}, Pred length: 12\nToken distribution (Batch 2): {6: 1, 1: 8, 32: 1, 10: 2}, Pred length: 12\nToken distribution (Batch 3): {1: 10, 32: 1, 56: 1}, Pred length: 12\nToken distribution (Batch 4): {10: 2, 1: 6, 6: 1, 19: 1, 4: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 5): {1: 7, 10: 3, 19: 1, 4: 1}, Pred length: 12\nToken distribution (Batch 6): {1: 6, 10: 2, 34: 1, 42: 1, 4: 2}, Pred length: 12\nToken distribution (Batch 7): {10: 4, 34: 1, 1: 8, 6: 1}, Pred length: 14\nToken distribution (Batch 8): {63: 1, 1: 3, 19: 2, 42: 1, 47: 2, 34: 1, 6: 1, 10: 1, 11: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 9): {1: 6, 22: 1, 34: 1, 32: 1, 50: 1}, Pred length: 10\nToken distribution (Batch 10): {1: 9, 10: 2, 27: 1, 11: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 11): {1: 8, 34: 1, 10: 2, 32: 1}, Pred length: 12\nToken distribution (Batch 12): {1: 9, 10: 2, 4: 1, 34: 1, 11: 1}, Pred length: 14\nToken distribution (Batch 13): {1: 8, 10: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 14): {10: 2, 47: 1, 1: 8, 32: 1}, Pred length: 12\nToken distribution (Batch 15): {1: 7, 47: 3, 11: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 16): {32: 1, 34: 1, 1: 6, 10: 2, 27: 1, 4: 1}, Pred length: 12\nToken distribution (Batch 17): {1: 5, 32: 3}, Pred length: 8\nToken distribution (Batch 18): {1: 6, 32: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 19): {1: 8, 35: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 20): {47: 1, 10: 2, 1: 3, 32: 2}, Pred length: 8\nToken distribution (Batch 21): {1: 7, 32: 2, 19: 1, 4: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 22): {1: 9, 10: 3}, Pred length: 12\nToken distribution (Batch 23): {1: 6, 10: 3, 43: 1, 11: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 24): {10: 1, 1: 8, 56: 1, 32: 2}, Pred length: 12\nToken distribution (Batch 25): {1: 11, 22: 1}, Pred length: 12\nToken distribution (Batch 26): {1: 6, 34: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 27): {10: 1, 1: 7, 47: 2, 19: 1, 56: 1}, Pred length: 12\nToken distribution (Batch 28): {1: 11, 34: 1, 27: 1, 22: 1}, Pred length: 14\nToken distribution (Batch 29): {1: 5, 12: 1, 32: 1, 35: 1}, Pred length: 8\nToken distribution (Batch 30): {1: 8, 10: 1, 11: 1}, Pred length: 10\nToken distribution (Batch 31): {1: 7, 10: 3, 34: 1, 32: 1}, Pred length: 12\nBatch 40, Gradient norm: 15.9258\nEpoch 9, Batch 40/58, Loss: 24.5943\nAvg Blank Probability: 0.0164\nSample predictions: ['aja', 'HaHa', 'faFajaja']\nGround Truth (first 3): ['-*Oj', 'ORPu7p', 'lM5P5a']\nRaw outputs (first 3): [[ 1 34  6  1 10  1  1 10 63  1  1  1  1  1 10  1 10  1  1  1 47  1  1  1\n  10  1  1 10  1  1  1  1]\n [ 1  1  1  1  1  1 10 10  1  1  1  1 10 10 47  1 32  1  1  1 10  1  1 10\n   1  1  1  1  1  1  1 10]\n [ 1  1  1 32  1 10 34 34 19 22  1 34 10  1  1  1 34  1  1  1  1  1  1 10\n  56  1  1 47  1  1  1  1]]\nInput length: 32, Label lengths: [4, 6, 6]\nToken distribution (Batch 0): {1: 8, 10: 4}, Pred length: 12\nToken distribution (Batch 1): {1: 7, 32: 1, 56: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 2): {34: 1, 1: 10, 48: 1, 47: 1, 5: 1}, Pred length: 14\nToken distribution (Batch 3): {1: 9, 34: 2, 11: 1}, Pred length: 12\nToken distribution (Batch 4): {1: 9, 34: 1, 47: 1, 48: 1}, Pred length: 12\nToken distribution (Batch 5): {56: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 6): {1: 5, 47: 1, 6: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 7): {11: 1, 1: 7, 22: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 8): {34: 1, 1: 9, 22: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 9): {1: 5, 32: 1, 43: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 10): {1: 5, 34: 1, 10: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 11): {32: 1, 1: 6, 10: 1}, Pred length: 8\nToken distribution (Batch 12): {1: 7, 34: 1, 32: 2, 27: 1, 10: 1, 5: 1, 55: 1}, Pred length: 14\nToken distribution (Batch 13): {1: 8, 34: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 14): {11: 1, 1: 9, 56: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 15): {1: 3, 4: 1, 47: 2, 56: 1, 19: 1, 32: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 16): {1: 6, 22: 1, 32: 1, 5: 1, 11: 1}, Pred length: 10\nToken distribution (Batch 17): {6: 1, 1: 9, 4: 1, 10: 2, 32: 1}, Pred length: 14\nToken distribution (Batch 18): {1: 7, 10: 1, 4: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 19): {10: 1, 1: 8, 32: 2, 34: 1}, Pred length: 12\nToken distribution (Batch 20): {10: 1, 11: 1, 1: 5, 34: 1}, Pred length: 8\nToken distribution (Batch 21): {1: 9, 10: 3, 27: 1, 4: 1}, Pred length: 14\nToken distribution (Batch 22): {1: 10, 42: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 23): {1: 5, 22: 1, 34: 2}, Pred length: 8\nToken distribution (Batch 24): {1: 8}, Pred length: 8\nToken distribution (Batch 25): {1: 9, 11: 2, 10: 1, 56: 1, 12: 1}, Pred length: 14\nToken distribution (Batch 26): {34: 1, 1: 7, 10: 1, 56: 1, 32: 2}, Pred length: 12\nToken distribution (Batch 27): {6: 1, 27: 2, 1: 2, 32: 2, 22: 1}, Pred length: 8\nToken distribution (Batch 28): {1: 5, 42: 1, 10: 2, 32: 2, 34: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 29): {1: 7, 34: 1, 10: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 7, 19: 1}, Pred length: 8\nToken distribution (Batch 31): {1: 8, 47: 2, 6: 1, 56: 1}, Pred length: 12\nBatch 50, Gradient norm: 29.6762\nEpoch 9, Batch 50/58, Loss: 26.2476\nAvg Blank Probability: 0.0165\nSample predictions: ['aj', 'aFa3ja', 'HaVUaea']\nGround Truth (first 3): ['to20hX', 'Dhn2E', 'PLY7AxX']\nRaw outputs (first 3): [[34  1 34  1  1 56  1 11 34  1  1 32  1  1 11  1  1  6  1 10 10  1  1  1\n   1  1 34  6  1 34  1  1]\n [ 1  1  1 34  1  1  1  1  1  1  1  1 34  1  1  1  1  1  1  1 11  1  1  1\n   1 11  1 27 42  1  1  1]\n [ 1  1  1  1  1  1  1  1  1 32 34  1  1  1  1  4  1  1  1  1  1  1  1 22\n   1 10  1  1 10 34  1  1]]\nInput length: 32, Label lengths: [6, 5, 7]\nEpoch 9/20, Loss: 25.2572\nToken distribution (Batch 0): {1: 8}, Pred length: 8\nToken distribution (Batch 1): {1: 8}, Pred length: 8\nToken distribution (Batch 2): {1: 12}, Pred length: 12\nToken distribution (Batch 3): {1: 12}, Pred length: 12\nToken distribution (Batch 4): {1: 10}, Pred length: 10\nToken distribution (Batch 5): {1: 10}, Pred length: 10\nToken distribution (Batch 6): {1: 8}, Pred length: 8\nToken distribution (Batch 7): {1: 10}, Pred length: 10\nToken distribution (Batch 8): {1: 14}, Pred length: 14\nToken distribution (Batch 9): {1: 8}, Pred length: 8\nValidation Loss: 25.4149\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['8ZME', 't4hU', '6bqtTF', 'vIomlo', 'nABah']\nCurrent Learning Rate: 3.8159387616300736e-07\nEpoch 10, Filtered data size: 2287, Sample labels: ['qV8ib8H', 'MdI8', '0tcL2']\nTrain size: 1829, Val size: 458\nToken distribution (Batch 0): {19: 1, 10: 1, 1: 7, 32: 2, 6: 1}, Pred length: 12\nToken distribution (Batch 1): {1: 11, 34: 1, 6: 2}, Pred length: 14\nToken distribution (Batch 2): {6: 1, 1: 8, 22: 1, 34: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 3): {10: 4, 1: 9, 35: 1}, Pred length: 14\nToken distribution (Batch 4): {34: 1, 1: 7, 10: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 5): {1: 11, 10: 1}, Pred length: 12\nToken distribution (Batch 6): {1: 8, 11: 3, 32: 2, 34: 1}, Pred length: 14\nToken distribution (Batch 7): {63: 1, 1: 8, 34: 1, 50: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 8): {1: 6, 6: 1, 47: 1, 22: 1, 32: 1, 10: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 9): {1: 9, 10: 2, 56: 1}, Pred length: 12\nToken distribution (Batch 10): {42: 1, 1: 6, 10: 2, 32: 1, 22: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 11): {1: 10, 34: 2, 22: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 12): {1: 8, 11: 1, 34: 1, 32: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 13): {1: 9, 34: 1, 56: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 14): {1: 12}, Pred length: 12\nToken distribution (Batch 15): {1: 6, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 16): {1: 4, 47: 1, 34: 1, 32: 2}, Pred length: 8\nToken distribution (Batch 17): {1: 11, 47: 2, 10: 1}, Pred length: 14\nToken distribution (Batch 18): {1: 10, 10: 2, 22: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 19): {1: 10, 19: 1, 10: 1, 50: 1, 27: 1}, Pred length: 14\nToken distribution (Batch 20): {1: 6, 10: 5, 6: 2, 43: 1}, Pred length: 14\nToken distribution (Batch 21): {1: 9, 10: 2, 34: 1}, Pred length: 12\nToken distribution (Batch 22): {34: 1, 32: 2, 1: 6, 10: 1, 22: 2}, Pred length: 12\nToken distribution (Batch 23): {1: 11, 4: 1}, Pred length: 12\nToken distribution (Batch 24): {1: 6, 10: 3, 6: 1, 32: 2}, Pred length: 12\nToken distribution (Batch 25): {1: 12}, Pred length: 12\nToken distribution (Batch 26): {1: 11, 32: 1}, Pred length: 12\nToken distribution (Batch 27): {1: 8, 19: 1, 32: 2, 11: 1}, Pred length: 12\nToken distribution (Batch 28): {1: 10, 34: 1, 10: 2, 56: 1}, Pred length: 14\nToken distribution (Batch 29): {10: 1, 19: 2, 1: 9, 47: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 30): {1: 5, 11: 1, 32: 1, 42: 1}, Pred length: 8\nToken distribution (Batch 31): {1: 6, 4: 2, 32: 1, 12: 1, 27: 1, 56: 1}, Pred length: 12\nBatch 0, Gradient norm: 17.4625\nEpoch 10, Batch 0/58, Loss: 22.7595\nAvg Blank Probability: 0.0165\nSample predictions: ['sjaFfFa', 'aHafa', 'favaHaA']\nGround Truth (first 3): ['GD31v*', 'km*b3k2', 'e2XcQZ']\nRaw outputs (first 3): [[19  1  6 10 34  1  1 63  1  1 42  1  1  1  1  1  1  1  1  1  1  1 34  1\n   1  1  1  1  1 10  1  1]\n [10  1  1  1  1  1 11  1  6 10  1  1 11  1  1 10 47  1 10  1 10 10 32  1\n   1  1  1 19  1 19  1  4]\n [ 1  1  1 10  1  1  1  1  1  1  1 34  1 34  1  1 34  1  1  1 10 34  1  1\n   1  1  1  1  1  1 11  1]]\nInput length: 32, Label lengths: [6, 7, 6]\nToken distribution (Batch 0): {1: 9, 10: 4, 43: 1}, Pred length: 14\nToken distribution (Batch 1): {11: 1, 10: 2, 19: 2, 1: 1, 47: 2, 32: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 2): {10: 2, 1: 7, 34: 1, 27: 1, 4: 1, 32: 2}, Pred length: 14\nToken distribution (Batch 3): {1: 9, 27: 1, 12: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 4): {1: 12, 34: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 5): {1: 7, 22: 1, 34: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 6): {1: 6, 34: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 7): {1: 7, 10: 3, 4: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 8): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 9): {1: 7, 11: 1, 47: 1, 19: 1}, Pred length: 10\nToken distribution (Batch 10): {1: 10}, Pred length: 10\nToken distribution (Batch 11): {1: 4, 12: 1, 10: 1, 32: 1, 11: 1}, Pred length: 8\nToken distribution (Batch 12): {10: 1, 56: 1, 1: 9, 4: 1, 34: 1, 35: 1}, Pred length: 14\nToken distribution (Batch 13): {1: 11, 32: 1}, Pred length: 12\nToken distribution (Batch 14): {1: 9, 10: 3, 34: 2}, Pred length: 14\nToken distribution (Batch 15): {4: 2, 10: 1, 1: 5}, Pred length: 8\nToken distribution (Batch 16): {10: 1, 1: 9, 11: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 17): {1: 9, 56: 1, 19: 1, 6: 2, 27: 1}, Pred length: 14\nToken distribution (Batch 18): {1: 8, 32: 2, 10: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 19): {56: 1, 1: 5, 19: 1, 34: 1, 32: 2}, Pred length: 10\nToken distribution (Batch 20): {11: 1, 1: 7, 10: 2}, Pred length: 10\nToken distribution (Batch 21): {1: 7, 11: 1, 22: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 22): {63: 1, 19: 1, 1: 6, 34: 4, 10: 2}, Pred length: 14\nToken distribution (Batch 23): {1: 6, 19: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 24): {1: 8, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 25): {1: 9, 32: 1}, Pred length: 10\nToken distribution (Batch 26): {1: 5, 10: 1, 4: 1, 19: 1}, Pred length: 8\nToken distribution (Batch 27): {1: 6, 10: 4, 32: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 28): {1: 7, 22: 1}, Pred length: 8\nToken distribution (Batch 29): {4: 1, 1: 5, 32: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 30): {1: 7, 42: 1, 32: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 31): {1: 6, 34: 1, 10: 1}, Pred length: 8\nBatch 10, Gradient norm: 17.6251\nEpoch 10, Batch 10/58, Loss: 26.1134\nAvg Blank Probability: 0.0166\nSample predictions: ['ajajaQa', 'kjsaUFU3sj', 'jaHaAdFaja']\nGround Truth (first 3): ['RjBDCUR', 'CYZf8', 'fSQ-97s']\nRaw outputs (first 3): [[ 1 11 10  1  1  1  1  1  1  1  1  1 10  1  1  4 10  1  1 56 11  1 63  1\n   1  1  1  1  1  4  1 32]\n [ 1 10  1  1  1  1  1  1  1  1  1  1 56  1  1  4  1  1  1  1  1  1 19 19\n   1  1  1  1  1  1 42  1]\n [10 19 34 27  1  1  1 10  1  1  1 12  1  1 10 10  1  1  1 19 10  1  1  1\n   1  1 10 10  1  1  1 34]]\nInput length: 32, Label lengths: [7, 5, 7]\nToken distribution (Batch 0): {10: 5, 1: 9}, Pred length: 14\nToken distribution (Batch 1): {1: 10, 34: 2, 47: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 2): {1: 7, 4: 1, 34: 1, 12: 1, 42: 1, 6: 1}, Pred length: 12\nToken distribution (Batch 3): {1: 8, 27: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 4): {1: 10, 32: 1, 43: 1}, Pred length: 12\nToken distribution (Batch 5): {1: 8, 10: 4, 34: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 6): {63: 1, 1: 12, 42: 1}, Pred length: 14\nToken distribution (Batch 7): {1: 9, 12: 1, 10: 1, 43: 1}, Pred length: 12\nToken distribution (Batch 8): {1: 6, 10: 3, 32: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 5, 10: 4, 32: 2, 19: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 8, 10: 1, 32: 1, 11: 2, 47: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 11): {1: 8, 32: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 12): {1: 4, 10: 4}, Pred length: 8\nToken distribution (Batch 13): {1: 6, 6: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 14): {1: 9, 10: 1, 5: 1, 11: 1}, Pred length: 12\nToken distribution (Batch 15): {34: 2, 1: 4, 22: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 16): {1: 4, 56: 1, 22: 2, 27: 1}, Pred length: 8\nToken distribution (Batch 17): {1: 6, 6: 1, 32: 1, 19: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 18): {10: 3, 1: 8, 32: 1, 19: 1, 22: 1}, Pred length: 14\nToken distribution (Batch 19): {10: 1, 34: 1, 1: 8, 47: 1, 35: 1, 32: 2}, Pred length: 14\nToken distribution (Batch 20): {56: 1, 34: 1, 1: 8, 10: 1, 4: 1}, Pred length: 12\nToken distribution (Batch 21): {1: 6, 47: 3, 19: 1, 10: 2, 5: 1, 22: 1}, Pred length: 14\nToken distribution (Batch 22): {1: 5, 4: 1, 6: 2, 34: 1, 10: 3}, Pred length: 12\nToken distribution (Batch 23): {1: 11, 10: 1, 19: 1, 4: 1}, Pred length: 14\nToken distribution (Batch 24): {10: 4, 1: 4, 35: 1, 43: 1}, Pred length: 10\nToken distribution (Batch 25): {1: 8, 35: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 26): {19: 1, 1: 6, 10: 2, 42: 1}, Pred length: 10\nToken distribution (Batch 27): {10: 1, 32: 1, 1: 8, 35: 1, 56: 1}, Pred length: 12\nToken distribution (Batch 28): {10: 3, 1: 7, 32: 2}, Pred length: 12\nToken distribution (Batch 29): {1: 6, 4: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 30): {4: 2, 1: 10, 32: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 31): {6: 1, 1: 8, 32: 2, 56: 1}, Pred length: 12\nBatch 20, Gradient norm: 17.5706\nEpoch 10, Batch 20/58, Loss: 24.1572\nAvg Blank Probability: 0.0168\nSample predictions: ['jajaj', 'aHaHUaFa', 'adHlaPf']\nGround Truth (first 3): ['szTCVQs', 'c4HrP*E', 'Uo3KrR']\nRaw outputs (first 3): [[10  1  1  1  1  1 63  1 34  1  1  1  1  1  1 34  1  1 10 10 56  1  1  1\n  10  1 19 10 10  1  4  6]\n [10  1  4  1  1  1  1 12  1 10  1  1  1  1  1  1 56  6  1 34 34 47  4  1\n   1  1  1 32  1  4  1  1]\n [10 34 34  1  1 10  1  1 10  1 10 32 10  1  1  1 22 32  1  1  1  1  6  1\n  10  1  1  1  1  1  1  1]]\nInput length: 32, Label lengths: [7, 7, 6]\nToken distribution (Batch 0): {56: 1, 1: 5, 10: 2}, Pred length: 8\nToken distribution (Batch 1): {1: 7, 10: 1, 32: 2}, Pred length: 10\nToken distribution (Batch 2): {1: 5, 32: 1, 5: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 3): {10: 1, 1: 9, 12: 1, 11: 1}, Pred length: 12\nToken distribution (Batch 4): {1: 9, 10: 2, 32: 1}, Pred length: 12\nToken distribution (Batch 5): {1: 8, 32: 2, 10: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 6): {1: 8, 12: 1, 10: 3}, Pred length: 12\nToken distribution (Batch 7): {1: 5, 11: 1, 35: 1, 34: 1, 47: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 8): {10: 1, 34: 1, 1: 6}, Pred length: 8\nToken distribution (Batch 9): {1: 8}, Pred length: 8\nToken distribution (Batch 10): {34: 1, 1: 7, 32: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 11): {1: 10, 32: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 12): {1: 11, 10: 1, 34: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 13): {1: 6, 10: 1, 32: 1, 43: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 14): {10: 3, 11: 1, 1: 9, 32: 1}, Pred length: 14\nToken distribution (Batch 15): {1: 9, 10: 1, 32: 1, 11: 1}, Pred length: 12\nToken distribution (Batch 16): {1: 7, 22: 1, 32: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 17): {1: 5, 11: 2, 34: 1}, Pred length: 8\nToken distribution (Batch 18): {1: 12, 32: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 19): {1: 10, 10: 2, 34: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 20): {10: 2, 1: 6}, Pred length: 8\nToken distribution (Batch 21): {4: 1, 1: 10, 32: 1}, Pred length: 12\nToken distribution (Batch 22): {1: 7, 4: 1, 32: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 23): {34: 1, 1: 9}, Pred length: 10\nToken distribution (Batch 24): {1: 5, 34: 1, 19: 1, 11: 1}, Pred length: 8\nToken distribution (Batch 25): {1: 9, 32: 1}, Pred length: 10\nToken distribution (Batch 26): {12: 1, 1: 8, 11: 1}, Pred length: 10\nToken distribution (Batch 27): {1: 8, 47: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 28): {1: 7, 32: 2, 47: 1}, Pred length: 10\nToken distribution (Batch 29): {19: 1, 10: 2, 1: 6, 5: 1, 6: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 30): {10: 2, 1: 7, 6: 1, 47: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 31): {1: 9, 47: 1, 10: 2}, Pred length: 12\nBatch 30, Gradient norm: 23.1823\nEpoch 10, Batch 30/58, Loss: 25.7644\nAvg Blank Probability: 0.0169\nSample predictions: ['3ajaj', 'ajFaFa', 'aFeaUa']\nGround Truth (first 3): ['eHu3', 'T7opU', '1xnk']\nRaw outputs (first 3): [[56  1  1 10  1  1  1  1 10  1 34  1  1  1 10  1  1  1  1  1 10  4  1 34\n   1  1 12  1  1 19 10  1]\n [ 1  1 32  1  1 32  1 11 34  1  1  1  1  1 10  1  1  1 32  1  1  1  1  1\n  34  1  1  1  1 10  1  0]\n [ 1  1  5  1  1 32  1  1  1  1  1  1 10 10 11  1  1  1  1  1  1  1  1  1\n  19  1 11  1  1 10  1  1]]\nInput length: 32, Label lengths: [4, 5, 4]\nToken distribution (Batch 0): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 1): {1: 7, 50: 1}, Pred length: 8\nToken distribution (Batch 2): {1: 8, 47: 3, 10: 1}, Pred length: 12\nToken distribution (Batch 3): {10: 3, 1: 3, 32: 2}, Pred length: 8\nToken distribution (Batch 4): {1: 5, 32: 1, 27: 1, 56: 1}, Pred length: 8\nToken distribution (Batch 5): {32: 2, 1: 7, 34: 1}, Pred length: 10\nToken distribution (Batch 6): {1: 6, 32: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 7): {1: 8, 34: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 8): {1: 8, 47: 1, 27: 1, 32: 3, 56: 1}, Pred length: 14\nToken distribution (Batch 9): {1: 5, 11: 1, 32: 2, 27: 1, 10: 1, 47: 1, 5: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 11, 19: 1}, Pred length: 12\nToken distribution (Batch 11): {1: 8, 11: 1, 42: 1, 56: 3, 10: 1}, Pred length: 14\nToken distribution (Batch 12): {11: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 13): {12: 1, 10: 3, 1: 3, 5: 1}, Pred length: 8\nToken distribution (Batch 14): {1: 12}, Pred length: 12\nToken distribution (Batch 15): {1: 9, 5: 1, 4: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 16): {10: 2, 1: 6, 11: 1, 47: 1, 32: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 17): {63: 1, 1: 10, 32: 2, 47: 1}, Pred length: 14\nToken distribution (Batch 18): {1: 10, 12: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 19): {1: 9, 19: 1}, Pred length: 10\nToken distribution (Batch 20): {34: 1, 1: 8, 4: 1, 47: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 21): {63: 1, 1: 7, 34: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 22): {1: 6, 34: 1, 6: 1, 11: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 23): {1: 8}, Pred length: 8\nToken distribution (Batch 24): {1: 12, 32: 1, 19: 1}, Pred length: 14\nToken distribution (Batch 25): {11: 1, 1: 7, 56: 1, 10: 2, 5: 1, 32: 2}, Pred length: 14\nToken distribution (Batch 26): {1: 9, 10: 3, 56: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 27): {1: 7, 6: 1}, Pred length: 8\nToken distribution (Batch 28): {1: 10, 34: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 29): {34: 1, 4: 1, 1: 6, 16: 1, 19: 1, 5: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 30): {1: 11, 32: 1, 22: 1, 6: 1}, Pred length: 14\nToken distribution (Batch 31): {1: 6, 34: 1, 12: 1}, Pred length: 8\nBatch 40, Gradient norm: 17.9841\nEpoch 10, Batch 40/58, Loss: 25.7157\nAvg Blank Probability: 0.0170\nSample predictions: ['aF', 'aXa', 'aUjaUaUa']\nGround Truth (first 3): ['3uh5', 'QtpG', 'eSIkxM']\nRaw outputs (first 3): [[ 1  1  1 10  1 32  1  1  1  1  1  1 11 12  1  1 10 63  1  1 34 63  1  1\n   1 11  1  1  1 34  1  1]\n [ 1  1  1  1  1 32 32  1  1  1  1  1  1 10  1  5  1  1 12  1  1  1 34  1\n   1  1 10  1  1  4  1  1]\n [ 1  1  1  1 32  1  1  1 47  1  1 11  1  1  1  1  1  1  1 19  4 34  1  1\n   1  1  1  1  1  1  1  1]]\nInput length: 32, Label lengths: [4, 4, 6]\nToken distribution (Batch 0): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 1): {1: 7, 10: 2, 56: 1}, Pred length: 10\nToken distribution (Batch 2): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 8, 10: 3, 32: 1}, Pred length: 12\nToken distribution (Batch 4): {10: 2, 1: 6, 34: 1, 11: 1}, Pred length: 10\nToken distribution (Batch 5): {1: 11, 10: 1}, Pred length: 12\nToken distribution (Batch 6): {10: 2, 1: 7, 12: 1, 47: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 7): {1: 7, 10: 3, 22: 1, 32: 1, 34: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 8): {1: 11, 10: 2, 32: 1}, Pred length: 14\nToken distribution (Batch 9): {1: 9, 10: 1, 47: 1, 22: 1, 34: 1, 35: 1}, Pred length: 14\nToken distribution (Batch 10): {1: 9, 32: 1, 10: 2}, Pred length: 12\nToken distribution (Batch 11): {1: 11, 34: 3}, Pred length: 14\nToken distribution (Batch 12): {4: 1, 34: 2, 19: 1, 1: 5, 22: 2, 10: 1}, Pred length: 12\nToken distribution (Batch 13): {1: 8, 10: 1, 34: 2, 32: 2, 47: 1}, Pred length: 14\nToken distribution (Batch 14): {11: 2, 1: 8, 47: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 15): {1: 10, 19: 1, 6: 1}, Pred length: 12\nToken distribution (Batch 16): {1: 7, 32: 1, 19: 1, 12: 1}, Pred length: 10\nToken distribution (Batch 17): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 18): {1: 8, 32: 1, 22: 1, 27: 2}, Pred length: 12\nToken distribution (Batch 19): {1: 4, 10: 2, 56: 1, 19: 1}, Pred length: 8\nToken distribution (Batch 20): {1: 10, 32: 2, 34: 2}, Pred length: 14\nToken distribution (Batch 21): {1: 9, 32: 1, 34: 2, 10: 2}, Pred length: 14\nToken distribution (Batch 22): {1: 14}, Pred length: 14\nToken distribution (Batch 23): {1: 6, 47: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 24): {1: 11, 35: 1, 47: 1, 27: 1}, Pred length: 14\nToken distribution (Batch 25): {1: 10, 27: 1, 10: 2, 34: 1}, Pred length: 14\nToken distribution (Batch 26): {11: 1, 12: 1, 1: 6, 10: 2, 4: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 27): {10: 3, 1: 6, 32: 2, 19: 1, 34: 1, 11: 1}, Pred length: 14\nToken distribution (Batch 28): {1: 7, 6: 1}, Pred length: 8\nToken distribution (Batch 29): {1: 6, 47: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 30): {1: 9, 6: 1, 19: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 31): {1: 8, 32: 1, 19: 1}, Pred length: 10\nBatch 50, Gradient norm: 17.2124\nEpoch 10, Batch 50/58, Loss: 24.2137\nAvg Blank Probability: 0.0172\nSample predictions: ['aja', 'aja3aja', 'aja']\nGround Truth (first 3): ['YKSA', 'gH2tX', 'aT2T']\nRaw outputs (first 3): [[ 1  1  1  1 10  1 10  1  1  1  1  1  4  1 11  1  1  1  1  1  1  1  1  1\n   1  1 11 10  1  1  1  1]\n [ 1 10  1 10  1  1  1  1  1  1  1  1 34 10 11  1  1  1 32  1  1 32  1  1\n   1  1 12  1  1  1  1  1]\n [ 1  1 10  1  1  1 12  1  1  1  1 34 19 34  1 19  1 32  1  1 32  1  1  1\n   1  1  1 10  6 47  1  1]]\nInput length: 32, Label lengths: [4, 5, 4]\nEpoch 10/20, Loss: 25.1898\nToken distribution (Batch 0): {1: 10}, Pred length: 10\nToken distribution (Batch 1): {1: 12}, Pred length: 12\nToken distribution (Batch 2): {1: 8}, Pred length: 8\nToken distribution (Batch 3): {1: 10}, Pred length: 10\nToken distribution (Batch 4): {1: 12}, Pred length: 12\nToken distribution (Batch 5): {1: 12}, Pred length: 12\nToken distribution (Batch 6): {1: 14}, Pred length: 14\nToken distribution (Batch 7): {1: 10}, Pred length: 10\nToken distribution (Batch 8): {1: 10}, Pred length: 10\nToken distribution (Batch 9): {1: 10}, Pred length: 10\nValidation Loss: 25.1711\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['77iEA', 'FLM94a', 'Y1zd', 'pjUgP', 'k5nyfT']\nCurrent Learning Rate: 4.6524758424985284e-07\nEpoch 11, Filtered data size: 5120, Sample labels: ['qV8ib8H', 'MdI8', '1XS0DRdJ']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 0): {1: 11, 42: 1}, Pred length: 12\nToken distribution (Batch 1): {1: 11, 10: 1, 22: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 2): {1: 17, 10: 3, 56: 1, 32: 1}, Pred length: 22\nToken distribution (Batch 3): {1: 11, 19: 1, 56: 1, 47: 1, 34: 1, 10: 1}, Pred length: 16\nToken distribution (Batch 4): {1: 9, 32: 1, 24: 1, 48: 1}, Pred length: 12\nToken distribution (Batch 5): {1: 8, 34: 2, 32: 2}, Pred length: 12\nToken distribution (Batch 6): {42: 1, 19: 1, 1: 14, 10: 1, 27: 1, 22: 1, 32: 1}, Pred length: 20\nToken distribution (Batch 7): {1: 5, 56: 1, 35: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 8): {1: 17, 34: 1}, Pred length: 18\nToken distribution (Batch 9): {35: 1, 22: 1, 1: 20, 32: 1, 56: 1}, Pred length: 24\nToken distribution (Batch 10): {1: 8, 34: 3, 32: 1}, Pred length: 12\nToken distribution (Batch 11): {1: 8}, Pred length: 8\nToken distribution (Batch 12): {1: 11, 4: 1, 10: 2, 27: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 13): {10: 4, 1: 12, 34: 2, 32: 2, 19: 1, 42: 1}, Pred length: 22\nToken distribution (Batch 14): {1: 7, 32: 2, 10: 2, 11: 1, 43: 1, 7: 1}, Pred length: 14\nToken distribution (Batch 15): {1: 15, 32: 1, 5: 1, 11: 1, 27: 1, 10: 1}, Pred length: 20\nToken distribution (Batch 16): {1: 3, 32: 5}, Pred length: 8\nToken distribution (Batch 17): {19: 1, 24: 1, 1: 7, 10: 1, 32: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 18): {1: 4, 42: 1, 10: 2, 34: 1}, Pred length: 8\nToken distribution (Batch 19): {1: 14, 6: 1, 4: 1, 34: 2}, Pred length: 18\nToken distribution (Batch 20): {1: 9, 32: 1, 10: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 21): {1: 7, 35: 1}, Pred length: 8\nToken distribution (Batch 22): {6: 1, 10: 3, 1: 9, 11: 1, 47: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 23): {1: 20, 32: 1, 63: 1, 4: 1, 48: 1}, Pred length: 24\nToken distribution (Batch 24): {1: 13, 47: 2, 34: 2, 5: 1, 19: 1, 23: 1}, Pred length: 20\nToken distribution (Batch 25): {10: 1, 1: 13, 19: 2, 34: 1, 11: 1, 12: 1, 47: 1}, Pred length: 20\nToken distribution (Batch 26): {12: 1, 1: 13, 47: 1, 32: 1, 34: 2, 10: 1, 50: 1}, Pred length: 20\nToken distribution (Batch 27): {1: 10, 35: 1, 6: 1, 34: 1, 10: 1, 27: 1, 5: 1}, Pred length: 16\nToken distribution (Batch 28): {1: 10, 27: 1, 10: 1, 11: 2, 47: 2, 32: 2}, Pred length: 18\nToken distribution (Batch 29): {1: 18, 34: 2, 32: 3, 10: 1}, Pred length: 24\nToken distribution (Batch 30): {1: 10, 10: 2, 11: 1, 22: 1}, Pred length: 14\nToken distribution (Batch 31): {34: 2, 1: 14, 32: 3, 42: 1}, Pred length: 20\nBatch 0, Gradient norm: 94.8436\nEpoch 11, Batch 0/128, Loss: 19.6219\nAvg Blank Probability: 0.0174\nSample predictions: ['aPa', 'ajavHa', 'ajaja3aFja']\nGround Truth (first 3): ['z1NetU', 'YHNhPtU', 'erict36xsy2']\nRaw outputs (first 3): [[ 1  1  1  1  1  1 42  1  1 35  1  1  1 10  1  1  1  1  1  1  1  1  6  1\n   1 10 12  1  1  1  1 34]\n [ 1  1  1  1  1  1 19 56  1 22 34  1  4 10 32  1 32 19 42  1  1 35 10  1\n   1  1  1 35  1 34  1  1]\n [ 1  1 10 19 32  1  1 35  1  1 34  1  1 10 10  1 32 24  1  1  1  1  1  1\n   1 19  1  6  1  1  1  1]]\nInput length: 32, Label lengths: [6, 7, 11]\nToken distribution (Batch 0): {10: 1, 1: 7, 34: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 1): {1: 8, 4: 1, 32: 1, 34: 1, 6: 1}, Pred length: 12\nToken distribution (Batch 2): {1: 15, 56: 1, 32: 1, 4: 1}, Pred length: 18\nToken distribution (Batch 3): {1: 13, 10: 3, 32: 1, 34: 1}, Pred length: 18\nToken distribution (Batch 4): {1: 9, 19: 1, 34: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 5): {12: 1, 1: 16, 32: 1, 10: 2}, Pred length: 20\nToken distribution (Batch 6): {1: 17, 11: 1, 19: 1, 32: 2, 6: 1, 34: 1, 10: 1}, Pred length: 24\nToken distribution (Batch 7): {1: 10, 11: 1, 35: 1, 19: 3, 4: 1}, Pred length: 16\nToken distribution (Batch 8): {11: 2, 1: 15, 10: 3, 42: 2}, Pred length: 22\nToken distribution (Batch 9): {1: 10}, Pred length: 10\nToken distribution (Batch 10): {1: 6, 11: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 11): {10: 2, 1: 4, 4: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 12): {1: 9, 10: 2, 11: 1}, Pred length: 12\nToken distribution (Batch 13): {1: 17, 10: 3, 34: 2, 32: 2}, Pred length: 24\nToken distribution (Batch 14): {1: 12, 47: 2, 22: 1, 56: 1, 32: 1, 27: 1, 10: 2}, Pred length: 20\nToken distribution (Batch 15): {1: 6, 32: 1, 6: 1, 10: 1, 11: 1}, Pred length: 10\nToken distribution (Batch 16): {10: 3, 1: 12, 6: 1, 35: 1, 11: 1}, Pred length: 18\nToken distribution (Batch 17): {1: 13, 47: 1, 19: 1, 10: 1, 34: 2, 32: 2, 56: 1, 11: 1}, Pred length: 22\nToken distribution (Batch 18): {1: 7, 10: 2, 34: 1, 4: 1, 43: 1}, Pred length: 12\nToken distribution (Batch 19): {10: 3, 43: 1, 1: 9, 27: 1, 32: 1, 47: 1}, Pred length: 16\nToken distribution (Batch 20): {6: 1, 1: 5, 10: 1, 4: 1}, Pred length: 8\nToken distribution (Batch 21): {1: 10, 10: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 22): {4: 1, 34: 1, 1: 11, 32: 4, 42: 1, 10: 2, 47: 1, 11: 1}, Pred length: 22\nToken distribution (Batch 23): {1: 12, 32: 1, 47: 1, 42: 1, 11: 1, 35: 1, 10: 3, 50: 1, 27: 2, 34: 1}, Pred length: 24\nToken distribution (Batch 24): {10: 1, 1: 12, 19: 1, 42: 1, 34: 2, 47: 1}, Pred length: 18\nToken distribution (Batch 25): {10: 2, 1: 13, 27: 1, 34: 2}, Pred length: 18\nToken distribution (Batch 26): {1: 14, 43: 1, 56: 1, 10: 1, 32: 2, 47: 2, 34: 1, 27: 1, 6: 1}, Pred length: 24\nToken distribution (Batch 27): {1: 11, 10: 4, 56: 1, 34: 2, 6: 2}, Pred length: 20\nToken distribution (Batch 28): {1: 9, 10: 2, 56: 1, 50: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 29): {12: 2, 1: 16, 10: 2, 47: 2, 34: 2}, Pred length: 24\nToken distribution (Batch 30): {1: 9, 34: 2, 32: 1}, Pred length: 12\nToken distribution (Batch 31): {6: 1, 1: 10, 4: 1, 22: 1, 10: 2, 27: 1, 34: 2}, Pred length: 18\nBatch 10, Gradient norm: 252.5550\nEpoch 11, Batch 10/128, Loss: 19.0857\nAvg Blank Probability: 0.0175\nSample predictions: ['jaHada', 'adaFaHfa', 'a3aFada']\nGround Truth (first 3): ['505gz', 'sgoRDx', 'SgSGYn-DI']\nRaw outputs (first 3): [[10  1  1  1  1 12  1  1 11  1  1 10  1  1  1  1 10  1  1 10  6  1  4  1\n  10 10  1  1  1 12  1  6]\n [ 1  1  1 10  1  1 11  1  1  1 11  1  1 10 47 32  1  1 10 43  1  1 34  1\n   1  1  1 10  1  1  1  1]\n [ 1  1  1  1 19  1  1 11 11  1 10  1 10  1  1  1  6 47  1  1  1  0  1 32\n   1  1 43  1  1  1  1  4]]\nInput length: 32, Label lengths: [5, 6, 9]\nToken distribution (Batch 0): {63: 1, 1: 8, 22: 1, 34: 1, 32: 1, 6: 1, 25: 1}, Pred length: 14\nToken distribution (Batch 1): {1: 8, 10: 1, 19: 1}, Pred length: 10\nToken distribution (Batch 2): {1: 6, 47: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 15, 10: 2, 32: 4, 47: 1}, Pred length: 22\nToken distribution (Batch 4): {10: 4, 1: 4, 34: 1, 32: 3}, Pred length: 12\nToken distribution (Batch 5): {1: 6, 34: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 6): {1: 13, 22: 1, 10: 2, 35: 1, 34: 1}, Pred length: 18\nToken distribution (Batch 7): {1: 17, 4: 1, 32: 2, 5: 1, 47: 1}, Pred length: 22\nToken distribution (Batch 8): {1: 13, 10: 1}, Pred length: 14\nToken distribution (Batch 9): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 10): {1: 7, 34: 1}, Pred length: 8\nToken distribution (Batch 11): {11: 1, 1: 9, 47: 1, 25: 1, 35: 1, 32: 2, 10: 1, 34: 1, 22: 1}, Pred length: 18\nToken distribution (Batch 12): {1: 16, 34: 2, 32: 1, 10: 3}, Pred length: 22\nToken distribution (Batch 13): {1: 13, 10: 2, 11: 1, 34: 1, 27: 2, 32: 1}, Pred length: 20\nToken distribution (Batch 14): {10: 2, 19: 1, 1: 5, 6: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 15): {1: 12, 47: 1, 32: 1, 34: 2, 56: 1, 10: 1}, Pred length: 18\nToken distribution (Batch 16): {34: 1, 1: 9, 47: 2, 56: 1, 10: 2, 4: 1}, Pred length: 16\nToken distribution (Batch 17): {1: 10, 56: 1, 6: 1}, Pred length: 12\nToken distribution (Batch 18): {1: 9, 10: 1, 22: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 19): {1: 19, 10: 2, 34: 1, 27: 2}, Pred length: 24\nToken distribution (Batch 20): {1: 13, 4: 1}, Pred length: 14\nToken distribution (Batch 21): {34: 1, 1: 10, 47: 2, 42: 1, 10: 2, 32: 2}, Pred length: 18\nToken distribution (Batch 22): {1: 12, 10: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 23): {4: 1, 1: 11}, Pred length: 12\nToken distribution (Batch 24): {10: 2, 1: 10, 47: 1, 34: 1, 56: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 25): {1: 10, 27: 1, 11: 1}, Pred length: 12\nToken distribution (Batch 26): {11: 1, 1: 4, 34: 1, 19: 1, 32: 2, 6: 1}, Pred length: 10\nToken distribution (Batch 27): {1: 10, 32: 2, 56: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 28): {1: 6, 10: 1, 19: 1}, Pred length: 8\nToken distribution (Batch 29): {4: 1, 1: 10, 32: 1}, Pred length: 12\nToken distribution (Batch 30): {1: 8, 42: 1, 32: 4, 47: 1, 22: 1, 10: 1}, Pred length: 16\nToken distribution (Batch 31): {1: 13, 32: 1, 12: 1, 10: 1, 11: 1, 47: 1}, Pred length: 18\nBatch 20, Gradient norm: 14.2185\nEpoch 11, Batch 20/128, Loss: 21.1018\nAvg Blank Probability: 0.0176\nSample predictions: ['-avaHFfaya', 'ajasa', 'aUaja']\nGround Truth (first 3): ['M7gGuUk', 'cHZ7k', 'iiC9']\nRaw outputs (first 3): [[63  1  1  1 10  1  1  1  1  1  1 11  1  1 10  1 12  1  1  0  1 34  1  4\n  10  1 11  1  1  4  1  1]\n [ 1  1 47 10 10 34  1  1  1  1  1  1 34  1 10  1 34  1  1  1  1  1  1  1\n   1  1  1  1  1  1  1  1]\n [ 1  1  1  1  1  1 22  1  1 10  1 47  1  1 19  1  1  1  1  1  1  1  1  1\n  47 27  1  1  1  1  1 32]]\nInput length: 32, Label lengths: [7, 5, 4]\nToken distribution (Batch 0): {1: 7, 19: 1, 6: 1, 32: 1, 12: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 1): {1: 14, 34: 2, 22: 1, 27: 1, 47: 1, 10: 2, 11: 1}, Pred length: 22\nToken distribution (Batch 2): {1: 9, 11: 1, 47: 2, 32: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 3): {1: 19, 32: 2, 10: 3}, Pred length: 24\nToken distribution (Batch 4): {11: 1, 1: 10, 47: 1, 4: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 5): {1: 6, 42: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 6): {1: 3, 6: 3, 32: 1, 10: 3, 47: 1, 11: 1}, Pred length: 12\nToken distribution (Batch 7): {34: 1, 1: 8, 10: 2, 56: 1}, Pred length: 12\nToken distribution (Batch 8): {1: 10, 34: 2, 22: 1, 56: 1, 10: 2}, Pred length: 16\nToken distribution (Batch 9): {10: 4, 34: 1, 1: 15, 19: 1, 32: 1}, Pred length: 22\nToken distribution (Batch 10): {1: 11, 47: 3, 42: 1, 32: 2, 12: 1, 27: 1, 34: 1}, Pred length: 20\nToken distribution (Batch 11): {1: 6, 10: 3, 32: 1}, Pred length: 10\nToken distribution (Batch 12): {1: 17, 10: 1, 27: 1, 22: 2, 34: 3}, Pred length: 24\nToken distribution (Batch 13): {1: 15, 12: 1, 32: 1, 10: 1}, Pred length: 18\nToken distribution (Batch 14): {1: 11, 47: 1, 11: 1, 10: 1, 12: 1, 6: 1}, Pred length: 16\nToken distribution (Batch 15): {10: 1, 1: 8, 47: 1, 35: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 16): {1: 11, 32: 1, 42: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 17): {1: 7, 47: 1, 10: 3, 34: 1}, Pred length: 12\nToken distribution (Batch 18): {1: 15, 4: 1, 10: 1, 32: 1, 47: 1, 5: 1}, Pred length: 20\nToken distribution (Batch 19): {63: 1, 1: 16, 10: 1, 22: 1, 35: 1}, Pred length: 20\nToken distribution (Batch 20): {1: 9, 19: 1, 32: 2}, Pred length: 12\nToken distribution (Batch 21): {1: 13, 47: 1, 22: 1, 43: 1, 34: 1, 10: 5, 19: 1, 32: 1}, Pred length: 24\nToken distribution (Batch 22): {10: 2, 1: 9, 11: 1, 47: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 23): {1: 17, 32: 2, 10: 1}, Pred length: 20\nToken distribution (Batch 24): {1: 8, 10: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 25): {10: 2, 1: 11, 6: 2, 11: 1}, Pred length: 16\nToken distribution (Batch 26): {1: 4, 32: 1, 47: 1, 10: 1, 11: 1}, Pred length: 8\nToken distribution (Batch 27): {32: 2, 1: 13, 22: 1, 11: 1, 34: 2, 27: 1, 10: 2, 4: 1, 56: 1}, Pred length: 24\nToken distribution (Batch 28): {10: 2, 1: 16, 4: 1, 32: 2, 56: 1, 6: 1, 27: 1}, Pred length: 24\nToken distribution (Batch 29): {34: 1, 1: 17, 4: 1, 27: 1, 47: 1, 10: 1}, Pred length: 22\nToken distribution (Batch 30): {12: 1, 1: 10, 10: 1, 47: 1, 11: 1, 22: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 31): {1: 18, 35: 1, 32: 1, 27: 1, 6: 1, 22: 1, 10: 1}, Pred length: 24\nBatch 30, Gradient norm: 50.0948\nEpoch 11, Batch 30/128, Loss: 18.5060\nAvg Blank Probability: 0.0178\nSample predictions: ['asafFalaHa', 'aHavaAUjHaka', 'akUaUFHa']\nGround Truth (first 3): ['8dYgdD', 'ZM-mIxQr*tq', 'VQqpeUZ']\nRaw outputs (first 3): [[ 1  1  1  1 11  6 12 34  1 10  1  1  1  1  1 10  1  1 56 63  1  1 10  1\n   1 10  1 32 47 34 12  1]\n [19  1  1  1  1  1  1  1 34 34 47  1 10  1  1  1 32 47  1  1 19  1  1  1\n   1  1 32  1 10  1  1  1]\n [ 1  1  1  1  1  1  6  1 34  1  1  1  1  1 47  1  1  1  1  1  1 47 11  1\n   1  6  1 22  1  4  1  1]]\nInput length: 32, Label lengths: [6, 11, 7]\nToken distribution (Batch 0): {1: 16, 10: 1, 47: 1, 22: 1, 56: 1}, Pred length: 20\nToken distribution (Batch 1): {1: 6, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 2): {1: 8, 4: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 3): {1: 11, 32: 1, 10: 1, 34: 2, 5: 1}, Pred length: 16\nToken distribution (Batch 4): {11: 1, 1: 6, 47: 2, 34: 5, 10: 2, 32: 1, 4: 1}, Pred length: 18\nToken distribution (Batch 5): {1: 13, 47: 1, 34: 1, 11: 2, 19: 1, 22: 3, 10: 1}, Pred length: 22\nToken distribution (Batch 6): {34: 1, 4: 1, 1: 16, 19: 1, 47: 2, 5: 1, 32: 1, 10: 1}, Pred length: 24\nToken distribution (Batch 7): {1: 4, 35: 1, 32: 1, 10: 2}, Pred length: 8\nToken distribution (Batch 8): {1: 16, 10: 4, 34: 1, 32: 2, 4: 1}, Pred length: 24\nToken distribution (Batch 9): {10: 2, 1: 6}, Pred length: 8\nToken distribution (Batch 10): {10: 2, 1: 18}, Pred length: 20\nToken distribution (Batch 11): {1: 8, 56: 1, 19: 1, 34: 2}, Pred length: 12\nToken distribution (Batch 12): {12: 2, 10: 2, 1: 13, 32: 1, 4: 1, 34: 1}, Pred length: 20\nToken distribution (Batch 13): {1: 13, 43: 1, 56: 2, 4: 1, 32: 1, 42: 1, 19: 1}, Pred length: 20\nToken distribution (Batch 14): {1: 8, 6: 1, 19: 1, 10: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 15): {1: 10, 32: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 16): {1: 8, 10: 2, 32: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 17): {1: 8, 32: 1, 10: 2, 43: 1}, Pred length: 12\nToken distribution (Batch 18): {11: 3, 10: 3, 1: 7, 34: 3, 19: 1, 35: 1}, Pred length: 18\nToken distribution (Batch 19): {10: 2, 1: 14, 34: 2, 32: 1, 19: 1, 47: 2, 4: 2}, Pred length: 24\nToken distribution (Batch 20): {1: 9, 34: 1}, Pred length: 10\nToken distribution (Batch 21): {1: 8, 56: 1, 32: 1, 11: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 22): {1: 15, 47: 3, 22: 1, 11: 1, 10: 1, 56: 1}, Pred length: 22\nToken distribution (Batch 23): {1: 15, 4: 1, 32: 2}, Pred length: 18\nToken distribution (Batch 24): {1: 21, 10: 1}, Pred length: 22\nToken distribution (Batch 25): {32: 3, 1: 7, 22: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 26): {1: 9, 10: 2, 32: 1, 56: 1, 19: 1}, Pred length: 14\nToken distribution (Batch 27): {1: 8}, Pred length: 8\nToken distribution (Batch 28): {1: 10, 47: 2, 10: 2}, Pred length: 14\nToken distribution (Batch 29): {34: 1, 1: 10, 10: 2, 48: 1}, Pred length: 14\nToken distribution (Batch 30): {1: 15, 32: 3, 47: 1, 22: 2, 10: 1}, Pred length: 22\nToken distribution (Batch 31): {1: 11, 34: 4, 10: 2, 27: 2, 47: 1, 32: 1, 35: 1}, Pred length: 22\nBatch 40, Gradient norm: 13.3016\nEpoch 11, Batch 40/128, Loss: 19.6802\nAvg Blank Probability: 0.0179\nSample predictions: ['ajaUva3a', 'ajaFa', 'adUa']\nGround Truth (first 3): ['BSmansJuhR', 'BMWS', 'nyVUF']\nRaw outputs (first 3): [[ 1  1  1  1 11  1 34  1  1 10 10  1 12  1  1  1  1  1 11 10  1  1 11  1\n   1 32  1  1  1 34  1  1]\n [ 1  1  4  1  1  1  4  1  1 10 10  1 10  1  1 32  1  1 10  1  1  1  1  1\n   1  1  1  1  1  1  1  1]\n [ 1 10 47 32  1 47  1  1  1  1  1  1  1 43  1  1  1 32  1  1  1 56  1  1\n   1  1  1  1  1 10 32 34]]\nInput length: 32, Label lengths: [10, 4, 5]\nToken distribution (Batch 0): {1: 13, 10: 1}, Pred length: 14\nToken distribution (Batch 1): {1: 19, 10: 4, 5: 1}, Pred length: 24\nToken distribution (Batch 2): {1: 7, 34: 1, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 3): {1: 15, 47: 1, 32: 1, 19: 1, 34: 2}, Pred length: 20\nToken distribution (Batch 4): {1: 10, 10: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 5): {1: 11, 34: 2, 4: 2, 10: 3, 6: 1, 47: 2, 56: 1, 32: 2}, Pred length: 24\nToken distribution (Batch 6): {10: 1, 6: 1, 1: 10, 32: 1, 34: 2, 27: 1}, Pred length: 16\nToken distribution (Batch 7): {1: 5, 10: 2, 34: 1}, Pred length: 8\nToken distribution (Batch 8): {1: 6, 4: 1, 10: 1, 34: 1, 35: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 8, 10: 1, 56: 1, 11: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 9, 10: 1, 4: 1, 42: 1}, Pred length: 12\nToken distribution (Batch 11): {1: 9, 34: 1, 10: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 12): {10: 3, 1: 7, 32: 2, 47: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 13): {1: 14, 47: 3, 12: 1, 50: 1, 27: 1, 34: 1, 10: 1}, Pred length: 22\nToken distribution (Batch 14): {32: 1, 1: 3, 34: 2, 56: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 15): {1: 18, 10: 1, 35: 1}, Pred length: 20\nToken distribution (Batch 16): {1: 14, 34: 2, 32: 2, 27: 1, 42: 1, 47: 2}, Pred length: 22\nToken distribution (Batch 17): {1: 7, 27: 2, 12: 1}, Pred length: 10\nToken distribution (Batch 18): {1: 10, 10: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 19): {1: 11, 35: 1, 34: 1, 32: 1, 10: 1, 19: 1}, Pred length: 16\nToken distribution (Batch 20): {1: 9, 6: 1, 47: 3, 34: 1}, Pred length: 14\nToken distribution (Batch 21): {1: 11, 34: 3, 32: 3, 56: 1, 22: 1, 12: 1}, Pred length: 20\nToken distribution (Batch 22): {1: 12, 34: 1, 32: 1, 10: 1, 47: 1}, Pred length: 16\nToken distribution (Batch 23): {11: 2, 42: 1, 10: 3, 34: 1, 1: 9, 32: 1, 6: 1}, Pred length: 18\nToken distribution (Batch 24): {1: 8, 34: 1, 19: 1, 32: 1, 10: 2, 47: 2, 27: 1}, Pred length: 16\nToken distribution (Batch 25): {10: 2, 1: 13, 27: 1, 47: 3, 12: 1}, Pred length: 20\nToken distribution (Batch 26): {1: 8, 10: 1, 32: 2, 11: 1, 35: 1, 47: 2, 19: 1}, Pred length: 16\nToken distribution (Batch 27): {1: 12, 56: 1, 27: 1, 34: 1, 47: 1}, Pred length: 16\nToken distribution (Batch 28): {1: 13, 11: 1, 34: 4, 32: 2, 47: 1, 27: 1}, Pred length: 22\nToken distribution (Batch 29): {12: 1, 1: 18, 11: 1, 10: 1, 27: 1}, Pred length: 22\nToken distribution (Batch 30): {34: 1, 1: 9, 47: 1, 6: 1, 32: 1, 19: 2, 10: 1}, Pred length: 16\nToken distribution (Batch 31): {1: 8}, Pred length: 8\nBatch 50, Gradient norm: 13.0354\nEpoch 11, Batch 50/128, Loss: 19.4790\nAvg Blank Probability: 0.0182\nSample predictions: ['aja', 'ajajajajaea', 'aHajaF']\nGround Truth (first 3): ['9*L6T79', 'Myr6OkWfynwh', 'CYZf8']\nRaw outputs (first 3): [[ 1  1  1  1  1  1 10  1  1  1  1  1 10 12 32  1 11  1 34  1  1  1  1 11\n   1 10  1  1  1 32 34  1]\n [ 1  1  1  1  1  1  6 10  1  1  1 34  1  1  1  1  1  1  1 35  1  1  1 42\n   1  1 10  1  1 12  1  1]\n [ 1  1  1  1 10  1  1 10  4 10  1  1 32  1  1  1  1  1 10  1  6 34  1 10\n  34  1 32  1  1  1  1  1]]\nInput length: 32, Label lengths: [7, 12, 5]\nToken distribution (Batch 0): {12: 1, 1: 6, 32: 1, 4: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 1): {1: 15, 4: 1, 32: 1, 12: 1, 47: 1, 27: 1, 34: 1, 5: 1}, Pred length: 22\nToken distribution (Batch 2): {1: 8, 5: 1, 27: 1, 22: 1, 32: 1, 19: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 3): {10: 3, 1: 9, 56: 1, 34: 1, 42: 1, 22: 1}, Pred length: 16\nToken distribution (Batch 4): {1: 11, 10: 2, 34: 3, 19: 1, 22: 1, 47: 1, 12: 2, 42: 1, 27: 1, 32: 1}, Pred length: 24\nToken distribution (Batch 5): {1: 14, 10: 1, 6: 1, 32: 2, 47: 1, 27: 1}, Pred length: 20\nToken distribution (Batch 6): {1: 15, 10: 2, 12: 1, 47: 1, 32: 2, 34: 1}, Pred length: 22\nToken distribution (Batch 7): {10: 1, 11: 1, 4: 1, 1: 12, 19: 2, 50: 1, 27: 1, 34: 1}, Pred length: 20\nToken distribution (Batch 8): {1: 12, 43: 1, 34: 2, 27: 1, 50: 1, 56: 1}, Pred length: 18\nToken distribution (Batch 9): {1: 8, 34: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 10): {1: 14, 11: 1, 32: 1, 19: 2, 27: 1, 10: 2, 22: 1}, Pred length: 22\nToken distribution (Batch 11): {1: 17, 27: 1, 24: 1, 22: 1, 5: 1, 47: 1, 19: 1, 34: 1}, Pred length: 24\nToken distribution (Batch 12): {1: 17, 32: 2, 19: 1, 22: 1, 43: 1}, Pred length: 22\nToken distribution (Batch 13): {1: 11, 34: 1}, Pred length: 12\nToken distribution (Batch 14): {10: 1, 1: 8, 32: 1}, Pred length: 10\nToken distribution (Batch 15): {1: 8, 47: 1, 19: 1, 6: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 16): {10: 2, 1: 3, 11: 1, 5: 1, 32: 2, 47: 1}, Pred length: 10\nToken distribution (Batch 17): {10: 4, 1: 15, 27: 1, 11: 2, 34: 2}, Pred length: 24\nToken distribution (Batch 18): {10: 1, 1: 12, 35: 1}, Pred length: 14\nToken distribution (Batch 19): {11: 1, 1: 5, 6: 1, 32: 2, 47: 2, 10: 1}, Pred length: 12\nToken distribution (Batch 20): {56: 1, 1: 10, 34: 1, 19: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 21): {1: 14, 12: 1, 10: 2, 43: 1, 5: 1, 22: 1, 34: 1, 32: 1}, Pred length: 22\nToken distribution (Batch 22): {1: 9, 32: 1}, Pred length: 10\nToken distribution (Batch 23): {1: 6, 32: 1, 34: 1, 22: 2}, Pred length: 10\nToken distribution (Batch 24): {6: 1, 1: 10, 34: 5, 10: 3, 56: 1, 32: 3, 19: 1}, Pred length: 24\nToken distribution (Batch 25): {1: 7, 10: 2, 32: 2, 47: 1}, Pred length: 12\nToken distribution (Batch 26): {1: 16, 11: 1, 19: 1, 34: 3, 5: 1}, Pred length: 22\nToken distribution (Batch 27): {1: 15, 43: 1, 6: 1, 10: 1, 47: 1, 34: 1}, Pred length: 20\nToken distribution (Batch 28): {10: 2, 12: 1, 1: 9, 42: 1, 32: 4, 27: 1, 47: 1, 19: 1}, Pred length: 20\nToken distribution (Batch 29): {1: 10, 32: 2, 47: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 30): {1: 7, 34: 1}, Pred length: 8\nToken distribution (Batch 31): {1: 9, 10: 1, 34: 1, 35: 1, 47: 1, 11: 1}, Pred length: 14\nBatch 60, Gradient norm: 637.1307\nEpoch 11, Batch 60/128, Loss: 18.7850\nAvg Blank Probability: 0.0183\nSample predictions: ['laFadaU', 'adaFalaUAaHaea', 'aeaAvFsaja']\nGround Truth (first 3): ['7Wa2G', 'G8Jr5EfhJpv', 'qPKCgfB']\nRaw outputs (first 3): [[12  1  1 10 11  1  1 10  1  1  1  4  1  1 10  1 10 10 10 11 56 10  1  1\n   6  1  1  1 10  1  1  1]\n [ 1  1  1  1  1 10  1 11  1  1 11  1  1  1  1  1 10  1  1  1  1  1  1 32\n   1 10  1  1 12  1  1  1]\n [ 1  1  5  1 10  1  1  4 43  1 32  1 32  1 32  1  0 10  1  0 34 12  1 34\n   1  1  1  1  1  1 34  1]]\nInput length: 32, Label lengths: [5, 11, 7]\nToken distribution (Batch 0): {1: 15, 19: 1, 11: 1, 34: 1, 47: 2, 32: 1, 10: 1}, Pred length: 22\nToken distribution (Batch 1): {11: 1, 6: 1, 1: 9, 32: 1, 27: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 2): {1: 13, 19: 1, 32: 1, 22: 1}, Pred length: 16\nToken distribution (Batch 3): {34: 3, 10: 4, 1: 8, 56: 1, 19: 1, 4: 1}, Pred length: 18\nToken distribution (Batch 4): {1: 3, 10: 3, 27: 1, 19: 1}, Pred length: 8\nToken distribution (Batch 5): {1: 18, 47: 1, 27: 1}, Pred length: 20\nToken distribution (Batch 6): {1: 2, 11: 1, 47: 1, 32: 1, 6: 1, 35: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 7): {1: 15, 10: 3, 19: 1, 6: 1, 47: 1, 32: 1}, Pred length: 22\nToken distribution (Batch 8): {1: 11, 19: 2, 34: 1}, Pred length: 14\nToken distribution (Batch 9): {1: 6, 19: 1, 27: 1, 10: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 10): {1: 13, 32: 3, 34: 1, 47: 1, 10: 1, 19: 1}, Pred length: 20\nToken distribution (Batch 11): {1: 16, 47: 3, 32: 2, 27: 1, 34: 2}, Pred length: 24\nToken distribution (Batch 12): {22: 1, 35: 2, 34: 1, 1: 13, 19: 1, 32: 1, 10: 2, 6: 1}, Pred length: 22\nToken distribution (Batch 13): {1: 9, 11: 2, 34: 1, 32: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 14): {1: 12, 19: 2, 32: 1, 47: 2, 34: 2, 22: 1}, Pred length: 20\nToken distribution (Batch 15): {1: 11, 34: 2, 4: 1}, Pred length: 14\nToken distribution (Batch 16): {1: 13, 10: 2, 32: 4, 34: 1, 56: 1, 5: 2, 6: 1}, Pred length: 24\nToken distribution (Batch 17): {1: 17, 22: 1}, Pred length: 18\nToken distribution (Batch 18): {10: 2, 19: 1, 1: 15, 11: 2, 32: 1, 27: 1, 47: 1, 34: 1}, Pred length: 24\nToken distribution (Batch 19): {1: 12, 34: 1, 42: 1, 11: 2}, Pred length: 16\nToken distribution (Batch 20): {4: 1, 1: 9, 32: 1, 43: 1, 34: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 21): {1: 13, 10: 2, 32: 2, 35: 1, 11: 1, 34: 1}, Pred length: 20\nToken distribution (Batch 22): {63: 1, 1: 13, 32: 4, 6: 1, 11: 1, 42: 1, 10: 1}, Pred length: 22\nToken distribution (Batch 23): {1: 6, 34: 2}, Pred length: 8\nToken distribution (Batch 24): {34: 3, 4: 1, 1: 11, 42: 1, 32: 2, 47: 1, 10: 1}, Pred length: 20\nToken distribution (Batch 25): {10: 1, 4: 1, 12: 2, 1: 3, 19: 1}, Pred length: 8\nToken distribution (Batch 26): {1: 10, 10: 2, 34: 2}, Pred length: 14\nToken distribution (Batch 27): {1: 8}, Pred length: 8\nToken distribution (Batch 28): {1: 17, 34: 1, 47: 1, 19: 1}, Pred length: 20\nToken distribution (Batch 29): {10: 3, 34: 1, 1: 15, 32: 2, 5: 1, 11: 1, 19: 1}, Pred length: 24\nToken distribution (Batch 30): {1: 14, 10: 4, 22: 1, 11: 1, 32: 2, 47: 2}, Pred length: 24\nToken distribution (Batch 31): {32: 1, 1: 6, 12: 1}, Pred length: 8\nBatch 70, Gradient norm: 21.5895\nEpoch 11, Batch 70/128, Loss: 19.0377\nAvg Blank Probability: 0.0185\nSample predictions: ['asakaHUaFUja', 'kfaFaAaH', 'asaFva']\nGround Truth (first 3): ['JUFDhchv6u7', '1MbsdUD', 'xPPTkVLl']\nRaw outputs (first 3): [[ 1 11  1 34  1  1  1  1  1  1  1 34 22  1  1 11  1  1 10  1  4  1 63  1\n   1 10  1  1  1 10  1 32]\n [ 1  6  1 10  1  1  1  1  1  1 32  1 35  1  1  1 10  1 19  1  1 10  1  1\n  34  0  1  1  1 34  1  1]\n [ 0  1  1  1  1  1 11  1  1 19  1  0 34 11 19 34 10  1  1 34  1  1  1  1\n   4 12  1  1  1  1  1  1]]\nInput length: 32, Label lengths: [11, 7, 8]\nToken distribution (Batch 0): {1: 11, 6: 1, 11: 2, 22: 1, 4: 1}, Pred length: 16\nToken distribution (Batch 1): {1: 11, 6: 1, 10: 1, 4: 1, 34: 1, 19: 1, 56: 1, 47: 1}, Pred length: 18\nToken distribution (Batch 2): {1: 5, 34: 3, 32: 1, 11: 1}, Pred length: 10\nToken distribution (Batch 3): {1: 6, 34: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 4): {1: 7, 47: 1, 10: 1, 32: 2, 34: 1}, Pred length: 12\nToken distribution (Batch 5): {1: 6, 19: 1, 10: 1, 42: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 6): {10: 3, 1: 9, 34: 2, 22: 1, 47: 3, 4: 1, 32: 3}, Pred length: 22\nToken distribution (Batch 7): {1: 5, 32: 1, 10: 2, 27: 2}, Pred length: 10\nToken distribution (Batch 8): {1: 13, 10: 2, 34: 1}, Pred length: 16\nToken distribution (Batch 9): {47: 1, 35: 1, 1: 6, 27: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 10): {1: 14, 11: 1, 10: 1, 19: 1, 34: 1, 4: 1, 47: 1}, Pred length: 20\nToken distribution (Batch 11): {1: 18, 34: 2}, Pred length: 20\nToken distribution (Batch 12): {1: 11, 11: 2, 19: 1, 50: 1, 32: 2, 34: 1}, Pred length: 18\nToken distribution (Batch 13): {47: 2, 1: 10, 34: 2, 4: 2, 55: 2}, Pred length: 18\nToken distribution (Batch 14): {10: 1, 1: 13, 32: 2, 47: 2, 12: 1, 27: 1}, Pred length: 20\nToken distribution (Batch 15): {1: 6, 56: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 16): {1: 13, 10: 1, 47: 2, 4: 1, 48: 1}, Pred length: 18\nToken distribution (Batch 17): {1: 6, 47: 1, 27: 1}, Pred length: 8\nToken distribution (Batch 18): {1: 10, 34: 1, 35: 1}, Pred length: 12\nToken distribution (Batch 19): {1: 8, 10: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 20): {4: 2, 19: 1, 1: 17, 34: 2}, Pred length: 22\nToken distribution (Batch 21): {1: 9, 34: 4, 10: 1}, Pred length: 14\nToken distribution (Batch 22): {1: 7, 10: 1, 22: 1, 48: 1}, Pred length: 10\nToken distribution (Batch 23): {1: 8, 10: 1, 34: 1, 56: 1, 5: 1}, Pred length: 12\nToken distribution (Batch 24): {1: 10, 6: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 25): {1: 12, 19: 1, 11: 1, 12: 1, 47: 1, 34: 2}, Pred length: 18\nToken distribution (Batch 26): {1: 11, 10: 4, 32: 1, 19: 1, 34: 1, 42: 1, 50: 1, 4: 1, 27: 1}, Pred length: 22\nToken distribution (Batch 27): {1: 15, 11: 1, 19: 2, 47: 1, 32: 1, 10: 2}, Pred length: 22\nToken distribution (Batch 28): {1: 6, 10: 2, 34: 3, 56: 1}, Pred length: 12\nToken distribution (Batch 29): {1: 8, 47: 1, 10: 1, 34: 1, 48: 1, 4: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 30): {1: 7, 4: 1, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 31): {10: 2, 1: 8}, Pred length: 10\nBatch 80, Gradient norm: 230.3425\nEpoch 11, Batch 80/128, Loss: 20.8975\nAvg Blank Probability: 0.0187\nSample predictions: ['afakavadak', 'afjadHasa3Ua', 'aHaFHkaH']\nGround Truth (first 3): ['d7VTMFbb', 'Ja8U7pP5T', 'O5N2A']\nRaw outputs (first 3): [[ 1  1  1  1  1  1  1 11  1  1  1  1 11  1 10  1  1 11  1  1  4  1  1  1\n   1  1  1  1  1  1  1 10]\n [ 1  1  1  1  1  1 10  1  1 47  1  1  1 47  1 56 10  1  1  1  4 34 10 10\n   1 19  1  1  1  1  0  1]\n [ 1  1  1  1  1  1  1  1  1 35 11  1  1  1 32  1  1  1  1  1  0  1  1  1\n   6 11  0  1  1  0  1  1]]\nInput length: 32, Label lengths: [8, 9, 5]\nToken distribution (Batch 0): {1: 6, 34: 1, 19: 1, 48: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 1): {1: 12, 32: 2, 4: 1, 34: 3, 11: 1, 35: 1}, Pred length: 20\nToken distribution (Batch 2): {1: 3, 47: 2, 56: 2, 10: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 10, 27: 2, 32: 2}, Pred length: 14\nToken distribution (Batch 4): {1: 9, 25: 1}, Pred length: 10\nToken distribution (Batch 5): {1: 17, 32: 1, 47: 1, 27: 1, 10: 3, 22: 1}, Pred length: 24\nToken distribution (Batch 6): {1: 8, 10: 2, 34: 3, 47: 1, 4: 1, 32: 3}, Pred length: 18\nToken distribution (Batch 7): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 8): {6: 1, 1: 6, 32: 1}, Pred length: 8\nToken distribution (Batch 9): {1: 15, 10: 2, 19: 1, 27: 1, 34: 3, 32: 1, 22: 1}, Pred length: 24\nToken distribution (Batch 10): {1: 15, 10: 3, 47: 1, 42: 1, 32: 1, 34: 1}, Pred length: 22\nToken distribution (Batch 11): {1: 12, 22: 1, 27: 1}, Pred length: 14\nToken distribution (Batch 12): {1: 8}, Pred length: 8\nToken distribution (Batch 13): {1: 7, 22: 1, 47: 3, 10: 1, 27: 2}, Pred length: 14\nToken distribution (Batch 14): {42: 1, 1: 19, 34: 3, 47: 1}, Pred length: 24\nToken distribution (Batch 15): {10: 2, 12: 1, 1: 9, 27: 1, 56: 1}, Pred length: 14\nToken distribution (Batch 16): {1: 13, 4: 1}, Pred length: 14\nToken distribution (Batch 17): {1: 8, 47: 2, 34: 1, 50: 1}, Pred length: 12\nToken distribution (Batch 18): {34: 3, 1: 14, 19: 1, 4: 1, 32: 3}, Pred length: 22\nToken distribution (Batch 19): {34: 1, 1: 11, 10: 1, 32: 2, 19: 1}, Pred length: 16\nToken distribution (Batch 20): {10: 1, 1: 11}, Pred length: 12\nToken distribution (Batch 21): {1: 10, 35: 1, 34: 3, 10: 2}, Pred length: 16\nToken distribution (Batch 22): {6: 2, 1: 11, 22: 1, 32: 1, 27: 1, 12: 1, 10: 1}, Pred length: 18\nToken distribution (Batch 23): {11: 1, 1: 9, 32: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 24): {1: 11, 32: 4, 47: 3, 19: 1, 10: 2, 6: 1, 42: 1, 5: 1}, Pred length: 24\nToken distribution (Batch 25): {1: 13, 22: 2, 56: 2, 47: 1, 34: 1, 27: 1}, Pred length: 20\nToken distribution (Batch 26): {1: 13, 34: 1, 27: 1, 10: 1}, Pred length: 16\nToken distribution (Batch 27): {1: 4, 6: 1, 10: 1, 34: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 28): {1: 8, 10: 2, 32: 2, 11: 1, 56: 1, 43: 1, 34: 1}, Pred length: 16\nToken distribution (Batch 29): {34: 1, 1: 19, 19: 1, 32: 1, 47: 1, 42: 1}, Pred length: 24\nToken distribution (Batch 30): {1: 14, 4: 2, 32: 2, 47: 2, 56: 1, 42: 1}, Pred length: 22\nToken distribution (Batch 31): {1: 15, 47: 1, 35: 1, 27: 1, 32: 1, 6: 1}, Pred length: 20\nBatch 90, Gradient norm: 1416.8936\nEpoch 11, Batch 90/128, Loss: 19.5804\nAvg Blank Probability: 0.0189\nSample predictions: ['aHasVva', 'aFdFaHaHkHaIa', 'aUa3j3a']\nGround Truth (first 3): ['nSew5', 'ehUdo*fudz', 'pVj7']\nRaw outputs (first 3): [[ 1  1  1  1  1  6  1  1  6  1  1  1  1  1 42 10  1  1 34 34 10  1  6 11\n   1  1  1  1  1 34  1  1]\n [ 1  1 47  1  1  1 10  1  1  1  1  1  1  1  1 12  1 47  1  1  1  1  1 11\n   1 22  1  1 10  1  4  1]\n [ 1 32 47  1  1  1  1  1  0 10  0  1  1  1  1  0  1  1 19  0  1 35 22  1\n   1  1 34  1  1  1  4  1]]\nInput length: 32, Label lengths: [5, 10, 4]\nToken distribution (Batch 0): {1: 6, 32: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 1): {1: 7, 32: 2, 10: 2, 6: 1}, Pred length: 12\nToken distribution (Batch 2): {1: 15, 10: 1, 22: 1, 32: 3}, Pred length: 20\nToken distribution (Batch 3): {1: 7, 34: 1, 4: 2, 6: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 4): {1: 10, 47: 2, 32: 1, 6: 1, 43: 1, 34: 1, 25: 1, 11: 1}, Pred length: 18\nToken distribution (Batch 5): {56: 1, 12: 1, 32: 1, 1: 8, 47: 1}, Pred length: 12\nToken distribution (Batch 6): {47: 1, 1: 9, 34: 2, 32: 1, 6: 1, 4: 1, 10: 1, 12: 1, 35: 1}, Pred length: 18\nToken distribution (Batch 7): {1: 9, 22: 1, 11: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 8): {34: 2, 1: 7, 4: 1, 47: 1, 50: 1}, Pred length: 12\nToken distribution (Batch 9): {10: 2, 1: 10, 27: 1, 47: 1, 34: 2}, Pred length: 16\nToken distribution (Batch 10): {34: 2, 1: 16, 10: 1, 4: 1, 47: 1, 35: 1}, Pred length: 22\nToken distribution (Batch 11): {63: 1, 1: 6, 27: 1}, Pred length: 8\nToken distribution (Batch 12): {1: 10, 47: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 13): {1: 5, 47: 1, 10: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 14): {1: 13, 34: 3, 10: 2}, Pred length: 18\nToken distribution (Batch 15): {1: 11, 11: 1, 32: 2, 47: 1, 10: 1}, Pred length: 16\nToken distribution (Batch 16): {10: 1, 1: 8, 34: 1, 32: 1, 11: 2, 6: 1}, Pred length: 14\nToken distribution (Batch 17): {1: 6, 11: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 18): {1: 11, 34: 3, 32: 1, 47: 1, 6: 1, 10: 2, 50: 1}, Pred length: 20\nToken distribution (Batch 19): {1: 7, 10: 1}, Pred length: 8\nToken distribution (Batch 20): {1: 4, 11: 1, 34: 1, 10: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 21): {1: 7, 48: 1, 4: 1, 19: 1}, Pred length: 10\nToken distribution (Batch 22): {34: 2, 1: 5, 43: 1, 10: 2}, Pred length: 10\nToken distribution (Batch 23): {1: 15, 35: 1, 10: 2, 32: 2}, Pred length: 20\nToken distribution (Batch 24): {1: 5, 47: 1, 56: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 25): {10: 2, 47: 1, 4: 1, 1: 11, 27: 1, 34: 2}, Pred length: 18\nToken distribution (Batch 26): {34: 3, 1: 11, 32: 2, 27: 1, 22: 1}, Pred length: 18\nToken distribution (Batch 27): {1: 4, 10: 1, 34: 2, 27: 1}, Pred length: 8\nToken distribution (Batch 28): {4: 1, 32: 1, 35: 1, 1: 17, 22: 1, 11: 1}, Pred length: 22\nToken distribution (Batch 29): {1: 7, 34: 2, 47: 1}, Pred length: 10\nToken distribution (Batch 30): {1: 15, 35: 1, 34: 1, 6: 1}, Pred length: 18\nToken distribution (Batch 31): {10: 1, 1: 10, 34: 1, 47: 1, 22: 1}, Pred length: 14\nBatch 100, Gradient norm: 1549.1018\nEpoch 11, Batch 100/128, Loss: 22.1149\nAvg Blank Probability: 0.0191\nSample predictions: ['aFava', 'aFajFafja', 'ajavFaFa']\nGround Truth (first 3): ['ufNK', '6bB19p', 'f7DEiBGEyH']\nRaw outputs (first 3): [[ 1  1  1  1  1 56 47  1 34 10 34 63  1  1  1  4 10  1  1  1  1  1  1  1\n  10 10 47  1  4  1  1 10]\n [ 1 32  1 34 47 12  1  1 34  1  1  1  1  1  1  1  1 11  1  1 11  1 34  1\n   1 47 34  1 32 34  1  1]\n [ 1  1  1  1 47 32 34  1  1  1  1  1  1 47  1  1 34  1  1  1  1 48  1 35\n   1  4  1  1 35  1  0  1]]\nInput length: 32, Label lengths: [4, 6, 10]\nToken distribution (Batch 0): {1: 12, 32: 1, 35: 1}, Pred length: 14\nToken distribution (Batch 1): {1: 15, 10: 2, 47: 1, 34: 1, 19: 1, 42: 1, 32: 2, 11: 1}, Pred length: 24\nToken distribution (Batch 2): {1: 10, 34: 2, 56: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 3): {1: 6, 10: 2}, Pred length: 8\nToken distribution (Batch 4): {19: 1, 1: 8, 6: 2, 5: 1}, Pred length: 12\nToken distribution (Batch 5): {63: 1, 1: 16, 27: 1, 47: 1, 19: 1}, Pred length: 20\nToken distribution (Batch 6): {1: 8, 19: 1, 22: 3, 42: 1, 47: 1, 27: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 7): {1: 12, 27: 3, 19: 1}, Pred length: 16\nToken distribution (Batch 8): {11: 2, 1: 13, 19: 2, 5: 1, 32: 1, 4: 1, 47: 1, 56: 1, 10: 1, 34: 1}, Pred length: 24\nToken distribution (Batch 9): {1: 7, 56: 1, 11: 1, 47: 1, 10: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 11, 34: 1, 10: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 11): {1: 17, 25: 1, 32: 3, 47: 1, 4: 1, 50: 1}, Pred length: 24\nToken distribution (Batch 12): {1: 13, 43: 2, 34: 3, 6: 1, 47: 1}, Pred length: 20\nToken distribution (Batch 13): {1: 12, 27: 1, 32: 2, 34: 2, 4: 1, 10: 1, 22: 1}, Pred length: 20\nToken distribution (Batch 14): {1: 9, 47: 1, 32: 2}, Pred length: 12\nToken distribution (Batch 15): {1: 11, 10: 2, 47: 1}, Pred length: 14\nToken distribution (Batch 16): {1: 12, 34: 1, 47: 1, 32: 1, 10: 1}, Pred length: 16\nToken distribution (Batch 17): {1: 12}, Pred length: 12\nToken distribution (Batch 18): {1: 7, 34: 2, 27: 1, 56: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 19): {10: 4, 42: 1, 1: 5, 19: 1, 47: 2, 32: 2, 22: 1}, Pred length: 16\nToken distribution (Batch 20): {22: 2, 19: 2, 1: 15, 4: 1, 56: 1, 34: 1, 10: 1, 11: 1}, Pred length: 24\nToken distribution (Batch 21): {4: 1, 1: 16, 42: 1, 11: 1, 32: 2, 10: 1}, Pred length: 22\nToken distribution (Batch 22): {1: 7, 34: 1}, Pred length: 8\nToken distribution (Batch 23): {10: 3, 1: 13, 11: 1, 34: 2, 19: 2, 32: 2, 47: 1}, Pred length: 24\nToken distribution (Batch 24): {56: 1, 1: 14, 11: 1, 47: 2, 22: 1, 34: 1, 35: 1, 27: 1}, Pred length: 22\nToken distribution (Batch 25): {1: 9, 47: 1, 56: 1, 32: 1, 10: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 26): {1: 8, 10: 2, 32: 1, 12: 1}, Pred length: 12\nToken distribution (Batch 27): {1: 17, 6: 2, 47: 2, 32: 1, 10: 1, 34: 1}, Pred length: 24\nToken distribution (Batch 28): {10: 2, 1: 12, 47: 1, 6: 1}, Pred length: 16\nToken distribution (Batch 29): {1: 10, 6: 1, 32: 1, 11: 1, 10: 1, 27: 1, 22: 1}, Pred length: 16\nToken distribution (Batch 30): {10: 2, 1: 6, 22: 2, 32: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 31): {1: 11, 4: 1, 27: 1, 34: 3}, Pred length: 16\nBatch 110, Gradient norm: 30.5727\nEpoch 11, Batch 110/128, Loss: 18.2720\nAvg Blank Probability: 0.0191\nSample predictions: ['aFaI', 'ajaUHasajPaFaFak', 'aH3ajaH']\nGround Truth (first 3): ['0efyPoj', 'oGD9-3hIZsaf', 'SH1tpfZ']\nRaw outputs (first 3): [[ 1  1 56  1 19 63  1  1 11  1  1  1  1  1  1  1  6  1  1 10 22  4  1  1\n  56  1  1  1 10  1 10  1]\n [ 1  1  1  1  1  1  1  1  1 56  1  1  1  1  0  1  1  1  1 42 19  1  1 10\n   1  1 10  1  1  1  1  1]\n [ 1  1  1 10  0  1  0  1  1  1 34 25  0  1 47 10  1  1 34  1  1  0  1 10\n   1  1 32  1  1  6  1  4]]\nInput length: 32, Label lengths: [7, 12, 7]\nToken distribution (Batch 0): {1: 18, 34: 3, 47: 1, 10: 1, 48: 1}, Pred length: 24\nToken distribution (Batch 1): {6: 1, 1: 18, 32: 1, 47: 1, 22: 1, 10: 1, 34: 1}, Pred length: 24\nToken distribution (Batch 2): {1: 10, 6: 1, 32: 2, 10: 1}, Pred length: 14\nToken distribution (Batch 3): {1: 14, 10: 1, 32: 2, 34: 1, 4: 1, 19: 1}, Pred length: 20\nToken distribution (Batch 4): {1: 10, 32: 2, 4: 1, 19: 1, 6: 1, 10: 1}, Pred length: 16\nToken distribution (Batch 5): {1: 13, 47: 3, 10: 2, 19: 1, 11: 1}, Pred length: 20\nToken distribution (Batch 6): {1: 13, 27: 3, 10: 1, 34: 2, 32: 1}, Pred length: 20\nToken distribution (Batch 7): {1: 6, 27: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 8): {47: 2, 1: 17, 4: 1, 32: 1, 10: 2, 19: 1}, Pred length: 24\nToken distribution (Batch 9): {1: 6, 32: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 10): {1: 13, 34: 3}, Pred length: 16\nToken distribution (Batch 11): {1: 5, 11: 1, 10: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 12): {1: 7, 10: 2, 34: 1}, Pred length: 10\nToken distribution (Batch 13): {1: 8, 4: 1, 56: 1, 34: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 14): {34: 2, 10: 2, 1: 11, 19: 1, 56: 1, 47: 1, 32: 2}, Pred length: 20\nToken distribution (Batch 15): {1: 14, 10: 2, 47: 1, 56: 1}, Pred length: 18\nToken distribution (Batch 16): {1: 17, 47: 1, 27: 1, 34: 2, 19: 1}, Pred length: 22\nToken distribution (Batch 17): {63: 1, 1: 9, 19: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 18): {1: 5, 10: 3, 32: 2}, Pred length: 10\nToken distribution (Batch 19): {1: 9, 5: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 12, 56: 1, 10: 1, 22: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 21): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 22): {10: 1, 1: 11, 32: 1, 22: 1}, Pred length: 14\nToken distribution (Batch 23): {47: 1, 1: 6, 42: 1, 22: 1, 32: 2, 34: 1}, Pred length: 12\nToken distribution (Batch 24): {1: 7, 35: 1, 22: 1, 34: 2, 32: 2, 4: 1}, Pred length: 14\nToken distribution (Batch 25): {10: 2, 12: 1, 1: 5}, Pred length: 8\nToken distribution (Batch 26): {1: 12, 34: 3, 19: 1, 35: 1, 27: 1}, Pred length: 18\nToken distribution (Batch 27): {1: 10, 47: 3, 10: 1}, Pred length: 14\nToken distribution (Batch 28): {1: 9, 19: 1}, Pred length: 10\nToken distribution (Batch 29): {10: 1, 32: 1, 34: 1, 1: 19}, Pred length: 22\nToken distribution (Batch 30): {34: 2, 1: 13, 32: 2, 10: 1}, Pred length: 18\nToken distribution (Batch 31): {1: 16, 32: 2, 19: 1, 10: 2, 34: 1}, Pred length: 22\nBatch 120, Gradient norm: 15.3303\nEpoch 11, Batch 120/128, Loss: 20.1925\nAvg Blank Probability: 0.0194\nSample predictions: ['aHUHjaHaVa', 'faFUavjaHa', 'afaFaFaja']\nGround Truth (first 3): ['gJEE0PrFHsMV', 'bxB7ZooFLL6-', '5lGFKI9']\nRaw outputs (first 3): [[12  6  1  1  1 10  1  1 12 32  1  1  1  1 34  1  1 63  1  1  1  1 10 10\n   1 10  1  4  1 10 10  1]\n [ 1  1  1 10  1  1  1  1 47  1  1  1  1  4 10 10  1  1  1  1  1  1  1 47\n   1 12  1  1  1 32 34 32]\n [ 1  1  6  1  1  0  1  1  1  1  1  1  1 56  1  1  1  1  1  1  1  1  1  1\n  35  1 34  0 19 34 34  1]]\nInput length: 32, Label lengths: [12, 12, 7]\nEpoch 11/20, Loss: 19.2863\nToken distribution (Batch 0): {1: 8}, Pred length: 8\nToken distribution (Batch 1): {1: 16}, Pred length: 16\nToken distribution (Batch 2): {1: 14}, Pred length: 14\nToken distribution (Batch 3): {1: 8}, Pred length: 8\nToken distribution (Batch 4): {1: 16}, Pred length: 16\nToken distribution (Batch 5): {1: 18}, Pred length: 18\nToken distribution (Batch 6): {1: 16}, Pred length: 16\nToken distribution (Batch 7): {1: 10}, Pred length: 10\nToken distribution (Batch 8): {1: 8}, Pred length: 8\nToken distribution (Batch 9): {1: 8}, Pred length: 8\nToken distribution (Batch 10): {1: 16}, Pred length: 16\nToken distribution (Batch 11): {1: 16}, Pred length: 16\nToken distribution (Batch 12): {1: 16}, Pred length: 16\nToken distribution (Batch 13): {1: 20}, Pred length: 20\nToken distribution (Batch 14): {1: 20}, Pred length: 20\nToken distribution (Batch 15): {1: 10}, Pred length: 10\nToken distribution (Batch 16): {1: 10}, Pred length: 10\nToken distribution (Batch 17): {1: 20}, Pred length: 20\nToken distribution (Batch 18): {1: 14}, Pred length: 14\nToken distribution (Batch 19): {1: 18}, Pred length: 18\nToken distribution (Batch 20): {1: 8}, Pred length: 8\nToken distribution (Batch 21): {1: 18}, Pred length: 18\nToken distribution (Batch 22): {1: 10}, Pred length: 10\nToken distribution (Batch 23): {1: 16}, Pred length: 16\nToken distribution (Batch 24): {1: 24}, Pred length: 24\nToken distribution (Batch 25): {1: 14}, Pred length: 14\nToken distribution (Batch 26): {1: 16}, Pred length: 16\nToken distribution (Batch 27): {1: 14}, Pred length: 14\nToken distribution (Batch 28): {1: 18}, Pred length: 18\nToken distribution (Batch 29): {1: 16}, Pred length: 16\nToken distribution (Batch 30): {1: 8}, Pred length: 8\nToken distribution (Batch 31): {1: 20}, Pred length: 20\nValidation Loss: 19.7404\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['8tBh', 'YlccKutI', 'SrP5dpl', '6UKi', 'B7nW102q']\nCurrent Learning Rate: 5.489012923366981e-07\nEpoch 12, Filtered data size: 5120, Sample labels: ['qV8ib8H', 'MdI8', '1XS0DRdJ']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 0): {1: 9, 32: 1, 19: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 1): {10: 1, 1: 13, 32: 4}, Pred length: 18\nToken distribution (Batch 2): {1: 9, 34: 1, 27: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 3): {4: 1, 47: 1, 1: 5, 10: 1, 32: 2}, Pred length: 10\nToken distribution (Batch 4): {1: 4, 56: 1, 10: 1, 6: 2, 34: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 5): {10: 3, 1: 12, 19: 1, 47: 1, 34: 1}, Pred length: 18\nToken distribution (Batch 6): {1: 13, 32: 3, 34: 3, 10: 1}, Pred length: 20\nToken distribution (Batch 7): {1: 6, 10: 3, 34: 1}, Pred length: 10\nToken distribution (Batch 8): {1: 7, 6: 1}, Pred length: 8\nToken distribution (Batch 9): {1: 10, 34: 2, 32: 1, 10: 1, 27: 2}, Pred length: 16\nToken distribution (Batch 10): {47: 1, 22: 2, 1: 12, 34: 1, 35: 1, 5: 1}, Pred length: 18\nToken distribution (Batch 11): {1: 5, 34: 1, 27: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 12): {1: 11, 47: 1, 34: 4, 32: 3, 56: 1}, Pred length: 20\nToken distribution (Batch 13): {1: 11, 10: 2, 22: 1}, Pred length: 14\nToken distribution (Batch 14): {11: 1, 1: 9}, Pred length: 10\nToken distribution (Batch 15): {1: 11, 10: 3, 19: 1, 43: 1, 47: 1, 34: 1}, Pred length: 18\nToken distribution (Batch 16): {1: 15, 27: 1, 11: 1, 48: 1, 35: 1, 42: 1}, Pred length: 20\nToken distribution (Batch 17): {1: 12, 42: 1, 10: 1, 35: 1, 22: 2, 34: 1}, Pred length: 18\nToken distribution (Batch 18): {34: 3, 1: 12, 47: 1, 10: 1, 19: 1, 32: 2, 42: 1, 27: 1}, Pred length: 22\nToken distribution (Batch 19): {1: 14, 34: 2, 10: 1, 47: 1}, Pred length: 18\nToken distribution (Batch 20): {1: 6, 47: 2, 10: 2, 56: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 21): {10: 1, 1: 8, 34: 1, 27: 2}, Pred length: 12\nToken distribution (Batch 22): {4: 1, 10: 2, 1: 8, 32: 1, 6: 1, 47: 2, 22: 1}, Pred length: 16\nToken distribution (Batch 23): {10: 3, 1: 14, 47: 1, 32: 1, 19: 1}, Pred length: 20\nToken distribution (Batch 24): {6: 1, 1: 5, 34: 1, 10: 1, 32: 2}, Pred length: 10\nToken distribution (Batch 25): {1: 6, 27: 1, 12: 1, 25: 1, 34: 1, 19: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 26): {1: 11, 4: 2, 32: 2, 34: 1, 47: 3, 12: 1}, Pred length: 20\nToken distribution (Batch 27): {1: 9, 32: 1}, Pred length: 10\nToken distribution (Batch 28): {10: 1, 4: 2, 1: 13, 22: 1, 32: 2, 19: 2, 56: 1, 34: 2}, Pred length: 24\nToken distribution (Batch 29): {34: 2, 10: 1, 32: 3, 1: 12, 22: 1, 50: 1}, Pred length: 20\nToken distribution (Batch 30): {1: 16, 10: 4, 32: 1, 19: 1, 35: 1, 34: 1}, Pred length: 24\nToken distribution (Batch 31): {1: 5, 12: 1, 27: 1, 47: 1}, Pred length: 8\nBatch 0, Gradient norm: 80.5787\nEpoch 12, Batch 0/128, Loss: 19.9694\nAvg Blank Probability: 0.0196\nSample predictions: ['aFasaja', 'jaFaFaFaFa', 'aHaAaj']\nGround Truth (first 3): ['PJXTQR', 'MJLUKiWiI', 'R71NmV']\nRaw outputs (first 3): [[ 1  1 32 10  1 47  1  1  1  1 47  4  1  1  1  1  4  1 34  1  1  1  4 10\n   6  1 19  1 10 34  1  1]\n [ 1 10  1  4  1 10  1  1  1  1 22  1 47 10 11  1  1  1  1  1  0 10 10  1\n   1  0  1  1 10  0  1  1]\n [ 1  1  1 47 56  1 32 10  6 34  1 34  1  1  1  1  1  1  1  1 47  1  1 10\n   1  1  0  0  4 32  0  0]]\nInput length: 32, Label lengths: [6, 9, 6]\nToken distribution (Batch 0): {4: 1, 1: 11, 34: 1, 6: 1, 47: 1, 10: 1}, Pred length: 16\nToken distribution (Batch 1): {32: 3, 1: 9}, Pred length: 12\nToken distribution (Batch 2): {1: 13, 6: 1, 47: 1, 19: 1}, Pred length: 16\nToken distribution (Batch 3): {1: 15, 10: 2, 34: 2, 47: 1, 32: 2}, Pred length: 22\nToken distribution (Batch 4): {1: 12, 32: 2, 34: 2, 11: 1, 19: 1}, Pred length: 18\nToken distribution (Batch 5): {1: 10, 19: 1, 22: 1, 27: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 6): {1: 14, 10: 2, 32: 2, 5: 1, 27: 1, 47: 2}, Pred length: 22\nToken distribution (Batch 7): {47: 2, 34: 4, 1: 7, 10: 1, 19: 1, 6: 1}, Pred length: 16\nToken distribution (Batch 8): {1: 7, 34: 2, 56: 1}, Pred length: 10\nToken distribution (Batch 9): {22: 1, 1: 13, 5: 1, 34: 2, 4: 1}, Pred length: 18\nToken distribution (Batch 10): {1: 9, 19: 1}, Pred length: 10\nToken distribution (Batch 11): {1: 7, 6: 1, 10: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 12): {1: 19, 32: 2, 47: 1}, Pred length: 22\nToken distribution (Batch 13): {1: 8, 34: 2, 6: 1, 10: 3}, Pred length: 14\nToken distribution (Batch 14): {1: 13, 19: 1, 32: 2}, Pred length: 16\nToken distribution (Batch 15): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 16): {10: 3, 11: 1, 5: 3, 1: 12, 35: 1, 22: 1, 34: 1}, Pred length: 22\nToken distribution (Batch 17): {1: 11, 10: 1, 47: 1, 5: 1}, Pred length: 14\nToken distribution (Batch 18): {10: 3, 1: 9, 4: 1, 34: 1, 12: 1, 32: 2, 35: 1, 56: 1, 11: 1}, Pred length: 20\nToken distribution (Batch 19): {1: 14, 34: 1, 27: 1, 32: 1, 55: 1}, Pred length: 18\nToken distribution (Batch 20): {1: 11, 22: 2, 47: 1}, Pred length: 14\nToken distribution (Batch 21): {34: 2, 1: 13, 42: 1, 11: 2, 47: 2, 12: 1, 10: 1, 22: 1, 48: 1}, Pred length: 24\nToken distribution (Batch 22): {4: 1, 1: 11, 22: 1, 19: 2, 10: 1}, Pred length: 16\nToken distribution (Batch 23): {1: 5, 10: 1, 32: 1, 25: 1}, Pred length: 8\nToken distribution (Batch 24): {1: 17, 10: 1, 11: 1, 22: 1}, Pred length: 20\nToken distribution (Batch 25): {1: 8, 4: 1, 32: 1, 34: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 26): {47: 2, 1: 10, 32: 3, 10: 2, 22: 1}, Pred length: 18\nToken distribution (Batch 27): {47: 1, 1: 11, 10: 2, 11: 1, 35: 1}, Pred length: 16\nToken distribution (Batch 28): {1: 5, 34: 3, 4: 1, 32: 3, 22: 2}, Pred length: 14\nToken distribution (Batch 29): {1: 9, 12: 1, 10: 1, 42: 1, 4: 1, 32: 2, 47: 1}, Pred length: 16\nToken distribution (Batch 30): {1: 14, 32: 3, 47: 1, 34: 1, 50: 1}, Pred length: 20\nToken distribution (Batch 31): {1: 10, 56: 1, 34: 2, 32: 1, 27: 1, 10: 1}, Pred length: 16\nBatch 10, Gradient norm: 13.4095\nEpoch 12, Batch 10/128, Loss: 18.5813\nAvg Blank Probability: 0.0197\nSample predictions: ['daHafUja', 'FaFa', 'afUasa']\nGround Truth (first 3): ['94Hkqwbd', 'ugvHoc', 'GH1VlPY-']\nRaw outputs (first 3): [[ 4 34  1  1  1 10  1  1  1 22  1 10  1 11  1  1 10  1 10  1  1  4  4  1\n   1  1 10  1  1  1  1 10]\n [ 0 32  1  1  1  1  1 47  1  1  1  1  1  1  0  1 11  1  1  1  1 34  1  1\n   1  4 47 47  0  1  0  1]\n [ 1  1  1  1  1  1  1 34  1  1  1  1  1  1 19  1  0 10  4  1  1  1  1 10\n   1  1  1  1 34  0  1 56]]\nInput length: 32, Label lengths: [8, 6, 8]\nToken distribution (Batch 0): {10: 1, 1: 14, 32: 1}, Pred length: 16\nToken distribution (Batch 1): {63: 1, 1: 6, 47: 1}, Pred length: 8\nToken distribution (Batch 2): {1: 15, 12: 1, 4: 2, 47: 1, 32: 2, 10: 2, 22: 1}, Pred length: 24\nToken distribution (Batch 3): {1: 12, 10: 3, 19: 1, 32: 1, 34: 2, 12: 1}, Pred length: 20\nToken distribution (Batch 4): {1: 10, 35: 2, 32: 1, 19: 1, 5: 1, 34: 6, 22: 1}, Pred length: 22\nToken distribution (Batch 5): {32: 2, 1: 8, 34: 1, 35: 1}, Pred length: 12\nToken distribution (Batch 6): {1: 10, 19: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 7): {10: 1, 1: 14, 32: 2, 22: 1}, Pred length: 18\nToken distribution (Batch 8): {34: 1, 10: 1, 1: 13, 4: 1, 32: 1, 27: 1}, Pred length: 18\nToken distribution (Batch 9): {10: 1, 32: 2, 1: 7, 34: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 9, 32: 1, 22: 2}, Pred length: 12\nToken distribution (Batch 11): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 12): {10: 1, 1: 6, 4: 1}, Pred length: 8\nToken distribution (Batch 13): {19: 2, 1: 16, 34: 1, 47: 2, 5: 1}, Pred length: 22\nToken distribution (Batch 14): {1: 15, 10: 2, 42: 2, 32: 1}, Pred length: 20\nToken distribution (Batch 15): {1: 13, 34: 2, 4: 1}, Pred length: 16\nToken distribution (Batch 16): {1: 8, 56: 1, 34: 3, 11: 1, 32: 3, 10: 3, 42: 1}, Pred length: 20\nToken distribution (Batch 17): {1: 17, 35: 1, 6: 1, 32: 2, 12: 1, 56: 1, 10: 1}, Pred length: 24\nToken distribution (Batch 18): {1: 5, 32: 2, 19: 1}, Pred length: 8\nToken distribution (Batch 19): {1: 9, 11: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 6, 34: 1, 10: 2, 11: 2, 6: 1}, Pred length: 12\nToken distribution (Batch 21): {10: 2, 1: 15, 6: 1, 27: 1, 34: 1, 42: 1, 19: 1}, Pred length: 22\nToken distribution (Batch 22): {1: 6, 11: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 23): {1: 9, 32: 1}, Pred length: 10\nToken distribution (Batch 24): {12: 1, 34: 1, 1: 6, 10: 1, 56: 2, 11: 1}, Pred length: 12\nToken distribution (Batch 25): {4: 1, 1: 8, 34: 2, 27: 1}, Pred length: 12\nToken distribution (Batch 26): {1: 10, 34: 2, 10: 3, 32: 1}, Pred length: 16\nToken distribution (Batch 27): {1: 16, 32: 2, 50: 1, 10: 2, 34: 1}, Pred length: 22\nToken distribution (Batch 28): {1: 9, 19: 1, 32: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 29): {1: 10, 10: 1, 56: 1, 32: 1, 22: 1, 11: 2}, Pred length: 16\nToken distribution (Batch 30): {1: 11, 19: 1, 32: 1, 10: 1, 27: 1, 47: 1}, Pred length: 16\nToken distribution (Batch 31): {1: 5, 34: 3, 22: 2, 32: 1, 5: 1}, Pred length: 12\nBatch 20, Gradient norm: 3601.8713\nEpoch 12, Batch 20/128, Loss: 20.1395\nAvg Blank Probability: 0.0200\nSample predictions: ['jaFa', '-aU', 'aladadaUaFjaFava']\nGround Truth (first 3): ['cTCqQjBS', 'rOBm', 'BCvIjhx8kefz']\nRaw outputs (first 3): [[10 63  1  1  1  1  1 10 11 10 10 10 10  1  1  1 32  1  1  1 11  1  1  1\n  12  4  0  1  1  1  1 34]\n [ 1  1 12  1  0 32  1  1 34 32  1  1  0 19  1  1  1  1  1  1  1 10  1  1\n   0  1  1  0  1  0  1  1]\n [ 1  0  1  1 35  1  1  1 10  1  1  1  4  1  1 34  0  1  1  1  1  1  1  1\n   0 34 34  1 19  1  0 34]]\nInput length: 32, Label lengths: [8, 4, 12]\nToken distribution (Batch 0): {47: 2, 1: 10}, Pred length: 12\nToken distribution (Batch 1): {1: 9, 12: 1}, Pred length: 10\nToken distribution (Batch 2): {1: 7, 47: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 6, 34: 1, 12: 1}, Pred length: 8\nToken distribution (Batch 4): {10: 1, 1: 14, 22: 1, 27: 1, 32: 1}, Pred length: 18\nToken distribution (Batch 5): {1: 15, 32: 1, 34: 2}, Pred length: 18\nToken distribution (Batch 6): {1: 13, 11: 2, 27: 1, 34: 1, 32: 1}, Pred length: 18\nToken distribution (Batch 7): {11: 1, 10: 1, 47: 1, 1: 6, 27: 1}, Pred length: 10\nToken distribution (Batch 8): {34: 2, 1: 7, 6: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 15, 47: 1, 32: 1, 10: 2, 34: 1}, Pred length: 20\nToken distribution (Batch 10): {11: 1, 1: 7, 47: 2, 10: 4, 27: 1, 6: 1}, Pred length: 16\nToken distribution (Batch 11): {11: 1, 1: 7, 10: 2, 47: 2, 34: 2, 32: 1, 5: 1}, Pred length: 16\nToken distribution (Batch 12): {1: 10, 10: 2, 34: 1, 11: 1, 19: 1, 27: 1, 47: 1, 32: 3}, Pred length: 20\nToken distribution (Batch 13): {1: 7, 5: 1}, Pred length: 8\nToken distribution (Batch 14): {6: 1, 1: 11, 19: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 15): {1: 8, 35: 1, 34: 1, 6: 2}, Pred length: 12\nToken distribution (Batch 16): {4: 1, 1: 10, 34: 1, 6: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 17): {1: 15, 32: 2, 63: 1, 19: 1, 47: 1}, Pred length: 20\nToken distribution (Batch 18): {10: 1, 34: 1, 1: 6}, Pred length: 8\nToken distribution (Batch 19): {1: 16, 32: 3, 34: 1, 10: 1, 11: 1, 56: 1, 50: 1}, Pred length: 24\nToken distribution (Batch 20): {1: 17, 10: 2, 34: 2, 5: 1}, Pred length: 22\nToken distribution (Batch 21): {1: 7, 34: 1}, Pred length: 8\nToken distribution (Batch 22): {1: 7, 32: 1, 10: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 23): {6: 1, 1: 18, 47: 2, 11: 2, 10: 1}, Pred length: 24\nToken distribution (Batch 24): {1: 17, 10: 2, 34: 2, 27: 1, 47: 1, 12: 1}, Pred length: 24\nToken distribution (Batch 25): {1: 6, 10: 3, 6: 1}, Pred length: 10\nToken distribution (Batch 26): {32: 1, 10: 2, 1: 6, 27: 1}, Pred length: 10\nToken distribution (Batch 27): {1: 2, 34: 2, 11: 1, 19: 1, 47: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 28): {1: 16, 56: 1, 47: 3, 6: 1, 34: 1}, Pred length: 22\nToken distribution (Batch 29): {32: 1, 10: 2, 1: 6, 11: 1, 34: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 30): {6: 1, 1: 10, 10: 2, 47: 1}, Pred length: 14\nToken distribution (Batch 31): {1: 5, 22: 1, 6: 1, 32: 1}, Pred length: 8\nBatch 30, Gradient norm: 1655.3776\nEpoch 12, Batch 30/128, Loss: 21.6985\nAvg Blank Probability: 0.0201\nSample predictions: ['UaUa', 'ala', 'aUa']\nGround Truth (first 3): ['HUUWOx', 'exxOu', 'vxrj']\nRaw outputs (first 3): [[10  1 10 10 47  1  1  0 34  1  1 11  1  1 10 34  4  1  1  1  1  1 34  6\n   1 10  1  1 19 32  6  1]\n [ 0  1  1  1 10  1  1 11  1  1 11  0 10  1  6  1  1  1 10  1  1 34  1  1\n   0  1 32 34  1 10  0  1]\n [ 1  1  0  0  1  1  1  0  1  1  1  1  1  1  0  1 34  1  0  1  1  1 32 47\n   1 10 10 11  1  0  1  1]]\nInput length: 32, Label lengths: [6, 5, 4]\nToken distribution (Batch 0): {1: 8, 19: 1, 47: 1, 22: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 1): {1: 10, 47: 2, 10: 1, 32: 1, 4: 1, 34: 1}, Pred length: 16\nToken distribution (Batch 2): {1: 6, 47: 2}, Pred length: 8\nToken distribution (Batch 3): {1: 13, 10: 2, 27: 2, 34: 1}, Pred length: 18\nToken distribution (Batch 4): {12: 1, 1: 12, 42: 1}, Pred length: 14\nToken distribution (Batch 5): {1: 9, 32: 2, 27: 1}, Pred length: 12\nToken distribution (Batch 6): {10: 2, 4: 1, 1: 3, 47: 2, 34: 2}, Pred length: 10\nToken distribution (Batch 7): {1: 6, 11: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 8): {1: 15, 32: 1, 27: 1, 10: 1}, Pred length: 18\nToken distribution (Batch 9): {1: 9, 11: 1}, Pred length: 10\nToken distribution (Batch 10): {10: 3, 1: 12, 34: 2, 47: 2, 32: 2, 42: 1}, Pred length: 22\nToken distribution (Batch 11): {1: 10, 6: 1, 19: 1, 47: 1, 27: 1}, Pred length: 14\nToken distribution (Batch 12): {1: 8, 19: 1, 47: 2, 10: 1}, Pred length: 12\nToken distribution (Batch 13): {1: 12, 11: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 14): {1: 6, 50: 1, 48: 1}, Pred length: 8\nToken distribution (Batch 15): {1: 9, 10: 3, 32: 2, 34: 2}, Pred length: 16\nToken distribution (Batch 16): {1: 14, 32: 5, 22: 1, 27: 1, 56: 1}, Pred length: 22\nToken distribution (Batch 17): {12: 1, 27: 2, 1: 19, 10: 1, 34: 1}, Pred length: 24\nToken distribution (Batch 18): {11: 1, 32: 3, 1: 5, 10: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 15, 5: 1, 34: 1, 11: 1, 22: 1, 10: 1}, Pred length: 20\nToken distribution (Batch 20): {1: 9, 10: 2, 5: 1}, Pred length: 12\nToken distribution (Batch 21): {1: 8, 5: 1, 10: 2, 47: 1}, Pred length: 12\nToken distribution (Batch 22): {12: 1, 1: 7, 11: 4}, Pred length: 12\nToken distribution (Batch 23): {1: 12}, Pred length: 12\nToken distribution (Batch 24): {1: 17, 47: 2, 34: 1}, Pred length: 20\nToken distribution (Batch 25): {1: 18, 34: 3, 10: 2, 32: 1}, Pred length: 24\nToken distribution (Batch 26): {10: 1, 1: 7, 34: 1, 6: 1, 11: 1, 12: 1}, Pred length: 12\nToken distribution (Batch 27): {47: 1, 56: 1, 1: 4, 10: 3, 32: 1, 22: 1, 27: 1, 34: 1, 5: 2, 6: 1}, Pred length: 16\nToken distribution (Batch 28): {1: 8}, Pred length: 8\nToken distribution (Batch 29): {10: 1, 1: 6, 34: 1}, Pred length: 8\nToken distribution (Batch 30): {1: 10, 63: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 31): {1: 17, 10: 2, 34: 1, 32: 2}, Pred length: 22\nBatch 40, Gradient norm: 433.2226\nEpoch 12, Batch 40/128, Loss: 20.9355\nAvg Blank Probability: 0.0204\nSample predictions: ['asaUavaHa', 'aUjaUaFdHa', 'aUaU']\nGround Truth (first 3): ['6dOZFh', 'qDalP*2r', '3yOj']\nRaw outputs (first 3): [[ 1  1  1  1 12  1  1 34  1  1  1  1 32  1  1  1  1  1 11  1  1  1  1  0\n   1  1 10  1  1  1  1  1]\n [ 1  1  1 10  1  1  0  1  1  0  0  6  1  1  1  1 32  0 32  1  0  1 12  1\n   1 34  1  0  1  0  1  1]\n [19 47  1  0  1  1  0  1 32  0  1  1  0  1  1  1  1 27 32  1  1  1  1  1\n   1  1 34  0  1  1  1  1]]\nInput length: 32, Label lengths: [6, 8, 4]\nToken distribution (Batch 0): {63: 1, 1: 11, 5: 1, 6: 1, 34: 2, 10: 1, 32: 2, 47: 1, 4: 1, 22: 1}, Pred length: 22\nToken distribution (Batch 1): {1: 12, 19: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 2): {1: 13, 47: 1}, Pred length: 14\nToken distribution (Batch 3): {1: 14, 10: 1, 34: 2, 4: 1, 19: 1, 47: 1, 32: 3, 12: 1}, Pred length: 24\nToken distribution (Batch 4): {12: 1, 1: 15, 34: 2, 27: 1, 10: 1}, Pred length: 20\nToken distribution (Batch 5): {1: 9, 34: 1, 32: 3, 10: 1}, Pred length: 14\nToken distribution (Batch 6): {47: 2, 1: 9, 11: 2, 22: 1, 32: 1, 27: 1}, Pred length: 16\nToken distribution (Batch 7): {1: 8, 19: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 8): {34: 4, 11: 1, 1: 10, 47: 3}, Pred length: 18\nToken distribution (Batch 9): {1: 9, 34: 3, 32: 3, 10: 1}, Pred length: 16\nToken distribution (Batch 10): {11: 1, 47: 1, 4: 1, 22: 1, 1: 4, 10: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 11): {1: 16, 22: 1, 32: 3, 10: 2}, Pred length: 22\nToken distribution (Batch 12): {1: 11, 34: 1, 32: 4}, Pred length: 16\nToken distribution (Batch 13): {1: 6, 47: 1, 12: 1}, Pred length: 8\nToken distribution (Batch 14): {1: 6, 10: 1, 34: 1, 47: 2, 26: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 15): {1: 8, 32: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 16): {1: 5, 32: 2, 10: 1, 34: 2, 4: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 17): {1: 16, 32: 1, 11: 1, 10: 1, 35: 1}, Pred length: 20\nToken distribution (Batch 18): {1: 11, 32: 1, 22: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 19): {1: 14, 32: 1, 47: 2, 34: 1}, Pred length: 18\nToken distribution (Batch 20): {1: 9, 34: 1, 56: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 21): {1: 6, 47: 1, 34: 3, 22: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 22): {34: 5, 1: 16, 47: 1, 35: 1, 6: 1}, Pred length: 24\nToken distribution (Batch 23): {34: 2, 6: 1, 1: 7, 42: 1, 47: 2, 5: 1}, Pred length: 14\nToken distribution (Batch 24): {1: 9, 19: 1, 47: 1, 10: 1, 5: 1, 35: 1}, Pred length: 14\nToken distribution (Batch 25): {1: 10, 34: 2}, Pred length: 12\nToken distribution (Batch 26): {1: 21, 32: 1}, Pred length: 22\nToken distribution (Batch 27): {1: 14, 32: 2, 10: 1, 34: 1, 6: 1, 5: 1}, Pred length: 20\nToken distribution (Batch 28): {1: 9, 10: 1, 12: 1, 47: 1, 35: 1, 4: 1}, Pred length: 14\nToken distribution (Batch 29): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 30): {48: 1, 11: 2, 1: 1, 47: 1, 10: 1, 34: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 31): {22: 1, 1: 7, 32: 1, 19: 1}, Pred length: 10\nBatch 50, Gradient norm: 19.3453\nEpoch 12, Batch 50/128, Loss: 19.8408\nAvg Blank Probability: 0.0207\nSample predictions: ['-aeafHajaFHaUdvaF', 'asaja', 'aUa']\nGround Truth (first 3): ['EpYDwlrPOiw', 'zcji3pN', 'Tx0qKBm']\nRaw outputs (first 3): [[63  1  1  1 10 10  1  1 11  1 35  1  1 10  1  1  1  1 34  0  1  4  0  1\n   1 34  1  1  1  1  0  1]\n [ 1  1  1 10  0  1 47  1 34  1 11  1  0  1  1  0  1  1  1  1  1  1 34 34\n   1  1  1  1 10  1  0 22]\n [ 5  1  0  1  0  0  1 19  0 34 47  0  1  1 10  0 32  1  0  0  1  1  0  6\n   1  0  1  0  1  1 11  1]]\nInput length: 32, Label lengths: [11, 7, 7]\nToken distribution (Batch 0): {1: 8, 10: 2, 4: 1, 27: 1, 32: 1, 34: 3}, Pred length: 16\nToken distribution (Batch 1): {1: 7, 47: 2, 32: 2, 10: 2, 27: 1}, Pred length: 14\nToken distribution (Batch 2): {1: 9, 12: 1, 10: 3, 56: 1, 32: 2, 47: 1, 11: 1, 19: 1, 34: 4, 4: 1}, Pred length: 24\nToken distribution (Batch 3): {1: 16, 11: 1, 10: 2, 34: 2, 6: 1}, Pred length: 22\nToken distribution (Batch 4): {34: 1, 10: 1, 1: 12, 32: 1, 27: 1}, Pred length: 16\nToken distribution (Batch 5): {1: 10, 11: 1, 35: 2, 10: 1, 34: 2, 32: 1, 47: 3}, Pred length: 20\nToken distribution (Batch 6): {1: 18, 32: 2}, Pred length: 20\nToken distribution (Batch 7): {4: 1, 1: 8, 34: 2, 32: 2, 6: 1}, Pred length: 14\nToken distribution (Batch 8): {1: 10, 10: 1, 47: 3, 12: 1, 27: 1}, Pred length: 16\nToken distribution (Batch 9): {1: 9, 34: 1, 32: 1, 6: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 5, 34: 2, 32: 1, 47: 2, 35: 2}, Pred length: 12\nToken distribution (Batch 11): {1: 11, 10: 2, 32: 2, 12: 1, 4: 1, 34: 1}, Pred length: 18\nToken distribution (Batch 12): {34: 3, 11: 1, 1: 10, 32: 3, 19: 2, 10: 1}, Pred length: 20\nToken distribution (Batch 13): {1: 15, 56: 1, 10: 2, 47: 1, 32: 1, 34: 3, 19: 1}, Pred length: 24\nToken distribution (Batch 14): {34: 2, 1: 10, 35: 1, 10: 1, 42: 1, 47: 2, 32: 1}, Pred length: 18\nToken distribution (Batch 15): {4: 1, 10: 1, 1: 6, 5: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 16): {10: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 17): {11: 1, 10: 1, 1: 6}, Pred length: 8\nToken distribution (Batch 18): {1: 5, 47: 2, 32: 1, 12: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 9, 11: 4, 19: 1, 34: 1, 4: 1}, Pred length: 16\nToken distribution (Batch 20): {1: 13, 32: 3, 34: 2, 10: 1, 27: 1, 42: 1, 22: 1}, Pred length: 22\nToken distribution (Batch 21): {10: 2, 1: 13, 63: 1, 5: 1, 47: 1, 6: 1, 32: 1, 34: 1, 22: 1}, Pred length: 22\nToken distribution (Batch 22): {1: 9, 34: 1, 10: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 23): {1: 16, 10: 2, 32: 2, 34: 2}, Pred length: 22\nToken distribution (Batch 24): {1: 10, 34: 2, 47: 1, 27: 1}, Pred length: 14\nToken distribution (Batch 25): {1: 15, 10: 1, 34: 1, 19: 1, 11: 1, 32: 1}, Pred length: 20\nToken distribution (Batch 26): {47: 2, 12: 1, 34: 3, 1: 3, 5: 1}, Pred length: 10\nToken distribution (Batch 27): {1: 13, 6: 1, 47: 1, 11: 1}, Pred length: 16\nToken distribution (Batch 28): {1: 21, 10: 1, 34: 1, 19: 1}, Pred length: 24\nToken distribution (Batch 29): {10: 1, 1: 7}, Pred length: 8\nToken distribution (Batch 30): {1: 20, 10: 1, 32: 1, 19: 1, 50: 1}, Pred length: 24\nToken distribution (Batch 31): {1: 12, 35: 1, 32: 3, 34: 2, 11: 1, 47: 3}, Pred length: 22\nBatch 60, Gradient norm: 69.0525\nEpoch 12, Batch 60/128, Loss: 18.3969\nAvg Blank Probability: 0.0209\nSample predictions: ['ajdaAaFaHaHjaH', 'aUFjAaFja', 'alaj3jFaUakasFaHjHdHa']\nGround Truth (first 3): ['B5NN*QCa', 'IAWP3*1', 'qwB*C7UWXCsz']\nRaw outputs (first 3): [[ 1  1  1  1 34  1  1 12  1 47  1 11 11  1  1  4 10  1  1  1  1 10 11  0\n   1 12 47 10  1  1  1  1]\n [ 1  1  1  1 34  1  1  0  1  1  0  0  0  1  0 10  1 11  1  1  1  1  1  0\n   1  1  0  1  1 10  1  1]\n [10  0 12 11  0  0  1  1  0  0 34  1 11  0  1  1  1  0  1 11  1 63  1  0\n   0  1  0  1  1  1 10  1]]\nInput length: 32, Label lengths: [8, 7, 12]\nToken distribution (Batch 0): {1: 4, 11: 2, 34: 2}, Pred length: 8\nToken distribution (Batch 1): {56: 1, 1: 16, 5: 1, 32: 4}, Pred length: 22\nToken distribution (Batch 2): {1: 16, 10: 2, 12: 1, 32: 2, 34: 1}, Pred length: 22\nToken distribution (Batch 3): {10: 3, 1: 15, 32: 3, 47: 3}, Pred length: 24\nToken distribution (Batch 4): {35: 1, 1: 17, 10: 1, 6: 1, 47: 1, 32: 1}, Pred length: 22\nToken distribution (Batch 5): {1: 9, 10: 2, 47: 2, 32: 4, 27: 1, 43: 1, 34: 1}, Pred length: 20\nToken distribution (Batch 6): {1: 6, 32: 1, 56: 1}, Pred length: 8\nToken distribution (Batch 7): {1: 9, 32: 2, 47: 3, 12: 1, 34: 1}, Pred length: 16\nToken distribution (Batch 8): {1: 8, 34: 1, 10: 1, 22: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 9): {1: 9, 10: 1, 27: 2, 47: 2}, Pred length: 14\nToken distribution (Batch 10): {1: 10, 10: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 11): {34: 2, 1: 15, 32: 2, 22: 1, 12: 1, 4: 1}, Pred length: 22\nToken distribution (Batch 12): {1: 15, 6: 1, 10: 1, 32: 3, 50: 1, 27: 1}, Pred length: 22\nToken distribution (Batch 13): {1: 7, 34: 1, 5: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 14): {1: 10, 34: 4, 12: 1, 32: 2, 5: 1, 10: 1, 47: 1}, Pred length: 20\nToken distribution (Batch 15): {1: 7, 6: 1}, Pred length: 8\nToken distribution (Batch 16): {1: 7, 11: 2, 19: 1, 32: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 17): {1: 5, 11: 2, 32: 1, 10: 2, 47: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 18): {10: 3, 1: 9, 34: 1, 32: 4, 47: 2, 27: 2, 35: 1}, Pred length: 22\nToken distribution (Batch 19): {1: 9, 32: 2, 11: 1, 19: 1, 27: 1, 34: 1, 10: 1}, Pred length: 16\nToken distribution (Batch 20): {47: 1, 10: 4, 1: 11, 34: 1, 56: 1, 32: 1, 27: 1}, Pred length: 20\nToken distribution (Batch 21): {1: 7, 32: 2, 10: 1, 34: 2}, Pred length: 12\nToken distribution (Batch 22): {32: 1, 1: 9, 11: 2, 42: 1, 47: 2, 10: 1}, Pred length: 16\nToken distribution (Batch 23): {1: 6, 10: 2, 32: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 24): {1: 7, 32: 2, 10: 1}, Pred length: 10\nToken distribution (Batch 25): {1: 13, 10: 2, 32: 3, 35: 2, 34: 3, 27: 1}, Pred length: 24\nToken distribution (Batch 26): {10: 3, 1: 9, 34: 3, 12: 1}, Pred length: 16\nToken distribution (Batch 27): {6: 2, 1: 14, 11: 1, 34: 3, 10: 1, 56: 1}, Pred length: 22\nToken distribution (Batch 28): {1: 9, 47: 2, 6: 1, 34: 1, 27: 1}, Pred length: 14\nToken distribution (Batch 29): {12: 1, 1: 11, 10: 1, 34: 1, 4: 2, 27: 2}, Pred length: 18\nToken distribution (Batch 30): {12: 1, 1: 14, 6: 2, 47: 1, 34: 2, 32: 2, 19: 1, 10: 1}, Pred length: 24\nToken distribution (Batch 31): {1: 15, 10: 2, 47: 1, 11: 1, 32: 1}, Pred length: 20\nBatch 70, Gradient norm: 21.2059\nEpoch 12, Batch 70/128, Loss: 18.5719\nAvg Blank Probability: 0.0212\nSample predictions: ['akHaH', '3aeaFaFa', 'ajalaFHaFja']\nGround Truth (first 3): ['Dyaa', 'pV0sSTp5HKk', 'VERmvCPbPGG']\nRaw outputs (first 3): [[ 1  0  1 10  1  0  1  1 19  1  1 34  1  1  1  4  1  1 10  1  1  1  0  1\n  10  1  1  1  0 47  1  6]\n [11  0  1  0 35  1  1  1  0  0  0  1  0 34  1  1  1  0  0  0 47  1 32  1\n   1  0  0  6  1  0 12  1]\n [ 0  1  1  0  1  0  1  1  0  0  1 32  0  1  1  1  0  1  0  1 10  1  0 10\n   0 10  1  0  0  1  1  1]]\nInput length: 32, Label lengths: [4, 11, 11]\nToken distribution (Batch 0): {12: 1, 1: 8, 10: 1, 27: 1, 50: 1}, Pred length: 12\nToken distribution (Batch 1): {34: 2, 1: 12, 27: 1, 11: 1}, Pred length: 16\nToken distribution (Batch 2): {19: 1, 10: 1, 1: 4, 35: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 3): {10: 1, 63: 1, 1: 7, 32: 1, 11: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 4): {1: 6, 11: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 5): {34: 3, 1: 12, 10: 2, 4: 1}, Pred length: 18\nToken distribution (Batch 6): {34: 3, 1: 11, 22: 1, 27: 1, 47: 1, 32: 1}, Pred length: 18\nToken distribution (Batch 7): {1: 16, 47: 2, 10: 1, 19: 1, 22: 1, 6: 1, 4: 1, 12: 1}, Pred length: 24\nToken distribution (Batch 8): {1: 13, 19: 1, 12: 1, 47: 2, 34: 1}, Pred length: 18\nToken distribution (Batch 9): {34: 2, 1: 14, 47: 1, 10: 2, 12: 2, 6: 1}, Pred length: 22\nToken distribution (Batch 10): {11: 1, 1: 12, 27: 1, 34: 2, 12: 1, 32: 3}, Pred length: 20\nToken distribution (Batch 11): {1: 15, 4: 2, 22: 1, 47: 2, 56: 1, 32: 1}, Pred length: 22\nToken distribution (Batch 12): {1: 4, 10: 2, 5: 2, 32: 2}, Pred length: 10\nToken distribution (Batch 13): {1: 9, 10: 3, 32: 1, 34: 3, 4: 1, 22: 1}, Pred length: 18\nToken distribution (Batch 14): {10: 2, 1: 11, 32: 2, 12: 1}, Pred length: 16\nToken distribution (Batch 15): {6: 1, 1: 6, 4: 1, 32: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 16): {10: 3, 1: 6, 47: 2, 35: 1, 32: 2}, Pred length: 14\nToken distribution (Batch 17): {34: 3, 1: 8, 19: 2, 11: 1}, Pred length: 14\nToken distribution (Batch 18): {1: 7, 19: 1, 50: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 15, 32: 2, 10: 1, 50: 1, 47: 1}, Pred length: 20\nToken distribution (Batch 20): {47: 1, 19: 1, 1: 10, 42: 1, 56: 1}, Pred length: 14\nToken distribution (Batch 21): {10: 2, 1: 17, 19: 2, 11: 1, 47: 1, 32: 1}, Pred length: 24\nToken distribution (Batch 22): {1: 18, 32: 2}, Pred length: 20\nToken distribution (Batch 23): {10: 1, 1: 8, 32: 1}, Pred length: 10\nToken distribution (Batch 24): {1: 9, 10: 1, 47: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 25): {1: 6, 22: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 26): {1: 11, 34: 3, 6: 1, 47: 2, 35: 1, 4: 2, 12: 1, 10: 2, 22: 1}, Pred length: 24\nToken distribution (Batch 27): {10: 2, 47: 2, 4: 1, 32: 2, 1: 13, 11: 1, 19: 1}, Pred length: 22\nToken distribution (Batch 28): {47: 3, 1: 14, 10: 1, 6: 1, 32: 1}, Pred length: 20\nToken distribution (Batch 29): {1: 17, 4: 1, 5: 1, 12: 1, 34: 1, 10: 1}, Pred length: 22\nToken distribution (Batch 30): {10: 2, 1: 14}, Pred length: 16\nToken distribution (Batch 31): {1: 10, 12: 1, 32: 1, 34: 2}, Pred length: 14\nBatch 80, Gradient norm: 15.5873\nEpoch 12, Batch 80/128, Loss: 18.8712\nAvg Blank Probability: 0.0214\nSample predictions: ['lajaAaXa', 'HaAakaHa', 'sjaIFa']\nGround Truth (first 3): ['ppN2gD', 'Y9DD71VU', 'mNkU']\nRaw outputs (first 3): [[ 1  1 10 10  1 34  0  1  1  1  0  1 12  1  1  0 10  1 32 10 47 10  1 10\n   1  1 10  1  1  1 11  1]\n [ 0  0  0 63 11  0 34  1  1 34 11  0  1  1 10  6 10 34  0  1 47  1  1  0\n   0  1  0 10 47  1  0  0]\n [ 1  1 10  0 10 10  1  0  0  1  1  1  0  1 10  1 10  1  1  0  0  1  1  1\n   1  1  0  0  0  1  1  0]]\nInput length: 32, Label lengths: [6, 8, 4]\nToken distribution (Batch 0): {4: 1, 1: 15, 43: 1, 56: 1, 47: 2, 32: 1, 10: 1}, Pred length: 22\nToken distribution (Batch 1): {1: 14, 34: 2}, Pred length: 16\nToken distribution (Batch 2): {1: 18, 10: 1, 47: 3, 32: 1, 42: 1}, Pred length: 24\nToken distribution (Batch 3): {1: 15, 11: 1, 10: 1, 34: 1, 32: 1, 47: 1}, Pred length: 20\nToken distribution (Batch 4): {1: 5, 4: 2, 10: 1}, Pred length: 8\nToken distribution (Batch 5): {1: 7, 56: 1, 10: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 6): {1: 12, 10: 2, 32: 1, 34: 2, 11: 1}, Pred length: 18\nToken distribution (Batch 7): {1: 12, 47: 1, 11: 1, 10: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 8): {1: 5, 10: 1, 12: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 9): {1: 8, 47: 1, 22: 2, 11: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 10, 47: 3, 43: 1, 50: 1, 10: 2, 6: 1, 27: 1, 12: 1}, Pred length: 20\nToken distribution (Batch 11): {1: 8, 47: 3, 32: 2, 4: 1, 27: 1, 56: 1, 55: 1, 34: 1}, Pred length: 18\nToken distribution (Batch 12): {1: 12, 11: 1, 47: 2, 35: 1, 10: 1, 6: 1}, Pred length: 18\nToken distribution (Batch 13): {19: 1, 1: 12, 4: 1, 47: 1, 34: 2, 56: 1}, Pred length: 18\nToken distribution (Batch 14): {1: 5, 5: 1, 10: 1, 19: 1, 11: 1, 12: 1, 47: 1, 22: 1, 34: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 15): {1: 9, 34: 2, 32: 3, 27: 1, 47: 1}, Pred length: 16\nToken distribution (Batch 16): {1: 11, 22: 1, 47: 2, 10: 3, 32: 1}, Pred length: 18\nToken distribution (Batch 17): {1: 11, 34: 2, 10: 1, 27: 1, 47: 1}, Pred length: 16\nToken distribution (Batch 18): {1: 4, 42: 1, 4: 1, 12: 1, 34: 3}, Pred length: 10\nToken distribution (Batch 19): {47: 1, 1: 6, 32: 1, 19: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 20): {1: 16, 10: 3, 34: 1, 27: 1, 48: 1, 4: 1, 11: 1}, Pred length: 24\nToken distribution (Batch 21): {1: 8, 6: 1, 34: 2, 10: 1}, Pred length: 12\nToken distribution (Batch 22): {1: 10, 10: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 23): {1: 7, 12: 1}, Pred length: 8\nToken distribution (Batch 24): {1: 12, 34: 1, 22: 1, 5: 1, 4: 1}, Pred length: 16\nToken distribution (Batch 25): {1: 7, 56: 1, 47: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 26): {1: 7, 11: 1}, Pred length: 8\nToken distribution (Batch 27): {1: 11, 32: 1, 6: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 28): {1: 10, 34: 2, 27: 1, 22: 1, 32: 5, 19: 1, 35: 1, 10: 1, 56: 1, 5: 1}, Pred length: 24\nToken distribution (Batch 29): {1: 14, 19: 1, 32: 1, 34: 1, 27: 1, 10: 2}, Pred length: 20\nToken distribution (Batch 30): {1: 16, 4: 1, 32: 1, 19: 1, 34: 1}, Pred length: 20\nToken distribution (Batch 31): {19: 1, 1: 5, 12: 1, 47: 1}, Pred length: 8\nBatch 90, Gradient norm: 1759.8268\nEpoch 12, Batch 90/128, Loss: 19.8228\nAvg Blank Probability: 0.0218\nSample predictions: ['daQa3UaFjaUa', 'aHaHa', 'ajaUaUaFaPa']\nGround Truth (first 3): ['XR0neMzo71h', 'l93TsSTa', 'kJc7FcTU6w7f']\nRaw outputs (first 3): [[10 11  1 10 34  0  1  0  1 24  1  1  4  0  1  1  1  1  6  1  6 34  1  0\n   1  0  1  1  1  1  1 63]\n [ 0  0  1  1  0  1  1  0  0  1  1 47  1 19  1  1  1  1  1  0  1  0  1  1\n   0  1  1  1  1  1  1 19]\n [ 0  0  1  0  0 56  1 47  1  1  1  0  1  1  0  1  0 34 42  0  0  0  1  0\n   0  1  0  1  1  0  0  1]]\nInput length: 32, Label lengths: [11, 8, 12]\nToken distribution (Batch 0): {1: 12, 22: 1, 10: 1, 47: 2}, Pred length: 16\nToken distribution (Batch 1): {19: 2, 32: 4, 1: 11, 56: 1, 27: 1, 22: 1}, Pred length: 20\nToken distribution (Batch 2): {1: 18, 19: 1, 34: 3, 10: 1, 7: 1}, Pred length: 24\nToken distribution (Batch 3): {1: 8, 42: 1, 32: 1, 35: 2}, Pred length: 12\nToken distribution (Batch 4): {1: 16, 10: 2, 56: 1, 6: 1}, Pred length: 20\nToken distribution (Batch 5): {1: 15, 47: 1, 35: 1, 34: 3, 10: 1, 32: 1}, Pred length: 22\nToken distribution (Batch 6): {1: 11, 34: 2, 32: 3, 56: 1, 27: 1}, Pred length: 18\nToken distribution (Batch 7): {1: 8, 56: 1, 35: 1, 32: 4, 19: 1, 34: 3, 22: 1, 6: 1}, Pred length: 20\nToken distribution (Batch 8): {12: 1, 47: 1, 10: 2, 1: 5, 32: 2, 34: 1}, Pred length: 12\nToken distribution (Batch 9): {1: 6, 11: 1, 32: 2, 47: 1}, Pred length: 10\nToken distribution (Batch 10): {10: 2, 19: 1, 1: 16, 50: 1, 4: 1, 27: 1, 47: 1, 32: 1}, Pred length: 24\nToken distribution (Batch 11): {1: 7, 27: 1, 47: 2}, Pred length: 10\nToken distribution (Batch 12): {1: 12, 4: 1, 27: 1, 34: 2, 47: 4, 22: 1, 6: 1}, Pred length: 22\nToken distribution (Batch 13): {1: 16, 34: 4, 10: 2, 47: 1, 32: 1}, Pred length: 24\nToken distribution (Batch 14): {1: 14, 32: 2, 34: 1, 47: 1}, Pred length: 18\nToken distribution (Batch 15): {11: 2, 1: 10, 10: 2}, Pred length: 14\nToken distribution (Batch 16): {1: 8, 32: 2, 10: 2, 34: 2}, Pred length: 14\nToken distribution (Batch 17): {10: 1, 1: 18, 32: 2, 34: 1}, Pred length: 22\nToken distribution (Batch 18): {1: 12, 22: 1, 4: 1, 34: 2, 12: 1, 43: 1, 35: 1, 32: 1}, Pred length: 20\nToken distribution (Batch 19): {1: 12, 34: 3, 10: 2, 32: 2, 19: 1, 42: 1, 47: 1}, Pred length: 22\nToken distribution (Batch 20): {1: 11, 27: 1}, Pred length: 12\nToken distribution (Batch 21): {1: 10, 12: 1, 19: 2, 47: 2, 11: 1}, Pred length: 16\nToken distribution (Batch 22): {1: 12, 22: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 23): {1: 10, 10: 1, 27: 1, 34: 1, 47: 1, 32: 2}, Pred length: 16\nToken distribution (Batch 24): {1: 14, 10: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 25): {1: 10, 32: 3, 34: 1, 47: 2}, Pred length: 16\nToken distribution (Batch 26): {6: 2, 1: 5, 19: 1, 11: 1, 56: 1}, Pred length: 10\nToken distribution (Batch 27): {1: 11, 22: 2, 47: 1, 34: 1, 10: 1}, Pred length: 16\nToken distribution (Batch 28): {1: 15, 47: 1, 10: 1, 11: 1}, Pred length: 18\nToken distribution (Batch 29): {10: 2, 1: 8, 4: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 30): {10: 1, 1: 7, 47: 2, 34: 2, 19: 2}, Pred length: 14\nToken distribution (Batch 31): {1: 8, 32: 2, 22: 1, 19: 1}, Pred length: 12\nBatch 100, Gradient norm: 13.7927\nEpoch 12, Batch 100/128, Loss: 17.4936\nAvg Blank Probability: 0.0221\nSample predictions: ['avajUaUa', 'sFaFa3aFaAvaF', 'asaHajHagaHa']\nGround Truth (first 3): ['hbZBBiRR', 'uvTIXpfTBF', 'cOq7ZlSayFGT']\nRaw outputs (first 3): [[ 1 34  1  1 10  1  0  1 12  1 10 32 10  1  1 11 10  1  1  0  4  1 11  1\n   1 12  1  0  1  1  1 10]\n [ 1  0  1  1  1  1  1  0 47  1  0  1  1  0  0  1  1 10  0  1  1  1  1  1\n   0  1  0  0  0 10  0  0]\n [ 0  0  1  1  0  1  0  0 10  1  0  0  1  0  0  0  0  0  0 34  1  0  0  0\n   1 32  1  1  1  0  1  0]]\nInput length: 32, Label lengths: [8, 10, 12]\nToken distribution (Batch 0): {1: 4, 10: 1, 19: 1, 34: 1, 35: 1}, Pred length: 8\nToken distribution (Batch 1): {35: 1, 11: 1, 47: 1, 1: 7, 4: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 2): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 3): {34: 4, 1: 13, 50: 1, 47: 1, 35: 1}, Pred length: 20\nToken distribution (Batch 4): {1: 16, 10: 2, 47: 4, 5: 1, 50: 1}, Pred length: 24\nToken distribution (Batch 5): {1: 18, 47: 3, 34: 2, 10: 1}, Pred length: 24\nToken distribution (Batch 6): {1: 5, 10: 2, 32: 1, 27: 2, 4: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 7): {12: 1, 1: 7, 10: 1, 47: 2, 32: 1, 34: 2}, Pred length: 14\nToken distribution (Batch 8): {1: 15, 47: 1, 34: 1, 32: 1, 22: 1, 6: 1}, Pred length: 20\nToken distribution (Batch 9): {1: 8, 22: 1, 25: 1}, Pred length: 10\nToken distribution (Batch 10): {1: 12}, Pred length: 12\nToken distribution (Batch 11): {1: 15, 11: 1, 19: 1, 32: 1}, Pred length: 18\nToken distribution (Batch 12): {12: 1, 1: 12, 32: 1, 42: 1, 35: 1}, Pred length: 16\nToken distribution (Batch 13): {10: 1, 1: 16, 27: 1, 34: 2, 47: 2, 32: 2}, Pred length: 24\nToken distribution (Batch 14): {1: 3, 10: 2, 34: 2, 4: 1}, Pred length: 8\nToken distribution (Batch 15): {32: 1, 1: 8, 19: 1, 10: 1, 6: 1, 34: 2}, Pred length: 14\nToken distribution (Batch 16): {1: 8, 47: 1, 42: 1, 34: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 17): {1: 6, 11: 2, 27: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 18): {1: 10, 34: 3, 27: 1, 22: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 19): {47: 1, 1: 6, 32: 1}, Pred length: 8\nToken distribution (Batch 20): {1: 13, 34: 1, 32: 3, 9: 1, 47: 2}, Pred length: 20\nToken distribution (Batch 21): {1: 10, 34: 2, 27: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 22): {1: 8, 6: 1, 34: 1, 11: 2, 32: 1, 56: 1}, Pred length: 14\nToken distribution (Batch 23): {1: 8, 47: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 24): {1: 11, 34: 2, 47: 3}, Pred length: 16\nToken distribution (Batch 25): {1: 14, 32: 1, 34: 1, 35: 2, 6: 1, 10: 1, 9: 1, 27: 1, 42: 1, 11: 1}, Pred length: 24\nToken distribution (Batch 26): {1: 6, 32: 1, 5: 1}, Pred length: 8\nToken distribution (Batch 27): {22: 1, 10: 1, 1: 7, 55: 1}, Pred length: 10\nToken distribution (Batch 28): {1: 6, 34: 1, 48: 1}, Pred length: 8\nToken distribution (Batch 29): {10: 2, 1: 14, 43: 1, 34: 1}, Pred length: 18\nToken distribution (Batch 30): {10: 1, 32: 1, 42: 1, 1: 15, 34: 4, 56: 1, 50: 1}, Pred length: 24\nToken distribution (Batch 31): {34: 1, 10: 1, 1: 5, 11: 1}, Pred length: 8\nBatch 110, Gradient norm: 26.2060\nEpoch 12, Batch 110/128, Loss: 21.0364\nAvg Blank Probability: 0.0224\nSample predictions: ['ajsaHIa', 'IkUadav', 'aFa']\nGround Truth (first 3): ['Y5n3', 'xv6JqB', 'j2OL']\nRaw outputs (first 3): [[ 1 32 47  1  1  1  1 34  1  0  0  0 12  0  1 34 10  0 32  1  0  1  6  1\n   1  1  0 22  1  1 10 34]\n [ 0  0  0 34  1  1  0  0  0  1  0  1  0 10  1 32  0  1  1  0  1  0  1  0\n   0  0  1 10  1  0  0  0]\n [ 0  0  0  1  0  0 10  0  1  1  0  1  0  0  0  0  1  0 34  0  0  1  0  0\n   0 32  1  0  0  1 42  1]]\nInput length: 32, Label lengths: [4, 6, 4]\nToken distribution (Batch 0): {1: 15, 34: 2, 19: 1}, Pred length: 18\nToken distribution (Batch 1): {1: 14, 34: 1, 56: 1, 10: 1, 32: 1}, Pred length: 18\nToken distribution (Batch 2): {1: 10, 11: 2, 22: 1, 10: 1, 32: 2}, Pred length: 16\nToken distribution (Batch 3): {1: 13, 27: 1, 34: 3, 32: 1, 55: 1, 12: 1}, Pred length: 20\nToken distribution (Batch 4): {22: 1, 4: 1, 1: 8, 6: 1, 10: 1, 19: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 5): {1: 4, 22: 1, 27: 1, 34: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 6): {1: 9, 47: 1, 6: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 7): {11: 1, 10: 1, 1: 10}, Pred length: 12\nToken distribution (Batch 8): {12: 1, 47: 2, 34: 2, 1: 7, 32: 4, 48: 1, 11: 1}, Pred length: 18\nToken distribution (Batch 9): {1: 3, 32: 2, 34: 1, 4: 1, 56: 1}, Pred length: 8\nToken distribution (Batch 10): {47: 3, 12: 3, 1: 5, 27: 1}, Pred length: 12\nToken distribution (Batch 11): {1: 14, 32: 2, 34: 2, 10: 3, 47: 1}, Pred length: 22\nToken distribution (Batch 12): {10: 2, 1: 9, 32: 2, 34: 2, 11: 1}, Pred length: 16\nToken distribution (Batch 13): {1: 13, 5: 1, 47: 3, 32: 1, 34: 3, 11: 1}, Pred length: 22\nToken distribution (Batch 14): {12: 1, 35: 1, 1: 13, 50: 1, 6: 1, 27: 1, 47: 1, 34: 1}, Pred length: 20\nToken distribution (Batch 15): {1: 16, 10: 2, 32: 1, 22: 1}, Pred length: 20\nToken distribution (Batch 16): {1: 11, 34: 1, 27: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 17): {1: 9, 19: 1, 10: 1, 34: 2, 12: 1, 6: 1, 56: 1}, Pred length: 16\nToken distribution (Batch 18): {1: 13, 32: 1, 27: 1, 19: 1}, Pred length: 16\nToken distribution (Batch 19): {10: 1, 19: 1, 34: 1, 4: 1, 1: 15, 6: 1, 47: 1, 35: 1, 11: 1, 22: 1}, Pred length: 24\nToken distribution (Batch 20): {1: 9, 47: 1, 32: 2}, Pred length: 12\nToken distribution (Batch 21): {34: 1, 1: 8, 22: 1, 32: 1, 27: 1, 11: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 22): {6: 2, 1: 14, 32: 3, 10: 1, 47: 2, 22: 1, 34: 1}, Pred length: 24\nToken distribution (Batch 23): {1: 7, 34: 1, 47: 1, 12: 1, 4: 1, 19: 1, 27: 1, 5: 1}, Pred length: 14\nToken distribution (Batch 24): {1: 8}, Pred length: 8\nToken distribution (Batch 25): {6: 1, 1: 12, 11: 3, 5: 1, 35: 1, 34: 1, 19: 2, 10: 1}, Pred length: 22\nToken distribution (Batch 26): {1: 14, 34: 2, 22: 1, 43: 1, 32: 4, 50: 1, 47: 1}, Pred length: 24\nToken distribution (Batch 27): {1: 4, 27: 2, 47: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 28): {11: 1, 1: 15, 32: 1, 4: 1, 47: 1, 19: 1, 48: 1, 5: 1}, Pred length: 22\nToken distribution (Batch 29): {10: 1, 1: 9}, Pred length: 10\nToken distribution (Batch 30): {1: 7, 10: 2, 27: 1}, Pred length: 10\nToken distribution (Batch 31): {4: 1, 10: 1, 1: 6, 32: 1, 34: 2, 27: 1, 22: 1, 35: 1}, Pred length: 14\nBatch 120, Gradient norm: 176.2538\nEpoch 12, Batch 120/128, Loss: 18.9839\nAvg Blank Probability: 0.0227\nSample predictions: ['aHasaHa', 'aHa3ajaFa', 'akavakjFaFa']\nGround Truth (first 3): ['n1fr8pds9', 'ihOo6nIG3', 'Ff8vk3O6']\nRaw outputs (first 3): [[ 1  1  1 47 34  1 12  0  1  0 42  1 10  1  6 11  1  1 10  1  1  0  0  1\n   1  1  1  1  1  0 10 11]\n [ 1  1  0  1  0  1  1 11  0  1  0  1  0  0  0  1  0  0  1 10  1  0  6  1\n   1  0  0  0  0  0  1  4]\n [ 1  1  1  1  0  1  0 10  0  0  0  1  1  0  0  1 34  0  0  0  0  0  1  0\n   0  0  0  0  1  1 10  0]]\nInput length: 32, Label lengths: [9, 9, 8]\nEpoch 12/20, Loss: 19.0537\nToken distribution (Batch 0): {1: 12}, Pred length: 12\nToken distribution (Batch 1): {1: 18}, Pred length: 18\nToken distribution (Batch 2): {1: 10}, Pred length: 10\nToken distribution (Batch 3): {1: 12}, Pred length: 12\nToken distribution (Batch 4): {1: 14}, Pred length: 14\nToken distribution (Batch 5): {1: 18}, Pred length: 18\nToken distribution (Batch 6): {1: 18}, Pred length: 18\nToken distribution (Batch 7): {1: 14}, Pred length: 14\nToken distribution (Batch 8): {1: 24}, Pred length: 24\nToken distribution (Batch 9): {1: 20}, Pred length: 20\nToken distribution (Batch 10): {1: 8}, Pred length: 8\nToken distribution (Batch 11): {1: 14}, Pred length: 14\nToken distribution (Batch 12): {1: 22}, Pred length: 22\nToken distribution (Batch 13): {1: 8}, Pred length: 8\nToken distribution (Batch 14): {1: 24}, Pred length: 24\nToken distribution (Batch 15): {1: 10}, Pred length: 10\nToken distribution (Batch 16): {1: 10}, Pred length: 10\nToken distribution (Batch 17): {1: 22}, Pred length: 22\nToken distribution (Batch 18): {1: 8}, Pred length: 8\nToken distribution (Batch 19): {1: 24}, Pred length: 24\nToken distribution (Batch 20): {1: 8}, Pred length: 8\nToken distribution (Batch 21): {1: 16}, Pred length: 16\nToken distribution (Batch 22): {1: 20}, Pred length: 20\nToken distribution (Batch 23): {1: 12}, Pred length: 12\nToken distribution (Batch 24): {1: 10}, Pred length: 10\nToken distribution (Batch 25): {1: 12}, Pred length: 12\nToken distribution (Batch 26): {1: 8}, Pred length: 8\nToken distribution (Batch 27): {1: 20}, Pred length: 20\nToken distribution (Batch 28): {1: 12}, Pred length: 12\nToken distribution (Batch 29): {1: 24}, Pred length: 24\nToken distribution (Batch 30): {1: 16}, Pred length: 16\nToken distribution (Batch 31): {1: 16}, Pred length: 16\nValidation Loss: 19.3094\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['REfCQH', 'kRgs-nNwq', 'YPm*R', 'ZlotyW', 'iB*c91h']\nCurrent Learning Rate: 6.304951684997056e-07\nEpoch 13, Filtered data size: 5120, Sample labels: ['qV8ib8H', 'MdI8', '1XS0DRdJ']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 0): {1: 11, 47: 1, 11: 1, 34: 1, 56: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 1): {1: 10, 34: 1, 32: 2, 12: 1}, Pred length: 14\nToken distribution (Batch 2): {10: 1, 1: 7, 32: 2}, Pred length: 10\nToken distribution (Batch 3): {1: 14, 32: 1, 10: 1}, Pred length: 16\nToken distribution (Batch 4): {11: 1, 1: 17, 32: 2}, Pred length: 20\nToken distribution (Batch 5): {1: 12, 56: 1, 47: 2, 32: 1, 10: 1, 19: 1}, Pred length: 18\nToken distribution (Batch 6): {1: 8, 35: 1, 47: 3, 34: 1, 27: 1}, Pred length: 14\nToken distribution (Batch 7): {1: 14, 6: 1, 22: 1, 27: 3, 32: 1, 56: 1, 4: 1, 10: 1, 47: 1}, Pred length: 24\nToken distribution (Batch 8): {11: 1, 56: 2, 47: 2, 22: 1, 1: 9, 27: 1, 10: 1, 32: 1}, Pred length: 18\nToken distribution (Batch 9): {12: 1, 34: 1, 32: 2, 1: 12, 47: 2}, Pred length: 18\nToken distribution (Batch 10): {11: 2, 1: 16, 32: 2, 47: 1, 27: 2, 5: 1}, Pred length: 24\nToken distribution (Batch 11): {1: 15, 32: 3, 10: 2, 34: 3, 11: 1}, Pred length: 24\nToken distribution (Batch 12): {12: 1, 1: 13, 47: 3, 32: 1, 34: 2, 10: 2}, Pred length: 22\nToken distribution (Batch 13): {32: 3, 1: 10, 10: 3, 19: 1, 6: 1, 35: 1, 34: 3}, Pred length: 22\nToken distribution (Batch 14): {1: 9, 34: 1, 32: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 15): {1: 6, 50: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 16): {1: 6, 34: 3, 22: 1, 27: 1, 32: 3}, Pred length: 14\nToken distribution (Batch 17): {1: 14, 34: 4, 27: 1, 22: 1, 47: 1, 10: 1}, Pred length: 22\nToken distribution (Batch 18): {1: 6, 10: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 19): {1: 12, 10: 2, 32: 2, 47: 1, 34: 1}, Pred length: 18\nToken distribution (Batch 20): {12: 1, 1: 15, 34: 3, 35: 1, 56: 1, 22: 1, 4: 1, 47: 1}, Pred length: 24\nToken distribution (Batch 21): {1: 15, 47: 1, 32: 1, 50: 1, 34: 2}, Pred length: 20\nToken distribution (Batch 22): {1: 5, 34: 3, 47: 1, 19: 2, 27: 3}, Pred length: 14\nToken distribution (Batch 23): {1: 10, 34: 3, 27: 1, 32: 2, 56: 2, 47: 2, 35: 2, 6: 1, 5: 1}, Pred length: 24\nToken distribution (Batch 24): {47: 2, 1: 6, 34: 3, 11: 1, 42: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 25): {1: 8, 32: 2, 5: 1, 28: 1, 34: 1, 47: 1, 56: 1, 27: 1}, Pred length: 16\nToken distribution (Batch 26): {1: 9, 10: 3, 34: 3, 47: 1, 32: 1, 11: 1, 35: 1, 12: 1}, Pred length: 20\nToken distribution (Batch 27): {1: 10, 10: 3, 47: 1, 11: 1, 34: 1, 5: 1, 19: 1}, Pred length: 18\nToken distribution (Batch 28): {35: 1, 1: 9, 34: 1, 47: 1, 12: 1, 27: 1}, Pred length: 14\nToken distribution (Batch 29): {1: 17, 19: 1, 34: 1, 47: 2, 32: 1, 22: 1, 42: 1}, Pred length: 24\nToken distribution (Batch 30): {1: 11, 35: 1}, Pred length: 12\nToken distribution (Batch 31): {1: 9, 11: 1, 56: 1, 12: 1}, Pred length: 12\nBatch 0, Gradient norm: 19.3318\nEpoch 13, Batch 0/128, Loss: 17.3194\nAvg Blank Probability: 0.0227\nSample predictions: ['aUakH3aFa', 'aHFaFala', 'jaFaFa']\nGround Truth (first 3): ['sG-Qf9CE', 'Qkhi*yB', 'b0v2w']\nRaw outputs (first 3): [[ 1 10  0  0  1  1 12  0  0 12  1  4  1 10 34  0  1  1  1  1  0  1  1  1\n   0  0  0  1  0  1  1  0]\n [ 0  1  0  1  0  1  1  0  0  0  0  1  0 32  1  1  1  1  0  1  0  0  1  1\n  47  1  1  0  0  0  1  0]\n [ 0  0  0  1  0  1  0  1 56  0  0  1  1  1  0  0  1  1  1  0  1  1  0  1\n   0 32  0  1  0  0  1 11]]\nInput length: 32, Label lengths: [8, 7, 5]\nToken distribution (Batch 0): {1: 9, 10: 2, 32: 1, 22: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 1): {34: 1, 1: 9, 47: 4, 4: 1, 32: 2, 11: 1}, Pred length: 18\nToken distribution (Batch 2): {1: 12, 42: 1, 34: 1, 11: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 3): {1: 9, 34: 3, 19: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 4): {1: 12, 34: 2, 27: 1, 22: 1}, Pred length: 16\nToken distribution (Batch 5): {11: 1, 4: 1, 1: 10, 34: 1, 5: 1}, Pred length: 14\nToken distribution (Batch 6): {34: 3, 1: 10, 4: 1, 10: 1, 27: 1}, Pred length: 16\nToken distribution (Batch 7): {1: 14, 34: 1, 4: 1, 32: 3, 22: 1, 47: 1, 19: 1, 5: 1, 10: 1}, Pred length: 24\nToken distribution (Batch 8): {1: 15, 12: 1, 22: 1, 34: 1, 10: 1, 4: 1}, Pred length: 20\nToken distribution (Batch 9): {34: 2, 1: 9, 47: 2, 32: 2, 10: 1, 22: 1, 48: 1}, Pred length: 18\nToken distribution (Batch 10): {27: 1, 1: 15, 10: 2, 32: 2}, Pred length: 20\nToken distribution (Batch 11): {34: 3, 1: 7, 47: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 12): {11: 1, 32: 1, 1: 6, 47: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 13): {1: 13, 22: 1, 47: 2, 32: 2}, Pred length: 18\nToken distribution (Batch 14): {10: 2, 32: 1, 1: 8, 22: 1}, Pred length: 12\nToken distribution (Batch 15): {1: 5, 4: 1, 42: 1, 34: 2, 35: 1, 10: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 16): {10: 1, 1: 10, 32: 1, 11: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 17): {47: 3, 34: 2, 32: 2, 1: 9, 12: 1, 5: 1}, Pred length: 18\nToken distribution (Batch 18): {1: 10, 10: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 19): {1: 13, 6: 1, 10: 2, 32: 2, 47: 1, 35: 1, 34: 1, 56: 1}, Pred length: 22\nToken distribution (Batch 20): {1: 13, 56: 1, 22: 1, 27: 1, 34: 2}, Pred length: 18\nToken distribution (Batch 21): {1: 9, 32: 4, 10: 1, 27: 1, 11: 1, 47: 1, 34: 1}, Pred length: 18\nToken distribution (Batch 22): {1: 9, 32: 3, 35: 2, 27: 1, 34: 1, 10: 1, 47: 2, 19: 1}, Pred length: 20\nToken distribution (Batch 23): {1: 13, 10: 2, 32: 1, 22: 1, 35: 1}, Pred length: 18\nToken distribution (Batch 24): {1: 18, 56: 1, 32: 3}, Pred length: 22\nToken distribution (Batch 25): {1: 10, 19: 1, 32: 5, 42: 1, 34: 2, 10: 2, 50: 1}, Pred length: 22\nToken distribution (Batch 26): {1: 12, 32: 1, 5: 1, 19: 1, 11: 1}, Pred length: 16\nToken distribution (Batch 27): {1: 10, 32: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 28): {1: 6, 47: 2, 56: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 29): {1: 15, 10: 2, 32: 2, 34: 1, 43: 1, 47: 1}, Pred length: 22\nToken distribution (Batch 30): {6: 1, 47: 2, 1: 5, 10: 2, 34: 2}, Pred length: 12\nToken distribution (Batch 31): {32: 1, 1: 8, 22: 1, 4: 1, 9: 1}, Pred length: 12\nBatch 10, Gradient norm: 48.9269\nEpoch 13, Batch 10/128, Loss: 17.5648\nAvg Blank Probability: 0.0231\nSample predictions: ['ajaFvajHa', 'HaUaUadUFka', 'aPHkaFa']\nGround Truth (first 3): ['yn4lFA4', 'Rp6fA2pdA', 'N9iyS1RI']\nRaw outputs (first 3): [[ 0 34  0  1  0 11  1  1 34  0 27 10  1 34  1  0  0  1  1 27  1  0  0  1\n  11  1 35  0  0  1  6  1]\n [ 1  0  1  1  0 11  0  1  1  0  0  0  0  0  0  1  0  0  1  0  1  0  1  0\n   0  0  1  1  0  0  0  0]\n [ 1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1\n   0  0  1  0  0  0  0  0]]\nInput length: 32, Label lengths: [7, 9, 8]\nToken distribution (Batch 0): {34: 1, 1: 7, 32: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 1): {22: 2, 1: 11, 47: 2, 32: 1, 6: 1, 10: 1}, Pred length: 18\nToken distribution (Batch 2): {1: 8, 10: 1, 32: 2, 19: 1}, Pred length: 12\nToken distribution (Batch 3): {1: 12, 10: 1, 27: 1, 34: 1, 11: 3, 43: 1, 4: 1, 35: 1, 56: 1}, Pred length: 22\nToken distribution (Batch 4): {6: 2, 4: 1, 1: 7, 32: 1, 22: 2, 10: 1, 34: 1, 56: 1}, Pred length: 16\nToken distribution (Batch 5): {1: 16, 12: 1, 27: 1, 47: 1, 34: 1}, Pred length: 20\nToken distribution (Batch 6): {63: 1, 1: 2, 34: 2, 47: 1, 4: 1, 32: 2, 10: 1}, Pred length: 10\nToken distribution (Batch 7): {1: 12, 34: 2, 22: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 8): {1: 10, 34: 3, 47: 1, 27: 1, 50: 1}, Pred length: 16\nToken distribution (Batch 9): {6: 1, 32: 1, 1: 10, 34: 1, 4: 1}, Pred length: 14\nToken distribution (Batch 10): {1: 16, 10: 2, 27: 1, 34: 2, 11: 2, 19: 1}, Pred length: 24\nToken distribution (Batch 11): {56: 1, 10: 1, 1: 7, 47: 1}, Pred length: 10\nToken distribution (Batch 12): {1: 7, 10: 1, 4: 1, 42: 1}, Pred length: 10\nToken distribution (Batch 13): {32: 1, 1: 8, 47: 1, 34: 2}, Pred length: 12\nToken distribution (Batch 14): {1: 14, 11: 1, 34: 1, 47: 2, 4: 1, 27: 1}, Pred length: 20\nToken distribution (Batch 15): {1: 10}, Pred length: 10\nToken distribution (Batch 16): {1: 13, 10: 2, 32: 1, 34: 3, 27: 3}, Pred length: 22\nToken distribution (Batch 17): {1: 7, 34: 2, 11: 1}, Pred length: 10\nToken distribution (Batch 18): {1: 12, 11: 1, 12: 1, 34: 2, 19: 1, 32: 2, 27: 1}, Pred length: 20\nToken distribution (Batch 19): {1: 9, 10: 1, 5: 1, 32: 3, 19: 1, 34: 1, 47: 1, 6: 1}, Pred length: 18\nToken distribution (Batch 20): {1: 17, 34: 3, 27: 1, 56: 1}, Pred length: 22\nToken distribution (Batch 21): {11: 1, 1: 8, 6: 1}, Pred length: 10\nToken distribution (Batch 22): {32: 1, 1: 5, 19: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 23): {1: 17, 47: 3, 19: 1, 10: 1, 5: 1, 34: 1}, Pred length: 24\nToken distribution (Batch 24): {34: 2, 1: 13, 10: 1, 47: 1, 11: 1}, Pred length: 18\nToken distribution (Batch 25): {1: 4, 4: 3, 32: 1}, Pred length: 8\nToken distribution (Batch 26): {1: 8}, Pred length: 8\nToken distribution (Batch 27): {11: 1, 1: 14, 27: 1, 32: 4, 10: 2, 47: 2}, Pred length: 24\nToken distribution (Batch 28): {47: 2, 1: 11, 56: 1}, Pred length: 14\nToken distribution (Batch 29): {1: 16, 32: 3, 47: 1, 10: 1, 12: 1}, Pred length: 22\nToken distribution (Batch 30): {10: 1, 1: 7, 34: 1, 50: 1, 32: 2}, Pred length: 12\nToken distribution (Batch 31): {1: 11, 47: 1, 10: 1, 34: 1}, Pred length: 14\nBatch 20, Gradient norm: 53.1565\nEpoch 13, Batch 20/128, Loss: 19.5029\nAvg Blank Probability: 0.0235\nSample predictions: ['HaFaj', 'vavUFafaj', 'ajFaFas']\nGround Truth (first 3): ['-iSUy', 'KXRTwkaLP', '2W5rck']\nRaw outputs (first 3): [[34  1 56  1  0  1  1  1  0  0  0  0  1  1  1  1  1  1  1  1  1  1  1  1\n   0 63  0 47 10 10  1 11]\n [34  0  1  1  6  1  0  1  1  0  0  0  0 32  0  0  0  1  0  0  0 11 32  1\n  34  1  0  0  0  0  0  0]\n [ 1  0  0 10  0  1  0  1  0  0  0  0  0  0  1  0  1  1  0  0  0  0  1  1\n   1  1  0  0  0  0  1  0]]\nInput length: 32, Label lengths: [5, 9, 6]\nToken distribution (Batch 0): {32: 1, 1: 11, 10: 3, 12: 1, 27: 2, 19: 1, 34: 2, 47: 1}, Pred length: 22\nToken distribution (Batch 1): {32: 1, 1: 13, 10: 2, 34: 2, 22: 1, 47: 1}, Pred length: 20\nToken distribution (Batch 2): {1: 14, 47: 2}, Pred length: 16\nToken distribution (Batch 3): {1: 14, 5: 1, 34: 2, 27: 1}, Pred length: 18\nToken distribution (Batch 4): {1: 10}, Pred length: 10\nToken distribution (Batch 5): {1: 12, 12: 1, 32: 1, 34: 1, 47: 1}, Pred length: 16\nToken distribution (Batch 6): {1: 6, 27: 1, 6: 1}, Pred length: 8\nToken distribution (Batch 7): {1: 9, 10: 1}, Pred length: 10\nToken distribution (Batch 8): {32: 2, 1: 6, 10: 2, 4: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 9): {34: 2, 5: 1, 1: 16, 32: 3, 10: 1, 47: 1}, Pred length: 24\nToken distribution (Batch 10): {1: 11, 34: 5, 10: 2, 12: 1, 32: 5}, Pred length: 24\nToken distribution (Batch 11): {1: 14, 42: 1, 35: 1, 34: 1, 47: 1}, Pred length: 18\nToken distribution (Batch 12): {1: 15, 34: 1, 12: 1, 32: 4, 10: 1, 4: 1, 47: 1}, Pred length: 24\nToken distribution (Batch 13): {35: 2, 1: 12, 27: 1, 10: 1, 34: 2}, Pred length: 18\nToken distribution (Batch 14): {32: 3, 19: 1, 1: 3, 11: 1}, Pred length: 8\nToken distribution (Batch 15): {34: 1, 1: 13, 27: 1, 12: 2, 47: 3}, Pred length: 20\nToken distribution (Batch 16): {1: 9, 10: 2, 47: 1}, Pred length: 12\nToken distribution (Batch 17): {34: 1, 1: 7, 11: 2, 47: 1, 12: 1}, Pred length: 12\nToken distribution (Batch 18): {1: 7, 34: 1, 35: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 6, 34: 3, 47: 2, 11: 1, 6: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 20): {47: 2, 1: 6, 27: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 21): {1: 11, 32: 2, 10: 2, 5: 1}, Pred length: 16\nToken distribution (Batch 22): {1: 10, 22: 2, 32: 2, 56: 1, 50: 1}, Pred length: 16\nToken distribution (Batch 23): {1: 16, 10: 1, 19: 1, 27: 1, 5: 1, 34: 1, 50: 1, 12: 1, 32: 1}, Pred length: 24\nToken distribution (Batch 24): {10: 2, 34: 2, 1: 6, 19: 1, 32: 1, 35: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 25): {1: 7, 19: 1}, Pred length: 8\nToken distribution (Batch 26): {34: 3, 1: 3, 11: 1, 32: 1, 47: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 27): {10: 3, 34: 1, 1: 5, 47: 1}, Pred length: 10\nToken distribution (Batch 28): {12: 1, 10: 3, 1: 9, 4: 1, 56: 1, 47: 1}, Pred length: 16\nToken distribution (Batch 29): {1: 9, 47: 1, 32: 3, 4: 2, 6: 1}, Pred length: 16\nToken distribution (Batch 30): {1: 7, 32: 4, 34: 1}, Pred length: 12\nToken distribution (Batch 31): {56: 1, 47: 1, 1: 15, 32: 2, 27: 1}, Pred length: 20\nBatch 30, Gradient norm: 22.0957\nEpoch 13, Batch 30/128, Loss: 19.4601\nAvg Blank Probability: 0.0239\nSample predictions: ['FajalaAasjaHUaH', 'FajaHavaHaU', 'aUaUa']\nGround Truth (first 3): ['Dn9wbaG*lMg', 'MBPrRRv32W', '4bKotFzV']\nRaw outputs (first 3): [[ 0 34 32  1  0  1  0 10  0  1 34  0  1  0  0  1  0  1  1  0  4 12 32  0\n   1  0  1 10  0  0  1  1]\n [ 0  0  0  1  1  1  0  0  0  0  0  0  0  0  0  0  0 34  1  1 47  0  0  0\n   0  0  0 10 12  0  0  0]\n [ 0  0  0  1  0  0  0 10  0  0  1  0  0  1  0  1  0  0  0  1  0  0  1  0\n   0  0  0  0  0  0  0  0]]\nInput length: 32, Label lengths: [11, 10, 8]\nToken distribution (Batch 0): {1: 14, 34: 1, 19: 1}, Pred length: 16\nToken distribution (Batch 1): {1: 10, 47: 2}, Pred length: 12\nToken distribution (Batch 2): {1: 16, 34: 2, 32: 2, 11: 1, 47: 1}, Pred length: 22\nToken distribution (Batch 3): {12: 1, 34: 4, 11: 2, 1: 11, 5: 1, 27: 1}, Pred length: 20\nToken distribution (Batch 4): {12: 2, 1: 12, 4: 3, 34: 1, 22: 1, 32: 2, 19: 1}, Pred length: 22\nToken distribution (Batch 5): {4: 2, 1: 9, 10: 1, 34: 1, 32: 3}, Pred length: 16\nToken distribution (Batch 6): {47: 2, 1: 15, 32: 1, 11: 1, 22: 1, 34: 2, 4: 1, 27: 1}, Pred length: 24\nToken distribution (Batch 7): {4: 1, 1: 10, 12: 1, 47: 2, 34: 2, 32: 1, 50: 1}, Pred length: 18\nToken distribution (Batch 8): {1: 8}, Pred length: 8\nToken distribution (Batch 9): {1: 4, 34: 2, 32: 2}, Pred length: 8\nToken distribution (Batch 10): {32: 1, 1: 9, 34: 3, 47: 1}, Pred length: 14\nToken distribution (Batch 11): {1: 16, 47: 1, 12: 1}, Pred length: 18\nToken distribution (Batch 12): {1: 7, 19: 1}, Pred length: 8\nToken distribution (Batch 13): {1: 10, 47: 1, 27: 2, 4: 1, 32: 1, 10: 1}, Pred length: 16\nToken distribution (Batch 14): {34: 3, 1: 8, 12: 1, 32: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 15): {1: 15, 32: 1, 34: 2, 47: 1, 10: 1}, Pred length: 20\nToken distribution (Batch 16): {1: 12, 32: 3, 27: 1}, Pred length: 16\nToken distribution (Batch 17): {1: 8, 47: 2, 12: 1, 19: 1, 34: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 18): {1: 17, 32: 1, 19: 2, 6: 1, 10: 1, 34: 2}, Pred length: 24\nToken distribution (Batch 19): {22: 1, 1: 6, 10: 1, 4: 2, 34: 2}, Pred length: 12\nToken distribution (Batch 20): {1: 12, 32: 2, 12: 1, 4: 1}, Pred length: 16\nToken distribution (Batch 21): {1: 10, 22: 1, 34: 1, 32: 1, 12: 1, 27: 1, 10: 1}, Pred length: 16\nToken distribution (Batch 22): {1: 17, 34: 1}, Pred length: 18\nToken distribution (Batch 23): {1: 8, 32: 2, 47: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 24): {4: 1, 1: 8, 47: 3, 12: 1, 32: 1, 27: 1, 34: 1}, Pred length: 16\nToken distribution (Batch 25): {32: 1, 34: 1, 1: 15, 19: 1, 42: 1, 10: 1, 47: 2}, Pred length: 22\nToken distribution (Batch 26): {47: 3, 6: 1, 1: 12, 32: 4, 10: 1, 19: 1}, Pred length: 22\nToken distribution (Batch 27): {1: 16, 10: 1, 50: 1, 19: 1, 34: 1, 55: 1, 32: 1}, Pred length: 22\nToken distribution (Batch 28): {4: 1, 1: 14, 12: 1, 6: 1, 34: 3, 32: 1, 47: 1}, Pred length: 22\nToken distribution (Batch 29): {1: 13, 34: 1, 32: 1, 10: 1, 12: 1, 47: 1, 56: 1, 43: 1}, Pred length: 20\nToken distribution (Batch 30): {1: 9, 10: 1, 6: 1, 32: 1, 47: 2, 34: 1, 19: 1}, Pred length: 16\nToken distribution (Batch 31): {11: 1, 6: 2, 1: 12, 10: 1, 27: 1, 47: 2, 34: 1}, Pred length: 20\nBatch 40, Gradient norm: 15.1634\nEpoch 13, Batch 40/128, Loss: 17.3863\nAvg Blank Probability: 0.0243\nSample predictions: ['aHasa', 'aUa', 'aHaHaFakaFaUa']\nGround Truth (first 3): ['BKnP9ljD', 'mGKAIZ', 'o0ZQylem-5t']\nRaw outputs (first 3): [[ 1  1  0  0  0 10  0 12  0  1 34  0  1  1  1  0  1  1  1  1  1 34 10  1\n   0  0  0  4  1 47  0  0]\n [ 0  0  0 12  0  0  0  0  1  1 32  1  0  1  0  1  0  1  1  0  0  0  1  1\n   0  0  0  0  0  0  0  0]\n [ 1  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  0  1  0  0  0  1  1\n   1  0  0  0  1  0  0  0]]\nInput length: 32, Label lengths: [8, 6, 11]\nToken distribution (Batch 0): {1: 9, 11: 1, 10: 1, 35: 1}, Pred length: 12\nToken distribution (Batch 1): {1: 10, 32: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 2): {1: 12, 34: 2, 22: 3, 10: 1}, Pred length: 18\nToken distribution (Batch 3): {4: 1, 1: 2, 22: 1, 47: 2, 19: 1, 56: 1, 10: 1, 11: 1}, Pred length: 10\nToken distribution (Batch 4): {12: 1, 4: 1, 1: 5, 32: 1}, Pred length: 8\nToken distribution (Batch 5): {4: 1, 1: 10, 47: 1}, Pred length: 12\nToken distribution (Batch 6): {1: 17, 47: 1, 50: 1, 27: 1, 12: 1, 32: 1, 4: 1, 34: 1}, Pred length: 24\nToken distribution (Batch 7): {1: 5, 10: 2, 34: 1}, Pred length: 8\nToken distribution (Batch 8): {1: 8}, Pred length: 8\nToken distribution (Batch 9): {1: 14, 34: 6, 10: 2, 32: 1, 11: 1}, Pred length: 24\nToken distribution (Batch 10): {10: 1, 1: 6, 27: 1}, Pred length: 8\nToken distribution (Batch 11): {1: 6, 43: 1, 47: 1, 12: 1, 6: 1}, Pred length: 10\nToken distribution (Batch 12): {32: 1, 1: 6, 34: 1, 56: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 13): {1: 8, 32: 1, 12: 1}, Pred length: 10\nToken distribution (Batch 14): {1: 13, 12: 1, 10: 4, 35: 1, 27: 1, 32: 2, 34: 1, 47: 1}, Pred length: 24\nToken distribution (Batch 15): {1: 2, 10: 1, 47: 2, 32: 2, 19: 1}, Pred length: 8\nToken distribution (Batch 16): {1: 9, 34: 1, 47: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 17): {1: 18, 32: 2, 10: 1, 34: 1}, Pred length: 22\nToken distribution (Batch 18): {1: 8, 4: 1, 47: 1, 34: 2, 32: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 19): {12: 1, 1: 9, 32: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 20): {4: 1, 47: 1, 1: 6, 32: 2}, Pred length: 10\nToken distribution (Batch 21): {1: 12, 43: 1, 19: 2, 35: 1, 34: 2, 32: 2, 5: 1, 6: 1}, Pred length: 22\nToken distribution (Batch 22): {1: 13, 32: 1, 5: 1, 47: 2, 10: 2, 35: 1, 34: 2}, Pred length: 22\nToken distribution (Batch 23): {1: 11, 12: 2, 19: 2, 32: 1, 6: 1, 34: 1}, Pred length: 18\nToken distribution (Batch 24): {10: 1, 6: 1, 1: 8, 32: 2, 22: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 25): {1: 15, 32: 4, 47: 1, 22: 1, 10: 1}, Pred length: 22\nToken distribution (Batch 26): {1: 12, 32: 1, 42: 1, 56: 1, 6: 1}, Pred length: 16\nToken distribution (Batch 27): {1: 13, 4: 1, 32: 2, 47: 1, 10: 3, 43: 1, 34: 1}, Pred length: 22\nToken distribution (Batch 28): {47: 1, 1: 16, 34: 1}, Pred length: 18\nToken distribution (Batch 29): {12: 1, 1: 11, 4: 1, 35: 1, 22: 2, 34: 3, 27: 1, 11: 1, 42: 1, 10: 1, 19: 1}, Pred length: 24\nToken distribution (Batch 30): {1: 13, 35: 1, 34: 2, 32: 1, 47: 2, 19: 1}, Pred length: 20\nToken distribution (Batch 31): {1: 11, 34: 1, 4: 1, 10: 2, 35: 2, 47: 2, 32: 2, 11: 1}, Pred length: 22\nBatch 50, Gradient norm: 151.5136\nEpoch 13, Batch 50/128, Loss: 19.7191\nAvg Blank Probability: 0.0246\nSample predictions: ['akajaI', 'aFaHa', 'aHaHavavjva']\nGround Truth (first 3): ['NY8B3x', 'gQ5-Lu', '9yHXr4C-Q']\nRaw outputs (first 3): [[34  1  1  1  0  0  1  1  0  0 10  1 10 34  0  0  1  0  1  0  0  0 47  0\n   0 10  1  1  0  1  0  0]\n [ 0  0  0  4  0  0  0  0  1  1  0  0 32  0  0  0  0  1  1 12  0  0  0  1\n   0  1  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  1  0\n   0  0  0  0  0  0  0  0]]\nInput length: 32, Label lengths: [6, 6, 9]\nToken distribution (Batch 0): {34: 2, 1: 12, 32: 2, 27: 1, 11: 1, 10: 1, 47: 1}, Pred length: 20\nToken distribution (Batch 1): {11: 1, 1: 4, 42: 1, 32: 1, 19: 1}, Pred length: 8\nToken distribution (Batch 2): {1: 12, 12: 2, 32: 5, 22: 1, 10: 1, 11: 1}, Pred length: 22\nToken distribution (Batch 3): {32: 2, 4: 2, 1: 7, 56: 2, 47: 2, 10: 1}, Pred length: 16\nToken distribution (Batch 4): {1: 9, 10: 2, 35: 1, 47: 3, 32: 1, 27: 1, 56: 1, 4: 1, 19: 1}, Pred length: 20\nToken distribution (Batch 5): {1: 10, 4: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 6): {1: 16, 12: 1, 22: 1, 35: 1, 6: 1}, Pred length: 20\nToken distribution (Batch 7): {1: 11, 19: 2, 10: 1, 32: 2, 27: 1, 47: 1}, Pred length: 18\nToken distribution (Batch 8): {1: 8, 34: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 9): {1: 11, 47: 1, 34: 1, 10: 1, 19: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 10): {1: 8, 34: 1, 11: 1, 35: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 11): {1: 11, 32: 2, 22: 1}, Pred length: 14\nToken distribution (Batch 12): {10: 4, 1: 6, 34: 2, 32: 4, 4: 1, 27: 1}, Pred length: 18\nToken distribution (Batch 13): {1: 4, 32: 1, 47: 3, 34: 1, 42: 1}, Pred length: 10\nToken distribution (Batch 14): {32: 2, 1: 7, 34: 2, 4: 1, 12: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 15): {1: 9, 10: 2, 19: 1, 34: 4}, Pred length: 16\nToken distribution (Batch 16): {47: 1, 1: 16, 32: 1, 22: 1, 34: 2, 35: 1, 4: 1, 27: 1}, Pred length: 24\nToken distribution (Batch 17): {1: 16, 10: 1, 22: 2, 4: 1, 56: 1, 32: 2, 27: 1}, Pred length: 24\nToken distribution (Batch 18): {1: 18, 34: 2, 32: 1, 11: 1}, Pred length: 22\nToken distribution (Batch 19): {1: 12, 10: 2, 34: 2}, Pred length: 16\nToken distribution (Batch 20): {1: 3, 4: 1, 34: 3, 47: 2, 10: 1, 6: 1, 11: 1}, Pred length: 12\nToken distribution (Batch 21): {10: 1, 1: 6, 32: 1}, Pred length: 8\nToken distribution (Batch 22): {47: 2, 1: 10, 10: 2, 42: 1, 34: 1}, Pred length: 16\nToken distribution (Batch 23): {1: 15, 47: 3, 22: 1, 55: 1, 32: 3, 50: 1}, Pred length: 24\nToken distribution (Batch 24): {1: 5, 34: 3, 32: 1, 10: 3}, Pred length: 12\nToken distribution (Batch 25): {1: 17, 32: 1, 34: 3, 47: 1, 10: 2}, Pred length: 24\nToken distribution (Batch 26): {1: 10, 34: 2, 10: 1, 19: 1}, Pred length: 14\nToken distribution (Batch 27): {1: 11, 34: 2, 32: 2, 35: 1}, Pred length: 16\nToken distribution (Batch 28): {4: 1, 32: 1, 1: 11, 34: 3, 11: 1, 27: 1}, Pred length: 18\nToken distribution (Batch 29): {1: 15, 12: 1, 47: 3, 32: 2, 34: 1}, Pred length: 22\nToken distribution (Batch 30): {1: 17, 19: 2, 34: 2, 10: 1, 12: 1, 27: 1}, Pred length: 24\nToken distribution (Batch 31): {1: 14, 10: 1, 4: 1, 19: 1, 32: 1, 47: 2}, Pred length: 20\nBatch 60, Gradient norm: 15.5701\nEpoch 13, Batch 60/128, Loss: 17.4942\nAvg Blank Probability: 0.0248\nSample predictions: ['HaFaAakajaFHaU', 'kaPFas', 'alaFvFalaFajaFak']\nGround Truth (first 3): ['oKl-De6nbS', 'rlk5', 'r3*ww2DKDCt']\nRaw outputs (first 3): [[ 0  0 34  1  1  1  0  1  0  1  1  0  1 43 56  1  0  0  0  1  0  1  1  0\n   0  0  0  1  1  0  1  1]\n [ 0  0  1  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0 47  0\n   0  1  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0\n   0  1 34  0  0  0  0  0]]\nInput length: 32, Label lengths: [10, 4, 11]\nToken distribution (Batch 0): {1: 12, 32: 4, 47: 1, 19: 2, 27: 1}, Pred length: 20\nToken distribution (Batch 1): {34: 4, 19: 1, 10: 2, 1: 10, 32: 3, 47: 1, 22: 1}, Pred length: 22\nToken distribution (Batch 2): {19: 1, 1: 15, 4: 1, 34: 3, 32: 2}, Pred length: 22\nToken distribution (Batch 3): {1: 12, 34: 3, 10: 1, 32: 2, 12: 1, 47: 1}, Pred length: 20\nToken distribution (Batch 4): {1: 11, 35: 1, 27: 1, 12: 1}, Pred length: 14\nToken distribution (Batch 5): {34: 2, 1: 13, 12: 1, 10: 2, 5: 1, 47: 1}, Pred length: 20\nToken distribution (Batch 6): {1: 6, 34: 3, 47: 1}, Pred length: 10\nToken distribution (Batch 7): {1: 8, 22: 1, 32: 1, 56: 1, 19: 1}, Pred length: 12\nToken distribution (Batch 8): {1: 8, 10: 2, 47: 1, 5: 2, 34: 2, 12: 1, 35: 1, 22: 1}, Pred length: 18\nToken distribution (Batch 9): {34: 3, 11: 1, 32: 2, 1: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 10): {1: 11, 34: 2, 32: 2, 12: 1, 22: 1, 47: 1}, Pred length: 18\nToken distribution (Batch 11): {1: 17, 34: 2, 5: 1, 43: 1, 47: 1, 10: 1, 32: 1}, Pred length: 24\nToken distribution (Batch 12): {22: 1, 1: 6, 47: 1, 32: 1, 19: 1}, Pred length: 10\nToken distribution (Batch 13): {1: 6, 47: 1, 10: 1, 32: 1, 34: 2, 19: 1, 27: 2}, Pred length: 14\nToken distribution (Batch 14): {47: 1, 1: 15, 32: 3, 48: 1, 12: 1, 34: 1}, Pred length: 22\nToken distribution (Batch 15): {1: 6, 47: 4}, Pred length: 10\nToken distribution (Batch 16): {10: 2, 1: 13, 34: 1}, Pred length: 16\nToken distribution (Batch 17): {34: 2, 47: 2, 1: 11, 35: 1}, Pred length: 16\nToken distribution (Batch 18): {1: 12, 22: 1, 34: 2, 32: 1, 12: 1, 43: 1, 10: 1, 11: 1, 56: 1, 47: 1}, Pred length: 22\nToken distribution (Batch 19): {1: 8, 11: 1, 35: 1, 6: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 20): {1: 10, 34: 3, 10: 2, 32: 2, 43: 1, 6: 1, 9: 1}, Pred length: 20\nToken distribution (Batch 21): {1: 8}, Pred length: 8\nToken distribution (Batch 22): {1: 13, 6: 1, 22: 1, 47: 2, 11: 1, 32: 1, 34: 3}, Pred length: 22\nToken distribution (Batch 23): {1: 8, 19: 1, 47: 1, 34: 2, 56: 1, 22: 1}, Pred length: 14\nToken distribution (Batch 24): {56: 1, 1: 15, 10: 1, 32: 1, 47: 2, 34: 1, 4: 1}, Pred length: 22\nToken distribution (Batch 25): {1: 17, 34: 3, 32: 2, 27: 1, 42: 1}, Pred length: 24\nToken distribution (Batch 26): {1: 7, 34: 1}, Pred length: 8\nToken distribution (Batch 27): {1: 9, 25: 1, 32: 2, 47: 2}, Pred length: 14\nToken distribution (Batch 28): {1: 14, 34: 3, 47: 1, 12: 1, 27: 1}, Pred length: 20\nToken distribution (Batch 29): {1: 11, 32: 2, 12: 1, 47: 2, 19: 1, 27: 1, 5: 1, 10: 1}, Pred length: 20\nToken distribution (Batch 30): {11: 1, 1: 5, 34: 2, 32: 1, 5: 1, 56: 1, 10: 1}, Pred length: 12\nToken distribution (Batch 31): {34: 2, 32: 2, 6: 2, 1: 8, 19: 1, 12: 1}, Pred length: 16\nBatch 70, Gradient norm: 773.5851\nEpoch 13, Batch 70/128, Loss: 17.9703\nAvg Blank Probability: 0.0253\nSample predictions: ['aFUasaAaFsaFa', 'HsjajFaUFavaH', 'sadaHaFaHaFa']\nGround Truth (first 3): ['VOycTAi4wz', '0NazvNoXZuH', 'A7pMWZmvPzp']\nRaw outputs (first 3): [[ 0  1  0 32  0  0  1  0  1  0  0 12  0  0 47  1  0  0  1  0 11 10  1  1\n   0  1 10  0  1  0  0  1]\n [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0\n   0  1  0  0  0  1  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  1  0  0  0  0  0  0]]\nInput length: 32, Label lengths: [10, 11, 11]\nToken distribution (Batch 0): {12: 1, 56: 1, 1: 15, 27: 1, 10: 1, 32: 1, 47: 1, 6: 1, 34: 2}, Pred length: 24\nToken distribution (Batch 1): {1: 11, 34: 1, 6: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 2): {6: 1, 1: 4, 47: 1, 56: 1, 34: 2, 4: 1, 5: 1, 32: 1, 27: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 3): {42: 1, 11: 1, 1: 3, 5: 1, 27: 2, 56: 1, 50: 1}, Pred length: 10\nToken distribution (Batch 4): {1: 10}, Pred length: 10\nToken distribution (Batch 5): {1: 6, 22: 1, 47: 1, 32: 1, 12: 1}, Pred length: 10\nToken distribution (Batch 6): {1: 14, 47: 1, 32: 1, 25: 1, 34: 2, 5: 1}, Pred length: 20\nToken distribution (Batch 7): {34: 3, 1: 11, 47: 3, 56: 1, 10: 1, 32: 1}, Pred length: 20\nToken distribution (Batch 8): {34: 3, 1: 11, 32: 2, 47: 1, 27: 1}, Pred length: 18\nToken distribution (Batch 9): {1: 11, 11: 1, 10: 2, 6: 2, 5: 2, 34: 1, 27: 2, 32: 1}, Pred length: 22\nToken distribution (Batch 10): {10: 2, 34: 1, 12: 1, 1: 12}, Pred length: 16\nToken distribution (Batch 11): {1: 4, 47: 1, 32: 1, 56: 1, 5: 1}, Pred length: 8\nToken distribution (Batch 12): {10: 2, 32: 2, 1: 10, 4: 1, 34: 1}, Pred length: 16\nToken distribution (Batch 13): {47: 1, 32: 3, 1: 14, 34: 1, 12: 1, 56: 1, 6: 1}, Pred length: 22\nToken distribution (Batch 14): {1: 10, 11: 2, 34: 2, 4: 1, 32: 2, 47: 1}, Pred length: 18\nToken distribution (Batch 15): {19: 2, 1: 9, 34: 1, 47: 1, 10: 3, 5: 1, 27: 2, 12: 1, 11: 1, 32: 1}, Pred length: 22\nToken distribution (Batch 16): {1: 15, 32: 1, 27: 1, 47: 2, 56: 1, 10: 2, 34: 1, 5: 1}, Pred length: 24\nToken distribution (Batch 17): {1: 7, 11: 1, 35: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 18): {11: 1, 1: 8, 32: 1, 47: 1, 4: 1}, Pred length: 12\nToken distribution (Batch 19): {4: 1, 1: 8, 34: 1, 10: 2, 11: 1, 12: 1}, Pred length: 14\nToken distribution (Batch 20): {1: 15, 34: 3, 10: 1, 32: 2, 47: 1, 25: 1, 12: 1}, Pred length: 24\nToken distribution (Batch 21): {1: 7, 42: 1, 27: 1, 34: 2, 47: 2, 10: 1}, Pred length: 14\nToken distribution (Batch 22): {1: 15, 32: 1}, Pred length: 16\nToken distribution (Batch 23): {1: 12, 47: 1, 12: 2, 34: 5, 27: 1, 6: 1, 19: 1, 32: 1}, Pred length: 24\nToken distribution (Batch 24): {1: 10, 6: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 25): {1: 12, 32: 6, 47: 1, 34: 1}, Pred length: 20\nToken distribution (Batch 26): {48: 1, 1: 12, 4: 1, 32: 2, 19: 1, 47: 1, 34: 1, 10: 1}, Pred length: 20\nToken distribution (Batch 27): {1: 13, 34: 1}, Pred length: 14\nToken distribution (Batch 28): {1: 9, 6: 1, 5: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 29): {10: 1, 47: 2, 34: 1, 1: 7, 5: 1}, Pred length: 12\nToken distribution (Batch 30): {10: 2, 1: 16, 22: 1, 47: 1}, Pred length: 20\nToken distribution (Batch 31): {1: 7, 42: 1}, Pred length: 8\nBatch 80, Gradient norm: 17.1908\nEpoch 13, Batch 80/128, Loss: 18.1339\nAvg Blank Probability: 0.0258\nSample predictions: ['l3aAajFaUafHaHa', 'aHfaU', 'faU3HdeFAajH']\nGround Truth (first 3): ['3-tcRTdgChG2', 'yIFQuyL', '-jwvv2i']\nRaw outputs (first 3): [[ 0 34  0 10  1  0  1  0  0  0 10  1  0  0  0  0  0  0  0  0  0  0  0  1\n   0  0  0  0  0  1  0  1]\n [ 0  0  0  0  0  1  0  0  0  1  0  0 10  0  0  0  1  0  0  0  0  1  1  0\n   1  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 32, Label lengths: [12, 7, 7]\nToken distribution (Batch 0): {1: 11, 32: 1, 56: 1, 10: 1, 47: 1, 27: 1, 34: 2}, Pred length: 18\nToken distribution (Batch 1): {1: 4, 34: 1, 32: 1, 19: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 2): {1: 10, 32: 2, 34: 2, 10: 2, 12: 1, 47: 1, 5: 2, 11: 1, 19: 1}, Pred length: 22\nToken distribution (Batch 3): {1: 10, 34: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 4): {32: 1, 1: 11, 11: 1, 47: 2, 10: 1}, Pred length: 16\nToken distribution (Batch 5): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 6): {1: 13, 56: 1, 32: 1, 22: 1}, Pred length: 16\nToken distribution (Batch 7): {1: 12, 47: 1, 34: 2, 19: 1}, Pred length: 16\nToken distribution (Batch 8): {10: 2, 34: 2, 1: 4}, Pred length: 8\nToken distribution (Batch 9): {1: 11, 22: 1}, Pred length: 12\nToken distribution (Batch 10): {1: 15, 34: 2, 4: 1, 35: 2, 32: 1, 11: 1}, Pred length: 22\nToken distribution (Batch 11): {34: 1, 1: 12, 11: 1, 10: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 12): {1: 10, 10: 1, 35: 1, 32: 1, 50: 1, 27: 2}, Pred length: 16\nToken distribution (Batch 13): {32: 1, 1: 9, 34: 2}, Pred length: 12\nToken distribution (Batch 14): {1: 11, 4: 1, 34: 2}, Pred length: 14\nToken distribution (Batch 15): {1: 8, 4: 1, 34: 2, 10: 3, 11: 2, 47: 1, 12: 1}, Pred length: 18\nToken distribution (Batch 16): {1: 18, 47: 2, 32: 1, 27: 1}, Pred length: 22\nToken distribution (Batch 17): {1: 9, 34: 1, 42: 1, 47: 2, 32: 1}, Pred length: 14\nToken distribution (Batch 18): {32: 3, 34: 2, 1: 10, 12: 1, 27: 1, 48: 1, 22: 1, 47: 1, 19: 1, 4: 1}, Pred length: 22\nToken distribution (Batch 19): {1: 7, 32: 1, 12: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 20): {11: 1, 47: 1, 6: 1, 50: 1, 1: 3, 32: 1}, Pred length: 8\nToken distribution (Batch 21): {1: 7, 12: 1, 6: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 22): {32: 4, 34: 2, 10: 1, 47: 1, 1: 10, 27: 2}, Pred length: 20\nToken distribution (Batch 23): {34: 2, 1: 3, 19: 1, 32: 2}, Pred length: 8\nToken distribution (Batch 24): {1: 13, 32: 2, 19: 2, 10: 2, 56: 1, 34: 1, 35: 1, 4: 1, 47: 1}, Pred length: 24\nToken distribution (Batch 25): {10: 2, 34: 4, 1: 6}, Pred length: 12\nToken distribution (Batch 26): {1: 7, 34: 1}, Pred length: 8\nToken distribution (Batch 27): {11: 1, 1: 7, 19: 1, 56: 1, 10: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 28): {63: 1, 1: 6, 27: 2, 5: 2, 32: 1}, Pred length: 12\nToken distribution (Batch 29): {1: 10, 34: 1, 32: 2, 50: 1}, Pred length: 14\nToken distribution (Batch 30): {10: 1, 1: 15, 32: 1, 34: 3, 47: 1, 4: 1}, Pred length: 22\nToken distribution (Batch 31): {1: 7, 4: 1}, Pred length: 8\nBatch 90, Gradient norm: 21.7577\nEpoch 13, Batch 90/128, Loss: 20.4412\nAvg Blank Probability: 0.0262\nSample predictions: ['aFa3jaUAHa', 'aHFsUa', 'aFaHajHaFalaUjaekeas']\nGround Truth (first 3): ['bs1hZE9p3', 'fT0d', 'c5QDDzswlwW']\nRaw outputs (first 3): [[ 0  0 10  1  0 10  0  0  1  1  0  0  0  0  1  0  0  1 12  0  1  0  0 10\n   1 47  0 10  1 10  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1  0  0  0  0  0  0\n   1  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 32, Label lengths: [9, 4, 11]\nToken distribution (Batch 0): {1: 10, 6: 1, 4: 1, 32: 1, 47: 1, 12: 1, 11: 1}, Pred length: 16\nToken distribution (Batch 1): {1: 15, 34: 1, 48: 1, 4: 1}, Pred length: 18\nToken distribution (Batch 2): {1: 8, 47: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 3): {1: 11, 10: 1}, Pred length: 12\nToken distribution (Batch 4): {1: 16, 34: 1, 47: 1}, Pred length: 18\nToken distribution (Batch 5): {47: 2, 1: 12, 34: 1, 32: 1, 10: 1, 12: 1}, Pred length: 18\nToken distribution (Batch 6): {1: 15, 11: 1, 10: 1, 34: 1, 27: 2}, Pred length: 20\nToken distribution (Batch 7): {1: 7, 47: 1, 32: 2}, Pred length: 10\nToken distribution (Batch 8): {12: 1, 34: 2, 1: 10, 19: 1, 10: 1, 47: 2, 32: 1}, Pred length: 18\nToken distribution (Batch 9): {1: 4, 47: 1, 34: 2, 4: 1}, Pred length: 8\nToken distribution (Batch 10): {11: 1, 27: 2, 34: 2, 1: 6, 32: 1}, Pred length: 12\nToken distribution (Batch 11): {10: 1, 1: 16, 32: 4, 47: 1, 27: 1, 6: 1}, Pred length: 24\nToken distribution (Batch 12): {1: 4, 47: 2, 34: 1, 19: 1}, Pred length: 8\nToken distribution (Batch 13): {1: 17, 34: 3, 10: 2, 47: 1, 5: 1}, Pred length: 24\nToken distribution (Batch 14): {11: 1, 1: 17, 47: 1, 56: 1, 6: 1, 19: 1, 50: 1, 27: 1}, Pred length: 24\nToken distribution (Batch 15): {1: 10, 56: 1, 10: 2, 34: 1, 32: 1, 47: 5, 27: 1, 19: 1}, Pred length: 22\nToken distribution (Batch 16): {10: 3, 34: 2, 1: 7, 47: 2, 27: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 17): {1: 9, 11: 1, 32: 1, 22: 1}, Pred length: 12\nToken distribution (Batch 18): {34: 4, 1: 8, 47: 2, 27: 3, 10: 3, 12: 1, 19: 1, 32: 1, 11: 1}, Pred length: 24\nToken distribution (Batch 19): {1: 17, 50: 1, 11: 1, 43: 1, 34: 1, 42: 1}, Pred length: 22\nToken distribution (Batch 20): {1: 17, 32: 1, 34: 2, 10: 1, 11: 1}, Pred length: 22\nToken distribution (Batch 21): {4: 1, 1: 8, 27: 1}, Pred length: 10\nToken distribution (Batch 22): {1: 13, 12: 1, 34: 1, 47: 1}, Pred length: 16\nToken distribution (Batch 23): {1: 16, 34: 3, 19: 2, 35: 1, 32: 1, 10: 1}, Pred length: 24\nToken distribution (Batch 24): {34: 2, 1: 5, 12: 1, 47: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 25): {32: 2, 12: 2, 1: 14, 34: 2, 5: 1, 27: 2, 11: 1}, Pred length: 24\nToken distribution (Batch 26): {1: 10, 4: 1, 32: 2, 47: 1, 34: 2}, Pred length: 16\nToken distribution (Batch 27): {1: 13, 11: 1, 47: 1, 25: 1, 32: 1, 19: 1}, Pred length: 18\nToken distribution (Batch 28): {19: 1, 32: 1, 47: 2, 1: 10, 34: 3, 27: 1}, Pred length: 18\nToken distribution (Batch 29): {34: 4, 1: 6, 10: 1, 32: 2, 12: 1}, Pred length: 14\nToken distribution (Batch 30): {47: 2, 1: 15, 25: 1, 34: 3, 32: 1}, Pred length: 22\nToken distribution (Batch 31): {1: 14, 10: 1, 47: 2, 32: 1}, Pred length: 18\nBatch 100, Gradient norm: 16234.8857\nEpoch 13, Batch 100/128, Loss: 17.4266\nAvg Blank Probability: 0.0263\nSample predictions: ['afdaFaUlak', 'aHVada', 'aUaAa']\nGround Truth (first 3): ['TlTOwX54', 'llCHcKlIb', 'qmG-8']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  1  0  1  0  0  0 10  0  0 34 10  1  0  0  0  0  0\n  11  0 10  1  0  0  0  1]\n [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n   0  0  0  0  0  0  0  0]]\nInput length: 32, Label lengths: [8, 9, 5]\nToken distribution (Batch 0): {1: 11, 32: 3, 19: 1, 27: 1}, Pred length: 16\nToken distribution (Batch 1): {32: 2, 1: 10, 34: 2, 47: 2}, Pred length: 16\nToken distribution (Batch 2): {34: 6, 47: 3, 1: 13, 35: 2}, Pred length: 24\nToken distribution (Batch 3): {1: 14, 10: 1, 11: 1, 48: 1, 34: 3, 32: 1, 47: 1}, Pred length: 22\nToken distribution (Batch 4): {32: 1, 1: 12, 12: 1, 11: 1, 34: 1, 10: 1, 35: 1}, Pred length: 18\nToken distribution (Batch 5): {1: 17, 34: 1, 32: 2, 22: 1, 4: 1}, Pred length: 22\nToken distribution (Batch 6): {25: 1, 1: 5, 34: 2, 32: 3, 11: 1, 19: 1, 6: 1}, Pred length: 14\nToken distribution (Batch 7): {1: 7, 12: 2, 50: 1, 11: 1, 10: 2, 47: 1, 22: 1, 4: 1}, Pred length: 16\nToken distribution (Batch 8): {1: 8, 19: 1, 34: 2, 12: 1}, Pred length: 12\nToken distribution (Batch 9): {1: 4, 47: 3, 19: 1, 32: 1, 11: 1}, Pred length: 10\nToken distribution (Batch 10): {1: 9, 34: 2, 32: 2, 22: 1, 10: 2}, Pred length: 16\nToken distribution (Batch 11): {20: 1, 35: 1, 32: 2, 1: 5, 27: 1, 47: 2, 34: 2}, Pred length: 14\nToken distribution (Batch 12): {4: 1, 1: 6, 34: 3, 32: 1, 6: 1}, Pred length: 12\nToken distribution (Batch 13): {1: 14, 32: 1, 34: 2, 35: 1}, Pred length: 18\nToken distribution (Batch 14): {1: 12, 32: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 15): {4: 1, 1: 15, 19: 2, 34: 2, 27: 1, 22: 1, 47: 2}, Pred length: 24\nToken distribution (Batch 16): {1: 8, 34: 4, 4: 1, 32: 1, 42: 1, 47: 2, 56: 1}, Pred length: 18\nToken distribution (Batch 17): {1: 6, 27: 1, 6: 1, 47: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 18): {1: 8, 10: 1, 32: 1, 27: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 19): {10: 3, 1: 13, 34: 1, 50: 1, 32: 3, 47: 1}, Pred length: 22\nToken distribution (Batch 20): {1: 8, 34: 1, 32: 1, 4: 2, 27: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 21): {1: 10, 10: 1, 32: 1, 34: 2}, Pred length: 14\nToken distribution (Batch 22): {47: 1, 1: 12, 34: 2, 10: 1}, Pred length: 16\nToken distribution (Batch 23): {1: 4, 10: 2, 32: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 24): {1: 12, 34: 2, 19: 1, 32: 1, 10: 1, 22: 1}, Pred length: 18\nToken distribution (Batch 25): {1: 16, 11: 2, 19: 1, 47: 1, 34: 2}, Pred length: 22\nToken distribution (Batch 26): {1: 4, 34: 3, 32: 2, 4: 1}, Pred length: 10\nToken distribution (Batch 27): {1: 15, 34: 2, 10: 1, 27: 1, 19: 1}, Pred length: 20\nToken distribution (Batch 28): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 29): {34: 2, 1: 11, 4: 1, 10: 1, 32: 1}, Pred length: 16\nToken distribution (Batch 30): {47: 3, 34: 1, 1: 9, 22: 1}, Pred length: 14\nToken distribution (Batch 31): {1: 17, 34: 1, 10: 1, 32: 1, 27: 1, 47: 1}, Pred length: 22\nBatch 110, Gradient norm: 22.3325\nEpoch 13, Batch 110/128, Loss: 17.9646\nAvg Blank Probability: 0.0271\nSample predictions: ['aFasaFaFAa', 'FaHUaUHaF', 'HUaUaIaHaHaHIaUHa']\nGround Truth (first 3): ['EQUWt6jB', '2kqoSJut', 'PP8oz0n6iGMk']\nRaw outputs (first 3): [[ 1  0  0  0  0  0  0 32  0  0  1  0  1  0  0  1  1  0  0  0  0  1  0  0\n   0  0  0  0 35  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 32, Label lengths: [8, 8, 12]\nToken distribution (Batch 0): {1: 4, 34: 3, 32: 3, 35: 1, 12: 1, 50: 1, 47: 2, 4: 1}, Pred length: 16\nToken distribution (Batch 1): {47: 3, 1: 9, 25: 1, 34: 1, 4: 1, 22: 1, 32: 1, 10: 1}, Pred length: 18\nToken distribution (Batch 2): {1: 7, 19: 1, 11: 1, 50: 1, 4: 1, 6: 1, 32: 1, 34: 3, 47: 2}, Pred length: 18\nToken distribution (Batch 3): {1: 14, 47: 1, 34: 2, 35: 1, 32: 3, 27: 1}, Pred length: 22\nToken distribution (Batch 4): {1: 18, 4: 1, 34: 2, 32: 1}, Pred length: 22\nToken distribution (Batch 5): {1: 5, 12: 1, 34: 2}, Pred length: 8\nToken distribution (Batch 6): {1: 8, 4: 1, 27: 1, 32: 3, 47: 2, 34: 1}, Pred length: 16\nToken distribution (Batch 7): {1: 13, 12: 1, 11: 1, 43: 1, 9: 1, 34: 2, 32: 1}, Pred length: 20\nToken distribution (Batch 8): {1: 10, 47: 1, 11: 2, 34: 2, 12: 1}, Pred length: 16\nToken distribution (Batch 9): {4: 1, 1: 6, 10: 2, 11: 1}, Pred length: 10\nToken distribution (Batch 10): {1: 8, 27: 1, 32: 3}, Pred length: 12\nToken distribution (Batch 11): {1: 12, 10: 2, 4: 2, 34: 1, 22: 1}, Pred length: 18\nToken distribution (Batch 12): {11: 1, 22: 1, 1: 10}, Pred length: 12\nToken distribution (Batch 13): {1: 6, 56: 1, 10: 1, 11: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 14): {10: 1, 1: 8, 34: 1, 35: 1, 47: 1}, Pred length: 12\nToken distribution (Batch 15): {1: 19, 34: 2, 63: 1, 19: 1, 47: 1}, Pred length: 24\nToken distribution (Batch 16): {1: 13, 34: 2, 32: 3}, Pred length: 18\nToken distribution (Batch 17): {1: 11, 4: 1, 34: 2, 32: 2, 5: 1, 27: 1}, Pred length: 18\nToken distribution (Batch 18): {12: 2, 47: 1, 1: 4, 10: 2, 34: 1, 27: 1, 5: 1}, Pred length: 12\nToken distribution (Batch 19): {1: 14, 34: 3, 4: 1, 19: 1, 32: 1, 27: 1, 22: 1}, Pred length: 22\nToken distribution (Batch 20): {1: 11, 47: 2, 34: 3, 50: 1, 56: 1, 11: 1, 10: 1}, Pred length: 20\nToken distribution (Batch 21): {1: 9, 34: 1, 56: 1, 50: 1}, Pred length: 12\nToken distribution (Batch 22): {47: 1, 1: 9, 6: 1, 34: 1, 35: 1, 32: 6, 11: 1}, Pred length: 20\nToken distribution (Batch 23): {1: 10, 27: 1, 5: 1, 34: 1, 10: 1, 32: 1}, Pred length: 15\nToken distribution (Batch 24): {34: 2, 1: 8, 11: 1, 32: 1, 19: 1, 4: 1}, Pred length: 14\nToken distribution (Batch 25): {19: 1, 47: 1, 1: 8, 10: 1, 11: 1}, Pred length: 12\nToken distribution (Batch 26): {1: 6, 12: 2, 32: 4, 10: 1, 34: 2, 47: 2, 27: 1}, Pred length: 18\nToken distribution (Batch 27): {1: 6, 4: 1, 34: 1, 10: 2}, Pred length: 10\nToken distribution (Batch 28): {1: 14, 34: 3, 50: 1, 47: 1, 32: 4, 19: 1}, Pred length: 24\nToken distribution (Batch 29): {1: 8, 32: 2, 34: 1, 47: 1, 19: 2, 10: 1, 11: 1}, Pred length: 16\nToken distribution (Batch 30): {1: 9, 12: 1, 32: 2, 10: 1, 27: 1}, Pred length: 14\nToken distribution (Batch 31): {1: 14, 47: 1, 32: 2, 42: 1, 27: 1, 10: 2, 4: 1}, Pred length: 22\nBatch 120, Gradient norm: 17.2518\nEpoch 13, Batch 120/128, Loss: 17.4701\nAvg Blank Probability: 0.0272\nSample predictions: ['aHFIlFXHUHdaFaUa', 'UayUHdavUFaja', 'asakXadfaFaHaUH']\nGround Truth (first 3): ['O6mLpqkJ', 'WnaWoHVUC', 'FV7tsxGAF']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0 34  0  0  0  0  0  0\n   0  0  0  0  0  0  0  1]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 32, Label lengths: [8, 9, 9]\nEpoch 13/20, Loss: 18.5256\nToken distribution (Batch 0): {1: 14}, Pred length: 14\nToken distribution (Batch 1): {1: 12}, Pred length: 12\nToken distribution (Batch 2): {1: 14}, Pred length: 14\nToken distribution (Batch 3): {1: 16}, Pred length: 16\nToken distribution (Batch 4): {1: 22}, Pred length: 22\nToken distribution (Batch 5): {1: 10}, Pred length: 10\nToken distribution (Batch 6): {1: 8}, Pred length: 8\nToken distribution (Batch 7): {1: 12}, Pred length: 12\nToken distribution (Batch 8): {1: 22}, Pred length: 22\nToken distribution (Batch 9): {1: 20}, Pred length: 20\nToken distribution (Batch 10): {1: 24}, Pred length: 24\nToken distribution (Batch 11): {1: 18}, Pred length: 18\nToken distribution (Batch 12): {1: 16}, Pred length: 16\nToken distribution (Batch 13): {1: 14}, Pred length: 14\nToken distribution (Batch 14): {1: 12}, Pred length: 12\nToken distribution (Batch 15): {1: 22}, Pred length: 22\nToken distribution (Batch 16): {1: 24}, Pred length: 24\nToken distribution (Batch 17): {1: 10}, Pred length: 10\nToken distribution (Batch 18): {1: 22}, Pred length: 22\nToken distribution (Batch 19): {1: 20}, Pred length: 20\nToken distribution (Batch 20): {1: 12}, Pred length: 12\nToken distribution (Batch 21): {1: 14}, Pred length: 14\nToken distribution (Batch 22): {1: 22}, Pred length: 22\nToken distribution (Batch 23): {1: 10}, Pred length: 10\nToken distribution (Batch 24): {1: 22}, Pred length: 22\nToken distribution (Batch 25): {1: 12}, Pred length: 12\nToken distribution (Batch 26): {1: 10}, Pred length: 10\nToken distribution (Batch 27): {1: 14}, Pred length: 14\nToken distribution (Batch 28): {1: 8}, Pred length: 8\nToken distribution (Batch 29): {1: 18}, Pred length: 18\nToken distribution (Batch 30): {1: 22}, Pred length: 22\nToken distribution (Batch 31): {1: 14}, Pred length: 14\nValidation Loss: 19.5267\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['WvmBR9f', 'RWh-GI', '5v4FwOA', 'bJKFH8CB', 'cGgvf6Z5uFb']\nCurrent Learning Rate: 7.08020100713192e-07\nEpoch 14, Filtered data size: 5120, Sample labels: ['qV8ib8H', 'MdI8', '1XS0DRdJ']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 0): {1: 12, 34: 1, 47: 1, 35: 1, 11: 1, 32: 2, 56: 1, 4: 1}, Pred length: 20\nToken distribution (Batch 1): {1: 8, 10: 1, 27: 3, 42: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 2): {47: 2, 1: 13, 12: 2, 32: 4, 34: 2, 10: 1}, Pred length: 24\nToken distribution (Batch 3): {35: 1, 1: 3, 47: 1, 32: 1}, Pred length: 6\nToken distribution (Batch 4): {6: 1, 47: 1, 4: 1, 12: 1, 1: 4, 34: 1, 11: 1}, Pred length: 10\nToken distribution (Batch 5): {1: 5, 11: 1, 47: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 6): {1: 6, 5: 1, 34: 1, 32: 2}, Pred length: 10\nToken distribution (Batch 7): {47: 1, 1: 10, 34: 1, 5: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 8): {1: 8, 34: 2, 32: 2, 47: 1, 11: 1, 10: 1, 4: 1}, Pred length: 16\nToken distribution (Batch 9): {47: 1, 1: 7, 34: 2}, Pred length: 10\nToken distribution (Batch 10): {1: 15, 32: 1, 34: 2}, Pred length: 18\nToken distribution (Batch 11): {1: 9, 4: 1}, Pred length: 10\nToken distribution (Batch 12): {1: 8, 34: 3, 19: 1}, Pred length: 12\nToken distribution (Batch 13): {12: 1, 1: 9, 6: 2, 34: 2, 47: 1, 32: 2, 10: 1}, Pred length: 18\nToken distribution (Batch 14): {1: 3, 19: 1}, Pred length: 4\nToken distribution (Batch 15): {1: 10, 34: 2, 10: 1, 32: 2, 27: 1}, Pred length: 16\nToken distribution (Batch 16): {34: 4, 11: 1, 47: 2, 1: 10, 10: 1, 27: 1, 32: 1}, Pred length: 20\nToken distribution (Batch 17): {1: 9, 22: 1}, Pred length: 10\nToken distribution (Batch 18): {34: 7, 1: 8, 47: 3, 56: 1, 32: 2, 12: 1}, Pred length: 22\nToken distribution (Batch 19): {1: 6, 32: 4, 34: 2, 19: 1, 5: 1, 47: 1, 6: 1}, Pred length: 16\nToken distribution (Batch 20): {47: 1, 1: 9, 22: 1, 34: 3, 10: 1, 4: 1}, Pred length: 16\nToken distribution (Batch 21): {1: 5, 11: 1, 32: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 22): {1: 6, 5: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 23): {1: 7, 34: 1, 11: 2}, Pred length: 10\nToken distribution (Batch 24): {11: 1, 34: 1, 1: 15, 19: 1, 32: 2, 27: 1, 10: 1}, Pred length: 22\nToken distribution (Batch 25): {1: 7, 34: 2, 4: 1, 12: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 26): {1: 11, 34: 3, 32: 1, 11: 1}, Pred length: 16\nToken distribution (Batch 27): {6: 1, 47: 3, 1: 11, 34: 3, 32: 2, 22: 1, 26: 1}, Pred length: 22\nToken distribution (Batch 28): {1: 5, 32: 2, 27: 5, 34: 1, 10: 1}, Pred length: 14\nToken distribution (Batch 29): {10: 1, 11: 1, 1: 6, 32: 3, 27: 1, 34: 1, 22: 1}, Pred length: 14\nToken distribution (Batch 30): {1: 5, 34: 1, 10: 1, 19: 1, 32: 2, 56: 1, 4: 1}, Pred length: 12\nToken distribution (Batch 31): {1: 10, 47: 2, 12: 1, 19: 1}, Pred length: 14\nBatch 0, Gradient norm: 29.9897\nEpoch 14, Batch 0/128, Loss: 18.9612\nAvg Blank Probability: 0.0279\nSample predictions: ['aHaUaIkF3aFad', 'ajaAaPAaHAa', 'UalFalHajaFUaHa']\nGround Truth (first 3): ['CM869Q5kRu', 'fqFFV7y', 'AYB92s0SqJ8K']\nRaw outputs (first 3): [[ 0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 11  0  1  0  1\n   0  6  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 32, Label lengths: [10, 7, 12]\nToken distribution (Batch 0): {34: 4, 56: 1, 32: 1, 5: 1, 1: 3, 27: 2}, Pred length: 12\nToken distribution (Batch 1): {1: 11, 6: 2, 32: 2, 12: 1, 34: 1, 47: 1}, Pred length: 18\nToken distribution (Batch 2): {1: 17, 35: 2, 34: 2, 32: 1}, Pred length: 22\nToken distribution (Batch 3): {47: 3, 1: 14, 32: 3, 42: 1, 10: 1, 34: 2}, Pred length: 24\nToken distribution (Batch 4): {47: 1, 1: 4, 32: 3, 4: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 5): {1: 7, 19: 1, 36: 1, 11: 1, 10: 1, 34: 1}, Pred length: 12\nToken distribution (Batch 6): {1: 14, 11: 1, 10: 1, 32: 1, 47: 1}, Pred length: 18\nToken distribution (Batch 7): {1: 10, 56: 1, 6: 1, 10: 1, 32: 1, 11: 1, 12: 1}, Pred length: 16\nToken distribution (Batch 8): {1: 16, 34: 3, 32: 4, 47: 1}, Pred length: 24\nToken distribution (Batch 9): {34: 2, 32: 2, 1: 9, 47: 2, 10: 1}, Pred length: 16\nToken distribution (Batch 10): {34: 1, 32: 1, 19: 1, 1: 6, 27: 1}, Pred length: 10\nToken distribution (Batch 11): {1: 8, 34: 2}, Pred length: 10\nToken distribution (Batch 12): {12: 1, 1: 9, 47: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 13): {1: 4, 10: 2, 11: 1, 47: 1, 34: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 14): {34: 1, 10: 1, 1: 10, 32: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 15): {1: 6, 5: 1, 34: 1, 10: 1, 32: 2, 27: 1}, Pred length: 12\nToken distribution (Batch 16): {1: 8, 35: 1, 19: 1, 47: 1, 6: 1, 32: 2}, Pred length: 14\nToken distribution (Batch 17): {1: 6, 32: 1}, Pred length: 7\nToken distribution (Batch 18): {10: 1, 1: 7, 34: 1, 4: 1}, Pred length: 10\nToken distribution (Batch 19): {12: 1, 1: 14, 34: 2, 27: 1, 47: 1, 5: 1, 32: 1, 43: 1}, Pred length: 22\nToken distribution (Batch 20): {10: 1, 1: 11, 47: 1, 4: 1, 34: 1}, Pred length: 15\nToken distribution (Batch 21): {1: 9, 47: 1, 27: 1, 22: 1, 32: 1, 19: 1}, Pred length: 14\nToken distribution (Batch 22): {34: 1, 1: 9, 48: 1, 32: 2, 11: 1}, Pred length: 14\nToken distribution (Batch 23): {1: 8, 47: 2, 32: 1, 22: 1, 27: 1, 34: 2, 25: 1}, Pred length: 16\nToken distribution (Batch 24): {1: 10, 32: 1, 12: 2, 10: 1}, Pred length: 14\nToken distribution (Batch 25): {1: 7, 43: 1}, Pred length: 8\nToken distribution (Batch 26): {1: 15, 12: 1, 32: 3, 47: 1, 6: 1, 42: 1}, Pred length: 22\nToken distribution (Batch 27): {12: 2, 1: 6, 22: 1, 34: 1}, Pred length: 10\nToken distribution (Batch 28): {34: 2, 4: 1, 1: 7, 11: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 29): {1: 9, 32: 4, 19: 2, 12: 1, 47: 1, 34: 1}, Pred length: 18\nToken distribution (Batch 30): {1: 9, 48: 1, 32: 2, 10: 1, 47: 3, 7: 1, 34: 1}, Pred length: 18\nToken distribution (Batch 31): {1: 4, 56: 1, 10: 1}, Pred length: 6\nBatch 10, Gradient norm: 19.4375\nEpoch 14, Batch 10/128, Loss: 18.3418\nAvg Blank Probability: 0.0282\nSample predictions: ['H3HFeaHAa', 'afaFalFfHaU', 'aIHaIaHaFa']\nGround Truth (first 3): ['aSA45o', 'bKtdmel2f', 'F1voonKUaTo']\nRaw outputs (first 3): [[ 0  0  0  0  0 34  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 32, Label lengths: [6, 9, 11]\nToken distribution (Batch 0): {1: 16, 32: 1, 34: 3}, Pred length: 20\nToken distribution (Batch 1): {1: 6, 22: 2, 27: 1, 10: 1, 12: 1, 19: 1, 5: 1}, Pred length: 13\nToken distribution (Batch 2): {11: 1, 34: 1, 1: 7, 12: 1, 32: 3, 19: 2}, Pred length: 15\nToken distribution (Batch 3): {10: 1, 1: 5, 32: 4, 34: 3, 11: 2, 47: 1}, Pred length: 16\nToken distribution (Batch 4): {34: 2, 1: 9, 35: 1}, Pred length: 12\nToken distribution (Batch 5): {10: 1, 27: 1, 42: 1, 1: 4, 47: 1}, Pred length: 8\nToken distribution (Batch 6): {47: 1, 1: 6, 12: 1, 34: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 7): {32: 2, 10: 2, 1: 19, 56: 1}, Pred length: 24\nToken distribution (Batch 8): {10: 1, 1: 12, 22: 1, 34: 2, 47: 2, 32: 2}, Pred length: 20\nToken distribution (Batch 9): {1: 6, 11: 1, 50: 1, 47: 1, 32: 1}, Pred length: 10\nToken distribution (Batch 10): {27: 1, 11: 1, 1: 3, 34: 1}, Pred length: 6\nToken distribution (Batch 11): {34: 1, 6: 1, 1: 8, 32: 1, 35: 1}, Pred length: 12\nToken distribution (Batch 12): {1: 12, 34: 2, 43: 1, 11: 1}, Pred length: 16\nToken distribution (Batch 13): {32: 2, 1: 5, 6: 1, 19: 1, 47: 1}, Pred length: 10\nToken distribution (Batch 14): {1: 5, 32: 1, 34: 1}, Pred length: 7\nToken distribution (Batch 15): {4: 1, 11: 1, 1: 11, 10: 1, 47: 1, 34: 2, 19: 1, 32: 1, 35: 1, 27: 1, 42: 1}, Pred length: 22\nToken distribution (Batch 16): {34: 4, 1: 5, 47: 1, 32: 2}, Pred length: 12\nToken distribution (Batch 17): {1: 8, 32: 3, 27: 1}, Pred length: 12\nToken distribution (Batch 18): {1: 8, 6: 1, 27: 2, 47: 2, 32: 1}, Pred length: 14\nToken distribution (Batch 19): {1: 8, 47: 3, 4: 1}, Pred length: 12\nToken distribution (Batch 20): {1: 13, 47: 1}, Pred length: 14\nToken distribution (Batch 21): {1: 6, 4: 1}, Pred length: 7\nToken distribution (Batch 22): {5: 1, 43: 1, 47: 2, 35: 1, 1: 6, 10: 1}, Pred length: 12\nToken distribution (Batch 23): {50: 1, 35: 1, 34: 2, 11: 1, 32: 2, 1: 9, 10: 1, 22: 5, 47: 1, 56: 1}, Pred length: 24\nToken distribution (Batch 24): {1: 7, 6: 1, 12: 1, 34: 2, 32: 1, 47: 1, 56: 1, 19: 1}, Pred length: 15\nToken distribution (Batch 25): {1: 11, 34: 3, 32: 3, 27: 1, 56: 1}, Pred length: 19\nToken distribution (Batch 26): {1: 15, 10: 1, 34: 3, 47: 4, 12: 1}, Pred length: 24\nToken distribution (Batch 27): {47: 2, 1: 9, 32: 2, 19: 1, 10: 1, 34: 1}, Pred length: 16\nToken distribution (Batch 28): {47: 1, 1: 2, 11: 2, 34: 2, 32: 3}, Pred length: 10\nToken distribution (Batch 29): {1: 11, 19: 1, 32: 3, 25: 1, 34: 3, 11: 1}, Pred length: 20\nToken distribution (Batch 30): {1: 6, 47: 1}, Pred length: 7\nToken distribution (Batch 31): {1: 3, 47: 1, 27: 1, 32: 1}, Pred length: 6\nBatch 20, Gradient norm: 44.0138\nEpoch 14, Batch 20/128, Loss: 17.6701\nAvg Blank Probability: 0.0287\nSample predictions: ['aFaHaH', 'avaAjlasve', 'kHalaFasFsF']\nGround Truth (first 3): ['YoX11wDPBV', '1xyXbxM5ENk', 'PvK1XHsaHw']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [10, 11, 10]\nToken distribution (Batch 0): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 1): {1: 12, 47: 2, 34: 2, 32: 4, 10: 2, 5: 1, 22: 1}, Pred length: 24\nToken distribution (Batch 2): {19: 1, 34: 1, 1: 5, 22: 1, 27: 3, 11: 1, 32: 4, 47: 2}, Pred length: 18\nToken distribution (Batch 3): {1: 5, 34: 1, 10: 1, 47: 1}, Pred length: 8\nToken distribution (Batch 4): {1: 12, 47: 3, 32: 2, 11: 1, 6: 1, 34: 1}, Pred length: 20\nToken distribution (Batch 5): {1: 13, 34: 3, 32: 2, 47: 1, 10: 1}, Pred length: 20\nToken distribution (Batch 6): {1: 9, 34: 1, 19: 1, 47: 1, 6: 1, 32: 1}, Pred length: 14\nToken distribution (Batch 7): {34: 4, 1: 3, 27: 1, 47: 1, 22: 1}, Pred length: 10\nToken distribution (Batch 8): {47: 2, 1: 9, 10: 2, 32: 1}, Pred length: 14\nToken distribution (Batch 9): {50: 1, 1: 7, 47: 1, 34: 2, 12: 1, 32: 2}, Pred length: 14\nToken distribution (Batch 10): {12: 1, 1: 8, 34: 8, 10: 1, 4: 1, 25: 1, 32: 2, 27: 2}, Pred length: 24\nToken distribution (Batch 11): {1: 7, 27: 1}, Pred length: 8\nToken distribution (Batch 12): {4: 1, 11: 1, 1: 8, 12: 1, 27: 1}, Pred length: 12\nToken distribution (Batch 13): {35: 2, 1: 15, 19: 2, 27: 1, 47: 2, 34: 2}, Pred length: 24\nToken distribution (Batch 14): {32: 2, 1: 15, 47: 1, 34: 2}, Pred length: 20\nToken distribution (Batch 15): {12: 1, 32: 1, 1: 4, 47: 1, 11: 1, 34: 2}, Pred length: 10\nToken distribution (Batch 16): {1: 3, 32: 1}, Pred length: 4\nToken distribution (Batch 17): {1: 2}, Pred length: 2\nToken distribution (Batch 18): {1: 4, 32: 1, 27: 1}, Pred length: 6\nToken distribution (Batch 19): {34: 1, 1: 12, 5: 1, 12: 1, 47: 1}, Pred length: 16\nToken distribution (Batch 20): {34: 2, 10: 1, 1: 5}, Pred length: 8\nToken distribution (Batch 21): {1: 2, 10: 1}, Pred length: 3\nToken distribution (Batch 22): {1: 4, 56: 1, 32: 1}, Pred length: 6\nToken distribution (Batch 23): {1: 3, 10: 1, 27: 1, 32: 1}, Pred length: 6\nToken distribution (Batch 24): {10: 1, 1: 15, 32: 1, 34: 4, 12: 1, 27: 1, 6: 1}, Pred length: 24\nToken distribution (Batch 25): {1: 17, 11: 1, 10: 1, 27: 1, 35: 1, 34: 2, 22: 1}, Pred length: 24\nToken distribution (Batch 26): {1: 7, 27: 1}, Pred length: 8\nToken distribution (Batch 27): {1: 8, 27: 1, 19: 1}, Pred length: 10\nToken distribution (Batch 28): {1: 3, 27: 1, 34: 2, 50: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 29): {1: 8, 32: 3, 35: 1, 47: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 30): {1: 4, 10: 1}, Pred length: 5\nToken distribution (Batch 31): {1: 5, 10: 1, 32: 1}, Pred length: 7\nBatch 30, Gradient norm: 23.6035\nEpoch 14, Batch 30/128, Loss: 18.7680\nAvg Blank Probability: 0.0299\nSample predictions: ['aFa', 'aUaHUaFjFeHvaFaja', 'sHavAakAFUFAUFa']\nGround Truth (first 3): ['c-sn', 'YeuykU-M7neB', 'uLLUM1jM4']\nRaw outputs (first 3): [[11  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  1  0  0  0  0  0]\n [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 32, Label lengths: [4, 12, 9]\nToken distribution (Batch 0): {1: 2}, Pred length: 2\nToken distribution (Batch 1): {32: 6, 34: 2, 27: 1, 1: 12, 19: 1, 12: 1, 56: 1}, Pred length: 24\nToken distribution (Batch 2): {34: 5, 4: 2, 47: 3, 1: 7, 19: 1}, Pred length: 18\nToken distribution (Batch 3): {47: 1, 1: 3, 43: 1, 27: 1, 32: 1}, Pred length: 7\nToken distribution (Batch 4): {34: 1, 1: 3}, Pred length: 4\nToken distribution (Batch 5): {32: 6, 1: 9, 34: 1, 12: 1, 10: 1, 4: 1, 19: 1}, Pred length: 20\nToken distribution (Batch 6): {32: 3, 6: 1, 1: 14, 5: 1, 10: 2, 27: 1, 34: 2}, Pred length: 24\nToken distribution (Batch 7): {1: 6, 32: 1, 22: 1}, Pred length: 8\nToken distribution (Batch 8): {1: 6, 27: 1}, Pred length: 7\nToken distribution (Batch 9): {12: 1, 11: 1, 34: 2, 1: 3, 19: 1}, Pred length: 8\nToken distribution (Batch 10): {1: 5, 32: 2, 34: 2, 47: 1}, Pred length: 10\nToken distribution (Batch 11): {1: 5, 22: 1}, Pred length: 6\nToken distribution (Batch 12): {1: 3, 34: 1, 32: 1, 4: 1}, Pred length: 6\nToken distribution (Batch 13): {1: 7, 34: 3, 12: 1, 32: 3}, Pred length: 14\nToken distribution (Batch 14): {12: 1, 34: 1, 1: 6}, Pred length: 8\nToken distribution (Batch 15): {1: 2, 34: 1}, Pred length: 3\nToken distribution (Batch 16): {34: 2, 1: 9, 10: 1, 27: 1, 47: 3}, Pred length: 16\nToken distribution (Batch 17): {1: 1, 34: 1, 10: 1}, Pred length: 3\nToken distribution (Batch 18): {1: 8, 6: 1, 27: 1}, Pred length: 10\nToken distribution (Batch 19): {1: 2, 11: 1}, Pred length: 3\nToken distribution (Batch 20): {1: 7, 47: 2, 11: 1}, Pred length: 10\nToken distribution (Batch 21): {1: 6, 34: 1, 27: 1}, Pred length: 8\nToken distribution (Batch 22): {1: 15, 47: 2, 34: 1, 32: 2}, Pred length: 20\nToken distribution (Batch 23): {1: 7, 32: 2, 47: 1, 12: 1, 35: 1}, Pred length: 12\nToken distribution (Batch 24): {1: 2, 4: 1}, Pred length: 3\nToken distribution (Batch 25): {34: 3, 1: 5, 32: 2, 55: 1}, Pred length: 11\nToken distribution (Batch 26): {1: 7, 5: 1, 32: 1}, Pred length: 9\nToken distribution (Batch 27): {1: 6, 32: 1, 34: 1, 10: 1}, Pred length: 9\nToken distribution (Batch 28): {56: 1, 1: 4, 34: 1, 27: 1}, Pred length: 7\nToken distribution (Batch 29): {12: 1, 1: 4, 10: 1, 47: 1, 27: 1}, Pred length: 8\nToken distribution (Batch 30): {1: 2, 32: 3, 5: 1, 12: 1, 10: 1}, Pred length: 8\nToken distribution (Batch 31): {1: 10, 34: 1, 32: 1}, Pred length: 12\nBatch 40, Gradient norm: 22.8002\nEpoch 14, Batch 40/128, Loss: 18.6325\nAvg Blank Probability: 0.0301\nSample predictions: ['a', 'FHAaFaHaFasala3a', 'HdUaUHsdHaHa']\nGround Truth (first 3): ['MHApRz', '9z8rl1xNQjMA', 'ujaFHoyne']\nRaw outputs (first 3): [[ 0  0  0  1  0  0  0  0  1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0\n   0 10  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 32, Label lengths: [6, 12, 9]\nToken distribution (Batch 0): {1: 2}, Pred length: 2\nToken distribution (Batch 1): {1: 4, 10: 1, 34: 1, 47: 1}, Pred length: 7\nToken distribution (Batch 2): {34: 2, 10: 1, 27: 1, 1: 5}, Pred length: 9\nToken distribution (Batch 3): {1: 2}, Pred length: 2\nToken distribution (Batch 4): {47: 2, 34: 2, 1: 4, 48: 1, 27: 1, 32: 2}, Pred length: 12\nToken distribution (Batch 5): {1: 3, 47: 1, 35: 1, 4: 1, 48: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 6): {1: 3, 47: 1, 32: 1, 27: 1, 4: 1}, Pred length: 7\nToken distribution (Batch 7): {32: 2, 27: 4, 1: 11, 34: 3, 47: 1, 19: 1}, Pred length: 22\nToken distribution (Batch 8): {34: 1, 27: 1}, Pred length: 2\nToken distribution (Batch 9): {1: 3, 56: 1}, Pred length: 4\nToken distribution (Batch 10): {47: 1, 1: 9, 32: 2, 34: 2}, Pred length: 14\nToken distribution (Batch 11): {10: 2, 1: 8, 47: 3, 34: 1}, Pred length: 14\nToken distribution (Batch 12): {34: 1, 1: 15, 12: 1, 10: 1}, Pred length: 18\nToken distribution (Batch 13): {1: 2}, Pred length: 2\nToken distribution (Batch 14): {1: 9, 34: 1, 4: 1, 19: 1, 47: 1, 6: 1}, Pred length: 14\nToken distribution (Batch 15): {1: 1, 19: 1}, Pred length: 2\nToken distribution (Batch 16): {47: 3, 1: 8, 34: 3}, Pred length: 14\nToken distribution (Batch 17): {10: 1, 5: 1}, Pred length: 2\nToken distribution (Batch 18): {27: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 6, 10: 2, 11: 1, 4: 1, 19: 1, 27: 1, 56: 1}, Pred length: 13\nToken distribution (Batch 20): {19: 1, 1: 1}, Pred length: 2\nToken distribution (Batch 21): {1: 2, 32: 1, 34: 1}, Pred length: 4\nToken distribution (Batch 22): {1: 2}, Pred length: 2\nToken distribution (Batch 23): {6: 1, 1: 5, 32: 1, 27: 1}, Pred length: 8\nToken distribution (Batch 24): {19: 1, 1: 12, 27: 1}, Pred length: 14\nToken distribution (Batch 25): {1: 3, 34: 1}, Pred length: 4\nToken distribution (Batch 26): {11: 1, 32: 1, 12: 1, 1: 3, 5: 1}, Pred length: 7\nToken distribution (Batch 27): {47: 1, 1: 8, 34: 1}, Pred length: 10\nToken distribution (Batch 28): {1: 6, 32: 1}, Pred length: 7\nToken distribution (Batch 29): {1: 2, 32: 1, 27: 1}, Pred length: 4\nToken distribution (Batch 30): {1: 1, 32: 2}, Pred length: 3\nToken distribution (Batch 31): {1: 13, 34: 2, 11: 1, 47: 1, 32: 2, 22: 1}, Pred length: 20\nBatch 50, Gradient norm: 20.4663\nEpoch 14, Batch 50/128, Loss: 18.0616\nAvg Blank Probability: 0.0307\nSample predictions: ['a', 'ajHUa', 'HjAaHa']\nGround Truth (first 3): ['-F-eUZog', '4ZhAu1rC-Q', 'a1IPv']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [8, 10, 5]\nToken distribution (Batch 0): {1: 1, 5: 1}, Pred length: 2\nToken distribution (Batch 1): {1: 6, 27: 3, 4: 1}, Pred length: 10\nToken distribution (Batch 2): {1: 15, 19: 1, 47: 2, 22: 1, 27: 1, 34: 1, 4: 1}, Pred length: 22\nToken distribution (Batch 3): {1: 1}, Pred length: 1\nToken distribution (Batch 4): {10: 2, 1: 6, 22: 1, 12: 1}, Pred length: 10\nToken distribution (Batch 5): {1: 8, 47: 1, 27: 1, 34: 1, 32: 1}, Pred length: 12\nToken distribution (Batch 6): {1: 7, 22: 1, 32: 1, 34: 2, 6: 1}, Pred length: 12\nToken distribution (Batch 7): {4: 1, 1: 3, 34: 1}, Pred length: 5\nToken distribution (Batch 8): {47: 1, 1: 7, 32: 2}, Pred length: 10\nToken distribution (Batch 9): {1: 2}, Pred length: 2\nToken distribution (Batch 10): {12: 2, 1: 4, 34: 1, 32: 1, 47: 1, 11: 1}, Pred length: 10\nToken distribution (Batch 11): {32: 1, 1: 2, 12: 1, 34: 1, 11: 1}, Pred length: 6\nToken distribution (Batch 12): {47: 2, 1: 8, 34: 3, 27: 1, 12: 1, 19: 1}, Pred length: 16\nToken distribution (Batch 13): {32: 1, 1: 1, 34: 1}, Pred length: 3\nToken distribution (Batch 14): {56: 1, 1: 6, 22: 1}, Pred length: 8\nToken distribution (Batch 15): {1: 4, 32: 2, 47: 1, 27: 1}, Pred length: 8\nToken distribution (Batch 16): {35: 1, 1: 7, 34: 2}, Pred length: 10\nToken distribution (Batch 17): {1: 3, 34: 1}, Pred length: 4\nToken distribution (Batch 18): {1: 7}, Pred length: 7\nToken distribution (Batch 19): {1: 16, 10: 1, 27: 1, 12: 1, 34: 1}, Pred length: 20\nToken distribution (Batch 20): {1: 3, 47: 1, 4: 1, 34: 1}, Pred length: 6\nToken distribution (Batch 21): {47: 2, 1: 5, 22: 1, 19: 1}, Pred length: 9\nToken distribution (Batch 22): {1: 7, 32: 1}, Pred length: 8\nToken distribution (Batch 23): {50: 1}, Pred length: 1\nToken distribution (Batch 24): {1: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 25): {1: 5, 34: 2, 27: 1, 10: 2, 35: 1, 4: 1, 11: 1, 47: 1}, Pred length: 14\nToken distribution (Batch 26): {1: 2, 12: 1, 34: 1}, Pred length: 4\nToken distribution (Batch 27): {1: 3}, Pred length: 3\nToken distribution (Batch 28): {1: 3, 32: 1, 10: 1}, Pred length: 5\nToken distribution (Batch 29): {1: 7, 34: 3}, Pred length: 10\nToken distribution (Batch 30): {1: 2, 42: 2, 34: 1}, Pred length: 5\nToken distribution (Batch 31): {34: 1}, Pred length: 1\nBatch 60, Gradient norm: 22.4061\nEpoch 14, Batch 60/128, Loss: 18.9582\nAvg Blank Probability: 0.0309\nSample predictions: ['ae', 'aAadaA', 'asaUavUAaHda']\nGround Truth (first 3): ['ryObp2*', 'ev7LqnOt94J', 'p48-aDDSeJK']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [7, 11, 11]\nToken distribution (Batch 0): {1: 4, 10: 1, 34: 1}, Pred length: 6\nToken distribution (Batch 1): {32: 1, 1: 5, 10: 2}, Pred length: 8\nToken distribution (Batch 2): {1: 5, 10: 1, 34: 1}, Pred length: 7\nToken distribution (Batch 3): {10: 1, 1: 15, 12: 1, 34: 4, 6: 1, 32: 1, 47: 1}, Pred length: 24\nToken distribution (Batch 4): {34: 1, 1: 4}, Pred length: 5\nToken distribution (Batch 5): {1: 5, 10: 1, 34: 1, 11: 1}, Pred length: 8\nToken distribution (Batch 6): {1: 5, 32: 1}, Pred length: 6\nToken distribution (Batch 7): {19: 1, 1: 6, 10: 1, 32: 2, 47: 2, 11: 1, 34: 1}, Pred length: 14\nToken distribution (Batch 8): {1: 2, 32: 2}, Pred length: 4\nToken distribution (Batch 9): {1: 1}, Pred length: 1\nToken distribution (Batch 10): {12: 1, 1: 1}, Pred length: 2\nToken distribution (Batch 11): {1: 5, 19: 1, 27: 1}, Pred length: 7\nToken distribution (Batch 12): {1: 5, 11: 1, 32: 1}, Pred length: 7\nToken distribution (Batch 13): {1: 2, 47: 1, 5: 1}, Pred length: 4\nToken distribution (Batch 14): {5: 2}, Pred length: 2\nToken distribution (Batch 15): {1: 4, 32: 1}, Pred length: 5\nToken distribution (Batch 16): {1: 6, 10: 1, 11: 1}, Pred length: 8\nToken distribution (Batch 17): {1: 1, 27: 1}, Pred length: 2\nToken distribution (Batch 18): {27: 1, 1: 10, 34: 2, 10: 1}, Pred length: 14\nToken distribution (Batch 19): {1: 3, 47: 2, 34: 3}, Pred length: 8\nToken distribution (Batch 20): {1: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 21): {1: 5, 32: 2, 6: 1}, Pred length: 8\nToken distribution (Batch 22): {32: 1}, Pred length: 1\nToken distribution (Batch 23): {32: 1}, Pred length: 1\nToken distribution (Batch 24): {34: 1, 1: 1}, Pred length: 2\nToken distribution (Batch 25): {12: 1}, Pred length: 1\nToken distribution (Batch 26): {1: 4, 32: 2, 47: 1, 34: 3}, Pred length: 10\nToken distribution (Batch 27): {35: 1, 34: 5, 32: 3, 1: 6}, Pred length: 15\nToken distribution (Batch 28): {1: 3, 34: 1, 19: 1}, Pred length: 5\nToken distribution (Batch 29): {1: 1}, Pred length: 1\nToken distribution (Batch 30): {1: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 31): {34: 2, 1: 6}, Pred length: 8\nBatch 70, Gradient norm: 406.7691\nEpoch 14, Batch 70/128, Loss: 19.0935\nAvg Blank Probability: 0.0313\nSample predictions: ['ajHa', 'Fajaj', 'ajaH']\nGround Truth (first 3): ['f01c', 'eCyg', 'qxRhqH']\nRaw outputs (first 3): [[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [4, 4, 6]\nToken distribution (Batch 0): {1: 6, 32: 2, 27: 2, 10: 1}, Pred length: 11\nToken distribution (Batch 1): {11: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 2): {1: 11, 34: 3}, Pred length: 14\nToken distribution (Batch 3): {1: 4, 34: 1}, Pred length: 5\nToken distribution (Batch 4): {34: 1, 32: 1, 1: 1}, Pred length: 3\nToken distribution (Batch 5): {27: 1}, Pred length: 1\nToken distribution (Batch 6): {34: 2}, Pred length: 2\nToken distribution (Batch 7): {1: 2, 32: 1}, Pred length: 3\nToken distribution (Batch 8): {1: 4}, Pred length: 4\nToken distribution (Batch 9): {1: 7, 47: 1, 10: 1, 34: 1, 32: 3, 4: 1}, Pred length: 14\nToken distribution (Batch 10): {1: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 11): {1: 2, 10: 3, 27: 1}, Pred length: 6\nToken distribution (Batch 12): {19: 1, 10: 1, 22: 1, 32: 1, 1: 5, 27: 1, 5: 1}, Pred length: 11\nToken distribution (Batch 13): {1: 3}, Pred length: 3\nToken distribution (Batch 14): {1: 3, 42: 1}, Pred length: 4\nToken distribution (Batch 15): {47: 1, 1: 13, 34: 2}, Pred length: 16\nToken distribution (Batch 16): {1: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 17): {1: 8, 47: 1}, Pred length: 9\nToken distribution (Batch 18): {1: 2, 27: 1}, Pred length: 3\nToken distribution (Batch 19): {5: 1}, Pred length: 1\nToken distribution (Batch 20): {32: 1}, Pred length: 1\nToken distribution (Batch 21): {34: 1}, Pred length: 1\nToken distribution (Batch 22): {1: 2}, Pred length: 2\nToken distribution (Batch 23): {10: 1}, Pred length: 1\nToken distribution (Batch 24): {1: 1}, Pred length: 1\nToken distribution (Batch 25): {1: 1}, Pred length: 1\nToken distribution (Batch 26): {34: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 3, 34: 1}, Pred length: 4\nToken distribution (Batch 28): {1: 10, 32: 1, 34: 1, 27: 2}, Pred length: 14\nToken distribution (Batch 29): {1: 3, 32: 1}, Pred length: 4\nToken distribution (Batch 30): {10: 2, 1: 4, 34: 1, 56: 1}, Pred length: 8\nToken distribution (Batch 31): {1: 4, 34: 1}, Pred length: 5\nBatch 80, Gradient norm: 20.2026\nEpoch 14, Batch 80/128, Loss: 17.0622\nAvg Blank Probability: 0.0322\nSample predictions: ['aFaAjaFA', 'kF', 'aHaHaHa']\nGround Truth (first 3): ['T4ei4vEgY', 'f2IvXe4aR', 'UubV8DhrN']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [9, 9, 9]\nToken distribution (Batch 0): {32: 1}, Pred length: 1\nToken distribution (Batch 1): {19: 1, 1: 6, 34: 1}, Pred length: 8\nToken distribution (Batch 2): {34: 1}, Pred length: 1\nToken distribution (Batch 3): {1: 2}, Pred length: 2\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {1: 1}, Pred length: 1\nToken distribution (Batch 7): {1: 3, 34: 1}, Pred length: 4\nToken distribution (Batch 8): {1: 3, 32: 1}, Pred length: 4\nToken distribution (Batch 9): {32: 1}, Pred length: 1\nToken distribution (Batch 10): {34: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 11): {1: 2}, Pred length: 2\nToken distribution (Batch 12): {19: 1}, Pred length: 1\nToken distribution (Batch 13): {11: 1, 47: 1, 32: 1, 5: 1}, Pred length: 4\nToken distribution (Batch 14): {5: 1, 1: 2, 32: 1}, Pred length: 4\nToken distribution (Batch 15): {1: 3, 47: 1, 27: 1, 32: 1}, Pred length: 6\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {32: 1}, Pred length: 1\nToken distribution (Batch 18): {47: 1, 1: 10, 35: 1, 32: 2, 6: 1, 11: 1, 34: 1, 56: 1}, Pred length: 18\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {1: 2}, Pred length: 2\nToken distribution (Batch 21): {1: 4}, Pred length: 4\nToken distribution (Batch 22): {11: 1}, Pred length: 1\nToken distribution (Batch 23): {34: 3, 1: 9, 19: 1, 35: 1, 50: 1, 27: 1}, Pred length: 16\nToken distribution (Batch 24): {1: 4}, Pred length: 4\nToken distribution (Batch 25): {19: 1, 1: 3, 34: 1}, Pred length: 5\nToken distribution (Batch 26): {19: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 3, 47: 1}, Pred length: 4\nToken distribution (Batch 28): {1: 9, 34: 2, 47: 1}, Pred length: 12\nToken distribution (Batch 29): {34: 1, 1: 1}, Pred length: 2\nToken distribution (Batch 30): {1: 2, 27: 1, 19: 1}, Pred length: 4\nToken distribution (Batch 31): {19: 1, 1: 1, 22: 1, 10: 1}, Pred length: 4\nBatch 90, Gradient norm: 36.9994\nEpoch 14, Batch 90/128, Loss: 18.3809\nAvg Blank Probability: 0.0331\nSample predictions: ['F', 'saHa', 'H']\nGround Truth (first 3): ['VFOV', 'tY87FSqe', 'WSDmEF2zhe']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [4, 8, 10]\nToken distribution (Batch 0): {1: 2, 47: 1, 32: 1}, Pred length: 4\nToken distribution (Batch 1): {32: 2}, Pred length: 2\nToken distribution (Batch 2): {1: 2}, Pred length: 2\nToken distribution (Batch 3): {1: 1}, Pred length: 1\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 2}, Pred length: 2\nToken distribution (Batch 6): {1: 3, 27: 1, 5: 1}, Pred length: 5\nToken distribution (Batch 7): {1: 3, 32: 1, 4: 1}, Pred length: 5\nToken distribution (Batch 8): {1: 2, 32: 1}, Pred length: 3\nToken distribution (Batch 9): {11: 1, 1: 2}, Pred length: 3\nToken distribution (Batch 10): {1: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 11): {1: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 12): {32: 1}, Pred length: 1\nToken distribution (Batch 13): {56: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {11: 2, 10: 1, 1: 2, 32: 1, 22: 1, 42: 1}, Pred length: 8\nToken distribution (Batch 16): {1: 7, 34: 1, 12: 1}, Pred length: 9\nToken distribution (Batch 17): {1: 1, 5: 1}, Pred length: 2\nToken distribution (Batch 18): {32: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 1, 10: 2, 34: 1}, Pred length: 4\nToken distribution (Batch 20): {1: 4, 27: 1}, Pred length: 5\nToken distribution (Batch 21): {1: 1}, Pred length: 1\nToken distribution (Batch 22): {11: 1, 1: 3, 34: 1}, Pred length: 5\nToken distribution (Batch 23): {5: 1}, Pred length: 1\nToken distribution (Batch 24): {47: 1, 1: 1}, Pred length: 2\nToken distribution (Batch 25): {32: 1}, Pred length: 1\nToken distribution (Batch 26): {1: 1, 4: 1}, Pred length: 2\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {1: 2, 12: 1, 19: 1}, Pred length: 4\nToken distribution (Batch 29): {1: 1}, Pred length: 1\nToken distribution (Batch 30): {1: 2, 47: 1, 34: 1, 56: 1}, Pred length: 5\nToken distribution (Batch 31): {1: 2, 19: 1}, Pred length: 3\nBatch 100, Gradient norm: 33.1389\nEpoch 14, Batch 100/128, Loss: 17.3948\nAvg Blank Probability: 0.0336\nSample predictions: ['aUaF', 'F', 'a']\nGround Truth (first 3): ['eLNFdw', 'rcgFxi1zWsc', 'NSMz7']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [6, 11, 5]\nToken distribution (Batch 0): {19: 1}, Pred length: 1\nToken distribution (Batch 1): {32: 1}, Pred length: 1\nToken distribution (Batch 2): {1: 4, 47: 1, 34: 1, 19: 1, 32: 1}, Pred length: 8\nToken distribution (Batch 3): {1: 2, 32: 1}, Pred length: 3\nToken distribution (Batch 4): {5: 1}, Pred length: 1\nToken distribution (Batch 5): {34: 1}, Pred length: 1\nToken distribution (Batch 6): {1: 1}, Pred length: 1\nToken distribution (Batch 7): {1: 1}, Pred length: 1\nToken distribution (Batch 8): {12: 1}, Pred length: 1\nToken distribution (Batch 9): {32: 1}, Pred length: 1\nToken distribution (Batch 10): {1: 2}, Pred length: 2\nToken distribution (Batch 11): {1: 4}, Pred length: 4\nToken distribution (Batch 12): {27: 1}, Pred length: 1\nToken distribution (Batch 13): {1: 1}, Pred length: 1\nToken distribution (Batch 14): {34: 1}, Pred length: 1\nToken distribution (Batch 15): {32: 1}, Pred length: 1\nToken distribution (Batch 16): {32: 1}, Pred length: 1\nToken distribution (Batch 17): {1: 1}, Pred length: 1\nToken distribution (Batch 18): {1: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 5, 11: 1, 32: 2, 34: 1, 10: 1}, Pred length: 10\nToken distribution (Batch 20): {34: 2, 1: 1}, Pred length: 3\nToken distribution (Batch 21): {34: 1, 4: 1}, Pred length: 2\nToken distribution (Batch 22): {1: 1}, Pred length: 1\nToken distribution (Batch 23): {11: 1, 1: 3, 34: 1, 27: 1}, Pred length: 6\nToken distribution (Batch 24): {34: 1}, Pred length: 1\nToken distribution (Batch 25): {1: 1, 10: 1}, Pred length: 2\nToken distribution (Batch 26): {10: 1, 1: 5, 4: 1}, Pred length: 7\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {34: 1}, Pred length: 1\nToken distribution (Batch 29): {1: 2, 27: 1}, Pred length: 3\nToken distribution (Batch 30): {34: 1, 5: 1}, Pred length: 2\nToken distribution (Batch 31): {1: 1, 34: 1}, Pred length: 2\nBatch 110, Gradient norm: 69.5112\nEpoch 14, Batch 110/128, Loss: 18.2501\nAvg Blank Probability: 0.0347\nSample predictions: ['s', 'F', 'aUaHasF']\nGround Truth (first 3): ['9TYJFy*c', 'k6H5', 'r6*Sjo*t3sP']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [8, 4, 11]\nToken distribution (Batch 0): {1: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 1): {32: 2}, Pred length: 2\nToken distribution (Batch 2): {32: 1}, Pred length: 1\nToken distribution (Batch 3): {34: 1}, Pred length: 1\nToken distribution (Batch 4): {34: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {34: 1}, Pred length: 1\nToken distribution (Batch 7): {11: 1}, Pred length: 1\nToken distribution (Batch 8): {34: 2, 1: 4}, Pred length: 6\nToken distribution (Batch 9): {1: 4, 4: 1, 19: 1}, Pred length: 6\nToken distribution (Batch 10): {12: 1, 5: 1}, Pred length: 2\nToken distribution (Batch 11): {11: 1}, Pred length: 1\nToken distribution (Batch 12): {1: 1}, Pred length: 1\nToken distribution (Batch 13): {1: 1}, Pred length: 1\nToken distribution (Batch 14): {56: 1}, Pred length: 1\nToken distribution (Batch 15): {1: 1}, Pred length: 1\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {34: 1}, Pred length: 1\nToken distribution (Batch 18): {11: 1, 1: 1, 34: 1}, Pred length: 3\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {1: 1}, Pred length: 1\nToken distribution (Batch 21): {1: 1, 19: 1}, Pred length: 2\nToken distribution (Batch 22): {1: 1}, Pred length: 1\nToken distribution (Batch 23): {32: 1}, Pred length: 1\nToken distribution (Batch 24): {34: 1, 27: 1}, Pred length: 2\nToken distribution (Batch 25): {12: 1, 32: 1, 1: 2}, Pred length: 4\nToken distribution (Batch 26): {11: 2, 1: 4, 32: 1, 34: 1}, Pred length: 8\nToken distribution (Batch 27): {32: 1}, Pred length: 1\nToken distribution (Batch 28): {47: 1, 1: 2, 34: 1}, Pred length: 4\nToken distribution (Batch 29): {1: 2, 34: 1}, Pred length: 3\nToken distribution (Batch 30): {5: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 2}, Pred length: 2\nBatch 120, Gradient norm: 26.5276\nEpoch 14, Batch 120/128, Loss: 18.2118\nAvg Blank Probability: 0.0355\nSample predictions: ['aF', 'F', 'F']\nGround Truth (first 3): ['ZTrx', '6ppVZGzezRiM', 'ugMEoCD']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [4, 12, 7]\nEpoch 14/20, Loss: 17.9211\nToken distribution (Batch 0): {1: 10}, Pred length: 10\nToken distribution (Batch 1): {1: 8}, Pred length: 8\nToken distribution (Batch 2): {1: 24}, Pred length: 24\nToken distribution (Batch 3): {1: 18}, Pred length: 18\nToken distribution (Batch 4): {1: 20}, Pred length: 20\nToken distribution (Batch 5): {1: 24}, Pred length: 24\nToken distribution (Batch 6): {1: 18}, Pred length: 18\nToken distribution (Batch 7): {1: 14}, Pred length: 14\nToken distribution (Batch 8): {1: 14}, Pred length: 14\nToken distribution (Batch 9): {1: 20}, Pred length: 20\nToken distribution (Batch 10): {1: 12}, Pred length: 12\nToken distribution (Batch 11): {1: 18}, Pred length: 18\nToken distribution (Batch 12): {1: 16}, Pred length: 16\nToken distribution (Batch 13): {1: 12}, Pred length: 12\nToken distribution (Batch 14): {1: 16}, Pred length: 16\nToken distribution (Batch 15): {1: 20}, Pred length: 20\nToken distribution (Batch 16): {1: 14}, Pred length: 14\nToken distribution (Batch 17): {1: 12}, Pred length: 12\nToken distribution (Batch 18): {1: 16}, Pred length: 16\nToken distribution (Batch 19): {1: 10}, Pred length: 10\nToken distribution (Batch 20): {1: 12}, Pred length: 12\nToken distribution (Batch 21): {1: 12}, Pred length: 12\nToken distribution (Batch 22): {1: 14}, Pred length: 14\nToken distribution (Batch 23): {1: 8}, Pred length: 8\nToken distribution (Batch 24): {1: 22}, Pred length: 22\nToken distribution (Batch 25): {1: 22}, Pred length: 22\nToken distribution (Batch 26): {1: 14}, Pred length: 14\nToken distribution (Batch 27): {1: 18}, Pred length: 18\nToken distribution (Batch 28): {1: 22}, Pred length: 22\nToken distribution (Batch 29): {1: 16}, Pred length: 16\nToken distribution (Batch 30): {1: 22}, Pred length: 22\nToken distribution (Batch 31): {1: 16}, Pred length: 16\nValidation Loss: 19.2772\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['DIah1', 'G5MV', 'rcBPH7qCznLg', 'fjINLLF24', 'haRXwvgP8D']\nCurrent Learning Rate: 7.795671678555625e-07\nEpoch 15, Filtered data size: 5120, Sample labels: ['qV8ib8H', 'MdI8', '1XS0DRdJ']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 0): {34: 2}, Pred length: 2\nToken distribution (Batch 1): {32: 2}, Pred length: 2\nToken distribution (Batch 2): {1: 1}, Pred length: 1\nToken distribution (Batch 3): {4: 1}, Pred length: 1\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {1: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 7): {42: 1}, Pred length: 1\nToken distribution (Batch 8): {19: 1}, Pred length: 1\nToken distribution (Batch 9): {19: 1}, Pred length: 1\nToken distribution (Batch 10): {1: 1}, Pred length: 1\nToken distribution (Batch 11): {1: 1}, Pred length: 1\nToken distribution (Batch 12): {1: 1}, Pred length: 1\nToken distribution (Batch 13): {32: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {47: 1, 1: 1, 34: 1}, Pred length: 3\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {1: 2}, Pred length: 2\nToken distribution (Batch 18): {34: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {5: 1}, Pred length: 1\nToken distribution (Batch 21): {5: 1}, Pred length: 1\nToken distribution (Batch 22): {1: 1}, Pred length: 1\nToken distribution (Batch 23): {1: 2, 32: 2}, Pred length: 4\nToken distribution (Batch 24): {1: 1}, Pred length: 1\nToken distribution (Batch 25): {1: 7}, Pred length: 7\nToken distribution (Batch 26): {32: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 28): {1: 1}, Pred length: 1\nToken distribution (Batch 29): {32: 1}, Pred length: 1\nToken distribution (Batch 30): {34: 1, 1: 1}, Pred length: 2\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nBatch 0, Gradient norm: 25.0513\nEpoch 15, Batch 0/128, Loss: 16.8986\nAvg Blank Probability: 0.0357\nSample predictions: ['H', 'F', 'a']\nGround Truth (first 3): ['bNh*8', 'ewhc7uXG-', 'k3SZ0FiF']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [5, 9, 8]\nToken distribution (Batch 0): {34: 1}, Pred length: 1\nToken distribution (Batch 1): {1: 1}, Pred length: 1\nToken distribution (Batch 2): {1: 1}, Pred length: 1\nToken distribution (Batch 3): {56: 1}, Pred length: 1\nToken distribution (Batch 4): {27: 1}, Pred length: 1\nToken distribution (Batch 5): {32: 1}, Pred length: 1\nToken distribution (Batch 6): {42: 1}, Pred length: 1\nToken distribution (Batch 7): {1: 1}, Pred length: 1\nToken distribution (Batch 8): {1: 1}, Pred length: 1\nToken distribution (Batch 9): {4: 1}, Pred length: 1\nToken distribution (Batch 10): {32: 1}, Pred length: 1\nToken distribution (Batch 11): {1: 1}, Pred length: 1\nToken distribution (Batch 12): {1: 1}, Pred length: 1\nToken distribution (Batch 13): {32: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {27: 1}, Pred length: 1\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {1: 1}, Pred length: 1\nToken distribution (Batch 18): {1: 1}, Pred length: 1\nToken distribution (Batch 19): {4: 1}, Pred length: 1\nToken distribution (Batch 20): {50: 1}, Pred length: 1\nToken distribution (Batch 21): {34: 1}, Pred length: 1\nToken distribution (Batch 22): {34: 2, 10: 1}, Pred length: 3\nToken distribution (Batch 23): {1: 1}, Pred length: 1\nToken distribution (Batch 24): {1: 1}, Pred length: 1\nToken distribution (Batch 25): {32: 1}, Pred length: 1\nToken distribution (Batch 26): {32: 1}, Pred length: 1\nToken distribution (Batch 27): {34: 1, 1: 1}, Pred length: 2\nToken distribution (Batch 28): {1: 1}, Pred length: 1\nToken distribution (Batch 29): {1: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 30): {32: 1}, Pred length: 1\nToken distribution (Batch 31): {32: 1}, Pred length: 1\nBatch 10, Gradient norm: 26.5815\nEpoch 15, Batch 10/128, Loss: 17.4423\nAvg Blank Probability: 0.0364\nSample predictions: ['H', 'a', 'a']\nGround Truth (first 3): ['U*i6EUJKfE-A', '9Hk10', 'WOIUwIC8COU']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [12, 5, 11]\nToken distribution (Batch 0): {1: 2, 34: 1}, Pred length: 3\nToken distribution (Batch 1): {1: 2}, Pred length: 2\nToken distribution (Batch 2): {32: 1}, Pred length: 1\nToken distribution (Batch 3): {1: 1}, Pred length: 1\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {1: 1}, Pred length: 1\nToken distribution (Batch 7): {32: 1}, Pred length: 1\nToken distribution (Batch 8): {19: 1, 1: 2}, Pred length: 3\nToken distribution (Batch 9): {32: 1}, Pred length: 1\nToken distribution (Batch 10): {34: 1}, Pred length: 1\nToken distribution (Batch 11): {19: 1}, Pred length: 1\nToken distribution (Batch 12): {4: 1}, Pred length: 1\nToken distribution (Batch 13): {1: 1}, Pred length: 1\nToken distribution (Batch 14): {32: 1}, Pred length: 1\nToken distribution (Batch 15): {1: 1}, Pred length: 1\nToken distribution (Batch 16): {27: 1}, Pred length: 1\nToken distribution (Batch 17): {1: 1}, Pred length: 1\nToken distribution (Batch 18): {27: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {32: 1}, Pred length: 1\nToken distribution (Batch 21): {34: 1}, Pred length: 1\nToken distribution (Batch 22): {4: 1}, Pred length: 1\nToken distribution (Batch 23): {1: 1}, Pred length: 1\nToken distribution (Batch 24): {1: 2, 34: 1}, Pred length: 3\nToken distribution (Batch 25): {24: 1}, Pred length: 1\nToken distribution (Batch 26): {1: 1}, Pred length: 1\nToken distribution (Batch 27): {27: 1}, Pred length: 1\nToken distribution (Batch 28): {34: 1}, Pred length: 1\nToken distribution (Batch 29): {1: 1}, Pred length: 1\nToken distribution (Batch 30): {1: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nBatch 20, Gradient norm: 40.9230\nEpoch 15, Batch 20/128, Loss: 18.0684\nAvg Blank Probability: 0.0385\nSample predictions: ['aHa', 'a', 'F']\nGround Truth (first 3): ['rbp9', '*v3oyiyPuIs', 'pxSdAdgOB8KC']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [4, 11, 12]\nToken distribution (Batch 0): {1: 1}, Pred length: 1\nToken distribution (Batch 1): {5: 1}, Pred length: 1\nToken distribution (Batch 2): {10: 1}, Pred length: 1\nToken distribution (Batch 3): {1: 1}, Pred length: 1\nToken distribution (Batch 4): {4: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {34: 1}, Pred length: 1\nToken distribution (Batch 7): {1: 1}, Pred length: 1\nToken distribution (Batch 8): {34: 1}, Pred length: 1\nToken distribution (Batch 9): {1: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 10): {34: 1, 42: 1}, Pred length: 2\nToken distribution (Batch 11): {4: 1}, Pred length: 1\nToken distribution (Batch 12): {1: 1}, Pred length: 1\nToken distribution (Batch 13): {4: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {32: 1}, Pred length: 1\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {43: 1}, Pred length: 1\nToken distribution (Batch 18): {32: 1}, Pred length: 1\nToken distribution (Batch 19): {34: 1}, Pred length: 1\nToken distribution (Batch 20): {5: 1}, Pred length: 1\nToken distribution (Batch 21): {1: 1}, Pred length: 1\nToken distribution (Batch 22): {1: 1}, Pred length: 1\nToken distribution (Batch 23): {1: 1}, Pred length: 1\nToken distribution (Batch 24): {19: 1}, Pred length: 1\nToken distribution (Batch 25): {34: 1}, Pred length: 1\nToken distribution (Batch 26): {5: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {1: 1}, Pred length: 1\nToken distribution (Batch 29): {1: 1}, Pred length: 1\nToken distribution (Batch 30): {1: 1}, Pred length: 1\nToken distribution (Batch 31): {32: 1}, Pred length: 1\nBatch 30, Gradient norm: 25.7227\nEpoch 15, Batch 30/128, Loss: 17.4326\nAvg Blank Probability: 0.0384\nSample predictions: ['a', 'e', 'j']\nGround Truth (first 3): ['GPkRoT', 'AqOT', 'z0feajRm']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [6, 4, 8]\nToken distribution (Batch 0): {32: 1}, Pred length: 1\nToken distribution (Batch 1): {1: 1}, Pred length: 1\nToken distribution (Batch 2): {1: 2, 32: 1}, Pred length: 3\nToken distribution (Batch 3): {1: 1}, Pred length: 1\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {27: 1}, Pred length: 1\nToken distribution (Batch 7): {56: 1}, Pred length: 1\nToken distribution (Batch 8): {34: 1}, Pred length: 1\nToken distribution (Batch 9): {1: 1}, Pred length: 1\nToken distribution (Batch 10): {1: 1}, Pred length: 1\nToken distribution (Batch 11): {19: 1}, Pred length: 1\nToken distribution (Batch 12): {34: 1}, Pred length: 1\nToken distribution (Batch 13): {1: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 14): {57: 1}, Pred length: 1\nToken distribution (Batch 15): {1: 1}, Pred length: 1\nToken distribution (Batch 16): {34: 1}, Pred length: 1\nToken distribution (Batch 17): {1: 1}, Pred length: 1\nToken distribution (Batch 18): {32: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {1: 1}, Pred length: 1\nToken distribution (Batch 21): {1: 1}, Pred length: 1\nToken distribution (Batch 22): {47: 1}, Pred length: 1\nToken distribution (Batch 23): {32: 1}, Pred length: 1\nToken distribution (Batch 24): {32: 1}, Pred length: 1\nToken distribution (Batch 25): {1: 1, 32: 1}, Pred length: 2\nToken distribution (Batch 26): {1: 1}, Pred length: 1\nToken distribution (Batch 27): {32: 1}, Pred length: 1\nToken distribution (Batch 28): {1: 1}, Pred length: 1\nToken distribution (Batch 29): {1: 1}, Pred length: 1\nToken distribution (Batch 30): {34: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nBatch 40, Gradient norm: 54.3521\nEpoch 15, Batch 40/128, Loss: 17.0612\nAvg Blank Probability: 0.0395\nSample predictions: ['F', 'a', 'aFa']\nGround Truth (first 3): ['jM7yLOFi', 'arWEOjNits', 'vJZY3V5CZk99']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [8, 10, 12]\nToken distribution (Batch 0): {1: 1}, Pred length: 1\nToken distribution (Batch 1): {11: 1}, Pred length: 1\nToken distribution (Batch 2): {1: 1}, Pred length: 1\nToken distribution (Batch 3): {32: 1}, Pred length: 1\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {32: 1}, Pred length: 1\nToken distribution (Batch 6): {34: 1}, Pred length: 1\nToken distribution (Batch 7): {34: 1}, Pred length: 1\nToken distribution (Batch 8): {27: 1}, Pred length: 1\nToken distribution (Batch 9): {1: 1}, Pred length: 1\nToken distribution (Batch 10): {32: 1}, Pred length: 1\nToken distribution (Batch 11): {27: 1}, Pred length: 1\nToken distribution (Batch 12): {5: 1}, Pred length: 1\nToken distribution (Batch 13): {1: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {5: 1}, Pred length: 1\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {34: 1}, Pred length: 1\nToken distribution (Batch 18): {19: 1}, Pred length: 1\nToken distribution (Batch 19): {32: 1}, Pred length: 1\nToken distribution (Batch 20): {32: 1}, Pred length: 1\nToken distribution (Batch 21): {5: 1}, Pred length: 1\nToken distribution (Batch 22): {32: 1}, Pred length: 1\nToken distribution (Batch 23): {11: 1}, Pred length: 1\nToken distribution (Batch 24): {1: 1}, Pred length: 1\nToken distribution (Batch 25): {1: 1}, Pred length: 1\nToken distribution (Batch 26): {1: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {19: 1}, Pred length: 1\nToken distribution (Batch 29): {1: 1}, Pred length: 1\nToken distribution (Batch 30): {34: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nBatch 50, Gradient norm: 21.6319\nEpoch 15, Batch 50/128, Loss: 16.0498\nAvg Blank Probability: 0.0403\nSample predictions: ['a', 'k', 'a']\nGround Truth (first 3): ['ttf5Nvzi3J', 'hk-EXvz0aSiv', 'uHgXGZqfj']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [10, 12, 9]\nToken distribution (Batch 0): {34: 1}, Pred length: 1\nToken distribution (Batch 1): {5: 1}, Pred length: 1\nToken distribution (Batch 2): {32: 1}, Pred length: 1\nToken distribution (Batch 3): {1: 1}, Pred length: 1\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {27: 1}, Pred length: 1\nToken distribution (Batch 6): {1: 1}, Pred length: 1\nToken distribution (Batch 7): {1: 1}, Pred length: 1\nToken distribution (Batch 8): {1: 1}, Pred length: 1\nToken distribution (Batch 9): {27: 1}, Pred length: 1\nToken distribution (Batch 10): {27: 1}, Pred length: 1\nToken distribution (Batch 11): {5: 1}, Pred length: 1\nToken distribution (Batch 12): {1: 1}, Pred length: 1\nToken distribution (Batch 13): {32: 1}, Pred length: 1\nToken distribution (Batch 14): {34: 1}, Pred length: 1\nToken distribution (Batch 15): {32: 1}, Pred length: 1\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {19: 1}, Pred length: 1\nToken distribution (Batch 18): {10: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {34: 1}, Pred length: 1\nToken distribution (Batch 21): {1: 1}, Pred length: 1\nToken distribution (Batch 22): {1: 1}, Pred length: 1\nToken distribution (Batch 23): {56: 1}, Pred length: 1\nToken distribution (Batch 24): {1: 1}, Pred length: 1\nToken distribution (Batch 25): {1: 1}, Pred length: 1\nToken distribution (Batch 26): {27: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {34: 1}, Pred length: 1\nToken distribution (Batch 29): {1: 1}, Pred length: 1\nToken distribution (Batch 30): {10: 1}, Pred length: 1\nToken distribution (Batch 31): {22: 1}, Pred length: 1\nBatch 60, Gradient norm: 27.0443\nEpoch 15, Batch 60/128, Loss: 17.4995\nAvg Blank Probability: 0.0423\nSample predictions: ['H', 'e', 'F']\nGround Truth (first 3): ['b005xtkbSvt', '7fr1jAmXu13', 'AlbhfS']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [11, 11, 6]\nToken distribution (Batch 0): {1: 1}, Pred length: 1\nToken distribution (Batch 1): {4: 1}, Pred length: 1\nToken distribution (Batch 2): {4: 1}, Pred length: 1\nToken distribution (Batch 3): {32: 1}, Pred length: 1\nToken distribution (Batch 4): {32: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {34: 1}, Pred length: 1\nToken distribution (Batch 7): {1: 1}, Pred length: 1\nToken distribution (Batch 8): {34: 1}, Pred length: 1\nToken distribution (Batch 9): {1: 1}, Pred length: 1\nToken distribution (Batch 10): {1: 1}, Pred length: 1\nToken distribution (Batch 11): {34: 1}, Pred length: 1\nToken distribution (Batch 12): {1: 1}, Pred length: 1\nToken distribution (Batch 13): {42: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {5: 1}, Pred length: 1\nToken distribution (Batch 16): {27: 1}, Pred length: 1\nToken distribution (Batch 17): {1: 1}, Pred length: 1\nToken distribution (Batch 18): {34: 1}, Pred length: 1\nToken distribution (Batch 19): {19: 1}, Pred length: 1\nToken distribution (Batch 20): {34: 1}, Pred length: 1\nToken distribution (Batch 21): {5: 1}, Pred length: 1\nToken distribution (Batch 22): {27: 1}, Pred length: 1\nToken distribution (Batch 23): {1: 1}, Pred length: 1\nToken distribution (Batch 24): {19: 1}, Pred length: 1\nToken distribution (Batch 25): {5: 1}, Pred length: 1\nToken distribution (Batch 26): {5: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {10: 1}, Pred length: 1\nToken distribution (Batch 29): {34: 1}, Pred length: 1\nToken distribution (Batch 30): {1: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nBatch 70, Gradient norm: 838.8120\nEpoch 15, Batch 70/128, Loss: 17.1833\nAvg Blank Probability: 0.0425\nSample predictions: ['a', 'd', 'd']\nGround Truth (first 3): ['K9QEp', 'qIHniobN', 'u26fBT']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [5, 8, 6]\nToken distribution (Batch 0): {4: 1}, Pred length: 1\nToken distribution (Batch 1): {32: 1}, Pred length: 1\nToken distribution (Batch 2): {1: 1}, Pred length: 1\nToken distribution (Batch 3): {1: 1}, Pred length: 1\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {32: 1}, Pred length: 1\nToken distribution (Batch 6): {34: 1}, Pred length: 1\nToken distribution (Batch 7): {1: 1}, Pred length: 1\nToken distribution (Batch 8): {34: 1}, Pred length: 1\nToken distribution (Batch 9): {34: 1}, Pred length: 1\nToken distribution (Batch 10): {5: 1}, Pred length: 1\nToken distribution (Batch 11): {32: 1}, Pred length: 1\nToken distribution (Batch 12): {32: 1}, Pred length: 1\nToken distribution (Batch 13): {56: 1}, Pred length: 1\nToken distribution (Batch 14): {19: 1}, Pred length: 1\nToken distribution (Batch 15): {1: 1}, Pred length: 1\nToken distribution (Batch 16): {19: 1}, Pred length: 1\nToken distribution (Batch 17): {4: 1}, Pred length: 1\nToken distribution (Batch 18): {1: 1}, Pred length: 1\nToken distribution (Batch 19): {5: 1}, Pred length: 1\nToken distribution (Batch 20): {1: 1}, Pred length: 1\nToken distribution (Batch 21): {11: 1}, Pred length: 1\nToken distribution (Batch 22): {34: 1}, Pred length: 1\nToken distribution (Batch 23): {34: 1}, Pred length: 1\nToken distribution (Batch 24): {32: 1}, Pred length: 1\nToken distribution (Batch 25): {1: 1}, Pred length: 1\nToken distribution (Batch 26): {1: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {19: 1}, Pred length: 1\nToken distribution (Batch 29): {5: 1}, Pred length: 1\nToken distribution (Batch 30): {32: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nBatch 80, Gradient norm: 30.1257\nEpoch 15, Batch 80/128, Loss: 17.7155\nAvg Blank Probability: 0.0436\nSample predictions: ['d', 'F', 'a']\nGround Truth (first 3): ['ohcDC5I', 'B6VgRc', 'qVcym']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [7, 6, 5]\nToken distribution (Batch 0): {1: 1}, Pred length: 1\nToken distribution (Batch 1): {11: 1}, Pred length: 1\nToken distribution (Batch 2): {32: 1}, Pred length: 1\nToken distribution (Batch 3): {56: 1}, Pred length: 1\nToken distribution (Batch 4): {5: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {42: 1}, Pred length: 1\nToken distribution (Batch 7): {19: 1}, Pred length: 1\nToken distribution (Batch 8): {32: 1}, Pred length: 1\nToken distribution (Batch 9): {19: 1}, Pred length: 1\nToken distribution (Batch 10): {27: 1}, Pred length: 1\nToken distribution (Batch 11): {1: 1}, Pred length: 1\nToken distribution (Batch 12): {1: 1}, Pred length: 1\nToken distribution (Batch 13): {4: 1}, Pred length: 1\nToken distribution (Batch 14): {32: 1}, Pred length: 1\nToken distribution (Batch 15): {1: 1}, Pred length: 1\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {1: 1}, Pred length: 1\nToken distribution (Batch 18): {1: 1}, Pred length: 1\nToken distribution (Batch 19): {32: 1}, Pred length: 1\nToken distribution (Batch 20): {27: 1}, Pred length: 1\nToken distribution (Batch 21): {11: 1}, Pred length: 1\nToken distribution (Batch 22): {19: 1}, Pred length: 1\nToken distribution (Batch 23): {32: 1}, Pred length: 1\nToken distribution (Batch 24): {1: 1}, Pred length: 1\nToken distribution (Batch 25): {19: 1}, Pred length: 1\nToken distribution (Batch 26): {32: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {34: 1}, Pred length: 1\nToken distribution (Batch 29): {32: 1}, Pred length: 1\nToken distribution (Batch 30): {1: 1}, Pred length: 1\nToken distribution (Batch 31): {19: 1}, Pred length: 1\nBatch 90, Gradient norm: 155.8137\nEpoch 15, Batch 90/128, Loss: 16.3054\nAvg Blank Probability: 0.0447\nSample predictions: ['a', 'k', 'F']\nGround Truth (first 3): ['6gq0wV', 'NMpWUcGpZs', '5vI9kN1z0yQ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [6, 10, 11]\nToken distribution (Batch 0): {1: 1}, Pred length: 1\nToken distribution (Batch 1): {1: 1}, Pred length: 1\nToken distribution (Batch 2): {34: 1}, Pred length: 1\nToken distribution (Batch 3): {32: 1}, Pred length: 1\nToken distribution (Batch 4): {11: 1}, Pred length: 1\nToken distribution (Batch 5): {32: 1}, Pred length: 1\nToken distribution (Batch 6): {1: 1}, Pred length: 1\nToken distribution (Batch 7): {32: 1}, Pred length: 1\nToken distribution (Batch 8): {1: 1}, Pred length: 1\nToken distribution (Batch 9): {11: 1}, Pred length: 1\nToken distribution (Batch 10): {1: 1}, Pred length: 1\nToken distribution (Batch 11): {34: 1}, Pred length: 1\nToken distribution (Batch 12): {1: 1}, Pred length: 1\nToken distribution (Batch 13): {5: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {34: 1}, Pred length: 1\nToken distribution (Batch 16): {34: 1}, Pred length: 1\nToken distribution (Batch 17): {19: 1}, Pred length: 1\nToken distribution (Batch 18): {19: 1}, Pred length: 1\nToken distribution (Batch 19): {5: 1}, Pred length: 1\nToken distribution (Batch 20): {32: 1}, Pred length: 1\nToken distribution (Batch 21): {1: 1}, Pred length: 1\nToken distribution (Batch 22): {1: 1}, Pred length: 1\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {34: 1}, Pred length: 1\nToken distribution (Batch 25): {1: 1}, Pred length: 1\nToken distribution (Batch 26): {27: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {4: 1}, Pred length: 1\nToken distribution (Batch 29): {4: 1}, Pred length: 1\nToken distribution (Batch 30): {1: 1}, Pred length: 1\nToken distribution (Batch 31): {11: 1}, Pred length: 1\nBatch 100, Gradient norm: 39.9530\nEpoch 15, Batch 100/128, Loss: 17.2808\nAvg Blank Probability: 0.0459\nSample predictions: ['a', 'a', 'H']\nGround Truth (first 3): ['2skSR', 'eyDiZ', 'VLzPb2XElCL']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [5, 5, 11]\nToken distribution (Batch 0): {1: 1}, Pred length: 1\nToken distribution (Batch 1): {1: 1}, Pred length: 1\nToken distribution (Batch 2): {1: 1}, Pred length: 1\nToken distribution (Batch 3): {1: 1}, Pred length: 1\nToken distribution (Batch 4): {11: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {5: 1}, Pred length: 1\nToken distribution (Batch 7): {34: 1}, Pred length: 1\nToken distribution (Batch 8): {34: 1}, Pred length: 1\nToken distribution (Batch 9): {1: 1}, Pred length: 1\nToken distribution (Batch 10): {1: 1}, Pred length: 1\nToken distribution (Batch 11): {34: 1}, Pred length: 1\nToken distribution (Batch 12): {1: 1}, Pred length: 1\nToken distribution (Batch 13): {1: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {1: 1}, Pred length: 1\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {32: 1}, Pred length: 1\nToken distribution (Batch 18): {32: 1}, Pred length: 1\nToken distribution (Batch 19): {32: 1}, Pred length: 1\nToken distribution (Batch 20): {27: 1}, Pred length: 1\nToken distribution (Batch 21): {1: 1}, Pred length: 1\nToken distribution (Batch 22): {1: 1}, Pred length: 1\nToken distribution (Batch 23): {1: 1}, Pred length: 1\nToken distribution (Batch 24): {27: 1}, Pred length: 1\nToken distribution (Batch 25): {32: 1}, Pred length: 1\nToken distribution (Batch 26): {1: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {32: 1}, Pred length: 1\nToken distribution (Batch 29): {11: 1}, Pred length: 1\nToken distribution (Batch 30): {11: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nBatch 110, Gradient norm: 47.1394\nEpoch 15, Batch 110/128, Loss: 16.6506\nAvg Blank Probability: 0.0476\nSample predictions: ['a', 'a', 'a']\nGround Truth (first 3): ['k6ei-KyTq0', 'hqSnrQVG7a8', '0XOs6EMw2u']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [10, 11, 10]\nToken distribution (Batch 0): {1: 1}, Pred length: 1\nToken distribution (Batch 1): {1: 1}, Pred length: 1\nToken distribution (Batch 2): {1: 1}, Pred length: 1\nToken distribution (Batch 3): {4: 1}, Pred length: 1\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {1: 1}, Pred length: 1\nToken distribution (Batch 7): {4: 1}, Pred length: 1\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {1: 1}, Pred length: 1\nToken distribution (Batch 10): {1: 1}, Pred length: 1\nToken distribution (Batch 11): {34: 1}, Pred length: 1\nToken distribution (Batch 12): {1: 1}, Pred length: 1\nToken distribution (Batch 13): {34: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {19: 1}, Pred length: 1\nToken distribution (Batch 17): {32: 1}, Pred length: 1\nToken distribution (Batch 18): {1: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {1: 1}, Pred length: 1\nToken distribution (Batch 22): {1: 1}, Pred length: 1\nToken distribution (Batch 23): {32: 1}, Pred length: 1\nToken distribution (Batch 24): {5: 1}, Pred length: 1\nToken distribution (Batch 25): {34: 1}, Pred length: 1\nToken distribution (Batch 26): {27: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {32: 1}, Pred length: 1\nToken distribution (Batch 29): {11: 1}, Pred length: 1\nToken distribution (Batch 30): {11: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nBatch 120, Gradient norm: 41.7707\nEpoch 15, Batch 120/128, Loss: 17.5718\nAvg Blank Probability: 0.0500\nSample predictions: ['a', 'a', 'a']\nGround Truth (first 3): ['85Ed', 'fpAq*7gK8Q', '*7VBcTBDcd']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [4, 10, 10]\nEpoch 15/20, Loss: 17.1175\nToken distribution (Batch 0): {1: 8}, Pred length: 8\nToken distribution (Batch 1): {1: 18}, Pred length: 18\nToken distribution (Batch 2): {1: 16}, Pred length: 16\nToken distribution (Batch 3): {1: 8}, Pred length: 8\nToken distribution (Batch 4): {1: 24}, Pred length: 24\nToken distribution (Batch 5): {1: 10}, Pred length: 10\nToken distribution (Batch 6): {1: 10}, Pred length: 10\nToken distribution (Batch 7): {1: 18}, Pred length: 18\nToken distribution (Batch 8): {1: 18}, Pred length: 18\nToken distribution (Batch 9): {1: 10}, Pred length: 10\nToken distribution (Batch 10): {1: 10}, Pred length: 10\nToken distribution (Batch 11): {1: 24}, Pred length: 24\nToken distribution (Batch 12): {1: 22}, Pred length: 22\nToken distribution (Batch 13): {1: 20}, Pred length: 20\nToken distribution (Batch 14): {1: 22}, Pred length: 22\nToken distribution (Batch 15): {1: 24}, Pred length: 24\nToken distribution (Batch 16): {1: 16}, Pred length: 16\nToken distribution (Batch 17): {1: 20}, Pred length: 20\nToken distribution (Batch 18): {1: 20}, Pred length: 20\nToken distribution (Batch 19): {1: 20}, Pred length: 20\nToken distribution (Batch 20): {1: 20}, Pred length: 20\nToken distribution (Batch 21): {1: 18}, Pred length: 18\nToken distribution (Batch 22): {1: 22}, Pred length: 22\nToken distribution (Batch 23): {1: 16}, Pred length: 16\nToken distribution (Batch 24): {1: 18}, Pred length: 18\nToken distribution (Batch 25): {1: 18}, Pred length: 18\nToken distribution (Batch 26): {1: 8}, Pred length: 8\nToken distribution (Batch 27): {1: 22}, Pred length: 22\nToken distribution (Batch 28): {1: 24}, Pred length: 24\nToken distribution (Batch 29): {1: 12}, Pred length: 12\nToken distribution (Batch 30): {1: 14}, Pred length: 14\nToken distribution (Batch 31): {1: 14}, Pred length: 14\nValidation Loss: 18.6832\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['rOBm', '169eLzbx-', 'a5sbUNJv', 'NY0Z', '2eZLLIaPlJzs']\nCurrent Learning Rate: 8.433746436826698e-07\nEpoch 16, Filtered data size: 5120, Sample labels: ['qV8ib8H', 'MdI8', '1XS0DRdJ']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 0): {1: 1}, Pred length: 1\nToken distribution (Batch 1): {19: 1}, Pred length: 1\nToken distribution (Batch 2): {19: 1}, Pred length: 1\nToken distribution (Batch 3): {1: 1}, Pred length: 1\nToken distribution (Batch 4): {19: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {1: 1}, Pred length: 1\nToken distribution (Batch 7): {32: 1}, Pred length: 1\nToken distribution (Batch 8): {34: 1}, Pred length: 1\nToken distribution (Batch 9): {32: 1}, Pred length: 1\nToken distribution (Batch 10): {34: 1}, Pred length: 1\nToken distribution (Batch 11): {1: 1}, Pred length: 1\nToken distribution (Batch 12): {32: 1}, Pred length: 1\nToken distribution (Batch 13): {1: 1}, Pred length: 1\nToken distribution (Batch 14): {5: 1}, Pred length: 1\nToken distribution (Batch 15): {34: 1}, Pred length: 1\nToken distribution (Batch 16): {34: 1}, Pred length: 1\nToken distribution (Batch 17): {1: 1}, Pred length: 1\nToken distribution (Batch 18): {4: 1}, Pred length: 1\nToken distribution (Batch 19): {32: 1}, Pred length: 1\nToken distribution (Batch 20): {32: 1}, Pred length: 1\nToken distribution (Batch 21): {19: 1}, Pred length: 1\nToken distribution (Batch 22): {32: 1}, Pred length: 1\nToken distribution (Batch 23): {19: 1}, Pred length: 1\nToken distribution (Batch 24): {1: 1}, Pred length: 1\nToken distribution (Batch 25): {1: 1}, Pred length: 1\nToken distribution (Batch 26): {34: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {32: 1}, Pred length: 1\nToken distribution (Batch 29): {1: 1}, Pred length: 1\nToken distribution (Batch 30): {32: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nBatch 0, Gradient norm: 46.6763\nEpoch 16, Batch 0/128, Loss: 16.0278\nAvg Blank Probability: 0.0505\nSample predictions: ['a', 's', 's']\nGround Truth (first 3): ['YZ2QxLPL', 'S3VkLRXF7', 'IMA3uDta']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [8, 9, 8]\nToken distribution (Batch 0): {5: 1}, Pred length: 1\nToken distribution (Batch 1): {4: 1}, Pred length: 1\nToken distribution (Batch 2): {4: 1}, Pred length: 1\nToken distribution (Batch 3): {19: 1}, Pred length: 1\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {34: 1}, Pred length: 1\nToken distribution (Batch 6): {1: 1}, Pred length: 1\nToken distribution (Batch 7): {32: 1}, Pred length: 1\nToken distribution (Batch 8): {4: 1}, Pred length: 1\nToken distribution (Batch 9): {34: 1}, Pred length: 1\nToken distribution (Batch 10): {1: 1}, Pred length: 1\nToken distribution (Batch 11): {1: 1}, Pred length: 1\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {34: 1}, Pred length: 1\nToken distribution (Batch 16): {5: 1}, Pred length: 1\nToken distribution (Batch 17): {19: 1}, Pred length: 1\nToken distribution (Batch 18): {27: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {1: 1}, Pred length: 1\nToken distribution (Batch 21): {1: 1}, Pred length: 1\nToken distribution (Batch 22): {32: 1}, Pred length: 1\nToken distribution (Batch 23): {32: 1}, Pred length: 1\nToken distribution (Batch 24): {34: 1}, Pred length: 1\nToken distribution (Batch 25): {5: 1}, Pred length: 1\nToken distribution (Batch 26): {5: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {1: 1}, Pred length: 1\nToken distribution (Batch 29): {19: 1}, Pred length: 1\nToken distribution (Batch 30): {1: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nBatch 10, Gradient norm: 39.5559\nEpoch 16, Batch 10/128, Loss: 17.8383\nAvg Blank Probability: 0.0522\nSample predictions: ['e', 'd', 'd']\nGround Truth (first 3): ['wlzLGs', '6*h1', 'YvQW4oNlVC']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [6, 4, 10]\nToken distribution (Batch 0): {19: 1}, Pred length: 1\nToken distribution (Batch 1): {34: 1}, Pred length: 1\nToken distribution (Batch 2): {4: 1}, Pred length: 1\nToken distribution (Batch 3): {34: 1}, Pred length: 1\nToken distribution (Batch 4): {34: 1}, Pred length: 1\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {11: 1}, Pred length: 1\nToken distribution (Batch 7): {5: 1}, Pred length: 1\nToken distribution (Batch 8): {1: 1}, Pred length: 1\nToken distribution (Batch 9): {34: 1}, Pred length: 1\nToken distribution (Batch 10): {27: 1}, Pred length: 1\nToken distribution (Batch 11): {32: 1}, Pred length: 1\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {19: 1}, Pred length: 1\nToken distribution (Batch 14): {11: 1}, Pred length: 1\nToken distribution (Batch 15): {32: 1}, Pred length: 1\nToken distribution (Batch 16): {11: 1}, Pred length: 1\nToken distribution (Batch 17): {4: 1}, Pred length: 1\nToken distribution (Batch 18): {34: 1}, Pred length: 1\nToken distribution (Batch 19): {19: 1}, Pred length: 1\nToken distribution (Batch 20): {1: 1}, Pred length: 1\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {1: 1}, Pred length: 1\nToken distribution (Batch 23): {19: 1}, Pred length: 1\nToken distribution (Batch 24): {5: 1}, Pred length: 1\nToken distribution (Batch 25): {1: 1}, Pred length: 1\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {34: 1}, Pred length: 1\nToken distribution (Batch 29): {32: 1}, Pred length: 1\nToken distribution (Batch 30): {1: 1}, Pred length: 1\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 20, Gradient norm: 31.5740\nEpoch 16, Batch 20/128, Loss: 17.3960\nAvg Blank Probability: 0.0542\nSample predictions: ['s', 'H', 'd']\nGround Truth (first 3): ['w7YbsY', 'XZpEaBn0C', '4nR9lB5xBjgO']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [6, 9, 12]\nToken distribution (Batch 0): {19: 1}, Pred length: 1\nToken distribution (Batch 1): {1: 1}, Pred length: 1\nToken distribution (Batch 2): {1: 1}, Pred length: 1\nToken distribution (Batch 3): {19: 1}, Pred length: 1\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {34: 1}, Pred length: 1\nToken distribution (Batch 6): {47: 1}, Pred length: 1\nToken distribution (Batch 7): {1: 1}, Pred length: 1\nToken distribution (Batch 8): {19: 1}, Pred length: 1\nToken distribution (Batch 9): {1: 1}, Pred length: 1\nToken distribution (Batch 10): {32: 1}, Pred length: 1\nToken distribution (Batch 11): {1: 1}, Pred length: 1\nToken distribution (Batch 12): {32: 1}, Pred length: 1\nToken distribution (Batch 13): {55: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {32: 1}, Pred length: 1\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {32: 1}, Pred length: 1\nToken distribution (Batch 18): {4: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {19: 1}, Pred length: 1\nToken distribution (Batch 21): {1: 1}, Pred length: 1\nToken distribution (Batch 22): {34: 1}, Pred length: 1\nToken distribution (Batch 23): {1: 1}, Pred length: 1\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {19: 1}, Pred length: 1\nToken distribution (Batch 26): {1: 1}, Pred length: 1\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {1: 1}, Pred length: 1\nToken distribution (Batch 30): {34: 1}, Pred length: 1\nToken distribution (Batch 31): {34: 1}, Pred length: 1\nBatch 30, Gradient norm: 92.4821\nEpoch 16, Batch 30/128, Loss: 16.8422\nAvg Blank Probability: 0.0555\nSample predictions: ['s', 'a', 'a']\nGround Truth (first 3): ['j2OL', '0Ic0zld0mV1', 'be5maBr0']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [4, 11, 8]\nToken distribution (Batch 0): {1: 1}, Pred length: 1\nToken distribution (Batch 1): {19: 1}, Pred length: 1\nToken distribution (Batch 2): {19: 1}, Pred length: 1\nToken distribution (Batch 3): {1: 1}, Pred length: 1\nToken distribution (Batch 4): {32: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {1: 1}, Pred length: 1\nToken distribution (Batch 7): {1: 1}, Pred length: 1\nToken distribution (Batch 8): {19: 1}, Pred length: 1\nToken distribution (Batch 9): {4: 1}, Pred length: 1\nToken distribution (Batch 10): {1: 1}, Pred length: 1\nToken distribution (Batch 11): {27: 1}, Pred length: 1\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {4: 1}, Pred length: 1\nToken distribution (Batch 14): {11: 1}, Pred length: 1\nToken distribution (Batch 15): {32: 1}, Pred length: 1\nToken distribution (Batch 16): {34: 1}, Pred length: 1\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {32: 1}, Pred length: 1\nToken distribution (Batch 20): {1: 1}, Pred length: 1\nToken distribution (Batch 21): {5: 1}, Pred length: 1\nToken distribution (Batch 22): {1: 1}, Pred length: 1\nToken distribution (Batch 23): {32: 1}, Pred length: 1\nToken distribution (Batch 24): {32: 1}, Pred length: 1\nToken distribution (Batch 25): {5: 1}, Pred length: 1\nToken distribution (Batch 26): {56: 1}, Pred length: 1\nToken distribution (Batch 27): {4: 1}, Pred length: 1\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {19: 1}, Pred length: 1\nToken distribution (Batch 30): {11: 1}, Pred length: 1\nToken distribution (Batch 31): {19: 1}, Pred length: 1\nBatch 40, Gradient norm: 79.3177\nEpoch 16, Batch 40/128, Loss: 16.1084\nAvg Blank Probability: 0.0567\nSample predictions: ['a', 's', 's']\nGround Truth (first 3): ['RKq8-0qs95I', 'kS*-5j', '5u8U-tk']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [11, 6, 7]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {42: 1}, Pred length: 1\nToken distribution (Batch 2): {34: 1}, Pred length: 1\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {34: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {19: 1}, Pred length: 1\nToken distribution (Batch 7): {5: 1}, Pred length: 1\nToken distribution (Batch 8): {34: 1}, Pred length: 1\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {27: 1}, Pred length: 1\nToken distribution (Batch 12): {34: 1}, Pred length: 1\nToken distribution (Batch 13): {1: 1}, Pred length: 1\nToken distribution (Batch 14): {32: 1}, Pred length: 1\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {32: 1}, Pred length: 1\nToken distribution (Batch 17): {1: 1}, Pred length: 1\nToken distribution (Batch 18): {1: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {1: 1}, Pred length: 1\nToken distribution (Batch 21): {4: 1}, Pred length: 1\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {32: 1}, Pred length: 1\nToken distribution (Batch 24): {1: 1}, Pred length: 1\nToken distribution (Batch 25): {11: 1}, Pred length: 1\nToken distribution (Batch 26): {1: 1}, Pred length: 1\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {34: 1}, Pred length: 1\nToken distribution (Batch 30): {27: 1}, Pred length: 1\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 50, Gradient norm: 23.1412\nEpoch 16, Batch 50/128, Loss: 13.8209\nAvg Blank Probability: 0.0596\nSample predictions: ['<empty>', 'P', 'H']\nGround Truth (first 3): ['7w57Jng', 'SHkvmO3', 'WvmBR9f']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [7, 7, 7]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {27: 1}, Pred length: 1\nToken distribution (Batch 3): {32: 1}, Pred length: 1\nToken distribution (Batch 4): {32: 1}, Pred length: 1\nToken distribution (Batch 5): {10: 1}, Pred length: 1\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {1: 1}, Pred length: 1\nToken distribution (Batch 10): {11: 1}, Pred length: 1\nToken distribution (Batch 11): {1: 1}, Pred length: 1\nToken distribution (Batch 12): {5: 1}, Pred length: 1\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {1: 1}, Pred length: 1\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {34: 1}, Pred length: 1\nToken distribution (Batch 24): {1: 1}, Pred length: 1\nToken distribution (Batch 25): {34: 1}, Pred length: 1\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 60, Gradient norm: 32.5307\nEpoch 16, Batch 60/128, Loss: 14.9991\nAvg Blank Probability: 0.0625\nSample predictions: ['<empty>', '<empty>', 'A']\nGround Truth (first 3): ['zcji3pN', 'fDh*39SvTD', 'ShDrSsSMs5nr']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [7, 10, 12]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {32: 1}, Pred length: 1\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {1: 1}, Pred length: 1\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {34: 1}, Pred length: 1\nToken distribution (Batch 6): {43: 1}, Pred length: 1\nToken distribution (Batch 7): {32: 1}, Pred length: 1\nToken distribution (Batch 8): {27: 1}, Pred length: 1\nToken distribution (Batch 9): {1: 1}, Pred length: 1\nToken distribution (Batch 10): {6: 1}, Pred length: 1\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {32: 1}, Pred length: 1\nToken distribution (Batch 13): {1: 1}, Pred length: 1\nToken distribution (Batch 14): {5: 1}, Pred length: 1\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {1: 1}, Pred length: 1\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {1: 1}, Pred length: 1\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {1: 1}, Pred length: 1\nToken distribution (Batch 26): {1: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {1: 1}, Pred length: 1\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 70, Gradient norm: 57.5571\nEpoch 16, Batch 70/128, Loss: 15.6933\nAvg Blank Probability: 0.0638\nSample predictions: ['<empty>', 'F', '<empty>']\nGround Truth (first 3): ['7HuV9Fk', 'XmpfCYJlPLt-', '0Ae*hWF-Is']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [7, 12, 10]\nToken distribution (Batch 0): {1: 1}, Pred length: 1\nToken distribution (Batch 1): {32: 1}, Pred length: 1\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {5: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {34: 1}, Pred length: 1\nToken distribution (Batch 7): {32: 1}, Pred length: 1\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {19: 1}, Pred length: 1\nToken distribution (Batch 10): {34: 1}, Pred length: 1\nToken distribution (Batch 11): {1: 1}, Pred length: 1\nToken distribution (Batch 12): {1: 1}, Pred length: 1\nToken distribution (Batch 13): {27: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {34: 1}, Pred length: 1\nToken distribution (Batch 25): {34: 1}, Pred length: 1\nToken distribution (Batch 26): {1: 1}, Pred length: 1\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {19: 1}, Pred length: 1\nToken distribution (Batch 29): {32: 1}, Pred length: 1\nToken distribution (Batch 30): {34: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nBatch 80, Gradient norm: 399.6093\nEpoch 16, Batch 80/128, Loss: 14.9331\nAvg Blank Probability: 0.0651\nSample predictions: ['a', 'F', '<empty>']\nGround Truth (first 3): ['T4ei4vEgY', 'VpXSIt', 'rh9uFq3N2mY']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [9, 6, 11]\nToken distribution (Batch 0): {32: 1}, Pred length: 1\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {1: 1}, Pred length: 1\nToken distribution (Batch 3): {34: 1}, Pred length: 1\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {19: 1}, Pred length: 1\nToken distribution (Batch 7): {1: 1}, Pred length: 1\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {32: 1}, Pred length: 1\nToken distribution (Batch 11): {5: 1}, Pred length: 1\nToken distribution (Batch 12): {27: 1}, Pred length: 1\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {1: 1}, Pred length: 1\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {1: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {1: 1}, Pred length: 1\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {4: 1}, Pred length: 1\nToken distribution (Batch 24): {5: 1}, Pred length: 1\nToken distribution (Batch 25): {34: 1}, Pred length: 1\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {32: 1}, Pred length: 1\nToken distribution (Batch 30): {1: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nBatch 90, Gradient norm: 62.7466\nEpoch 16, Batch 90/128, Loss: 15.5042\nAvg Blank Probability: 0.0673\nSample predictions: ['F', '<empty>', 'a']\nGround Truth (first 3): ['ka2pmUh', 'cACl', 't4hU']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [7, 4, 4]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {1: 1}, Pred length: 1\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {19: 1}, Pred length: 1\nToken distribution (Batch 5): {32: 1}, Pred length: 1\nToken distribution (Batch 6): {1: 1}, Pred length: 1\nToken distribution (Batch 7): {34: 1}, Pred length: 1\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {4: 1}, Pred length: 1\nToken distribution (Batch 11): {1: 1}, Pred length: 1\nToken distribution (Batch 12): {34: 1}, Pred length: 1\nToken distribution (Batch 13): {1: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {34: 1}, Pred length: 1\nToken distribution (Batch 20): {27: 1}, Pred length: 1\nToken distribution (Batch 21): {34: 1}, Pred length: 1\nToken distribution (Batch 22): {34: 1}, Pred length: 1\nToken distribution (Batch 23): {1: 1}, Pred length: 1\nToken distribution (Batch 24): {47: 1}, Pred length: 1\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 100, Gradient norm: 28.9402\nEpoch 16, Batch 100/128, Loss: 14.7798\nAvg Blank Probability: 0.0700\nSample predictions: ['<empty>', 'a', '<empty>']\nGround Truth (first 3): ['uA8T-', 'bSNdZA', 'kXLyc']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [5, 6, 5]\nToken distribution (Batch 0): {34: 1}, Pred length: 1\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {1: 1}, Pred length: 1\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {1: 1}, Pred length: 1\nToken distribution (Batch 7): {32: 1}, Pred length: 1\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {34: 1}, Pred length: 1\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {1: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {1: 1}, Pred length: 1\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {1: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nBatch 110, Gradient norm: 37.6552\nEpoch 16, Batch 110/128, Loss: 15.9348\nAvg Blank Probability: 0.0730\nSample predictions: ['H', '<empty>', 'a']\nGround Truth (first 3): ['VZ4Vn*sPCaVi', '*ovwV', 'ejdqW']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [12, 5, 5]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {1: 1}, Pred length: 1\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {1: 1}, Pred length: 1\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {32: 1}, Pred length: 1\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 120, Gradient norm: 217.2696\nEpoch 16, Batch 120/128, Loss: 14.0947\nAvg Blank Probability: 0.0758\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['z9Hz1b0-4K*', '6oGLt99', 'NjDj60Gc']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [11, 7, 8]\nEpoch 16/20, Loss: 15.8559\nToken distribution (Batch 0): {1: 1}, Pred length: 1\nToken distribution (Batch 1): {1: 1}, Pred length: 1\nToken distribution (Batch 2): {1: 1}, Pred length: 1\nToken distribution (Batch 3): {1: 14}, Pred length: 14\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 12}, Pred length: 12\nToken distribution (Batch 6): {1: 22}, Pred length: 22\nToken distribution (Batch 7): {1: 1}, Pred length: 1\nToken distribution (Batch 8): {1: 20}, Pred length: 20\nToken distribution (Batch 9): {1: 12}, Pred length: 12\nToken distribution (Batch 10): {1: 1}, Pred length: 1\nToken distribution (Batch 11): {1: 1}, Pred length: 1\nToken distribution (Batch 12): {1: 24}, Pred length: 24\nToken distribution (Batch 13): {1: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {1: 12}, Pred length: 12\nToken distribution (Batch 16): {1: 18}, Pred length: 18\nToken distribution (Batch 17): {1: 14}, Pred length: 14\nToken distribution (Batch 18): {1: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {1: 18}, Pred length: 18\nToken distribution (Batch 21): {1: 1}, Pred length: 1\nToken distribution (Batch 22): {1: 1}, Pred length: 1\nToken distribution (Batch 23): {1: 1}, Pred length: 1\nToken distribution (Batch 24): {1: 1}, Pred length: 1\nToken distribution (Batch 25): {1: 1}, Pred length: 1\nToken distribution (Batch 26): {1: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 20}, Pred length: 20\nToken distribution (Batch 28): {1: 10}, Pred length: 10\nToken distribution (Batch 29): {1: 18}, Pred length: 18\nToken distribution (Batch 30): {1: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nValidation Loss: 18.6803\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['lIL3QJfm', '6DK3', 'Oc6EKcYhvX', 'A0FORIO', 'LcwxB']\nCurrent Learning Rate: 8.978713763747791e-07\nEpoch 17, Filtered data size: 5120, Sample labels: ['qV8ib8H', 'MdI8', '1XS0DRdJ']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {32: 1}, Pred length: 1\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {1: 1}, Pred length: 1\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {19: 1}, Pred length: 1\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {34: 1}, Pred length: 1\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 0, Gradient norm: 80.6793\nEpoch 17, Batch 0/128, Loss: 15.3555\nAvg Blank Probability: 0.0748\nSample predictions: ['<empty>', '<empty>', 'F']\nGround Truth (first 3): ['L9*p', 'z3htP0*5ZQg', 'tMYS']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [4, 11, 4]\nToken distribution (Batch 0): {34: 1}, Pred length: 1\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {19: 1}, Pred length: 1\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {1: 1}, Pred length: 1\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {34: 1}, Pred length: 1\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {32: 1}, Pred length: 1\nBatch 10, Gradient norm: 358.1092\nEpoch 17, Batch 10/128, Loss: 15.1486\nAvg Blank Probability: 0.0793\nSample predictions: ['H', '<empty>', '<empty>']\nGround Truth (first 3): ['9EPjUWf', 'EO*7nTO*a', 'YyqWVBEEtd']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [7, 9, 10]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {32: 1}, Pred length: 1\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {1: 1}, Pred length: 1\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {42: 1}, Pred length: 1\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 20, Gradient norm: 216.2946\nEpoch 17, Batch 20/128, Loss: 16.0990\nAvg Blank Probability: 0.0828\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['SiZI12', 'HyQ8C', 'rcgFxi1zWsc']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [6, 5, 11]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {1: 1}, Pred length: 1\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 30, Gradient norm: 56.8127\nEpoch 17, Batch 30/128, Loss: 15.1263\nAvg Blank Probability: 0.0893\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['o-G76XcNoZA', 'rbp9', 'AnHwRS']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [11, 4, 6]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 40, Gradient norm: 36.1733\nEpoch 17, Batch 40/128, Loss: 14.6426\nAvg Blank Probability: 0.0923\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['CeVViIigGS', 'lxr1FDs19', '0nZxh5d']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [10, 9, 7]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {42: 1}, Pred length: 1\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {1: 1}, Pred length: 1\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 50, Gradient norm: 436.3875\nEpoch 17, Batch 50/128, Loss: 14.5199\nAvg Blank Probability: 0.0929\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['RFaKOdrNd0F', 'AQB8eK4Y2', 'SywL96']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [11, 9, 6]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {1: 1}, Pred length: 1\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 60, Gradient norm: 266.1904\nEpoch 17, Batch 60/128, Loss: 14.8792\nAvg Blank Probability: 0.0991\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['oyjaGl', 'UVAzR5vxck', 'AW5umt71zvg']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [6, 10, 11]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 70, Gradient norm: 115.8634\nEpoch 17, Batch 70/128, Loss: 14.4520\nAvg Blank Probability: 0.1053\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['MHApRz', 'KdpStVdKxxyd', 'tOkmw']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [6, 12, 5]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 80, Gradient norm: 1088.4746\nEpoch 17, Batch 80/128, Loss: 13.8205\nAvg Blank Probability: 0.1058\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['M8BBDh4uh', 'xbB0ZbZWneG8', 'FBxZ3wSl-6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [9, 12, 10]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 90, Gradient norm: 1505.7753\nEpoch 17, Batch 90/128, Loss: 14.1484\nAvg Blank Probability: 0.1113\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['6WIYA', 'yey8ssl2', 'TJEHKvDy']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [5, 8, 8]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 100, Gradient norm: 1999.6146\nEpoch 17, Batch 100/128, Loss: 13.5593\nAvg Blank Probability: 0.1225\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['KU6e', 'BWi1*p', 'MXGb81HM']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [4, 6, 8]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 110, Gradient norm: 374.1015\nEpoch 17, Batch 110/128, Loss: 12.9617\nAvg Blank Probability: 0.1202\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['PmxbrWu', '4jRevbS2b3l', 'sfqPb']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [7, 11, 5]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 120, Gradient norm: 64.1998\nEpoch 17, Batch 120/128, Loss: 14.1304\nAvg Blank Probability: 0.1310\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['mwJs', 'mh5JdU', 'a2IViAI3RM7Z']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [4, 6, 12]\nEpoch 17/20, Loss: 14.3171\nToken distribution (Batch 0): {1: 1}, Pred length: 1\nToken distribution (Batch 1): {1: 1}, Pred length: 1\nToken distribution (Batch 2): {1: 1}, Pred length: 1\nToken distribution (Batch 3): {1: 1}, Pred length: 1\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {1: 1}, Pred length: 1\nToken distribution (Batch 7): {1: 1}, Pred length: 1\nToken distribution (Batch 8): {1: 1}, Pred length: 1\nToken distribution (Batch 9): {1: 1}, Pred length: 1\nToken distribution (Batch 10): {1: 1}, Pred length: 1\nToken distribution (Batch 11): {1: 1}, Pred length: 1\nToken distribution (Batch 12): {1: 1}, Pred length: 1\nToken distribution (Batch 13): {1: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {1: 1}, Pred length: 1\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {1: 1}, Pred length: 1\nToken distribution (Batch 18): {1: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {1: 1}, Pred length: 1\nToken distribution (Batch 21): {1: 1}, Pred length: 1\nToken distribution (Batch 22): {1: 1}, Pred length: 1\nToken distribution (Batch 23): {1: 1}, Pred length: 1\nToken distribution (Batch 24): {1: 1}, Pred length: 1\nToken distribution (Batch 25): {1: 1}, Pred length: 1\nToken distribution (Batch 26): {1: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {1: 1}, Pred length: 1\nToken distribution (Batch 29): {1: 1}, Pred length: 1\nToken distribution (Batch 30): {1: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nValidation Loss: 17.9706\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['lW3nU1mVXmY', 'epwZJNmK8', 'q0bDzqe', 'MxvSuEX', 'iHsDg3akVwQ']\nCurrent Learning Rate: 9.417154755087244e-07\nEpoch 18, Filtered data size: 5120, Sample labels: ['qV8ib8H', 'MdI8', '1XS0DRdJ']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 0, Gradient norm: 93.1129\nEpoch 18, Batch 0/128, Loss: 14.4708\nAvg Blank Probability: 0.1340\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['2HdzMeVVBsYs', '5LHnRo*Th', 'b21F']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [12, 9, 4]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 10, Gradient norm: 13496.2021\nEpoch 18, Batch 10/128, Loss: 12.6489\nAvg Blank Probability: 0.1436\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['k2ivVnRSfaU', '3Aqq', 'YyqWVBEEtd']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [11, 4, 10]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 20, Gradient norm: 55.2552\nEpoch 18, Batch 20/128, Loss: 13.1258\nAvg Blank Probability: 0.1453\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['BGf7Xw', 'Vpku', 'fNSigIib2e']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [6, 4, 10]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 30, Gradient norm: 3159.5024\nEpoch 18, Batch 30/128, Loss: 12.9096\nAvg Blank Probability: 0.1520\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['FC1jnHEB', 'rW6i2vxP*lS0', '1Lj5fHzNms']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [8, 12, 10]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 40, Gradient norm: 37.3421\nEpoch 18, Batch 40/128, Loss: 12.8162\nAvg Blank Probability: 0.1577\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['B7L9-8', 'byDhLaGBE', 'Fy5r']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [6, 9, 4]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 50, Gradient norm: 3036140.2500\nEpoch 18, Batch 50/128, Loss: 13.4886\nAvg Blank Probability: 0.1684\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['G4w9KxtV', '94V1', 'GMHqgp']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [8, 4, 6]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 60, Gradient norm: 1164684.0000\nEpoch 18, Batch 60/128, Loss: 12.2724\nAvg Blank Probability: 0.1784\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['7Olc', 'N51BCQ0m', 'TSKcawSV']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [4, 8, 8]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 70, Gradient norm: 3036.3596\nEpoch 18, Batch 70/128, Loss: 11.8502\nAvg Blank Probability: 0.1869\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['1f27PCbUwMFb', 'AnHwRS', 'hbNt3']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [12, 6, 5]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 80, Gradient norm: 49320.2969\nEpoch 18, Batch 80/128, Loss: 11.8761\nAvg Blank Probability: 0.2039\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['whY-MHfsr', 'mNkU', 'vv9k0']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [9, 4, 5]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 90, Gradient norm: 5114.1255\nEpoch 18, Batch 90/128, Loss: 11.9592\nAvg Blank Probability: 0.2070\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Qcr93Fhm-8aD', 'eCyg', '0WMO']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [12, 4, 4]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 100, Gradient norm: 464604.6562\nEpoch 18, Batch 100/128, Loss: 12.1224\nAvg Blank Probability: 0.2142\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['TZ5IlrMxDkXg', 'Ufo6MO', 'dhDEk44']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [12, 6, 7]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 110, Gradient norm: 31194.1426\nEpoch 18, Batch 110/128, Loss: 11.4084\nAvg Blank Probability: 0.2240\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Fv*L', 'H2CIjmDxE', 'NoNof7M']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [4, 9, 7]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 120, Gradient norm: 355161.2812\nEpoch 18, Batch 120/128, Loss: 11.3424\nAvg Blank Probability: 0.2469\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['afiAJm9qHdSE', 'Ja8U7pP5T', 'CAot9p']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [12, 9, 6]\nEpoch 18/20, Loss: 12.3237\nToken distribution (Batch 0): {1: 1}, Pred length: 1\nToken distribution (Batch 1): {1: 1}, Pred length: 1\nToken distribution (Batch 2): {1: 1}, Pred length: 1\nToken distribution (Batch 3): {1: 1}, Pred length: 1\nToken distribution (Batch 4): {1: 1}, Pred length: 1\nToken distribution (Batch 5): {1: 1}, Pred length: 1\nToken distribution (Batch 6): {1: 1}, Pred length: 1\nToken distribution (Batch 7): {1: 1}, Pred length: 1\nToken distribution (Batch 8): {1: 1}, Pred length: 1\nToken distribution (Batch 9): {1: 1}, Pred length: 1\nToken distribution (Batch 10): {1: 1}, Pred length: 1\nToken distribution (Batch 11): {1: 1}, Pred length: 1\nToken distribution (Batch 12): {1: 1}, Pred length: 1\nToken distribution (Batch 13): {1: 1}, Pred length: 1\nToken distribution (Batch 14): {1: 1}, Pred length: 1\nToken distribution (Batch 15): {1: 1}, Pred length: 1\nToken distribution (Batch 16): {1: 1}, Pred length: 1\nToken distribution (Batch 17): {1: 1}, Pred length: 1\nToken distribution (Batch 18): {1: 1}, Pred length: 1\nToken distribution (Batch 19): {1: 1}, Pred length: 1\nToken distribution (Batch 20): {1: 1}, Pred length: 1\nToken distribution (Batch 21): {1: 1}, Pred length: 1\nToken distribution (Batch 22): {1: 1}, Pred length: 1\nToken distribution (Batch 23): {1: 1}, Pred length: 1\nToken distribution (Batch 24): {1: 1}, Pred length: 1\nToken distribution (Batch 25): {1: 1}, Pred length: 1\nToken distribution (Batch 26): {1: 1}, Pred length: 1\nToken distribution (Batch 27): {1: 1}, Pred length: 1\nToken distribution (Batch 28): {1: 1}, Pred length: 1\nToken distribution (Batch 29): {1: 1}, Pred length: 1\nToken distribution (Batch 30): {1: 1}, Pred length: 1\nToken distribution (Batch 31): {1: 1}, Pred length: 1\nValidation Loss: 17.4535\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['dwPE1ggpj7S1', 'Tz*EyBqiH6', 'lDQ39', 'rbBAXx', 'xPTQd-mx']\nCurrent Learning Rate: 9.738273538536054e-07\nEpoch 19, Filtered data size: 5120, Sample labels: ['qV8ib8H', 'MdI8', '1XS0DRdJ']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 0, Gradient norm: 39.7902\nEpoch 19, Batch 0/128, Loss: 11.4033\nAvg Blank Probability: 0.2446\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['GOdnFzBK8o', 'TSKcawSV', 'b5WDpS2']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [10, 8, 7]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 10, Gradient norm: 34.5314\nEpoch 19, Batch 10/128, Loss: 10.6013\nAvg Blank Probability: 0.2612\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['gKc8sos9Nky', 'vE9VDpFFzW', 'I2WwCVmMK']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [11, 10, 9]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 20, Gradient norm: 1462282.8750\nEpoch 19, Batch 20/128, Loss: 10.9096\nAvg Blank Probability: 0.2620\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['LQIDp', 'pmbTGRVDlE1', 'u7fJHa1']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [5, 11, 7]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 30, Gradient norm: 39.8435\nEpoch 19, Batch 30/128, Loss: 10.3207\nAvg Blank Probability: 0.2865\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['IYgCN-G9BqJq', 'zrxFZubdQ1', 'j6hdqLjL']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [12, 10, 8]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 40, Gradient norm: 68.9948\nEpoch 19, Batch 40/128, Loss: 10.4432\nAvg Blank Probability: 0.3000\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['nSvLAYkFlk', 'kuuVxX4', 'XLxuczjl']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [10, 7, 8]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 50, Gradient norm: 2627742.0000\nEpoch 19, Batch 50/128, Loss: 10.1583\nAvg Blank Probability: 0.3262\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['gk7fCb', 'UYICrDzd0n', '0vqdMr']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [6, 10, 6]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 60, Gradient norm: 85.1634\nEpoch 19, Batch 60/128, Loss: 10.3197\nAvg Blank Probability: 0.3473\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['GCP8jv', 'a4WA', 'BiACdB']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [6, 4, 6]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 70, Gradient norm: 7551655.5000\nEpoch 19, Batch 70/128, Loss: 9.9878\nAvg Blank Probability: 0.3529\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['akgOs', 'LR4bD', 'l8ppZrI']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [5, 5, 7]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 80, Gradient norm: 583.8644\nEpoch 19, Batch 80/128, Loss: 9.8201\nAvg Blank Probability: 0.3640\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['32wcFkBGWp1', 'x-tVOPU', 'fR-mobM']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [11, 7, 7]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 90, Gradient norm: 757.3771\nEpoch 19, Batch 90/128, Loss: 9.7555\nAvg Blank Probability: 0.3800\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['xFhvf1xXDP', 'usHJ3PK', 'HjBGChnSWWO']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [10, 7, 11]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 100, Gradient norm: 2708743936.0000\nEpoch 19, Batch 100/128, Loss: 9.3717\nAvg Blank Probability: 0.4164\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['zlUlt39V1q', 'vFUA', 'Dhn2E']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [10, 4, 5]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 110, Gradient norm: 36.2146\nEpoch 19, Batch 110/128, Loss: 8.7973\nAvg Blank Probability: 0.4309\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['5F8x3g', 'KdpStVdKxxyd', 'zXTnNL']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [6, 12, 6]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 120, Gradient norm: 338833248.0000\nEpoch 19, Batch 120/128, Loss: 8.9700\nAvg Blank Probability: 0.4562\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Pi5cnfrd-K', 'J4K--', 'tWkltF*EFYQ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [10, 5, 11]\nEpoch 19/20, Loss: 10.0507\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nValidation Loss: 16.3498\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['kzx5N9aA', 'hI1EHFRBuPu0', 'wmPmH4HXmpo', 'VAD1', 'pBqirWzEH']\nCurrent Learning Rate: 9.934163103913567e-07\nEpoch 20, Filtered data size: 5120, Sample labels: ['qV8ib8H', 'MdI8', '1XS0DRdJ']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 0, Gradient norm: 90476.4297\nEpoch 20, Batch 0/128, Loss: 9.1116\nAvg Blank Probability: 0.4659\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['kZxrX', 'qYa1', 'U0ab']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [5, 4, 4]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 10, Gradient norm: 3357131264.0000\nEpoch 20, Batch 10/128, Loss: 8.8663\nAvg Blank Probability: 0.4877\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['c4K8AIjGTc9', 'j2OL', 'lCHJRL1']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [11, 4, 7]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 20, Gradient norm: 1090678489088.0000\nEpoch 20, Batch 20/128, Loss: 8.4727\nAvg Blank Probability: 0.5136\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['J-sc3', 'PP8oz0n6iGMk', 'xAGgoH3r']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [5, 12, 8]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 30, Gradient norm: 9090.1797\nEpoch 20, Batch 30/128, Loss: 8.4606\nAvg Blank Probability: 0.5352\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['VVEB6', 'zZy3', 'BiUFfu']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [5, 4, 6]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 40, Gradient norm: 450.0069\nEpoch 20, Batch 40/128, Loss: 8.0093\nAvg Blank Probability: 0.5613\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['3R3uP7agGPiq', 'vL*biFM', 'mzvm*AyGQC']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [12, 7, 10]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 50, Gradient norm: 2407.0920\nEpoch 20, Batch 50/128, Loss: 8.0799\nAvg Blank Probability: 0.5746\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['zOYeRqo', 'XoMr*d', '7eEqzisX']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [7, 6, 8]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 60, Gradient norm: 698.1422\nEpoch 20, Batch 60/128, Loss: 7.8898\nAvg Blank Probability: 0.5885\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['FZC-0ZQtXx6-', 'KCJio1y1', 'ZM-mIxQr*tq']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [12, 8, 11]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 70, Gradient norm: 107195176.0000\nEpoch 20, Batch 70/128, Loss: 7.7462\nAvg Blank Probability: 0.6168\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['sOAc-gvSBDW', 'IWh0dNamvC3', '8xLIdo']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [11, 11, 6]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 80, Gradient norm: 906517824.0000\nEpoch 20, Batch 80/128, Loss: 7.7068\nAvg Blank Probability: 0.6383\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['M9HcgBJVtB', '7YD5uT', '9aix']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [10, 6, 4]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 90, Gradient norm: 2404406981033984.0000\nEpoch 20, Batch 90/128, Loss: 7.5339\nAvg Blank Probability: 0.6572\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['tAWFoS3', 'u3j00o', 'Rlui']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [7, 6, 4]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 100, Gradient norm: 3662447104.0000\nEpoch 20, Batch 100/128, Loss: 7.5950\nAvg Blank Probability: 0.6577\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Yi9w*f', 'NClxveIgroB', 'U1pMk8QDjA']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [6, 11, 10]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 110, Gradient norm: 1276805.0000\nEpoch 20, Batch 110/128, Loss: 7.3509\nAvg Blank Probability: 0.6841\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['zRPPIHMv', 'ngat3toMLek', 'IseoZPwf']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [8, 11, 8]\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nBatch 120, Gradient norm: 6886.4326\nEpoch 20, Batch 120/128, Loss: 7.2556\nAvg Blank Probability: 0.7117\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['yPe8J', 'LRLfw', 'PzyrZrS']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 32, Label lengths: [5, 5, 7]\nEpoch 20/20, Loss: 8.0010\nToken distribution (Batch 0): {}, Pred length: 0\nToken distribution (Batch 1): {}, Pred length: 0\nToken distribution (Batch 2): {}, Pred length: 0\nToken distribution (Batch 3): {}, Pred length: 0\nToken distribution (Batch 4): {}, Pred length: 0\nToken distribution (Batch 5): {}, Pred length: 0\nToken distribution (Batch 6): {}, Pred length: 0\nToken distribution (Batch 7): {}, Pred length: 0\nToken distribution (Batch 8): {}, Pred length: 0\nToken distribution (Batch 9): {}, Pred length: 0\nToken distribution (Batch 10): {}, Pred length: 0\nToken distribution (Batch 11): {}, Pred length: 0\nToken distribution (Batch 12): {}, Pred length: 0\nToken distribution (Batch 13): {}, Pred length: 0\nToken distribution (Batch 14): {}, Pred length: 0\nToken distribution (Batch 15): {}, Pred length: 0\nToken distribution (Batch 16): {}, Pred length: 0\nToken distribution (Batch 17): {}, Pred length: 0\nToken distribution (Batch 18): {}, Pred length: 0\nToken distribution (Batch 19): {}, Pred length: 0\nToken distribution (Batch 20): {}, Pred length: 0\nToken distribution (Batch 21): {}, Pred length: 0\nToken distribution (Batch 22): {}, Pred length: 0\nToken distribution (Batch 23): {}, Pred length: 0\nToken distribution (Batch 24): {}, Pred length: 0\nToken distribution (Batch 25): {}, Pred length: 0\nToken distribution (Batch 26): {}, Pred length: 0\nToken distribution (Batch 27): {}, Pred length: 0\nToken distribution (Batch 28): {}, Pred length: 0\nToken distribution (Batch 29): {}, Pred length: 0\nToken distribution (Batch 30): {}, Pred length: 0\nToken distribution (Batch 31): {}, Pred length: 0\nValidation Loss: 15.2139\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['sHxLmy233x', 'jZKnb0VEm', 'NtpAG', 'wgnSKBrlJ2W', 'VpXSIt']\nCurrent Learning Rate: 1e-06\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"def zip_folder_with_shutil(source_folder, output_path):\n    '''Function for zip dir data'''\n    shutil.make_archive(output_path, 'zip', source_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T17:19:08.437093Z","iopub.execute_input":"2025-03-11T17:19:08.437371Z","iopub.status.idle":"2025-03-11T17:19:08.442700Z","shell.execute_reply.started":"2025-03-11T17:19:08.437347Z","shell.execute_reply":"2025-03-11T17:19:08.441401Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/backgrounds', '/kaggle/working/backgrounds')\nzip_folder_with_shutil('/kaggle/working/synthetic_data', '/kaggle/working/synthetic_data')\nzip_folder_with_shutil('/kaggle/working/model_dir', '/kaggle/working/model_dir')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T17:19:08.446950Z","iopub.execute_input":"2025-03-11T17:19:08.447292Z","iopub.status.idle":"2025-03-11T17:19:11.782027Z","shell.execute_reply.started":"2025-03-11T17:19:08.447263Z","shell.execute_reply":"2025-03-11T17:19:11.780951Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/runs', '/kaggle/working/runs')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T17:19:11.783249Z","iopub.execute_input":"2025-03-11T17:19:11.783812Z","iopub.status.idle":"2025-03-11T17:19:11.842761Z","shell.execute_reply.started":"2025-03-11T17:19:11.783764Z","shell.execute_reply":"2025-03-11T17:19:11.841540Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"#!tensorboard --logdir=/kaggle/working/runs --port 6006","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T17:19:11.843886Z","iopub.execute_input":"2025-03-11T17:19:11.844254Z","iopub.status.idle":"2025-03-11T17:19:11.848120Z","shell.execute_reply.started":"2025-03-11T17:19:11.844229Z","shell.execute_reply":"2025-03-11T17:19:11.847227Z"}},"outputs":[],"execution_count":29}]}