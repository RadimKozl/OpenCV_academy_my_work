{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10911708,"sourceType":"datasetVersion","datasetId":6783030}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---------------\n\n# **<font style=\"color:Black\">Create OCR by PyTorch</font>**\n-------------------\n-----------------","metadata":{}},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Installation and import libraries</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"!pip install  pillow \n!pip install opencv-python\n!pip install matplotlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:18.082363Z","iopub.execute_input":"2025-03-06T22:02:18.082676Z","iopub.status.idle":"2025-03-06T22:02:32.050281Z","shell.execute_reply.started":"2025-03-06T22:02:18.082643Z","shell.execute_reply":"2025-03-06T22:02:32.048997Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.20->matplotlib) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport random\nfrom PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter\nimport numpy as np\nimport cv2\n\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F  # Add this import\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:32.052127Z","iopub.execute_input":"2025-03-06T22:02:32.052432Z","iopub.status.idle":"2025-03-06T22:02:39.082470Z","shell.execute_reply.started":"2025-03-06T22:02:32.052407Z","shell.execute_reply":"2025-03-06T22:02:39.081598Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Hyperparameters</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"OUTPUT_DIR = os.path.join('/kaggle','working','synthetic_data','images')\nMODEL_DIR = os.path.join('/kaggle','working','model_dir')\nLABELS_FILE = os.path.join('/kaggle','working','synthetic_data','labels.txt')\nNUM_SAMPLES = 5120  # Number of images generated\nIMG_WIDTH = 128\nIMG_HEIGHT = 32\nBATCH_SIZE = 32\nEPOCHS = 10\nLEARNING_RATE = 1e-5  # Lowered from 1e-4\nWEIGHT_DECAY = 1e-4  # Increased from 1e-4\nWARMUP_STEPS = 1000  # Reduced to ~1 epoch (160 batches)\nENTROPY_WEIGHT = 2.0\nTEMPERATURE = 0.2     # New: sharpen softmax\nBEAM_WIDTH = 10\nCHARSET = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-*\"  # Group characters\nMAX_TEXT_LENGTH = 10  # Maximum length of text in an image\nFONT_DIR = os.path.join('/kaggle','input','google-fonts','GoogleFontScripts') # Folder with TrueType fonts (.ttf)\nBACKGROUND_DIR = os.path.join('/kaggle','working','backgrounds')  # New folder for background (optional)\nNUMBER_BACKGROUND_IMAGE = 50","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.083776Z","iopub.execute_input":"2025-03-06T22:02:39.084371Z","iopub.status.idle":"2025-03-06T22:02:39.090397Z","shell.execute_reply.started":"2025-03-06T22:02:39.084236Z","shell.execute_reply":"2025-03-06T22:02:39.089357Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Utils support functions</font>**\n-------------------","metadata":{}},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Create output folders</font>**","metadata":{}},{"cell_type":"code","source":"os.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(BACKGROUND_DIR, exist_ok=True)\n\n# Creates a new file\nwith open(LABELS_FILE, 'w') as fp:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.091327Z","iopub.execute_input":"2025-03-06T22:02:39.091670Z","iopub.status.idle":"2025-03-06T22:02:39.115557Z","shell.execute_reply.started":"2025-03-06T22:02:39.091637Z","shell.execute_reply":"2025-03-06T22:02:39.114388Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load the font list (add the paths to the .ttf files to the \"fonts\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"font_files = [\n    os.path.join(FONT_DIR, f) for f in os.listdir(FONT_DIR) \n    if f.endswith('.ttf') and os.path.isfile(os.path.join(FONT_DIR, f))\n]\nif not font_files:\n    raise FileNotFoundError(\"No fonts found in 'fonts' folder. Add .ttf files!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.116695Z","iopub.execute_input":"2025-03-06T22:02:39.117061Z","iopub.status.idle":"2025-03-06T22:02:39.461454Z","shell.execute_reply.started":"2025-03-06T22:02:39.117024Z","shell.execute_reply":"2025-03-06T22:02:39.460351Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generating a simple gradient background</font>**","metadata":{}},{"cell_type":"code","source":"def generate_gradient_background(filename, size=(128, 32)):\n    img = Image.new('L', size, color=230)  # Lighter gray as a base\n    draw = ImageDraw.Draw(img)\n    for y in range(size[1]):\n        # Soft gradient with low contrast\n        color = int(230 - 20 * (y / size[1]))  # From light gray to slightly darker\n        draw.line([(0, y), (size[0], y)], fill=color)\n    # Background blur\n    img = img.filter(ImageFilter.GaussianBlur(radius=2))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.463942Z","iopub.execute_input":"2025-03-06T22:02:39.464233Z","iopub.status.idle":"2025-03-06T22:02:39.469917Z","shell.execute_reply.started":"2025-03-06T22:02:39.464178Z","shell.execute_reply":"2025-03-06T22:02:39.468954Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generate a background with noise (paper texture)</font>**","metadata":{}},{"cell_type":"code","source":"def generate_paper_texture(filename, size=(128, 32)):\n    img = Image.new('L', size, color=220)  # Lighter gray\n    noise = np.random.normal(0, 5, size).astype(np.uint8)  # Less noise\n    noise_img = Image.fromarray(noise)\n    img.paste(noise_img, (0, 0), noise_img)\n    # Blur for a softer effect\n    img = img.filter(ImageFilter.GaussianBlur(radius=1.5))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.471734Z","iopub.execute_input":"2025-03-06T22:02:39.472060Z","iopub.status.idle":"2025-03-06T22:02:39.489601Z","shell.execute_reply.started":"2025-03-06T22:02:39.472035Z","shell.execute_reply":"2025-03-06T22:02:39.488608Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Creating multiple backgrounds</font>**","metadata":{}},{"cell_type":"code","source":"for i in range(NUMBER_BACKGROUND_IMAGE):\n    generate_gradient_background(f\"gradient_{i}.png\")\n    generate_paper_texture(f\"paper_{i}.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.490555Z","iopub.execute_input":"2025-03-06T22:02:39.490853Z","iopub.status.idle":"2025-03-06T22:02:39.597845Z","shell.execute_reply.started":"2025-03-06T22:02:39.490828Z","shell.execute_reply":"2025-03-06T22:02:39.596938Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load backgrounds (optional, add images to the \"backgrounds\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"background_files = (\n    [os.path.join(BACKGROUND_DIR, f) for f in os.listdir(BACKGROUND_DIR) \n     if f.endswith(('.png', '.jpg', '.jpeg'))] if os.path.exists(BACKGROUND_DIR) else []\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.598700Z","iopub.execute_input":"2025-03-06T22:02:39.598949Z","iopub.status.idle":"2025-03-06T22:02:39.604102Z","shell.execute_reply.started":"2025-03-06T22:02:39.598929Z","shell.execute_reply":"2025-03-06T22:02:39.603270Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Random text generation function</font>**","metadata":{}},{"cell_type":"code","source":"def generate_random_text(max_length):\n    length = random.randint(1, max_length)\n    return ''.join(random.choice(CHARSET) for _ in range(length))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.604987Z","iopub.execute_input":"2025-03-06T22:02:39.605314Z","iopub.status.idle":"2025-03-06T22:02:39.621483Z","shell.execute_reply.started":"2025-03-06T22:02:39.605281Z","shell.execute_reply":"2025-03-06T22:02:39.620336Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Functions for adding noise and distortions</font>**","metadata":{}},{"cell_type":"code","source":"def add_noise_and_distortion(img):\n    img_array = np.array(img)\n    # Mild Gaussian noise with lower intensity\n    if random.random() > 0.5:  # 50% šance\n        noise = np.random.normal(0, random.randint(5, 15), img_array.shape).astype(np.uint8)\n        img_array = cv2.add(img_array, noise)\n    # Subtle perspective distortion\n    rows, cols = img_array.shape\n    src_points = np.float32([[0, 0], [cols-1, 0], [0, rows-1], [cols-1, rows-1]])\n    dst_points = np.float32([\n        [random.uniform(0, 3), random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), random.uniform(0, 3)],\n        [random.uniform(0, 3), rows-1-random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), rows-1-random.uniform(0, 3)]\n    ])\n    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n    img_array = cv2.warpPerspective(img_array, matrix, (cols, rows))\n    return Image.fromarray(img_array)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.622475Z","iopub.execute_input":"2025-03-06T22:02:39.622769Z","iopub.status.idle":"2025-03-06T22:02:39.634140Z","shell.execute_reply.started":"2025-03-06T22:02:39.622742Z","shell.execute_reply":"2025-03-06T22:02:39.633175Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Improved image generation feature</font>**","metadata":{}},{"cell_type":"code","source":"def generate_synthetic_image(text, font_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n    # Pozadí\n    if background_files:\n        bg_path = random.choice(background_files)\n        img = Image.open(bg_path).convert('L').resize(img_size)\n    else:\n        img = Image.new('L', img_size, color=230)\n        draw = ImageDraw.Draw(img)\n        for y in range(img_size[1]):\n            color = int(230 - 20 * (y / img_size[1]))\n            draw.line([(0, y), (img_size[0], y)], fill=color)\n        img = img.filter(ImageFilter.GaussianBlur(radius=2))\n\n    draw = ImageDraw.Draw(img)\n\n    # Iterativní úprava fontu a textu\n    font_size = random.randint(20, min(IMG_HEIGHT-2, 28))\n    max_attempts = 5  # Omezení počtu pokusů\n    for attempt in range(max_attempts):\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n        if text_width <= IMG_WIDTH - 10:  # Text vejde\n            break\n        elif len(text) > 1:  # Zkrať text, pokud je příliš dlouhý\n            text = text[:len(text)//2]\n        else:  # Sniž velikost fontu\n            font_size = max(10, font_size - 5)  # Minimální velikost 10\n\n    # Pokud se nepodaří, použij minimální font a jednopísmený text\n    if text_width > IMG_WIDTH - 10:\n        text = text[0]  # Použij první písmeno\n        font_size = 10\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n    # Pozice textu\n    x = random.randint(5, max(5, IMG_WIDTH - text_width - 5))\n    y = random.randint(5, max(5, IMG_HEIGHT - text_height - 5))\n\n    # Zvýraznění textu\n    text_color = random.randint(0, 50)\n    outline_color = 200\n    for offset_x in [-1, 0, 1]:\n        for offset_y in [-1, 0, 1]:\n            if offset_x != 0 or offset_y != 0:\n                draw.text((x + offset_x, y + offset_y), text, font=font, fill=outline_color)\n    draw.text((x, y), text, font=font, fill=text_color)\n\n    # Šum a deformace\n    img = add_noise_and_distortion(img)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.635542Z","iopub.execute_input":"2025-03-06T22:02:39.635871Z","iopub.status.idle":"2025-03-06T22:02:39.653830Z","shell.execute_reply.started":"2025-03-06T22:02:39.635846Z","shell.execute_reply":"2025-03-06T22:02:39.652872Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function for splitting labels</font>**","metadata":{}},{"cell_type":"code","source":"def split_labels(labels, label_lengths):\n    \"\"\"Split a flat tensor of labels into a list of label sequences based on lengths.\"\"\"\n    split_labels = []\n    start = 0\n    for length in label_lengths:\n        split_labels.append(labels[start:start + length])\n        start += length\n    return split_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.654667Z","iopub.execute_input":"2025-03-06T22:02:39.654934Z","iopub.status.idle":"2025-03-06T22:02:39.671912Z","shell.execute_reply.started":"2025-03-06T22:02:39.654911Z","shell.execute_reply":"2025-03-06T22:02:39.670843Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function of Beam search decoding</font>**","metadata":{}},{"cell_type":"code","source":"def beam_search_decode(output, idx_to_char, beam_width=BEAM_WIDTH):\n    probs = output.softmax(2).cpu().numpy()  # [T, B, C]\n    T, B, C = probs.shape\n    predictions = []\n    \n    for b in range(B):\n        sequence_probs = [(0.0, [], 1.0)]  # (log_prob, sequence, prob)\n        for t in range(T):\n            new_sequences = []\n            for log_prob, seq, prob in sequence_probs:\n                top_k_probs, top_k_idx = torch.topk(torch.tensor(probs[t, b]), beam_width)\n                for k_prob, k_idx in zip(top_k_probs, top_k_idx):\n                    new_seq = seq + [k_idx.item()]\n                    new_prob = prob * k_prob.item()\n                    new_log_prob = log_prob + np.log(k_prob.item())\n                    new_sequences.append((new_log_prob, new_seq, new_prob))\n            sequence_probs = sorted(new_sequences, key=lambda x: x[0], reverse=True)[:beam_width]\n        \n        # Collapse CTC repeats and remove blanks\n        best_seq = sequence_probs[0][1]  # Highest log_prob sequence\n        decoded = []\n        prev = -1\n        for idx in best_seq:\n            if idx != 0 and idx != prev:  # Skip blanks (0) and repeats\n                decoded.append(idx_to_char.get(idx, ''))\n            prev = idx\n        predictions.append(''.join(decoded) if decoded else '<empty>')\n    \n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.673138Z","iopub.execute_input":"2025-03-06T22:02:39.673465Z","iopub.status.idle":"2025-03-06T22:02:39.688493Z","shell.execute_reply.started":"2025-03-06T22:02:39.673439Z","shell.execute_reply":"2025-03-06T22:02:39.687406Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Custom collate function</font>**","metadata":{}},{"cell_type":"code","source":"def custom_collate_fn(batch):\n    images, labels, label_lengths = zip(*batch)\n    # Stack images (all same size)\n    images = torch.stack(images, dim=0)\n    # Concatenate labels into a flat tensor\n    labels = torch.cat(labels, dim=0)\n    # Convert label_lengths to tensor\n    label_lengths = torch.tensor(label_lengths, dtype=torch.long)\n    return images, labels, label_lengths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.689467Z","iopub.execute_input":"2025-03-06T22:02:39.689795Z","iopub.status.idle":"2025-03-06T22:02:39.707740Z","shell.execute_reply.started":"2025-03-06T22:02:39.689763Z","shell.execute_reply":"2025-03-06T22:02:39.706786Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generování datasetu</font>**","metadata":{}},{"cell_type":"code","source":"def create_synthetic_dataset(num_samples):\n    labels = []\n    for i in range(num_samples):\n        text = generate_random_text(MAX_TEXT_LENGTH)\n        if not text:\n            continue\n        font_path = random.choice(font_files)\n        img = generate_synthetic_image(text, font_path)\n        img_name = f\"img_{i:05d}.png\"\n        img_path = os.path.join(OUTPUT_DIR, img_name)\n        img.save(img_path)\n        labels.append(f\"{img_name}\\t{text}\")  # Use tab (\\t) instead of space\n        if i % 100 == 0:\n            print(f\"Generated {i}/{num_samples} images\")\n\n    if labels:\n        with open(LABELS_FILE, 'w') as f:\n            f.write(\"\\n\".join(labels))\n        print(f\"Dataset generated! Images saved in '{OUTPUT_DIR}', labels in '{LABELS_FILE}'\")\n    else:\n        print(\"No labels generated!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.708652Z","iopub.execute_input":"2025-03-06T22:02:39.708912Z","iopub.status.idle":"2025-03-06T22:02:39.723636Z","shell.execute_reply.started":"2025-03-06T22:02:39.708890Z","shell.execute_reply":"2025-03-06T22:02:39.722619Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Mapping characters to indices and back</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"char_to_idx = {char: idx + 1 for idx, char in enumerate(CHARSET)}  # 0 is reserved for blank (CTC)\nidx_to_char = {idx: char for char, idx in char_to_idx.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.724568Z","iopub.execute_input":"2025-03-06T22:02:39.724828Z","iopub.status.idle":"2025-03-06T22:02:39.744081Z","shell.execute_reply.started":"2025-03-06T22:02:39.724805Z","shell.execute_reply":"2025-03-06T22:02:39.743087Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom dataset</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRDataset(Dataset):\n    def __init__(self, image_dir, labels_file):\n        self.image_dir = image_dir\n        self.labels_file = labels_file\n        self.data = []\n        with open(labels_file, 'r') as f:\n            for line in f:\n                if not line.strip():  # Skip empty lines\n                    continue\n                image_path, label = line.strip().split('\\t')\n                label_length = len(label)\n                self.data.append((image_path, label, label_length))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_path, label, label_length = self.data[idx]\n        image = Image.open(os.path.join(self.image_dir, image_path)).convert('L')\n        image = transforms.ToTensor()(image)\n        label_encoded = torch.tensor([char_to_idx[c] for c in label], dtype=torch.long)\n        return image, label_encoded, label_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.747234Z","iopub.execute_input":"2025-03-06T22:02:39.747510Z","iopub.status.idle":"2025-03-06T22:02:39.763532Z","shell.execute_reply.started":"2025-03-06T22:02:39.747488Z","shell.execute_reply":"2025-03-06T22:02:39.762648Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom CTC Loss with Blank Penalty</font>**\n-------------------\n> CTC Loss with Entropy Regularization","metadata":{}},{"cell_type":"code","source":"class CTCLossWithBlankPenalty(nn.Module):\n    def __init__(self, blank=0, zero_infinity=True, blank_penalty_weight=0.5, entropy_weight=0.5, label_smoothing=0.1):\n        super(CTCLossWithBlankPenalty, self).__init__()\n        self.blank = blank\n        self.zero_infinity = zero_infinity\n        self.blank_penalty_weight = blank_penalty_weight\n        self.entropy_weight = entropy_weight\n        self.label_smoothing = label_smoothing\n\n    def forward(self, log_probs, targets, input_lengths, target_lengths):\n        ctc_loss = F.ctc_loss(\n            log_probs,\n            targets,\n            input_lengths,\n            target_lengths,\n            blank=self.blank,\n            reduction='mean',\n            zero_infinity=self.zero_infinity\n        )\n        blank_probs = log_probs[:, :, self.blank].exp()\n        avg_blank_prob = blank_probs.mean(dim=0).mean()\n        probs = log_probs.exp()\n        entropy = -torch.sum(probs * log_probs, dim=2).mean()\n        total_loss = ctc_loss + self.blank_penalty_weight * avg_blank_prob - self.entropy_weight * entropy\n        return total_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.764740Z","iopub.execute_input":"2025-03-06T22:02:39.765059Z","iopub.status.idle":"2025-03-06T22:02:39.778699Z","shell.execute_reply.started":"2025-03-06T22:02:39.765027Z","shell.execute_reply":"2025-03-06T22:02:39.777768Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Model definition (CNN + RNN + CTC)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRModel(nn.Module):\n    def __init__(self, num_chars):\n        super(OCRModel, self).__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # 32x128 -> 16x64\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # 16x64 -> 8x32\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.Dropout(0.5)\n        )\n        self.linear = nn.Linear(256 * (IMG_HEIGHT // 4), 512)\n        self.rnn = nn.LSTM(\n            input_size=512,\n            hidden_size=256,  # Increased capacity\n            num_layers=3,     # Deeper RNN\n            bidirectional=True,\n            batch_first=True,\n            dropout=0.5\n        )\n        self.fc = nn.Linear(256 * 2, num_chars + 1)\n\n    def forward(self, x):\n        x = self.cnn(x)\n        x = x.permute(0, 3, 1, 2)\n        x = x.reshape(x.size(0), x.size(1), -1)\n        x = self.linear(x)\n        x = self.rnn(x)[0]\n        x = self.fc(x)\n        x = x[:, :MAX_TEXT_LENGTH, :]\n        x = x / TEMPERATURE  # Apply temperature scaling\n        x = x.permute(1, 0, 2)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.779678Z","iopub.execute_input":"2025-03-06T22:02:39.779982Z","iopub.status.idle":"2025-03-06T22:02:39.800087Z","shell.execute_reply.started":"2025-03-06T22:02:39.779948Z","shell.execute_reply":"2025-03-06T22:02:39.799277Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Training</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, device, epoch, warmup_steps=WARMUP_STEPS):\n    model.train()\n    total_loss = 0\n    global_step = epoch * len(train_loader)\n    for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n        imgs, labels = imgs.to(device), labels.to(device)\n        label_lengths = label_lengths.to(device)\n\n        if global_step < warmup_steps:\n            lr_scale = min(1.0, float(global_step + 1) / warmup_steps)\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = LEARNING_RATE * lr_scale\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        outputs = outputs.log_softmax(2)\n\n        batch_size = imgs.size(0)\n        seq_length = outputs.size(0)\n        input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n\n        loss = criterion(outputs, labels, input_lengths, label_lengths)\n        if torch.isnan(loss) or torch.isinf(loss):\n            print(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n            continue\n\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)  # Tightened from 5.0\n        optimizer.step()\n        total_loss += loss.item()\n        global_step += 1\n\n        if batch_idx % 10 == 0:\n            with torch.no_grad():\n                pred_texts = beam_search_decode(outputs, idx_to_char)  # Switch to beam search\n                raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n                blank_probs = outputs[:, :, 0].exp().mean(dim=0).mean().item()\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:3]]\n                print(f\"Batch {batch_idx}, Gradient norm: {grad_norm.item():.4f}\")\n                print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n                print(f\"Avg Blank Probability: {blank_probs:.4f}\")\n                print(f\"Sample predictions: {pred_texts[:3]}\")\n                print(f\"Ground Truth (first 3): {ground_truth}\")\n                print(f\"Raw outputs (first 3): {raw_outputs}\")\n\n    avg_loss = total_loss / len(train_loader)\n    return avg_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.801144Z","iopub.execute_input":"2025-03-06T22:02:39.801492Z","iopub.status.idle":"2025-03-06T22:02:39.826179Z","shell.execute_reply.started":"2025-03-06T22:02:39.801468Z","shell.execute_reply":"2025-03-06T22:02:39.825158Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Inference (prediction)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def decode_prediction(output, idx_to_char):\n    probs = output.softmax(2)\n    max_probs, preds = probs.max(dim=2)\n    preds = preds.cpu().numpy()\n    max_probs = max_probs.cpu().numpy()\n    texts = []\n    for i, (pred, prob) in enumerate(zip(preds.T, max_probs.T)):\n        print(f\"Raw prediction {i} (pre-filter): {pred}, Max probs: {prob}\")\n        # Dynamic threshold: 75th percentile of max probs in this sequence\n        threshold = np.percentile(prob, 75)\n        print(f\"Dynamic threshold for prediction {i}: {threshold:.4f}\")\n        pred_text = []\n        prev = -1\n        for idx, p in zip(pred, prob):\n            if idx != 0 and idx != prev and p > threshold:\n                pred_text.append(idx_to_char.get(idx, ''))\n            prev = idx\n        decoded = ''.join(pred_text)\n        texts.append(decoded if decoded else '<empty>')\n    return texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.827098Z","iopub.execute_input":"2025-03-06T22:02:39.827389Z","iopub.status.idle":"2025-03-06T22:02:39.847046Z","shell.execute_reply.started":"2025-03-06T22:02:39.827365Z","shell.execute_reply":"2025-03-06T22:02:39.845943Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Main launch</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    if not font_files:\n        print(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n    else:\n        create_synthetic_dataset(NUM_SAMPLES)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    full_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n    if len(full_dataset) == 0:\n        print(\"Dataset is empty! Check labels.txt or image directory.\")\n    else:\n        # Curriculum phases with pre-filtering\n        model = OCRModel(num_chars=len(CHARSET)).to(device)\n        criterion = CTCLossWithBlankPenalty(blank=0, zero_infinity=True, blank_penalty_weight=0.5, entropy_weight=ENTROPY_WEIGHT, label_smoothing=0.1)\n        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n\n        best_loss = float('inf')\n        for epoch in range(EPOCHS):\n            # Filter full dataset based on curriculum phase\n            if epoch < 15:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 5]\n            elif epoch < 20:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 7]\n            else:\n                filtered_data = full_dataset.data\n\n            # Create a new dataset with filtered data\n            curr_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n            curr_dataset.data = filtered_data  # Overwrite with filtered data\n\n            # Split into train and validation\n            train_size = int(0.8 * len(curr_dataset))\n            val_size = len(curr_dataset) - train_size\n            train_dataset, val_dataset = torch.utils.data.random_split(curr_dataset, [train_size, val_size])\n\n            # Create data loaders\n            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n            val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n            \n            loss = train_model(model, train_loader, criterion, optimizer, device, epoch)\n            print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss:.4f}\")\n\n            # Validation\n            model.eval()\n            val_loss = 0\n            with torch.no_grad():\n                for imgs, labels, label_lengths in val_loader:\n                    imgs, labels = imgs.to(device), labels.to(device)\n                    label_lengths = label_lengths.to(device)\n                    outputs = model(imgs)\n                    outputs = outputs.log_softmax(2)\n                    seq_length = outputs.size(0)\n                    input_lengths = torch.full((imgs.size(0),), seq_length, dtype=torch.long).to(device)\n                    val_loss += criterion(outputs, labels, input_lengths, label_lengths).item()\n                \n                val_loss /= len(val_loader)\n                pred_texts = beam_search_decode(outputs, idx_to_char)\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:5]]\n                print(f\"Validation Loss: {val_loss:.4f}\")\n                print(\"Validation Predictions:\", pred_texts[:5])\n                print(\"Ground Truth:\", ground_truth)\n\n            model.train()\n            scheduler.step()\n            print(f\"Current Learning Rate: {optimizer.param_groups[0]['lr']}\")\n\n            if val_loss < best_loss:\n                best_loss = val_loss\n                torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'best_ocr_model.pth'))\n\n        torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'final_ocr_model.pth'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:02:39.848001Z","iopub.execute_input":"2025-03-06T22:02:39.848344Z","iopub.status.idle":"2025-03-06T22:12:32.640269Z","shell.execute_reply.started":"2025-03-06T22:02:39.848320Z","shell.execute_reply":"2025-03-06T22:12:32.639177Z"}},"outputs":[{"name":"stdout","text":"Generated 0/5120 images\nGenerated 100/5120 images\nGenerated 200/5120 images\nGenerated 300/5120 images\nGenerated 400/5120 images\nGenerated 500/5120 images\nGenerated 600/5120 images\nGenerated 700/5120 images\nGenerated 800/5120 images\nGenerated 900/5120 images\nGenerated 1000/5120 images\nGenerated 1100/5120 images\nGenerated 1200/5120 images\nGenerated 1300/5120 images\nGenerated 1400/5120 images\nGenerated 1500/5120 images\nGenerated 1600/5120 images\nGenerated 1700/5120 images\nGenerated 1800/5120 images\nGenerated 1900/5120 images\nGenerated 2000/5120 images\nGenerated 2100/5120 images\nGenerated 2200/5120 images\nGenerated 2300/5120 images\nGenerated 2400/5120 images\nGenerated 2500/5120 images\nGenerated 2600/5120 images\nGenerated 2700/5120 images\nGenerated 2800/5120 images\nGenerated 2900/5120 images\nGenerated 3000/5120 images\nGenerated 3100/5120 images\nGenerated 3200/5120 images\nGenerated 3300/5120 images\nGenerated 3400/5120 images\nGenerated 3500/5120 images\nGenerated 3600/5120 images\nGenerated 3700/5120 images\nGenerated 3800/5120 images\nGenerated 3900/5120 images\nGenerated 4000/5120 images\nGenerated 4100/5120 images\nGenerated 4200/5120 images\nGenerated 4300/5120 images\nGenerated 4400/5120 images\nGenerated 4500/5120 images\nGenerated 4600/5120 images\nGenerated 4700/5120 images\nGenerated 4800/5120 images\nGenerated 4900/5120 images\nGenerated 5000/5120 images\nGenerated 5100/5120 images\nDataset generated! Images saved in '/kaggle/working/synthetic_data/images', labels in '/kaggle/working/synthetic_data/labels.txt'\nBatch 0, Gradient norm: 15.8859\nEpoch 1, Batch 0/65, Loss: 7.2420\nAvg Blank Probability: 0.0144\nSample predictions: ['s', 'cs', 'scs']\nGround Truth (first 3): ['*t', 'ID2', 'UIWz']\nRaw outputs (first 3): [[19  3 19  3  3 43 12 12  3 12 19 12 19  3  3 19  3 50  3 12  3  3  3  3\n  19  3 43 19 21 12  3  3]\n [19  3 19 19 19 43  3 21  3 19 19  3 19  3  3 19 43 19  3 19 19  3  3  3\n  19  3 19 19 14 12  3  3]\n [19 19 19 19 19 19 19 19  3 19 19  3 19  3  3 19  3 19 19 19 19 19  3 19\n  19  3 19 19  3  3  3 19]]\nBatch 10, Gradient norm: 13.8497\nEpoch 1, Batch 10/65, Loss: 5.3077\nAvg Blank Probability: 0.0147\nSample predictions: ['cscs', 'cscsle', 'csc']\nGround Truth (first 3): ['fPJu', 'eXmd', '5']\nRaw outputs (first 3): [[ 3  3  3 12  3 19 19  3 43 19  3  3 19  3  3  3 19  3 19  3 19 19  3 19\n   3  3  3  3 21  3  3  3]\n [ 3  3  3 19 19 19 19 19  3 19 19  3  3  3  3  3  3 43 19 19 19 19 19 19\n   3 19  3 19 43  3  3 12]\n [ 3  3 19 19 19 19 19 19  3 19 19 19 19 19  3  3 19 19 19 19 14 19 10 19\n   3 19  3 19 43  3  3 12]]\nBatch 20, Gradient norm: 20.7223\nEpoch 1, Batch 20/65, Loss: 10.2305\nAvg Blank Probability: 0.0148\nSample predictions: ['cscs', 'cQsa', 'uscscsc']\nGround Truth (first 3): ['FT', '7ES1P', 'GOFD']\nRaw outputs (first 3): [[ 3  3 21  3 43 12  3  3  3  3 43  3 43 12 12  3  3  3 21  3 43 43 19 43\n   3  3  3 19 12  3  3  3]\n [ 3  3 19  3 19 12  3 19 19  3 43  3 43 22 16  3 19  3 19  3 43 19 19 43\n   3 48  3 19  3  3  3  3]\n [ 3 43  3  3 19 12  3 19 19 19 19  3 19 22 19  3 19  3 19  3  3 19 19 19\n   3  3 19 19  3 19  3  3]]\nBatch 30, Gradient norm: 19.2344\nEpoch 1, Batch 30/65, Loss: 9.6959\nAvg Blank Probability: 0.0148\nSample predictions: ['usXs', 'cpVcQsRQ', 'sQs']\nGround Truth (first 3): ['AMV', 'VS8', 'a']\nRaw outputs (first 3): [[21  3 19 19 19  3 21 43 43 12  3 12 19 19  3 19  3 12 19  3 19 19  3 12\n  19  3  3  3  3  3  3  3]\n [19 16 43 19 43 19 19 19 43  3  3 19 19 19  3 19 19  3 19  3 19 19  3  3\n   3 19 19  3  3  3  3  3]\n [19 48 19 19 19  3 19 19 19  3  3 19 19 19  3 19 33  3 19 19 19 19 19 19\n  19 19 19 19  3  3 19 19]]\nBatch 40, Gradient norm: 25.9148\nEpoch 1, Batch 40/65, Loss: 13.7555\nAvg Blank Probability: 0.0151\nSample predictions: ['csRPs', 's', 'ls']\nGround Truth (first 3): ['Zp', 'lZljm', '4vx']\nRaw outputs (first 3): [[ 3 19 12 19 12  3  3  3 43 21 19  3  3  3  3  3  3  3  3  3 19 19  3 19\n   3 19  3 19 19  3  3  3]\n [19 19 19 19 43  3 19 19 19 19 19 19 19 12 19 19  3 19  3  3 19 19  3 19\n   3 19  3 19 19  3 19  3]\n [19 19 19 19 43 19 19 19 19 19  3 19 19 19 19 19  3 19  3  3 19 19  3 19\n  19 19  3 19 19 19 19  3]]\nBatch 50, Gradient norm: 11.1189\nEpoch 1, Batch 50/65, Loss: 3.0730\nAvg Blank Probability: 0.0153\nSample predictions: ['lQlcsQc', 'cscV', 'XscsDs']\nGround Truth (first 3): ['3E2zI', 'EasrU', 'QIO']\nRaw outputs (first 3): [[12  3 50 12  3  3 19 12 21  3 19 43 19 12 12 12 19 19  3  3 12  3 19  3\n   3  3  3  3  3 19 12 43]\n [43  3 19  3 19  3 19 19 19  3 19 19 19  3 12 19 19 19 19  3 12 19 19  3\n   3  3  3  3 19 19 12 43]\n [12  3  3 19 19 19 19 43 19 19 19 19 19 19 12 19 19 19 19  3 12 19 48  3\n   3 43 19  3 19 19  3 48]]\nBatch 60, Gradient norm: 19.6586\nEpoch 1, Batch 60/65, Loss: 8.6485\nAvg Blank Probability: 0.0160\nSample predictions: ['cQRsQ', 'csPs', 'cs']\nGround Truth (first 3): ['S', '*D', '4IJI']\nRaw outputs (first 3): [[ 3  3  3 43  3  3 43 12 43  3 19  3  3  3 12  3 12 30 12  3  3 19 19  3\n   3  3 19  3  3  3  3 19]\n [ 3 19 19 43 19  3  3  3 19  3 19  3  3  3 12  3  3  3 19 19 49 19 19  3\n   3  3 19  3  3  3  3 19]\n [ 3 19 19 19 42 19 43  3 19  3 19 19 19  3 30 30  3  3 19 19 19 19 19  3\n   3  3 19  3 42  3 19 19]]\nEpoch 1/10, Loss: 8.1639\nValidation Loss: 8.5136\nValidation Predictions: ['cs', 'cs', 'cs', 'cs', 'cs']\nGround Truth: ['w', 'L', 'EB3IB', 'a', 'svlO']\nCurrent Learning Rate: 6.585651096483481e-07\nBatch 0, Gradient norm: 14.2575\nEpoch 2, Batch 0/65, Loss: 5.1000\nAvg Blank Probability: 0.0161\nSample predictions: ['csncscs', 'cs', 'cs']\nGround Truth (first 3): ['fsE92', '35s', 'AzmNM']\nRaw outputs (first 3): [[ 3  3  3 43  3  3  3 19  3  3  3 33  3  3 19 12  3  3  3  3  3 12 12  3\n   3  3 43  3  3 19 19 14]\n [ 3 19  3  1 19  3 19 19  1  3  3 19  3 50 19  3 19 19 19  3 19 19 19  3\n   3  3 43 19 19 19 19 43]\n [ 3 19  3 19 22 19 19 19  3  3 19  3  3 43 19 19 19 42 19  3  3  3 19  3\n   3  3 19 42 43 19 19 43]]\nBatch 10, Gradient norm: 14.9040\nEpoch 2, Batch 10/65, Loss: 5.5555\nAvg Blank Probability: 0.0165\nSample predictions: ['lVcsacs', 'csnscsc', 'csQcs']\nGround Truth (first 3): ['3lSc', 'q2j', 'f']\nRaw outputs (first 3): [[12  3  3  3  3  3 14 43 19  3  3 21 19 19  3  3  3 50 12 22  3  1  3 43\n  12  3  3 19 43 19  3  3]\n [48 19  3 19 12  3  3 43  3 30 43 19 19 19 19 19 19  3 19  3 19  3  3 43\n  19 19 12 19 43 19 19  3]\n [ 3 14 19 19 14 19 19 19 19  3  3  3 19 19  3 43 19  3 19  3 19 62 19 19\n  19 19 12 19  3 19 19  3]]\nBatch 20, Gradient norm: 27.2647\nEpoch 2, Batch 20/65, Loss: 11.5084\nAvg Blank Probability: 0.0174\nSample predictions: ['cscscs', 'Qsvscse', 'QsQs']\nGround Truth (first 3): ['wiNL', 'efk', 'rc']\nRaw outputs (first 3): [[ 3 43 43  3 14  3 48  1  3 12  3  3  3 43  3 21  1 12 12  3  3 12  3 14\n   3  3  3  3 19  3  3  3]\n [19 19 43  3 14 19 48  1  3  3  3 43 19 19  3  3 43  3  3 14 43 19  3  3\n   3  3 19  3 19  3  3  3]\n [19 19 43  3 19 19 48 43 19  3 19 43  3 19 19  3  3 10 19 43 43 19 43  3\n  19 19 19  3 19 19 19 19]]\nBatch 30, Gradient norm: 19.5242\nEpoch 2, Batch 30/65, Loss: 7.2407\nAvg Blank Probability: 0.0183\nSample predictions: ['cQs', 'sQPsQu', 'sc']\nGround Truth (first 3): ['m--4', 'b', 'E']\nRaw outputs (first 3): [[ 3 19 19 12  3 12  3  3  3 19 12  3 19  3  3  3  3 43  3 12  3  3 19  3\n  12  3 19  3 43  3  3  3]\n [43 19 19  3 22 12 19 43 19 19 19  3 19  3 19  3  3  3  3 21  3 21 19  3\n  50 19 19 19  3  3 19 19]\n [19 19 19 19 19 43 19  3  3 19 19  1 19  3 19  3  3  3  3 19  3 43 19 19\n  19 19 19  3 19  3 19 19]]\nBatch 40, Gradient norm: 18.9236\nEpoch 2, Batch 40/65, Loss: 6.2978\nAvg Blank Probability: 0.0193\nSample predictions: ['css', 'Qsns', 'ncsc']\nGround Truth (first 3): ['u', 'rJnr', 'EkC']\nRaw outputs (first 3): [[ 3 43 14  3  3  3 14 14  3 12  3  3  3  3  3  3  3 19 12  3 43  3  3 19\n  21  3 43  3 19 21  3  3]\n [19 43  3 43  3 19 33 19 14  3  3 19 19  0  3  3 19 19  3  3 43  3  3 44\n   3  3 43  3  3 43  3  3]\n [19 19  3  0  3 19 33  3 19  3  0 19 19 19  3 19 19 19 19  3  3 19  3 19\n  42  3  0  3  3  3  3  3]]\nBatch 50, Gradient norm: 24.6544\nEpoch 2, Batch 50/65, Loss: 8.4177\nAvg Blank Probability: 0.0202\nSample predictions: ['csc', 'cRR', 'css']\nGround Truth (first 3): ['ph', 'vmm', '2oVKs']\nRaw outputs (first 3): [[ 3  3  3  3  3 12 12 43 43 12 43 12  3 12  3 12  3  0  3 19  3  3  3  3\n   3 43 12  3  3 12  3  3]\n [ 3  3 19  3  3  0  3 43 14 19 19  3  3 19  3  3  3 19 43 19 19  3 33 19\n   3 30 12  3  3 19  0 19]\n [ 3  3  0  3  3  0 19 43 14  3  0  3  3 19 19  3 19 19 21 19 19 19 19 19\n  19 43  3  3  3 19 19 43]]\nBatch 60, Gradient norm: 25.0373\nEpoch 2, Batch 60/65, Loss: 8.8157\nAvg Blank Probability: 0.0213\nSample predictions: ['cscsP', 'uc', 'cac']\nGround Truth (first 3): ['Y', 't3eRN', '68JB']\nRaw outputs (first 3): [[ 3 21  3  3  3 12  3  0  0 12 19 12 12 12 12 12 19  3  3 43 43  3  3 43\n  12 19 43 21  3  0 19 22]\n [19  3  1  3  0 19  0  0 19 19  3 19  0  0 19 19 19  3  3  0  0 19 19  3\n   3 14 43  3  3  0 19 19]\n [ 3  3  0 19  0  0 44  0  0  0 19 19  0  0  0 19  3  0  3  0  0 19  0 19\n  19 14 43  0  0  0 19 19]]\nEpoch 2/10, Loss: 7.6029\nValidation Loss: 7.4814\nValidation Predictions: ['c', 'c', 'c', 'c', 'c']\nGround Truth: ['ExKV', 'a', 'CfB', 'vaO6', 'g4V']\nCurrent Learning Rate: 1.2781595990581672e-06\nBatch 0, Gradient norm: 23.8577\nEpoch 3, Batch 0/65, Loss: 7.0357\nAvg Blank Probability: 0.0226\nSample predictions: ['c', '<empty>', 'c']\nGround Truth (first 3): ['Wk', '7', 't']\nRaw outputs (first 3): [[ 3  0  3 12  3 12 19  3  0  3 19  0  0  3  3  3  0 19  3  3  3 12  3 12\n  19 19 43  3  3  3  3  3]\n [ 3  0  3  3  3  0  3  0  0  3 19  0  0  0  0  3  0 19  3 19  3 12 14  3\n  19  0 12  3  0  3  0  0]\n [ 0  0  0  3  0  0  3 44  0  0 19  0  0  3  0  3  0 42  3 19 19 43 19  3\n   0  0  0 51  0  3  3  0]]\nBatch 10, Gradient norm: 21.0110\nEpoch 3, Batch 10/65, Loss: 5.6126\nAvg Blank Probability: 0.0239\nSample predictions: ['c', 'cs', 'c']\nGround Truth (first 3): ['bVBg', 'b', 'vHuv']\nRaw outputs (first 3): [[ 3  3  3  0  3  3 12  3  3  3  3 19  3  3  3  3  3  0  3 30 43  3  3  3\n  43  3  0  3  0 12  0  0]\n [ 0 19  0  0  3  0  0  3  3  0  0 19  3  0  0  0  0  0  3  0  0  3  3  3\n   0  3  0  3  0 12 19  0]\n [ 0  0  0  0  3  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0 42  3\n   0  3  0  0  0  0  0  3]]\nBatch 20, Gradient norm: 20.0246\nEpoch 3, Batch 20/65, Loss: 4.8007\nAvg Blank Probability: 0.0260\nSample predictions: ['<empty>', 'c', '<empty>']\nGround Truth (first 3): ['28', 'Xs00', 'mabv']\nRaw outputs (first 3): [[ 0  3  0  0  0  0  3  3  0  0  3  3  0  3  3  3  3  1 19  0  0  3  3  0\n   0  0  3  0  3  0  0  3]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  3  0  0  0  0  0  0  0\n   0  0  3  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0 19  0  3  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nBatch 30, Gradient norm: 24.8257\nEpoch 3, Batch 30/65, Loss: 5.9479\nAvg Blank Probability: 0.0290\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['GM', 'uP4w', 'eu9WG']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 3 3 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 24.3402\nEpoch 3, Batch 40/65, Loss: 5.4376\nAvg Blank Probability: 0.0319\nSample predictions: ['<empty>', 'c', 'c']\nGround Truth (first 3): ['hTlqB', 'PZ', 'U']\nRaw outputs (first 3): [[0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 24.3706\nEpoch 3, Batch 50/65, Loss: 4.7724\nAvg Blank Probability: 0.0352\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['K', 'Wa', 'Qt']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 42.6809\nEpoch 3, Batch 60/65, Loss: 10.1363\nAvg Blank Probability: 0.0414\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['OWG', 'KHA', 'uHHx']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 3/10, Loss: 6.2248\nValidation Loss: 5.4710\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['7', '7', 'Q1B4w', 'R2Od1', 'Tutu']\nCurrent Learning Rate: 1.8338207956963012e-06\nBatch 0, Gradient norm: 29.6475\nEpoch 4, Batch 0/65, Loss: 5.3233\nAvg Blank Probability: 0.0440\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['UsyDJ', 'xz', '08JgT']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 23.9582\nEpoch 4, Batch 10/65, Loss: 3.2627\nAvg Blank Probability: 0.0511\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['opjk', 'UoU', '35s']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 23.5484\nEpoch 4, Batch 20/65, Loss: 2.2724\nAvg Blank Probability: 0.0614\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['MYRjP', 'kF2m', 'DA0t']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 27.5198\nEpoch 4, Batch 30/65, Loss: 3.0145\nAvg Blank Probability: 0.0751\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['a', 'YK4xP', 'M']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 33.7377\nEpoch 4, Batch 40/65, Loss: 3.9017\nAvg Blank Probability: 0.0925\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['RVi', '*t', 'H11R9']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 32.7960\nEpoch 4, Batch 50/65, Loss: 3.2541\nAvg Blank Probability: 0.1138\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['vBee', 'B', 'vuV']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 27.0888\nEpoch 4, Batch 60/65, Loss: 2.1080\nAvg Blank Probability: 0.1606\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['DaN', 'h', 'svlO']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 4/10, Loss: 3.4540\nValidation Loss: 0.9544\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['p', 'PvZE7', 'xW', 'AZ', 'G*74E']\nCurrent Learning Rate: 2.319087192664086e-06\nBatch 0, Gradient norm: 25.1087\nEpoch 5, Batch 0/65, Loss: 1.4937\nAvg Blank Probability: 0.1812\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['UT', 'Yn', 'WDjHx']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 12.0002\nEpoch 5, Batch 10/65, Loss: 0.0380\nAvg Blank Probability: 0.2275\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['zDLio', 'q', 'X9U']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 2.7702\nEpoch 5, Batch 20/65, Loss: -0.5485\nAvg Blank Probability: 0.3050\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['uV', 'eDCk', 'P']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 4.8755\nEpoch 5, Batch 30/65, Loss: 0.3489\nAvg Blank Probability: 0.3551\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['8', 'oCq', '8']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 5.2150\nEpoch 5, Batch 40/65, Loss: 0.8086\nAvg Blank Probability: 0.3887\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['I27', 'GOIJf', 'GwAJ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 3.5452\nEpoch 5, Batch 50/65, Loss: -0.1723\nAvg Blank Probability: 0.3550\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['tF9a', 'Tw', 'DNuHe']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 3.3737\nEpoch 5, Batch 60/65, Loss: 0.2948\nAvg Blank Probability: 0.3774\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['tmjak', 'vBee', 'Li5wh']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 5/10, Loss: 0.4965\nValidation Loss: 0.5755\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['0', 'vUV', 'h', 'H11R9', 'E']\nCurrent Learning Rate: 2.7188470506254736e-06\nBatch 0, Gradient norm: 11.2275\nEpoch 6, Batch 0/65, Loss: 1.3239\nAvg Blank Probability: 0.3788\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['s0', 'fbFF7', 'U']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 4.1277\nEpoch 6, Batch 10/65, Loss: 0.6542\nAvg Blank Probability: 0.3926\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['y6a', 'E', 'g']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 3.7193\nEpoch 6, Batch 20/65, Loss: 0.0740\nAvg Blank Probability: 0.3830\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['a', '8', '6Wi']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 5.2028\nEpoch 6, Batch 30/65, Loss: 0.3013\nAvg Blank Probability: 0.3466\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['JMa', 'had', 'K']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 3.3625\nEpoch 6, Batch 40/65, Loss: 0.0248\nAvg Blank Probability: 0.3612\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Wb', 'Me5A', 'M38c']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 6.3608\nEpoch 6, Batch 50/65, Loss: -0.5737\nAvg Blank Probability: 0.3613\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['YBIr', 'lCKG', 'mP']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 4.0096\nEpoch 6, Batch 60/65, Loss: 0.2675\nAvg Blank Probability: 0.3972\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['gq', 'uV', '*']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 6/10, Loss: 0.1849\nValidation Loss: 0.4021\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['g', 'DY', 'n*b0g', 'oF0p', '4']\nCurrent Learning Rate: 3.003850716312653e-06\nBatch 0, Gradient norm: 4.8442\nEpoch 7, Batch 0/65, Loss: 0.0947\nAvg Blank Probability: 0.3445\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['EViR', '7iP', '3J-i']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 4.3565\nEpoch 7, Batch 10/65, Loss: -0.2905\nAvg Blank Probability: 0.3589\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['cTmFd', 'Hl03P', 'ulMa']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 5.6599\nEpoch 7, Batch 20/65, Loss: -0.6357\nAvg Blank Probability: 0.3468\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['wL4Gj', 'g', 'EX8B']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 7.5463\nEpoch 7, Batch 30/65, Loss: -0.8102\nAvg Blank Probability: 0.3468\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['0YO', 'qv', 'NY6h']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 13.1679\nEpoch 7, Batch 40/65, Loss: 0.9911\nAvg Blank Probability: 0.3529\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['y', 'e7', 'HJ5V']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 3.4930\nEpoch 7, Batch 50/65, Loss: -0.0620\nAvg Blank Probability: 0.3492\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['bw', 'ae', 'wZQUo']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 3.3867\nEpoch 7, Batch 60/65, Loss: 0.1958\nAvg Blank Probability: 0.3911\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['fsE92', 'uQ', 'Y']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 7/10, Loss: 0.0872\nValidation Loss: 0.4747\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['Yer', 'M', 'PZ', 'b', 'MhL']\nCurrent Learning Rate: 3.1177978943751096e-06\nBatch 0, Gradient norm: 3.2931\nEpoch 8, Batch 0/65, Loss: 0.2641\nAvg Blank Probability: 0.3882\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['bu', 'Q', 'Ugfrg']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 10.9085\nEpoch 8, Batch 10/65, Loss: 1.0547\nAvg Blank Probability: 0.3860\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['X', 'C', '5spE']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 6.2462\nEpoch 8, Batch 20/65, Loss: -0.3084\nAvg Blank Probability: 0.3714\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['zM', 'cq-W', 'l7Ek7']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 7.5831\nEpoch 8, Batch 30/65, Loss: 0.2774\nAvg Blank Probability: 0.3488\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['B', '*qm7', 'W']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 5.0371\nEpoch 8, Batch 40/65, Loss: -0.1625\nAvg Blank Probability: 0.3345\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['9', 'vDYT-', 'GB8']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 3.7182\nEpoch 8, Batch 50/65, Loss: -0.2170\nAvg Blank Probability: 0.3432\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['p-Fy', 'Z', 'qv']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 4.2799\nEpoch 8, Batch 60/65, Loss: -0.4176\nAvg Blank Probability: 0.3483\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['MhL', 'f39L', 'eIS']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 8/10, Loss: -0.0016\nValidation Loss: -0.0511\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['K0', 'DoGn', '0FqRQ', 'uOI5K', 'YRX']\nCurrent Learning Rate: 2.945899869148652e-06\nBatch 0, Gradient norm: 6.8273\nEpoch 9, Batch 0/65, Loss: -0.2392\nAvg Blank Probability: 0.3116\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['68', 'divV', 'OJR']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 4.5421\nEpoch 9, Batch 10/65, Loss: 0.1479\nAvg Blank Probability: 0.3631\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['1b-', 'tO', 'bnem']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 5.4802\nEpoch 9, Batch 20/65, Loss: 0.0183\nAvg Blank Probability: 0.3936\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['8Komw', '30R', 'IV']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 11.6797\nEpoch 9, Batch 30/65, Loss: 0.4317\nAvg Blank Probability: 0.3608\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['2R-', 'lIck', 'dWa']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 7.1816\nEpoch 9, Batch 40/65, Loss: 0.4342\nAvg Blank Probability: 0.3886\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['xFDKk', 'zH', '*DS']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 6.1825\nEpoch 9, Batch 50/65, Loss: -0.3037\nAvg Blank Probability: 0.3573\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['rR', 'cP', 'My']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 5.7812\nEpoch 9, Batch 60/65, Loss: -0.2924\nAvg Blank Probability: 0.3460\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['AfYfg', 'A4b', 'OR']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 9/10, Loss: -0.1293\nValidation Loss: 0.0715\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['Ku', 'gW0h', 'c4l', 'c', 'AySl']\nCurrent Learning Rate: 2.2429163275110118e-06\nBatch 0, Gradient norm: 5.3199\nEpoch 10, Batch 0/65, Loss: -0.6175\nAvg Blank Probability: 0.3383\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['oeJF', 'X', '*']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 11.9210\nEpoch 10, Batch 10/65, Loss: -0.4871\nAvg Blank Probability: 0.3842\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['yKSt', 'R9ha', 'jl9']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 8.5156\nEpoch 10, Batch 20/65, Loss: -0.6208\nAvg Blank Probability: 0.3344\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['OR', 'w', 'c']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 10.5972\nEpoch 10, Batch 30/65, Loss: -0.4252\nAvg Blank Probability: 0.3283\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['1-S5', '9', '1VNHg']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 14.0879\nEpoch 10, Batch 40/65, Loss: -0.6252\nAvg Blank Probability: 0.3634\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['CrO', 'KrS', 'hdv4']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 9.1139\nEpoch 10, Batch 50/65, Loss: -0.5441\nAvg Blank Probability: 0.3592\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['iG', 'yuoLD', '5']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 6.3095\nEpoch 10, Batch 60/65, Loss: -0.4719\nAvg Blank Probability: 0.3212\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Hv', '9', 'e7']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 10/10, Loss: -0.2639\nValidation Loss: -0.0241\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['FUR', '0*iz', 'CSP', 'WN1m', 'cP']\nCurrent Learning Rate: 1e-06\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"def zip_folder_with_shutil(source_folder, output_path):\n    '''Function for zip dir data'''\n    shutil.make_archive(output_path, 'zip', source_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:12:32.641314Z","iopub.execute_input":"2025-03-06T22:12:32.641665Z","iopub.status.idle":"2025-03-06T22:12:32.646013Z","shell.execute_reply.started":"2025-03-06T22:12:32.641639Z","shell.execute_reply":"2025-03-06T22:12:32.645024Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/backgrounds', '/kaggle/working/backgrounds')\nzip_folder_with_shutil('/kaggle/working/synthetic_data', '/kaggle/working/synthetic_data')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:12:32.646880Z","iopub.execute_input":"2025-03-06T22:12:32.647149Z","iopub.status.idle":"2025-03-06T22:12:33.659595Z","shell.execute_reply.started":"2025-03-06T22:12:32.647118Z","shell.execute_reply":"2025-03-06T22:12:33.658649Z"}},"outputs":[],"execution_count":25}]}