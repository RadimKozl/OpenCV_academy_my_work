{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10951507,"sourceType":"datasetVersion","datasetId":6783030}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/radimkzl/pytorch-ocr?scriptVersionId=245483185\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"---------------\n\n# **<font style=\"color:Black\">Create OCR by PyTorch</font>**\n-------------------\n-----------------","metadata":{}},{"cell_type":"code","source":"!pip install python-Levenshtein\n!pip install optuna\n!pip install optuna-dashboard --quiet\n!pip install --upgrade structlog\n!pip install onnx onnxruntime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:08:54.409923Z","iopub.execute_input":"2025-05-12T06:08:54.410138Z","iopub.status.idle":"2025-05-12T06:09:18.396969Z","shell.execute_reply.started":"2025-05-12T06:08:54.410116Z","shell.execute_reply":"2025-05-12T06:09:18.396065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!pip install tensorboard\n!tensorboard --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:18.398281Z","iopub.execute_input":"2025-05-12T06:09:18.398607Z","iopub.status.idle":"2025-05-12T06:09:36.650437Z","shell.execute_reply.started":"2025-05-12T06:09:18.39858Z","shell.execute_reply":"2025-05-12T06:09:36.649297Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport random\nimport time\nimport datetime\nimport math\nimport re\nimport string\nimport getpass\nimport threading\nfrom PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter\nimport numpy as np\nimport cv2\n\nimport logging\nimport structlog\nimport json\n\nfrom typing import Iterator, Tuple\n\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\nfrom tqdm import tqdm\n\nfrom Levenshtein import distance as levenshtein_distance\n\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F  # Add this import\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\n\nimport torch.nn.utils as nn_utils\n\nimport optuna\nfrom optuna.trial import Trial\nfrom optuna import visualization \nfrom optuna_dashboard import run_server\n\nimport onnx\nimport onnxruntime as ort","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:36.651983Z","iopub.execute_input":"2025-05-12T06:09:36.652314Z","iopub.status.idle":"2025-05-12T06:09:47.866829Z","shell.execute_reply.started":"2025-05-12T06:09:36.652278Z","shell.execute_reply":"2025-05-12T06:09:47.866098Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Logger settings</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"LOGS_DIR = os.path.join(\"/kaggle\",\"working\",\"logs\")\nos.makedirs(LOGS_DIR, exist_ok=True)\nlog_file_path = os.path.join(LOGS_DIR, \"train_logs.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:47.86908Z","iopub.execute_input":"2025-05-12T06:09:47.869626Z","iopub.status.idle":"2025-05-12T06:09:47.873854Z","shell.execute_reply.started":"2025-05-12T06:09:47.869599Z","shell.execute_reply":"2025-05-12T06:09:47.872913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configuration of the main logger\ndef configure_main_logger():\n    structlog.configure(\n        processors=[\n            structlog.stdlib.add_log_level,\n            structlog.stdlib.add_logger_name,\n            structlog.processors.TimeStamper(fmt=\"iso\"),\n            structlog.processors.format_exc_info,\n            structlog.processors.JSONRenderer(sort_keys=True),\n        ],\n        context_class=dict,\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        wrapper_class=structlog.stdlib.BoundLogger,\n    )\n\nconfigure_main_logger()  # Function call for configuring the main logger\n\n# Configuration Optuna logger\ndef configure_optuna_logger():\n    structlog.configure(\n        processors=[\n            structlog.stdlib.add_log_level,\n            structlog.stdlib.add_logger_name,\n            structlog.processors.TimeStamper(fmt=\"iso\"),\n            structlog.processors.format_exc_info,\n            structlog.processors.JSONRenderer(sort_keys=True),\n        ],\n        context_class=dict,\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        wrapper_class=structlog.stdlib.BoundLogger,\n    )\n\nconfigure_optuna_logger()  # Function call for Optuna logger configuration\n\n# Configuration Function logger\ndef configure_function_logger():\n    structlog.configure(\n        processors=[\n            structlog.stdlib.add_log_level,\n            structlog.stdlib.add_logger_name,\n            structlog.processors.TimeStamper(fmt=\"iso\"),\n            structlog.processors.format_exc_info,\n            structlog.processors.JSONRenderer(sort_keys=True),\n        ],\n        context_class=dict,\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        wrapper_class=structlog.stdlib.BoundLogger,\n    )\n\nconfigure_function_logger()  # Function call for Optuna logger configuration\n\n# Configuration Final Train logger\ndef configure_finaltrain_logger():\n    \"\"\"Configures the structlog logger to provide structured JSON logs\n    suitable for final train process.\n\n    This function sets up structlog with a predefined set of processors\n    to format log messages as JSON. The configuration includes adding\n    log level and logger name, timestamping in ISO format, formatting\n    exception information, and rendering the final log entry as a sorted\n    JSON string.\n    \"\"\"    \n    structlog.configure(\n        processors=[\n            structlog.stdlib.add_log_level,\n            structlog.stdlib.add_logger_name,\n            structlog.processors.TimeStamper(fmt=\"iso\"),\n            structlog.processors.format_exc_info,\n            structlog.processors.JSONRenderer(sort_keys=True),\n        ],\n        context_class=dict,\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        wrapper_class=structlog.stdlib.BoundLogger,\n    )\n\nconfigure_finaltrain_logger() # Function call for final train logger configuration","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:47.875201Z","iopub.execute_input":"2025-05-12T06:09:47.875442Z","iopub.status.idle":"2025-05-12T06:09:48.020982Z","shell.execute_reply.started":"2025-05-12T06:09:47.875406Z","shell.execute_reply":"2025-05-12T06:09:48.020016Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Custom handler for writing logs to JSON file\nclass RotatingJSONFileHandler(logging.Handler):\n    def __init__(self, directory: str, max_bytes: int = 10*1024*1024, backup_count: int = 5, buffer_size: int = 100):\n        \"\"\"\n        Initializes the handler for spinning JSON logs with buffering.\n\n        Args:\n            directory (str): Directory where log files are stored.\n            max_bytes (int): Maximum file size before rotation (default: 10 MB).\n            backup_count (int): Number of backup files (default: 5).\n            buffer_size (int): Buffer size before writing to disk (default: 100 records).\n        \"\"\"\n        super().__init__()\n        self.directory = directory\n        self.max_bytes = max_bytes\n        self.backup_count = backup_count\n        self.buffer_size = buffer_size\n        self.buffer = []  # Buffer pre log záznamy\n        self.filename = self._get_filename()\n        self.file = open(self.filename, \"a\", encoding=\"utf-8\")\n        os.makedirs(directory, exist_ok=True)  # Zabezpečí vytvorenie adresára\n\n    def _get_filename(self) -> str:\n        \"\"\"Generates a file name with a timestamp.\"\"\"\n        timestamp = time.strftime(\"%Y%m%d%H%M%S\")\n        return os.path.join(self.directory, f\"train_{timestamp}.json\")\n\n    def _should_rotate(self) -> bool:\n        \"\"\"Checks whether a file needs to be rotated based on its size.\"\"\"\n        self.file.flush()\n        try:\n            return os.path.getsize(self.filename) > self.max_bytes\n        except OSError:\n            return False  # Ak súbor neexistuje alebo nie je dostupný, nerotujeme\n\n    def _do_rotate(self) -> None:\n        \"\"\"Performs file rotation.\"\"\"\n        self.file.close()\n        base_name = self.filename.split('.')[0]\n        \n        # Posun starých súborov (napr. train_xxx_1.json -> train_xxx_2.json)\n        for i in range(self.backup_count - 1, 0, -1):\n            old_file = f\"{base_name}_{i}.json\"\n            new_file = f\"{base_name}_{i+1}.json\"\n            if os.path.exists(old_file):\n                os.rename(old_file, new_file)\n        \n        # Premenovanie aktuálneho súboru na _1\n        if os.path.exists(self.filename):\n            os.rename(self.filename, f\"{base_name}_1.json\")\n        \n        self.filename = self._get_filename()\n        self.file = open(self.filename, \"a\", encoding=\"utf-8\")\n\n    def emit(self, record: logging.LogRecord) -> None:\n        \"\"\"\n        It processes the log record and adds it to the buffer. If the buffer is full or the record is critical, \n        it writes the buffer to disk.\n        \"\"\"\n        try:\n            log_entry = self._format_record(record)\n            self.buffer.append(log_entry + \"\\n\")\n\n            # Zápis bufferu na disk, ak je plný alebo ide o varovanie/chybu\n            if len(self.buffer) >= self.buffer_size or record.levelno >= logging.WARNING:\n                self._flush_buffer()\n\n        except Exception as e:\n            print(f\"Error in RotatingJSONFileHandler.emit: {e}\")\n\n    def _format_record(self, record: logging.LogRecord) -> str:\n        \"\"\"Formats the log record into a JSON string.\"\"\"\n        try:\n            # Pokúsi sa parsovať správu ako JSON, ak už je v správnom formáte\n            log_entry = record.getMessage()\n            json.loads(log_entry)\n            return log_entry\n        except json.JSONDecodeError:\n            # Ak nie je JSON, vytvorí štruktúrovaný JSON záznam\n            return json.dumps({\n                \"timestamp\": record.created,\n                \"level\": record.levelname,\n                \"logger\": record.name,\n                \"message\": str(record.msg),\n                \"args\": record.args if record.args else None,\n                \"exc_info\": str(record.exc_info) if record.exc_info else None\n            }, ensure_ascii=False)\n\n    def _flush_buffer(self) -> None:\n        \"\"\"Writes the contents of the buffer to disk and flushes it.\"\"\"\n        if not self.buffer:\n            return\n        \n        if self._should_rotate():\n            self._do_rotate()\n\n        try:\n            self.file.writelines(self.buffer)\n            self.file.flush()\n        except IOError as e:\n            print(f\"Error writing to file {self.filename}: {e}\")\n        \n        self.buffer = []\n\n    def close(self) -> None:\n        \"\"\"Closes the handler and writes the remaining buffer.\"\"\"\n        self._flush_buffer()\n        self.file.close()\n        super().close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:48.022034Z","iopub.execute_input":"2025-05-12T06:09:48.02233Z","iopub.status.idle":"2025-05-12T06:09:48.039416Z","shell.execute_reply.started":"2025-05-12T06:09:48.022304Z","shell.execute_reply":"2025-05-12T06:09:48.038649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the main logger\nmain_logger = structlog.get_logger(\"mainlog\")\n\n# Creating an Optuna logger\noptuna_logger = structlog.get_logger(\"optunalog\")\n\n# Creating an Function logger\nfunction_logger = structlog.get_logger(\"functionlog\")\n\n# Creating an Final Train logger\nfinaltrain_logger = structlog.get_logger(\"finaltrainlog\")\n\n# Set levels for each logger\nlogging.getLogger(\"mainlog\").setLevel(logging.DEBUG) # main_logger\nlogging.getLogger(\"optunalog\").setLevel(logging.DEBUG) # optuna_logger\nlogging.getLogger(\"functionlog\").setLevel(logging.DEBUG) # function_logger\nlogging.getLogger(\"finaltrainlog\").setLevel(logging.DEBUG) # finaltrain_logger\n\n# Creating a RotatingJSONFileHandler\nrotating_json_file_handler = RotatingJSONFileHandler(directory=LOGS_DIR, max_bytes=10*1024*1024, backup_count=5, buffer_size=50)\n\n# Adding RotatingJSONFileHandler to the root logger\nlogging.getLogger().addHandler(rotating_json_file_handler)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:48.040267Z","iopub.execute_input":"2025-05-12T06:09:48.0406Z","iopub.status.idle":"2025-05-12T06:09:48.059044Z","shell.execute_reply.started":"2025-05-12T06:09:48.040532Z","shell.execute_reply":"2025-05-12T06:09:48.058323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"main_logger.info('Star process of notebook.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:48.059895Z","iopub.execute_input":"2025-05-12T06:09:48.060183Z","iopub.status.idle":"2025-05-12T06:09:48.079656Z","shell.execute_reply.started":"2025-05-12T06:09:48.060159Z","shell.execute_reply":"2025-05-12T06:09:48.078942Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Hyperparameters</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"seed = 3\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:48.080504Z","iopub.execute_input":"2025-05-12T06:09:48.080781Z","iopub.status.idle":"2025-05-12T06:09:48.101216Z","shell.execute_reply.started":"2025-05-12T06:09:48.080753Z","shell.execute_reply":"2025-05-12T06:09:48.100221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"FINAL_TRAINING = True  # Set to True for final training, False for Optuna optimization\nPRETRAINED_MODEL_PATH = None\nOUTPUT_DIR = os.path.join('/kaggle','working','synthetic_data','images')\nTENSORBOARD_DIR = os.path.join('/kaggle','working','runs')\nOPTUNA_DIR = os.path.join('/kaggle','working','optuna')\nMODEL_DIR = os.path.join('/kaggle','working','model_dir')\nLABELS_FILE = os.path.join('/kaggle','working','synthetic_data','labels.txt')\nNUM_SAMPLES = 20480  # Number of images generated\nIMG_WIDTH = 128 #256\nIMG_HEIGHT = 32 #64\nBATCH_SIZE = 32\nEPOCHS = 10\nFINAL_EPOCHS = 50\nLEARNING_RATE = 3e-4\nWEIGHT_DECAY =  1e-4\nWARMUP_STEPS = 2000\nTEMPERATURE =  1.0\nCTC_ENTROPY_WEIGHT = 0.2\nCTC_LABEL_SMOOTHING = 0.1\nCTC_BLANK_PENALTY_WEIGHT = 0.2\nBSD_BEAM_WIDTH = 20\nBSD_BLANK_PENALTY =  -0.2\nBSD_LENGTH_PENALTY = -1.0\nGRADIENT_CLIPPING_VALUE = 5.0\nMAX_SEQ_LENGTH = 9\nCHARSET = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789- \"  # Characters used in license plates\nFONT_DIR = os.path.join('/kaggle','input','google-fonts','GoogleFontScripts') # Folder with TrueType fonts (.ttf)\nBACKGROUND_DIR = os.path.join('/kaggle','working','backgrounds')  # New folder for background (optional)\nNUMBER_BACKGROUND_IMAGE = 2000\nNUMBER_OF_OPTUNA_TRIALS = 100\nGRADIENT_NORM_TRESHOLD = 350\nNUMBER_OF_BATCH_REPORT = 25","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:48.102043Z","iopub.execute_input":"2025-05-12T06:09:48.102281Z","iopub.status.idle":"2025-05-12T06:09:48.108122Z","shell.execute_reply.started":"2025-05-12T06:09:48.102263Z","shell.execute_reply":"2025-05-12T06:09:48.107289Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"main_logger.info('Set Base hyperparameters.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:48.108869Z","iopub.execute_input":"2025-05-12T06:09:48.109128Z","iopub.status.idle":"2025-05-12T06:09:48.12903Z","shell.execute_reply.started":"2025-05-12T06:09:48.109108Z","shell.execute_reply":"2025-05-12T06:09:48.128369Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Utils support functions</font>**\n-------------------","metadata":{}},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Create output folders</font>**","metadata":{}},{"cell_type":"code","source":"os.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(BACKGROUND_DIR, exist_ok=True)\nos.makedirs(TENSORBOARD_DIR, exist_ok=True)\nos.makedirs(OPTUNA_DIR, exist_ok=True)\n\n# Creates a new file\nwith open(LABELS_FILE, 'w') as fp:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:48.129985Z","iopub.execute_input":"2025-05-12T06:09:48.130237Z","iopub.status.idle":"2025-05-12T06:09:48.144429Z","shell.execute_reply.started":"2025-05-12T06:09:48.130208Z","shell.execute_reply":"2025-05-12T06:09:48.143769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"main_logger.info('Create dirs structure.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:48.147583Z","iopub.execute_input":"2025-05-12T06:09:48.147836Z","iopub.status.idle":"2025-05-12T06:09:48.158416Z","shell.execute_reply.started":"2025-05-12T06:09:48.147816Z","shell.execute_reply":"2025-05-12T06:09:48.157615Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load the font list (add the paths to the .ttf files to the \"fonts\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"font_files = [\n    os.path.join(FONT_DIR, f) for f in os.listdir(FONT_DIR) \n    if f.endswith('.ttf') and os.path.isfile(os.path.join(FONT_DIR, f))\n]\nif not font_files:\n    raise FileNotFoundError(\"No fonts found in 'fonts' folder. Add .ttf files!\")\n    main_logger.error(\"No fonts found in 'fonts' folder. Add .ttf files!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:48.160315Z","iopub.execute_input":"2025-05-12T06:09:48.160574Z","iopub.status.idle":"2025-05-12T06:09:51.488034Z","shell.execute_reply.started":"2025-05-12T06:09:48.160554Z","shell.execute_reply":"2025-05-12T06:09:51.487107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"main_logger.info('Load google-fonts files from dataset.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:51.489281Z","iopub.execute_input":"2025-05-12T06:09:51.489684Z","iopub.status.idle":"2025-05-12T06:09:51.493145Z","shell.execute_reply.started":"2025-05-12T06:09:51.489646Z","shell.execute_reply":"2025-05-12T06:09:51.492539Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generating a simple gradient background</font>**","metadata":{}},{"cell_type":"code","source":"def generate_gradient_background(filename, size=(128, 32)):\n    \"\"\"\n    Generates a gradient background image and saves it to a specified file.\n\n    This function creates a grayscale image with a soft gradient effect, where the color transitions\n    from a lighter gray at the top to a slightly darker gray at the bottom. The image is then blurred\n    to create a smooth background effect.\n\n    Args:\n        filename (str): The name of the file where the generated image will be saved.\n        size (tuple, optional): The dimensions (width, height) of the generated image. Defaults to (128, 32).\n\n    The function uses the Python Imaging Library (PIL) to create and manipulate the image.\n    \"\"\"\n    img = Image.new('L', size, color=230)  # Lighter gray as a base\n    draw = ImageDraw.Draw(img)\n    for y in range(size[1]):\n        # Soft gradient with low contrast\n        color = int(230 - 20 * (y / size[1]))  # From light gray to slightly darker\n        draw.line([(0, y), (size[0], y)], fill=color)\n    # Background blur\n    img = img.filter(ImageFilter.GaussianBlur(radius=2))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:51.494077Z","iopub.execute_input":"2025-05-12T06:09:51.494373Z","iopub.status.idle":"2025-05-12T06:09:51.510554Z","shell.execute_reply.started":"2025-05-12T06:09:51.494342Z","shell.execute_reply":"2025-05-12T06:09:51.509631Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generate a background with noise (paper texture)</font>**","metadata":{}},{"cell_type":"code","source":"def generate_paper_texture(filename, size=(128, 32)):\n    img = Image.new('L', size, color=220)  # Lighter gray\n    noise = np.random.normal(0, 5, size).astype(np.uint8)  # Less noise\n    noise_img = Image.fromarray(noise)\n    img.paste(noise_img, (0, 0), noise_img)\n    # Blur for a softer effect\n    img = img.filter(ImageFilter.GaussianBlur(radius=1.5))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:51.511423Z","iopub.execute_input":"2025-05-12T06:09:51.511725Z","iopub.status.idle":"2025-05-12T06:09:51.52337Z","shell.execute_reply.started":"2025-05-12T06:09:51.511696Z","shell.execute_reply":"2025-05-12T06:09:51.522714Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Creating multiple backgrounds</font>**","metadata":{}},{"cell_type":"code","source":"for i in range(NUMBER_BACKGROUND_IMAGE):\n    generate_gradient_background(f\"gradient_{i}.png\")\n    generate_paper_texture(f\"paper_{i}.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:51.524292Z","iopub.execute_input":"2025-05-12T06:09:51.524608Z","iopub.status.idle":"2025-05-12T06:09:55.364333Z","shell.execute_reply.started":"2025-05-12T06:09:51.524579Z","shell.execute_reply":"2025-05-12T06:09:55.363661Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"main_logger.info('Background images was generated.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.36516Z","iopub.execute_input":"2025-05-12T06:09:55.365414Z","iopub.status.idle":"2025-05-12T06:09:55.36964Z","shell.execute_reply.started":"2025-05-12T06:09:55.365392Z","shell.execute_reply":"2025-05-12T06:09:55.368695Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load backgrounds (optional, add images to the \"backgrounds\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"background_files = (\n    [os.path.join(BACKGROUND_DIR, f) for f in os.listdir(BACKGROUND_DIR) \n     if f.endswith(('.png', '.jpg', '.jpeg'))] if os.path.exists(BACKGROUND_DIR) else []\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.370729Z","iopub.execute_input":"2025-05-12T06:09:55.371104Z","iopub.status.idle":"2025-05-12T06:09:55.408421Z","shell.execute_reply.started":"2025-05-12T06:09:55.371066Z","shell.execute_reply":"2025-05-12T06:09:55.407883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"main_logger.info('Background images was loaded for useing.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.409129Z","iopub.execute_input":"2025-05-12T06:09:55.409409Z","iopub.status.idle":"2025-05-12T06:09:55.413021Z","shell.execute_reply.started":"2025-05-12T06:09:55.409387Z","shell.execute_reply":"2025-05-12T06:09:55.412083Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">List of setting type of formats</font>**","metadata":{}},{"cell_type":"code","source":"formats = {\n    \"Czech Republic\": [\n        {\n            \"regex\": r\"[A-Z]\\d[A-Z]{5}\",\n            \"description\": \"One letter, one digit, five letters\",\n            \"weight\": 0.95  # Kept the same\n        },\n        {\n            \"regex\": r\"[A-Z]\\d-[A-Z]{5}\",\n            \"description\": \"One letter, one digit, dash, five letters\",\n            \"weight\": 0.05  # Kept the same\n        }\n    ],\n    \"Germany\": [\n        {\n            \"regex\": r\"[A-Z]-[A-Z]{2} \\d{3}\",\n            \"description\": \"One letter, dash, two letters, space, three digits\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce space and dash frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{4}\\d{2}\",\n            \"description\": \"Four letters, two digits\",\n            \"weight\": 0.15  # Increased from 0.1 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{5}\\d{1}\",\n            \"description\": \"Five letters, one digit\",\n            \"weight\": 0.7  # Kept the same\n        }\n    ],\n    \"France\": [\n        {\n            \"regex\": r\"[A-Z]{2}-\\d{3}-[A-Z]{2}\",\n            \"description\": \"Two letters, dash, three digits, dash, two letters\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{2} \\d{3} [A-Z]{2}\",\n            \"description\": \"Two letters, space, three digits, space, two letters\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{2}\\d{3}[A-Z]{2}\",\n            \"description\": \"Two letters, three digits, two letters\",\n            \"weight\": 0.15  # Increased from 0.1 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{4}\\d{2}\",\n            \"description\": \"Four letters, two digits\",\n            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{5}\\d{1}\",\n            \"description\": \"Five letters, one digit\",\n            \"weight\": 0.45  # Kept the same\n        }\n    ],\n    \"United Kingdom\": [\n        {\n            \"regex\": r\"[A-Z]{2}\\d{2} [A-Z]{3}\",\n            \"description\": \"Two letters, two digits, space, three letters\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{2}\\d{2}[A-Z]{3}\",\n            \"description\": \"Two letters, two digits, three letters\",\n            \"weight\": 0.15  # Increased from 0.1 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{4}\\d{1}\",\n            \"description\": \"Four letters, one digit\",\n            \"weight\": 0.7  # Kept the same\n        }\n    ],\n    \"Brazil\": [\n        {\n            \"regex\": r\"\\d{3}[A-Z]{4}\",\n            \"description\": \"Three digits, four letters\",\n            \"weight\": 0.35  # Increased from 0.3 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{4}\\d{2}\",\n            \"description\": \"Four letters, two digits\",\n            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{3}-\\d{2}-[A-Z]{2}\",\n            \"description\": \"Three letters, dash, two digits, dash, two letters\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{5}\\d{1}\",\n            \"description\": \"Five letters, one digit\",\n            \"weight\": 0.4  # Reduced from 0.45 to balance overall distribution\n        }\n    ],\n    \"Australia\": [\n        {\n            \"regex\": r\"[A-Z]{3}-\\d{3}\",\n            \"description\": \"Three letters, dash, three digits\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{3} \\d{3}\",\n            \"description\": \"Three letters, space, three digits\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{4}\\d{2}\",\n            \"description\": \"Four letters, two digits\",\n            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{5}\\d{1}\",\n            \"description\": \"Five letters, one digit\",\n            \"weight\": 0.6  # Increased from 0.55 to maintain letter frequency\n        }\n    ],\n    \"Austria\": [\n        {\n            \"regex\": r\"\\d[A-Z]{4}\\d{2}\",\n            \"description\": \"One digit, four letters, two digits\",\n            \"weight\": 0.35  # Increased from 0.3 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{5}\\d{1}\",\n            \"description\": \"Five letters, one digit\",\n            \"weight\": 0.5  # Kept the same\n        },\n        {\n            \"regex\": r\"\\d-[A-Z]{4}-\\d{2}\",\n            \"description\": \"One digit, dash, four letters, dash, two digits\",\n            \"weight\": 0.05  # Reduced from 0.1 to reduce dash frequency\n        },\n        {\n            \"regex\": r\"\\d [A-Z]{4} \\d{2}\",\n            \"description\": \"One digit, space, four letters, space, two digits\",\n            \"weight\": 0.1  # Kept the same\n        }\n    ],\n    \"Italy\": [\n        {\n            \"regex\": r\"[A-Z]{2} \\d{3}[A-Z]{2}\",\n            \"description\": \"Two letters, space, three digits, space, two letters\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{2}-\\d{3}[A-Z]{2}\",\n            \"description\": \"Two letters, dash, three digits, two letters\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{2}\\d{3}[A-Z]{2}\",\n            \"description\": \"Two letters, three digits, two letters\",\n            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{4}\\d{2}\",\n            \"description\": \"Four letters, two digits\",\n            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{5}\\d{1}\",\n            \"description\": \"Five letters, one digit\",\n            \"weight\": 0.5  # Kept the same\n        }\n    ],\n    \"Belgium\": [\n        {\n            \"regex\": r\"\\d-[A-Z]{3}-\\d{3}\",\n            \"description\": \"One digit, dash, three letters, dash, three digits\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{4}\\d{2}\",\n            \"description\": \"Four letters, two digits\",\n            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{5}\\d{1}\",\n            \"description\": \"Five letters, one digit\",\n            \"weight\": 0.55  # Kept the same\n        },\n        {\n            \"regex\": r\"[A-Z] \\d{3} [A-Z]{3}\",\n            \"description\": \"One letter, space, three digits, space, three letters\",\n            \"weight\": 0.2  # Kept the same\n        }\n    ],\n    \"Spain\": [\n        {\n            \"regex\": r\"[A-Z]{4}\\d{3}\",\n            \"description\": \"Four letters, three digits\",\n            \"weight\": 0.35  # Increased from 0.3 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{4}-\\d{2}-[A-Z]\",\n            \"description\": \"Four letters, dash, two digits, dash, one letter\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{5}\\d{1}\",\n            \"description\": \"Five letters, one digit\",\n            \"weight\": 0.4  # Kept the same\n        },\n        {\n            \"regex\": r\"[A-Z]{4} \\d{2} [A-Z]\",\n            \"description\": \"Four letters, space, two digits, space, one letter\",\n            \"weight\": 0.1  # Kept the same\n        }\n    ],\n    \"Hungary\": [\n        {\n            \"regex\": r\"[A-Z] \\d{2} [A-Z]{3}\",\n            \"description\": \"One letter, space, two digits, space, three letters\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n        },\n        {\n            \"regex\": r\"[A-Z]\\d{2}[A-Z]{3}\",\n            \"description\": \"One letter, two digits, three letters\",\n            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{4}\\d{1}\",\n            \"description\": \"Four letters, one digit\",\n            \"weight\": 0.65  # Kept the same\n        },\n        {\n            \"regex\": r\"[A-Z]\\d-[A-Z]{3}-\\d\",\n            \"description\": \"One letter, one digit, dash, three letters, dash, one digit\",\n            \"weight\": 0.1  # Kept the same\n        }\n    ],\n    \"Norway\": [\n        {\n            \"regex\": r\"\\d{2}[A-Z]{5}\",\n            \"description\": \"Two digits, five letters\",\n            \"weight\": 0.35  # Increased from 0.3 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{2}-\\d{2}-[A-Z]{3}\",\n            \"description\": \"Two letters, dash, two digits, dash, three letters\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{2} \\d{2} [A-Z]{3}\",\n            \"description\": \"Two letters, space, two digits, space, three letters\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{5}\\d{1}\",\n            \"description\": \"Five letters, one digit\",\n            \"weight\": 0.35  # Increased from 0.3 to maintain letter frequency\n        }\n    ],\n    \"Sweden\": [\n        {\n            \"regex\": r\"[A-Z]{3} \\d{3}\",\n            \"description\": \"Three letters, space, three digits\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{4}\\d{2}\",\n            \"description\": \"Four letters, two digits\",\n            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{5}\\d{1}\",\n            \"description\": \"Five letters, one digit\",\n            \"weight\": 0.75  # Kept the same\n        }\n    ],\n    \"Netherlands\": [\n        {\n            \"regex\": r\"[A-Z]{2}-\\d{2}-[A-Z]{2}\",\n            \"description\": \"Two letters, dash, two digits, dash, two letters\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{2}\\d{2}[A-Z]{2}\",\n            \"description\": \"Two letters, two digits, two letters\",\n            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{4}\\d{1}\",\n            \"description\": \"Four letters, one digit\",\n            \"weight\": 0.55  # Kept the same\n        },\n        {\n            \"regex\": r\"[A-Z]{2} \\d{2} [A-Z]{2}\",\n            \"description\": \"Two letters, space, two digits, space, two letters\",\n            \"weight\": 0.2  # Reduced from 0.2 to maintain balance\n        }\n    ],\n    \"Serbia\": [\n        {\n            \"regex\": r\"[A-Z]{2} \\d{3}-[A-Z]{2}\",\n            \"description\": \"Two letters, space, three digits, dash, two letters\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce space and dash frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{2}\\d{3}[A-Z]{2}\",\n            \"description\": \"Two letters, three digits, two letters\",\n            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{4}\\d{2}\",\n            \"description\": \"Four letters, two digits\",\n            \"weight\": 0.05  # Kept the same\n        },\n        {\n            \"regex\": r\"[A-Z]{5}\\d{1}\",\n            \"description\": \"Five letters, one digit\",\n            \"weight\": 0.7  # Kept the same\n        }\n    ],\n    \"Ukraine\": [\n        {\n            \"regex\": r\"\\d{2}[A-Z]{4}\\d{2}\",\n            \"description\": \"Two digits, four letters, two digits\",\n            \"weight\": 0.35  # Increased from 0.3 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{5}\\d{1}\",\n            \"description\": \"Five letters, one digit\",\n            \"weight\": 0.5  # Kept the same\n        },\n        {\n            \"regex\": r\"\\d{2}-[A-Z]{4}-\\d\",\n            \"description\": \"Two digits, dash, four letters, dash, one digit\",\n            \"weight\": 0.05  # Reduced from 0.1 to reduce dash frequency\n        },\n        {\n            \"regex\": r\"\\d{2} [A-Z]{4} \\d\",\n            \"description\": \"Two digits, space, four letters, space, one digit\",\n            \"weight\": 0.1  # Kept the same\n        }\n    ],\n    \"USA_v1\": [\n        {\n            \"regex\": r\"[A-Z]{4}\\d{2}\",\n            \"description\": \"Four letters, two digits\",\n            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{5}\\d{1}\",\n            \"description\": \"Five letters, one digit\",\n            \"weight\": 0.9  # Reduced from 0.95 to balance overall distribution\n        }\n    ],\n    \"USA_v2\": [\n        {\n            \"regex\": r\"\\d{3}-[A-Z]{3}\",\n            \"description\": \"Three digits, dash, three letters\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n        },\n        {\n            \"regex\": r\"\\d{3} [A-Z]{3}\",\n            \"description\": \"Three digits, space, three letters\",\n            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{4}\\d{2}\",\n            \"description\": \"Four letters, two digits\",\n            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n        },\n        {\n            \"regex\": r\"[A-Z]{5}\\d{1}\",\n            \"description\": \"Five letters, one digit\",\n            \"weight\": 0.6  # Increased from 0.55 to maintain letter frequency\n        }\n    ]\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.413925Z","iopub.execute_input":"2025-05-12T06:09:55.414113Z","iopub.status.idle":"2025-05-12T06:09:55.430385Z","shell.execute_reply.started":"2025-05-12T06:09:55.414097Z","shell.execute_reply":"2025-05-12T06:09:55.429513Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Random text generation function</font>**","metadata":{}},{"cell_type":"code","source":"def generate_random_license_plate_from_regex(regex_format):\n    license_plate = \"\"\n    i = 0\n    \n    while i < len(regex_format):\n        char = regex_format[i]\n\n        # Handle escaped sequences like \\d or \\w\n        if char == '\\\\' and i + 1 < len(regex_format):\n            next_char = regex_format[i + 1]\n            repeat = 1\n            i += 2  # Skip backslash and the next character\n\n            # Check for repetition pattern {n}\n            if i < len(regex_format) and regex_format[i] == '{':\n                match = re.match(r\"\\{(\\d+)\\}\", regex_format[i:])\n                if match:\n                    repeat = int(match.group(1))\n                    i += len(match.group(0))  # Skip {n}\n\n            if next_char == 'd':\n                license_plate += ''.join(random.choice(string.digits) for _ in range(repeat))\n            elif next_char == 'w':\n                license_plate += ''.join(random.choice(string.ascii_uppercase) for _ in range(repeat))\n            else:\n                license_plate += next_char  # Treat as literal if not \\d or \\w\n\n        # Handle character classes like [A-Z] or [0-9]\n        elif char == '[':\n            j = regex_format.find(']', i)\n            if j != -1:\n                options = regex_format[i+1:j]\n                i = j + 1  # Move past ]\n\n                repeat = 1\n                if i < len(regex_format) and regex_format[i] == '{':\n                    match = re.match(r\"\\{(\\d+)\\}\", regex_format[i:])\n                    if match:\n                        repeat = int(match.group(1))\n                        i += len(match.group(0))  # Skip {n}\n\n                if options == 'A-Z':\n                    license_plate += ''.join(random.choice(string.ascii_uppercase) for _ in range(repeat))\n                elif options == '0-9':\n                    license_plate += ''.join(random.choice(string.digits) for _ in range(repeat))\n                else:\n                    license_plate += ''.join(random.choice(options) for _ in range(repeat))\n            else:\n                license_plate += char  # Unmatched [, treat as literal\n\n        # Handle literal characters (e.g., space, dash)\n        else:\n            license_plate += char\n            i += 1\n\n    return license_plate","metadata":{"execution":{"iopub.status.busy":"2025-05-12T06:09:55.431183Z","iopub.execute_input":"2025-05-12T06:09:55.431562Z","iopub.status.idle":"2025-05-12T06:09:55.443842Z","shell.execute_reply.started":"2025-05-12T06:09:55.431496Z","shell.execute_reply":"2025-05-12T06:09:55.443127Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_random_license_plate(formats):\n    # Choose a random country\n    country = random.choice(list(formats.keys()))\n    country_formats = formats[country]\n\n    # If the format is a list (multiple options), select by weight\n    if isinstance(country_formats, list):\n        weights = [fmt[\"weight\"] for fmt in country_formats]\n        chosen_format = random.choices(country_formats, weights=weights, k=1)[0]\n        regex_format = chosen_format[\"regex\"]\n    else:\n        regex_format = country_formats[\"regex\"]\n\n    # Generate license plate according to selected regex\n    license_plate = generate_random_license_plate_from_regex(regex_format)\n    return license_plate, country","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.444601Z","iopub.execute_input":"2025-05-12T06:09:55.444913Z","iopub.status.idle":"2025-05-12T06:09:55.461032Z","shell.execute_reply.started":"2025-05-12T06:09:55.444871Z","shell.execute_reply":"2025-05-12T06:09:55.46032Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test code\nfor _ in range(10):\n    license_plate, country = generate_random_license_plate(formats)\n    print(f\"Country: {country}, License Plate: {license_plate}\")\n    main_logger.debug(f'Testing generation of Licence Plate text\\n: Country: {country}, License Plate: {license_plate}\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.461872Z","iopub.execute_input":"2025-05-12T06:09:55.462149Z","iopub.status.idle":"2025-05-12T06:09:55.482965Z","shell.execute_reply.started":"2025-05-12T06:09:55.462121Z","shell.execute_reply":"2025-05-12T06:09:55.481753Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function for clean labels of file</font>**\n- Open labels.txt and ensure that all labels only contain characters from CHARSET. If there are any invalid characters, clean the file:","metadata":{}},{"cell_type":"code","source":"def clean_labels_file(labels_file, valid_chars):\n    \"\"\"\n    Cleans the labels file by removing invalid characters from each label.\n\n    Args:\n        labels_file (str): Path to the labels file.\n        valid_chars (set): Set of valid characters allowed in labels.\n    \"\"\"\n    with open(labels_file, 'r') as f:\n        lines = f.readlines()\n    \n    cleaned_lines = []\n    num_modified = 0\n    num_removed = 0\n    for line in lines:\n        parts = line.strip().split('\\t')\n        if len(parts) != 2:\n            num_removed += 1\n            continue\n        img_path, label = parts\n        cleaned_label = ''.join(c for c in label if c in valid_chars)\n        if cleaned_label:  # Only keep non-empty labels\n            if cleaned_label != label:\n                num_modified += 1\n            cleaned_lines.append(f\"{img_path}\\t{cleaned_label}\\n\")\n        else:\n            num_removed += 1\n    \n    with open(labels_file, 'w') as f:\n        f.writelines(cleaned_lines)\n    \n    print(f\"Cleaned {labels_file}: {num_modified} labels modified, {num_removed} labels removed.\")\n    function_logger.info(f\"Cleaned {labels_file}: {num_modified} labels modified, {num_removed} labels removed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.483848Z","iopub.execute_input":"2025-05-12T06:09:55.48408Z","iopub.status.idle":"2025-05-12T06:09:55.496517Z","shell.execute_reply.started":"2025-05-12T06:09:55.484052Z","shell.execute_reply":"2025-05-12T06:09:55.494924Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Functions for adding noise and distortions</font>**","metadata":{}},{"cell_type":"code","source":"def add_noise_and_distortion(img):\n    \"\"\"\n    Adds random noise and distortion effects to an input image.\n\n    This function takes an image as input and applies random Gaussian noise, rotation, and perspective distortion to simulate real-world imperfections. \n    The modifications are applied randomly to create variability in the output.\n\n    Args:\n        img (PIL.Image.Image): The input image to which noise and distortion will be applied.\n\n    Returns:\n        PIL.Image.Image: The modified image with added noise and distortion effects.\n\n    The function uses NumPy for array manipulations and OpenCV for image transformations.\n    \"\"\"\n    img_array = np.array(img)\n\n    # Add Gaussian noise\n    if random.random() > 0.5:\n        noise = np.random.normal(0, random.randint(10, 25), img_array.shape).astype(np.uint8)\n        img_array = cv2.add(img_array, noise)\n\n    # Apply rotation\n    angle = random.uniform(-5, 5)\n    rows, cols = img_array.shape[:2]\n    M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n    img_array = cv2.warpAffine(img_array, M, (cols, rows))\n\n    # Apply perspective distortion\n    src_points = np.float32([[0, 0], [cols-1, 0], [0, rows-1], [cols-1, rows-1]])\n    dst_points = np.float32([\n        [random.uniform(0, 5), random.uniform(0, 5)],\n        [cols-1-random.uniform(0, 5), random.uniform(0, 5)],\n        [random.uniform(0, 5), rows-1-random.uniform(0, 5)],\n        [cols-1-random.uniform(0, 5), rows-1-random.uniform(0, 5)]\n    ])\n    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n    img_array = cv2.warpPerspective(img_array, matrix, (cols, rows))\n\n    return Image.fromarray(img_array)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.497185Z","iopub.execute_input":"2025-05-12T06:09:55.497517Z","iopub.status.idle":"2025-05-12T06:09:55.515378Z","shell.execute_reply.started":"2025-05-12T06:09:55.497483Z","shell.execute_reply":"2025-05-12T06:09:55.514164Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Improved image generation feature</font>**","metadata":{}},{"cell_type":"code","source":"def generate_synthetic_image(text, font_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n    \"\"\"\n    Generates a synthetic image with specified text and font, optionally using a background image.\n\n    This function creates an image with a given text rendered using a specified font. \n    The image can have a background selected from available background files or a generated gradient background. \n    The text is positioned randomly within the image, and the function ensures that the text fits within the image dimensions by adjusting the font size or shortening the text if necessary. \n    The image is then modified with noise and distortion effects to simulate real-world conditions.\n\n    Args:\n        text (str): The text to be rendered on the image.\n        font_path (str): The file path to the TrueType font to be used for rendering the text.\n        img_size (tuple, optional): The dimensions (width, height) of the generated image. Defaults to (IMG_WIDTH, IMG_HEIGHT).\n\n    Returns:\n        PIL.Image.Image: The generated synthetic image with the specified text and effects.\n\n    The function uses the Python Imaging Library (PIL) for image creation and manipulation, and it relies on the `add_noise_and_distortion` function to apply additional effects to the image.\n    \"\"\"\n    # Background\n    if background_files:\n        bg_path = random.choice(background_files)\n        img = Image.open(bg_path).convert('L').resize(img_size)\n    else:\n        img = Image.new('L', img_size, color=230)\n        draw = ImageDraw.Draw(img)\n        for y in range(img_size[1]):\n            color = int(230 - 20 * (y / img_size[1]))\n            draw.line([(0, y), (img_size[0], y)], fill=color)\n        img = img.filter(ImageFilter.GaussianBlur(radius=2))\n\n    draw = ImageDraw.Draw(img)\n\n    # Iterative font and text editing\n    font_size = random.randint(20, min(IMG_HEIGHT-2, 28))\n    max_attempts = 5  # Limiting the number of attempts\n    for attempt in range(max_attempts):\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n        if text_width <= IMG_WIDTH - 10:  # Text will fit\n            break\n        elif len(text) > 1:  # Shorten the text if it is too long.\n            text = text[:len(text)//2]\n        else:  # Reduce font size\n            font_size = max(10, font_size - 5)  # Minimum size 10\n\n    # If that doesn't work, use a minimal font and single-letter text.\n    if text_width > IMG_WIDTH - 10:\n        text = text[0]  # Use the first letter\n        font_size = 10\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n    # Text position\n    x = random.randint(5, max(5, IMG_WIDTH - text_width - 5))\n    y = random.randint(5, max(5, IMG_HEIGHT - text_height - 5))\n\n    # Highlighting text\n    text_color = random.randint(0, 50)\n    outline_color = 200\n    for offset_x in [-1, 0, 1]:\n        for offset_y in [-1, 0, 1]:\n            if offset_x != 0 or offset_y != 0:\n                draw.text((x + offset_x, y + offset_y), text, font=font, fill=outline_color)\n    draw.text((x, y), text, font=font, fill=text_color)\n\n    # Noise and distortion\n    img = add_noise_and_distortion(img)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.516296Z","iopub.execute_input":"2025-05-12T06:09:55.516564Z","iopub.status.idle":"2025-05-12T06:09:55.534936Z","shell.execute_reply.started":"2025-05-12T06:09:55.516535Z","shell.execute_reply":"2025-05-12T06:09:55.53398Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function for splitting labels</font>**","metadata":{}},{"cell_type":"code","source":"def split_labels(labels, label_lengths):\n    \"\"\"\n    Splits a sequence of labels into sub-sequences based on specified lengths.\n    \n    This function takes a single concatenated sequence of labels and splits it into multiple sub-sequences. \n    The lengths of these sub-sequences are specified by the `label_lengths` parameter. \n    Each sub-sequence is extracted from the `labels` sequence and appended to a list, which is then returned.\n    \n    Args:\n        labels (str or list): The concatenated sequence of labels to be split. This can be a string or a list of characters/elements.\n        label_lengths (list of int): A list of integers where each integer specifies the length of a corresponding sub-sequence to be extracted from `labels`.\n    \n    Returns:\n        list: A list of sub-sequences extracted from `labels` according to the specified lengths in `label_lengths`.\n    \n    Example:\n        >>> split_labels(\"abcdefgh\", [2, 3, 3])\n        ['ab', 'cde', 'fgh']\n    \"\"\"\n    split_labels = []\n    start = 0\n    for length in label_lengths:\n        split_labels.append(labels[start:start + length])\n        start += length\n    return split_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.535942Z","iopub.execute_input":"2025-05-12T06:09:55.536255Z","iopub.status.idle":"2025-05-12T06:09:55.552814Z","shell.execute_reply.started":"2025-05-12T06:09:55.536223Z","shell.execute_reply":"2025-05-12T06:09:55.552002Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function of Beam search decoding</font>**","metadata":{}},{"cell_type":"code","source":"def beam_search_decode(output, idx_to_char, target_lengths, beam_width=5, blank_penalty=0.1, length_penalty=0.1, global_step=0):\n    \"\"\"\n    Performs beam search decoding on the model's output logits.\n\n    Args:\n        output (torch.Tensor): Model output logits, shape (T, B, C).\n        idx_to_char (dict): Mapping from indices to characters.\n        target_lengths (torch.Tensor): Target label lengths for each batch.\n        beam_width (int): Number of beams to keep during search.\n        blank_penalty (float): Penalty for blank token.\n        length_penalty (float): Penalty for sequence length.\n        global_step (int): Global step for logging purposes.\n\n    Returns:\n        list: List of decoded strings for each batch.\n    \"\"\"\n    T, B, C = output.shape\n    output = output.softmax(2)  # Convert logits to probabilities\n\n    decoded_texts = []\n    for b in range(B):\n        # Get the probabilities for this batch\n        probs = output[:, b, :]  # (T, C)\n\n        # Initialize the beam with an empty sequence\n        beams = [([], 0.0)]  # (sequence, log_prob)\n\n        # For each time step\n        for t in range(T):\n            new_beams = []\n            for seq, log_prob in beams:\n                # For each possible character\n                for c in range(C):\n                    prob = probs[t, c].item()\n                    if prob < 1e-10:  # Avoid log(0)\n                        continue\n                    new_log_prob = log_prob + math.log(prob)\n\n                    # Apply blank penalty\n                    if c == 0:  # Blank token\n                        new_log_prob += blank_penalty\n\n                    new_seq = seq + [c]\n                    new_beams.append((new_seq, new_log_prob))\n\n            # Keep the top beam_width sequences\n            new_beams.sort(key=lambda x: x[1], reverse=True)\n            beams = new_beams[:beam_width]\n\n        # Apply length penalty to the final beams\n        beams = [(seq, log_prob + length_penalty * len(seq)) for seq, log_prob in beams]\n        beams.sort(key=lambda x: x[1], reverse=True)\n        best_seq = beams[0][0]  # Best sequence\n\n        # Convert indices to characters, skipping blanks and duplicates\n        decoded = []\n        prev_char = None\n        for idx in best_seq:\n            if idx == 0:  # Skip blank token\n                continue\n            char = idx_to_char.get(idx, '')\n            if char and char != prev_char:  # Skip duplicates\n                decoded.append(char)\n            prev_char = char\n\n        decoded_text = ''.join(decoded)\n        decoded_texts.append(decoded_text)\n\n    return decoded_texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.553874Z","iopub.execute_input":"2025-05-12T06:09:55.554103Z","iopub.status.idle":"2025-05-12T06:09:55.57185Z","shell.execute_reply.started":"2025-05-12T06:09:55.554084Z","shell.execute_reply":"2025-05-12T06:09:55.571071Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Custom collate function</font>**","metadata":{}},{"cell_type":"code","source":"def custom_collate_fn(batch):\n    \"\"\"\n    Custom collate function for combining a batch of data samples into a single batch.\n\n    This function is used to process a batch of data samples, typically for use in a data loader during model training or evaluation. It stacks images, concatenates labels, and converts label lengths into tensors, preparing the data for efficient processing in a neural network.\n\n    Args:\n        batch (list of tuples): A list where each element is a tuple containing:\n            - An image tensor.\n            - A label tensor.\n            - An integer representing the length of the label.\n\n    Returns:\n        tuple: A tuple containing:\n            - images (torch.Tensor): A tensor of stacked images from the batch.\n            - labels (torch.Tensor): A concatenated tensor of labels from the batch.\n            - label_lengths (torch.Tensor): A tensor of label lengths from the batch.\n\n    The function ensures that the images, labels, and label lengths are properly formatted as tensors, making them compatible with PyTorch operations.\n    \"\"\"\n    images, labels, label_lengths = zip(*batch)\n    # Stack images (all same size)\n    images = torch.stack(images, dim=0)\n    # Concatenate labels into a flat tensor\n    labels = torch.cat(labels, dim=0)\n    # Convert label_lengths to tensor\n    label_lengths = torch.tensor(label_lengths, dtype=torch.long)\n    return images, labels, label_lengths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.572707Z","iopub.execute_input":"2025-05-12T06:09:55.572998Z","iopub.status.idle":"2025-05-12T06:09:55.588791Z","shell.execute_reply.started":"2025-05-12T06:09:55.572969Z","shell.execute_reply":"2025-05-12T06:09:55.588042Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Analyze dataset char frequency</font>**","metadata":{}},{"cell_type":"code","source":"def analyze_dataset_char_frequency(labels_file, charset):\n    \"\"\"\n    Analyzes the character frequency in the generated dataset and displays a progress bar.\n    \n    Args:\n        labels_file (str): Path to the labels file (e.g., LABELS_FILE).\n        charset (str): String containing all possible characters (e.g., CHARSET).\n    \n    Returns:\n        dict: Dictionary with character frequencies.\n    \"\"\"\n    if not os.path.exists(labels_file):\n        print(f\"Error: Labels file '{labels_file}' does not exist!\")\n        function_logger.error(f\"Error: Labels file '{labels_file}' does not exist!\")\n        return {}\n\n    # Read labels and extract texts\n    with open(labels_file, 'r') as f:\n        labels = [line.split('\\t')[1].strip() for line in f if '\\t' in line]\n\n    if not labels:\n        print(\"Error: No valid labels found in the file!\")\n        return {}\n\n    # Count character frequencies\n    all_chars = ''.join(labels)\n    char_counts = Counter(all_chars)\n\n    # Prepare data for the bar plot\n    chars = list(charset)\n    frequencies = [char_counts.get(char, 0) for char in chars]\n\n    # Create a progress bar (bar plot)\n    plt.figure(figsize=(12, 6))\n    plt.bar(chars, frequencies, color='skyblue')\n    plt.xlabel('Characters')\n    plt.ylabel('Frequency')\n    plt.title('Character Frequency in Dataset')\n    plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n    plt.tight_layout()\n\n    # Display the plot\n    plt.show()\n\n    # Print summary\n    total_chars = sum(frequencies)\n    print(f\"Total characters analyzed: {total_chars}\")\n    print(\"Character frequencies:\", dict(char_counts))\n    function_logger.debug(f\"Total characters analyzed: {total_chars}\")\n    function_logger.debug(f\"Character frequencies: {dict(char_counts)}\")\n\n    return dict(char_counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.58985Z","iopub.execute_input":"2025-05-12T06:09:55.590143Z","iopub.status.idle":"2025-05-12T06:09:55.610611Z","shell.execute_reply.started":"2025-05-12T06:09:55.590117Z","shell.execute_reply":"2025-05-12T06:09:55.609575Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generating a data file</font>**","metadata":{}},{"cell_type":"code","source":"def create_synthetic_dataset(num_samples):\n    \"\"\"\n    Creates a synthetic dataset with images and corresponding labels.\n    \n    Args:\n        num_samples (int): Number of images to generate.\n    \n    Notes:\n        It uses global variables: OUTPUT_DIR, LABELS_FILE, font_files, MAX_TEXT_LENGTH, MIN_TEXT_LENGTH, CHARSET.\n        It assumes the existence of the generate_synthetic_image and generate_random_license_plate functions,\n        and access to font_files.\n    \"\"\"\n    # Ensure OUTPUT_DIR exists\n    if not os.path.exists(OUTPUT_DIR):\n        os.makedirs(OUTPUT_DIR)\n        print(f\"Created directory: {OUTPUT_DIR}\")\n        function_logger.info(f\"Created directory: {OUTPUT_DIR}\")\n\n    # Define valid characters based on CHARSET\n    valid_chars = set(CHARSET)  # CHARSET = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789- \"\n    \n    labels = []\n    for i in range(num_samples):\n        # Generate text for a license plate\n        text, country = generate_random_license_plate(formats)\n        if not text:\n            function_logger.warning(f\"Skipping sample {i}: Empty text generated.\")\n            continue  # Skip if text is empty\n\n        # Ensure the generated text only contains valid characters\n        cleaned_text = ''.join(c for c in text if c in valid_chars)\n        if not cleaned_text:\n            function_logger.warning(f\"Skipping sample {i}: No valid characters in text '{text}'.\")\n            continue  # Skip if the cleaned text is empty\n\n        # Random font selection\n        font_path = random.choice(font_files)\n        \n        # Image generation\n        try:\n            img = generate_synthetic_image(cleaned_text, font_path)\n            img_name = f\"img_{i:05d}.png\"\n            img_path = os.path.join(OUTPUT_DIR, img_name)\n            img.save(img_path)\n        except Exception as e:\n            function_logger.error(f\"Failed to generate image for sample {i} (Text: {cleaned_text}): {str(e)}\")\n            continue\n\n        # Save the label\n        labels.append(f\"{img_name}\\t{cleaned_text}\")\n        \n        # Progress report\n        if i % 100 == 0:\n            print(f\"Generated {i}/{num_samples} images (Country: {country}, Text: {cleaned_text})\")\n            function_logger.debug(f\"Generated {i}/{num_samples} images (Country: {country}, Text: {cleaned_text})\")\n\n    # Save labels to a file\n    if labels:\n        with open(LABELS_FILE, 'w') as f:\n            f.write(\"\\n\".join(labels))\n        print(f\"Labels written to '{LABELS_FILE}' (before cleaning).\")\n        function_logger.debug(f\"Labels written to '{LABELS_FILE}' (before cleaning).\")\n\n        # Clean the labels file to ensure no invalid characters remain\n        clean_labels_file(LABELS_FILE, valid_chars)\n\n        # Analyze and display character frequency\n        analyze_dataset_char_frequency(LABELS_FILE, CHARSET)\n        \n        print(f\"Dataset generated! Images saved in '{OUTPUT_DIR}', labels in '{LABELS_FILE}'\")\n        function_logger.info(f\"Dataset generated! Images saved in '{OUTPUT_DIR}', labels in '{LABELS_FILE}'\")\n    else:\n        print(\"No labels generated! Check the generate_random_license_plate function or font files.\")\n        function_logger.error(\"No labels generated! Check the generate_random_license_plate function or font files.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.611493Z","iopub.execute_input":"2025-05-12T06:09:55.611773Z","iopub.status.idle":"2025-05-12T06:09:55.628462Z","shell.execute_reply.started":"2025-05-12T06:09:55.611746Z","shell.execute_reply":"2025-05-12T06:09:55.627732Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Mapping characters to indices and back</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"num_chars = len(CHARSET) + 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.629489Z","iopub.execute_input":"2025-05-12T06:09:55.629771Z","iopub.status.idle":"2025-05-12T06:09:55.645145Z","shell.execute_reply.started":"2025-05-12T06:09:55.62975Z","shell.execute_reply":"2025-05-12T06:09:55.644208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"char_to_idx = {char: idx + 1 for idx, char in enumerate(CHARSET)}  # 0 is reserved for blank (CTC)\nidx_to_char = {idx: char for char, idx in char_to_idx.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.64599Z","iopub.execute_input":"2025-05-12T06:09:55.646316Z","iopub.status.idle":"2025-05-12T06:09:55.658221Z","shell.execute_reply.started":"2025-05-12T06:09:55.646283Z","shell.execute_reply":"2025-05-12T06:09:55.657342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"main_logger.info('Mapping characters to indices and back was done.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.659102Z","iopub.execute_input":"2025-05-12T06:09:55.659385Z","iopub.status.idle":"2025-05-12T06:09:55.678571Z","shell.execute_reply.started":"2025-05-12T06:09:55.659357Z","shell.execute_reply":"2025-05-12T06:09:55.677688Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Test regex generation</font>**\n-------------------","metadata":{}},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom dataset</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRDataset(Dataset):\n    \"\"\"\n    A custom dataset class for Optical Character Recognition (OCR) tasks.\n\n    This class extends PyTorch's Dataset class and is used to load and preprocess images and their corresponding labels for OCR tasks. It reads image paths and labels from a file and provides methods to access the data.\n\n    Args:\n        Dataset (torch.utils.data.Dataset): The base dataset class from PyTorch.\n    \"\"\"\n    def __init__(self, image_dir, labels_file):\n        \"\"\"\n        Initializes the OCRDataset with the directory containing images and the file containing labels.\n\n        Args:\n            image_dir (str): The directory path where the images are stored.\n            labels_file (str): The file path containing the labels corresponding to the images. The file should have each line formatted as 'image_path\\tlabel'.\n        \"\"\"\n        self.image_dir = image_dir\n        self.labels_file = labels_file\n        self.data = []\n        with open(labels_file, 'r') as f:\n            for line in f:\n                if not line.strip():  # Skip empty lines\n                    continue\n                image_path, label = line.strip().split('\\t')\n                label_length = len(label)\n                self.data.append((image_path, label, label_length))\n\n    def __len__(self):\n        \"\"\"_summary_\n\n        Returns:\n            _type_: _description_\n        \"\"\"\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_path, label, label_length = self.data[idx]\n        image = Image.open(os.path.join(self.image_dir, image_path)).convert('L')\n        image = transforms.ToTensor()(image)\n        label_encoded = torch.tensor([char_to_idx[c] for c in label], dtype=torch.long)\n        return image, label_encoded, label_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.679091Z","iopub.execute_input":"2025-05-12T06:09:55.67932Z","iopub.status.idle":"2025-05-12T06:09:55.699109Z","shell.execute_reply.started":"2025-05-12T06:09:55.679297Z","shell.execute_reply":"2025-05-12T06:09:55.69828Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom CTC Loss with Blank Penalty</font>**\n-------------------\n> CTC Loss with Entropy Regularization","metadata":{}},{"cell_type":"code","source":"class CTCLossWithBlankPenalty(nn.Module):\n    \"\"\"\n    A custom loss module that extends the Connectionist Temporal Classification (CTC) loss with additional penalties.\n\n    This class adds penalties for blank predictions and entropy to the standard CTC loss, which is commonly used in sequence-to-sequence tasks like speech recognition and OCR. \n    The penalties help to regularize the model and improve convergence during training.\n\n    Args:\n        nn (torch.nn.Module): The base module class from PyTorch.\n    \"\"\"\n\n    def __init__(self, blank=0, zero_infinity=True, blank_penalty_weight=1.0, entropy_weight=0.5, label_smoothing=0.1):\n        \"\"\"\n        Initializes the CTCLossWithBlankPenalty with specified parameters.\n\n        Args:\n            blank (int, optional): The index of the blank label. Defaults to 0.\n            zero_infinity (bool, optional): Whether to zero the loss of sequences with infinite loss. Defaults to True.\n            blank_penalty_weight (float, optional): The weight of the blank penalty. Defaults to 1.0.\n            entropy_weight (float, optional): The weight of the entropy penalty. Defaults to 0.5.\n            label_smoothing (float, optional): The amount of label smoothing to apply. Defaults to 0.1.\n        \"\"\"\n        super().__init__()\n        self.ctc_loss = nn.CTCLoss(blank=blank, reduction='mean', zero_infinity=zero_infinity)\n        self.blank = blank  # Add blank index as an attribute\n        self.blank_penalty_weight = blank_penalty_weight\n        self.entropy_weight = entropy_weight  \n        self.label_smoothing = label_smoothing\n        self.global_step = 0\n\n    def update_blank_penalty(self, global_step):\n        \"\"\"\n        Updates the blank penalty weight based on the current global step.\n\n        This method gradually reduces the blank penalty weight over the first 1,000 steps to stabilize training.\n\n        Args:\n            global_step (int): The current global step or iteration number.\n        \"\"\"\n        # Gradual reduction of penalty over the first 1,000 steps\n        self.global_step = global_step\n        decay_factor = max(0.1, 1.0 - self.global_step / 1000.0)\n        self.blank_penalty_weight = 1.0 * decay_factor\n\n    def forward(self, log_probs, targets, input_lengths, target_lengths):\n        \"\"\"\n        Computes the total loss, including CTC loss, blank penalty, and entropy penalty.\n\n        Args:\n            log_probs (torch.Tensor): The log probabilities output by the model, of shape (T, N, C), \n                                      where T is the input sequence length, N is the batch size, and C is the number of classes.\n            targets (torch.Tensor): The target sequences, of shape (N, S), where S is the target sequence length.\n            input_lengths (torch.Tensor): The lengths of the input sequences, of shape (N,).\n            target_lengths (torch.Tensor): The lengths of the target sequences, of shape (N,).\n\n        Returns:\n            torch.Tensor: The total loss, which is the sum of the CTC loss, blank penalty, and entropy penalty.\n        \"\"\"\n        # Standard CTC loss\n        ctc_loss = self.ctc_loss(log_probs, targets, input_lengths, target_lengths)\n\n        # Blank penalty: penalize high blank probability (updated to be proportional)\n        blank_probs = log_probs[:, :, self.blank].exp().mean()\n        blank_penalty = self.blank_penalty_weight * blank_probs  # Changed from -torch.log(1 - blank_probs + 1e-4) * self.blank_penalty_weight\n\n        # Entropy regularization\n        probs = log_probs.exp()\n        entropy = -torch.sum(probs * log_probs, dim=-1).mean()\n        entropy_loss = -self.entropy_weight * entropy\n\n        # Total loss\n        total_loss = ctc_loss + blank_penalty + entropy_loss\n        return total_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.700048Z","iopub.execute_input":"2025-05-12T06:09:55.700349Z","iopub.status.idle":"2025-05-12T06:09:55.720065Z","shell.execute_reply.started":"2025-05-12T06:09:55.700323Z","shell.execute_reply":"2025-05-12T06:09:55.718876Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom functions of metrics</font>**","metadata":{}},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Character Error Rate (CER)</font>**\n\n- Measures the number of character-level errors (insertions, deletions, substitutions) between the predicted text and the ground truth, normalized by the length of the ground truth.","metadata":{}},{"cell_type":"code","source":"def compute_cer(pred_texts, ground_truth):\n    \"\"\"\n    Computes the Character Error Rate (CER) between predicted texts and ground truth.\n\n    Args:\n        pred_texts (list of str): List of predicted texts.\n        ground_truth (list of str): List of ground truth texts.\n\n    Returns:\n        float: Average CER across the batch.\n    \"\"\"\n    total_errors = 0\n    total_chars = 0\n    for pred, gt in zip(pred_texts, ground_truth):\n        errors = levenshtein_distance(pred, gt)\n        total_errors += errors\n        total_chars += len(gt)\n    cer = total_errors / total_chars if total_chars > 0 else 0\n    return cer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.721032Z","iopub.execute_input":"2025-05-12T06:09:55.721305Z","iopub.status.idle":"2025-05-12T06:09:55.738061Z","shell.execute_reply.started":"2025-05-12T06:09:55.721285Z","shell.execute_reply":"2025-05-12T06:09:55.737183Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Word Error Rate (WER)</font>**\n\n- Measures the number of word-level errors (insertions, deletions, substitutions) between the predicted text and the ground truth, normalized by the number of words in the ground truth.","metadata":{}},{"cell_type":"code","source":"def compute_wer(pred_texts, ground_truth):\n    \"\"\"\n    Computes the Word Error Rate (WER) between predicted texts and ground truth.\n\n    Args:\n        pred_texts (list of str): List of predicted texts.\n        ground_truth (list of str): List of ground truth texts.\n\n    Returns:\n        float: Average WER across the batch.\n    \"\"\"\n    total_errors = 0\n    total_words = 0\n    for pred, gt in zip(pred_texts, ground_truth):\n        pred_words = pred.split()\n        gt_words = gt.split()\n        errors = levenshtein_distance(pred_words, gt_words)\n        total_errors += errors\n        total_words += len(gt_words)\n    wer = total_errors / total_words if total_words > 0 else 0\n    return wer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.74458Z","iopub.execute_input":"2025-05-12T06:09:55.744856Z","iopub.status.idle":"2025-05-12T06:09:55.757952Z","shell.execute_reply.started":"2025-05-12T06:09:55.744828Z","shell.execute_reply":"2025-05-12T06:09:55.757095Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">CER/WER Probability</font>**\n\n- This could be interpreted as the probability of errors at the character or word level, often derived from the model's output probabilities. For this implementation, we'll compute it as the average probability of the predicted characters/words being incorrect, based on the model's softmax probabilities.\n\n","metadata":{}},{"cell_type":"code","source":"def compute_cer_wer_probability(outputs, pred_texts, ground_truth, idx_to_char):\n    \"\"\"\n    Computes the CER/WER probability based on the model's output probabilities.\n\n    Args:\n        outputs (torch.Tensor): Model output probabilities (after softmax), shape (T, B, C).\n        pred_texts (list of str): List of predicted texts.\n        ground_truth (list of str): List of ground truth texts.\n        idx_to_char (dict): Mapping from indices to characters.\n\n    Returns:\n        tuple: (cer_prob, wer_prob) - Average CER and WER probabilities.\n    \"\"\"\n    probs = outputs.softmax(2)  # (T, B, C)\n    T, B, C = probs.shape\n    char_to_idx = {char: idx for idx, char in idx_to_char.items()}\n\n    # Verify that indices in char_to_idx are within bounds\n    max_idx = max(char_to_idx.values())\n    if max_idx >= C:\n        raise ValueError(f\"char_to_idx contains an index {max_idx} that exceeds the vocabulary size {C}\")\n\n    cer_probs = []\n    wer_probs = []\n\n    for b in range(B):\n        pred = pred_texts[b]\n        gt = ground_truth[b]\n\n        # Character-level probability (CER probability)\n        char_error_prob = 0.0\n        for i, (p_char, g_char) in enumerate(zip(pred, gt)):\n            if i >= T:  # Skip if beyond sequence length\n                break\n            p_idx = char_to_idx.get(p_char, 0)\n            g_idx = char_to_idx.get(g_char, 0)\n\n            # Handle invalid indices\n            if g_idx >= C:\n                print(f\"Warning: g_char '{g_char}' maps to invalid index {g_idx}. Valid range: 0 to {C-1}\")\n                g_idx = 0  # Fallback to blank token\n            if p_idx >= C:\n                print(f\"Warning: p_char '{p_char}' maps to invalid index {p_idx}. Valid range: 0 to {C-1}\")\n                p_idx = 0  # Fallback to blank token\n\n            p_prob = probs[i, b, p_idx].item()\n            g_prob = probs[i, b, g_idx].item()\n            error_prob = 1.0 - g_prob  # Probability of error for this character\n            char_error_prob += error_prob\n        char_error_prob = char_error_prob / len(gt) if len(gt) > 0 else 0\n        cer_probs.append(char_error_prob)\n\n        # Word-level probability (WER probability)\n        pred_words = pred.split()\n        gt_words = gt.split()\n        word_error_prob = 0.0\n        for i, (p_word, g_word) in enumerate(zip(pred_words, gt_words)):\n            p_chars = list(p_word)\n            g_chars = list(g_word)\n            word_prob = 0.0\n            for j, (p_char, g_char) in enumerate(zip(p_chars, g_chars)):\n                if i * len(p_word) + j >= T:  # Skip if beyond sequence length\n                    break\n                p_idx = char_to_idx.get(p_char, 0)\n                g_idx = char_to_idx.get(g_char, 0)\n\n                # Handle invalid indices\n                if g_idx >= C:\n                    print(f\"Warning: g_char '{g_char}' maps to invalid index {g_idx}. Valid range: 0 to {C-1}\")\n                    g_idx = 0  # Fallback to blank token\n                if p_idx >= C:\n                    print(f\"Warning: p_char '{p_char}' maps to invalid index {p_idx}. Valid range: 0 to {C-1}\")\n                    p_idx = 0  # Fallback to blank token\n\n                p_prob = probs[i * len(p_word) + j, b, p_idx].item()\n                g_prob = probs[i * len(p_word) + j, b, g_idx].item()\n                error_prob = 1.0 - g_prob\n                word_prob += error_prob\n            word_prob = word_prob / len(g_chars) if len(g_chars) > 0 else 0\n            word_error_prob += word_prob\n        word_error_prob = word_error_prob / len(gt_words) if len(gt_words) > 0 else 0\n        wer_probs.append(word_error_prob)\n\n    avg_cer_prob = sum(cer_probs) / len(cer_probs) if cer_probs else 0\n    avg_wer_prob = sum(wer_probs) / len(wer_probs) if wer_probs else 0\n    return avg_cer_prob, avg_wer_prob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.759774Z","iopub.execute_input":"2025-05-12T06:09:55.760019Z","iopub.status.idle":"2025-05-12T06:09:55.779094Z","shell.execute_reply.started":"2025-05-12T06:09:55.76Z","shell.execute_reply":"2025-05-12T06:09:55.778295Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Harmonic Mean</font>**\n\n- Harmonic Mean is a metric that helps us find the optimal solution between the CER and WER metrics.","metadata":{}},{"cell_type":"code","source":"def compute_harmonic_mean(val_cer, val_wer):\n    \"\"\"\n    Calculates the harmonic mean of the CER and WER values.\n\n    Args:\n    val_cer (float): Character Error Rate value.\n    val_wer (float): Word Error Rate value.\n\n    Returns:\n    float: Harmonic mean of the CER and WER.\n    \"\"\"\n    if val_cer + val_wer == 0:\n        harmonic_mean = 0.0\n    else:\n        harmonic_mean = 2 / (1 / (val_cer + 1e-9) + 1 / (val_wer + 1e-9))\n    return harmonic_mean","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.779838Z","iopub.execute_input":"2025-05-12T06:09:55.780122Z","iopub.status.idle":"2025-05-12T06:09:55.796183Z","shell.execute_reply.started":"2025-05-12T06:09:55.780095Z","shell.execute_reply":"2025-05-12T06:09:55.795505Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Model definition (CNN + RNN + CTC)</font>**\n-------------------","metadata":{}},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Configuration file</font>**","metadata":{}},{"cell_type":"code","source":"config_model = {\n    'cnn_layers': [\n        {'type': 'conv', 'out_channels': 256, 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu', 'dropout': 0.3},\n        {'type': 'pool', 'kernel_size': 2, 'stride': 2},\n        {'type': 'conv', 'out_channels': 512, 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu', 'dropout': 0.2},\n        {'type': 'pool', 'kernel_size': 2, 'stride': 2},\n        {'type': 'conv', 'out_channels': 768, 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu'},\n        {'type': 'pool', 'kernel_size': (2, 2), 'stride': (2, 1), 'padding': (0, 1)},  # CRNN pooling\n        {'type': 'conv', 'out_channels': 512, 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu'},\n        {'type': 'pool', 'kernel_size': (2, 2), 'stride': (2, 1), 'padding': (0, 1)},  # CRNN pooling\n    ],\n    'rnn_type': 'lstm',\n    'rnn_layers': 3,\n    'hidden_size': 512,\n    'bidirectional': True,\n    'dropout': 0.3,\n    'fc_layers': [num_chars],  # One layer for OCR\n}\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.796917Z","iopub.execute_input":"2025-05-12T06:09:55.797165Z","iopub.status.idle":"2025-05-12T06:09:55.814303Z","shell.execute_reply.started":"2025-05-12T06:09:55.797141Z","shell.execute_reply":"2025-05-12T06:09:55.813544Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Model architecture</font>**","metadata":{}},{"cell_type":"code","source":"class OCRModel(nn.Module):\n    \"\"\"\n    A neural network model for Optical Character Recognition (OCR) tasks.\n    \n    This class defines an OCR model that combines Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) to process and recognize text in images. \n    The model architecture is configurable through a configuration dictionary.\n    \n    Args:\n        nn (torch.nn.Module): The base module class from PyTorch.\n    \"\"\"\n    def __init__(self, config):\n        \"\"\"\n        Initializes the OCRModel with a given configuration.\n\n        Args:\n            config (dict): A dictionary containing the configuration parameters for the model, including CNN layers, RNN type, hidden size, and more.\n        \"\"\"\n        super(OCRModel, self).__init__()\n        self.cnn = self.build_cnn(config['cnn_layers'])\n        \n        # Calculating input size for RNN after CNN\n        num_pools = sum(1 for layer in config['cnn_layers'] if layer['type'] == 'pool')\n        height_after_cnn = IMG_HEIGHT // (2 ** num_pools)\n        last_conv_out = [layer['out_channels'] for layer in config['cnn_layers'] if layer['type'] == 'conv'][-1]\n        rnn_input_size = last_conv_out * height_after_cnn\n        \n        self.rnn = self.build_rnn(config, rnn_input_size)\n        rnn_output_size = config['hidden_size'] * 2 if config['bidirectional'] else config['hidden_size']\n        self.fc = self.build_fc(config, rnn_output_size)\n\n    def build_cnn(self, cnn_config):\n        \"\"\"\n        Builds the CNN part of the model based on the provided configuration.\n\n        Args:\n            cnn_config (list of dict): A list of dictionaries, each specifying a layer in the CNN. Each dictionary contains parameters like type, out_channels, kernel_size, etc.\n\n        Returns:\n            nn.Sequential: A sequential container of CNN layers.\n        \"\"\"\n        layers = []\n        in_channels = 1\n        for layer in cnn_config:\n            if layer['type'] == 'conv':\n                layers.append(nn.Conv2d(in_channels, layer['out_channels'], layer['kernel_size'], \n                                        layer['stride'], layer['padding']))\n                if layer.get('batchnorm', False):\n                    layers.append(nn.BatchNorm2d(layer['out_channels']))\n                if layer.get('activation') == 'relu':\n                    layers.append(nn.ReLU())\n                elif layer.get('activation') == 'leaky_relu':\n                    layers.append(nn.LeakyReLU(0.2))\n                if 'dropout' in layer:\n                    layers.append(nn.Dropout2d(layer['dropout']))\n                in_channels = layer['out_channels']\n            elif layer['type'] == 'pool':\n                layers.append(nn.MaxPool2d(layer['kernel_size'], layer['stride'], layer.get('padding', 0)))\n        return nn.Sequential(*layers)\n\n    def build_rnn(self, config, input_size):\n        \"\"\"\n        Creates an RNN part (LSTM or GRU) according to the configuration.\n\n        Args:\n            config (dict): The configuration dictionary containing RNN parameters.\n            input_size (int): The input size for the RNN.\n\n        Raises:\n            ValueError: If the RNN type specified in the configuration is unknown.\n\n        Returns:\n            nn.Module: An RNN module (LSTM or GRU).\n        \"\"\"\n        if config['rnn_type'] == 'lstm':\n            return nn.LSTM(input_size, config['hidden_size'], num_layers=config['rnn_layers'], \n                          bidirectional=config['bidirectional'], dropout=config['dropout'])\n        elif config['rnn_type'] == 'gru':\n            return nn.GRU(input_size, config['hidden_size'], num_layers=config['rnn_layers'], \n                         bidirectional=config['bidirectional'], dropout=config['dropout'])\n        else:\n            raise ValueError(\"Unknown RNN type: {}\".format(config['rnn_type']))\n\n    def build_fc(self, config, input_size):\n        \"\"\"\n        Creates output fully connected layers.\n\n        Args:\n            config (dict): The configuration dictionary containing fully connected layer parameters.\n            input_size (int): The input size for the fully connected layers.\n\n        Returns:\n            nn.Sequential: A sequential container of fully connected layers.\n        \"\"\"\n        layers = []\n        fc_layers = config['fc_layers']\n        for out_features in fc_layers[:-1]:\n            layers.append(nn.Linear(input_size, out_features))\n            layers.append(nn.ReLU())\n            layers.append(nn.Dropout(config['dropout']))\n            input_size = out_features\n        layers.append(nn.Linear(input_size, fc_layers[-1]))\n        return nn.Sequential(*layers)\n\n    def forward(self, x, max_length=None):\n        \"\"\"\n        Performs a forward pass through the OCR model.\n\n        Args:\n            x (torch.Tensor): The input tensor, typically an image.\n            max_length (int, optional): The maximum length for the RNN output. Defaults to None.\n\n        Returns:\n            torch.Tensor: The output tensor after passing through the CNN, RNN, and fully connected layers.\n        \"\"\"\n        x = self.cnn(x)\n        batch, channels, height, width = x.size()\n        x = x.view(batch, channels * height, width).permute(2, 0, 1)  # (width, batch, features)\n        if max_length is not None:\n            x = x[:max_length]\n        x, _ = self.rnn(x)\n        x = self.fc(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.815202Z","iopub.execute_input":"2025-05-12T06:09:55.815504Z","iopub.status.idle":"2025-05-12T06:09:55.833308Z","shell.execute_reply.started":"2025-05-12T06:09:55.815471Z","shell.execute_reply":"2025-05-12T06:09:55.832524Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Training</font>**\n-------------------","metadata":{}},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Initializing the scales</font>**","metadata":{}},{"cell_type":"code","source":"def initialize_weights(model):\n    for name, module in model.named_modules():\n        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.LSTM) or isinstance(module, nn.GRU):\n            for param_name, param in module.named_parameters():\n                if 'weight' in param_name:\n                    nn.init.orthogonal_(param)\n                elif 'bias' in param_name:\n                    nn.init.zeros_(param)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.834118Z","iopub.execute_input":"2025-05-12T06:09:55.834391Z","iopub.status.idle":"2025-05-12T06:09:55.861808Z","shell.execute_reply.started":"2025-05-12T06:09:55.834371Z","shell.execute_reply":"2025-05-12T06:09:55.860959Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Calculating the gradient norm before trimming (for logging)</font>**","metadata":{}},{"cell_type":"code","source":"def compute_gradient_norm(parameters: Iterator[torch.Tensor]) -> float:\n    total_norm = 0.0\n    for p in parameters:\n        if p.grad is not None:\n            # Compute the Frobenius norm (default) over all elements in the tensor\n            param_norm = torch.linalg.norm(p.grad.detach(), ord=None)\n            total_norm += param_norm.item() ** 2\n    total_norm = total_norm ** 0.5\n    return total_norm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.86254Z","iopub.execute_input":"2025-05-12T06:09:55.862847Z","iopub.status.idle":"2025-05-12T06:09:55.87623Z","shell.execute_reply.started":"2025-05-12T06:09:55.862824Z","shell.execute_reply":"2025-05-12T06:09:55.875397Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function of train model</font>**","metadata":{}},{"cell_type":"code","source":"def train(\n    full_dataset,\n    device,\n    config_model,\n    pretrained_model_path=None,\n    num_epochs=EPOCHS,\n    learning_rate=LEARNING_RATE,\n    weight_decay=WEIGHT_DECAY,\n    warmup_steps=WARMUP_STEPS,\n    temperature=TEMPERATURE,\n    ctc_entropy_weight=CTC_ENTROPY_WEIGHT,\n    ctc_label_smoothing=CTC_LABEL_SMOOTHING,\n    ctc_blank_penalty_weight=CTC_BLANK_PENALTY_WEIGHT,\n    bsd_beam_width=BSD_BEAM_WIDTH,\n    bsd_blank_penalty=BSD_BLANK_PENALTY,\n    bsd_length_penalty=BSD_LENGTH_PENALTY,\n    gradient_clipping_value=GRADIENT_CLIPPING_VALUE,\n    gradient_norm_threshold=GRADIENT_NORM_TRESHOLD\n):\n    \"\"\"\n    Train the OCR model for final training with optimized hyperparameters.\n    Saves the best model with full training state for resuming training.\n    Saves the final model with minimal state for production and exports it to ONNX.\n\n    Args:\n        full_dataset: OCRDataset instance containing the dataset.\n        device: Torch device (cuda or cpu).\n        config_model: Dictionary containing model architecture configuration.\n        pretrained_model_path: Path to pre-trained model or checkpoint (optional).\n        num_epochs: Number of training epochs.\n        learning_rate: Learning rate for the optimizer.\n        weight_decay: Weight decay for the optimizer.\n        warmup_steps: Number of warmup steps for learning rate.\n        temperature: Temperature for scaling model outputs.\n        ctc_entropy_weight: Weight for CTC entropy regularization.\n        ctc_label_smoothing: Label smoothing factor for CTC loss.\n        ctc_blank_penalty_weight: Weight for blank penalty in CTC loss.\n        bsd_beam_width: Beam width for beam search decoding.\n        bsd_blank_penalty: Blank penalty for beam search decoding.\n        bsd_length_penalty: Length penalty for beam search decoding.\n        gradient_clipping_value: Max norm for gradient clipping.\n        gradient_norm_threshold: Threshold for skipping batches with high gradient norms.\n\n    Returns:\n        tuple: (best_val_loss, final_val_cer, final_val_wer, final_harmonic_mean) from the final epoch.\n    \"\"\"\n    # Initialize model\n    model = OCRModel(config=config_model).to(device)\n\n    # Initialize optimizer and schedulers\n    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(1.0, step / warmup_steps))\n    plateau_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n\n    # Load pre-trained model or checkpoint if provided\n    start_epoch = 0\n    if pretrained_model_path is not None and os.path.exists(pretrained_model_path):\n        checkpoint = torch.load(pretrained_model_path, map_location=device)\n        if 'model_state_dict' in checkpoint:  # Full checkpoint\n            model.load_state_dict(checkpoint['model_state_dict'])\n            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n            plateau_scheduler.load_state_dict(checkpoint['plateau_scheduler_state_dict'])\n            start_epoch = checkpoint['epoch'] + 1\n            best_val_loss = checkpoint['best_val_loss']\n            # Restore hyperparameters (optional, as they are passed as args)\n            learning_rate = checkpoint['hyperparameters']['learning_rate']\n            weight_decay = checkpoint['hyperparameters']['weight_decay']\n            warmup_steps = checkpoint['hyperparameters']['warmup_steps']\n            temperature = checkpoint['hyperparameters']['temperature']\n            ctc_entropy_weight = checkpoint['hyperparameters']['ctc_entropy_weight']\n            ctc_label_smoothing = checkpoint['hyperparameters']['ctc_label_smoothing']\n            ctc_blank_penalty_weight = checkpoint['hyperparameters']['ctc_blank_penalty_weight']\n            bsd_beam_width = checkpoint['hyperparameters']['bsd_beam_width']\n            bsd_blank_penalty = checkpoint['hyperparameters']['bsd_blank_penalty']\n            bsd_length_penalty = checkpoint['hyperparameters']['bsd_length_penalty']\n            gradient_clipping_value = checkpoint['hyperparameters']['gradient_clipping_value']\n            gradient_norm_threshold = checkpoint['hyperparameters']['gradient_norm_threshold']\n            finaltrain_logger.info(f\"Loaded full checkpoint from {pretrained_model_path}, resuming from epoch {start_epoch}\")\n        else:  # Only model weights\n            model.load_state_dict(checkpoint)\n            best_val_loss = float('inf')\n            finaltrain_logger.info(f\"Loaded model weights from {pretrained_model_path}\")\n    else:\n        initialize_weights(model)\n        best_val_loss = float('inf')\n        finaltrain_logger.info(\"Initialized model with random weights\")\n\n    # TensorBoard setup\n    log_dir = os.path.join(TENSORBOARD_DIR, \"ocr_final_training\")\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    writer = SummaryWriter(log_dir)\n\n    # Log model configuration\n    config_text = \"\\n\".join([f\"{k}: {v}\" for k, v in config_model.items()])\n    writer.add_text('Config/model', config_text, 0)\n    finaltrain_logger.info(f\"Model configuration:\\n{config_model}\")\n\n    # Log model graph\n    try:\n        sample_input = torch.randn(1, 1, IMG_HEIGHT, IMG_WIDTH).to(device)\n        writer.add_graph(model, sample_input)\n        finaltrain_logger.info(\"Logged model graph to TensorBoard\")\n    except Exception as e:\n        finaltrain_logger.warning(f\"Failed to log model graph: {str(e)}\")\n\n    global_step = start_epoch * len(full_dataset) // BATCH_SIZE\n\n    # Initialize variables to store final metrics\n    final_val_cer = 0.0\n    final_val_wer = 0.0\n    final_harmonic_mean = 0.0\n\n    for epoch in tqdm(range(start_epoch, num_epochs), desc=\"Epochs\"):\n        finaltrain_logger.info(f\"Starting epoch {epoch+1}/{num_epochs}\")\n\n        # Curriculum learning: Filter data by label length\n        label_lengths = [lbl_len for _, _, lbl_len in full_dataset.data]\n        finaltrain_logger.debug(f\"Label lengths: {label_lengths}\")\n        if epoch < 5:\n            filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 10]\n        elif epoch < 10:\n            filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 15]\n        else:\n            filtered_data = full_dataset.data\n        sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]\n        finaltrain_logger.debug(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n\n        # Create filtered dataset\n        curr_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n        curr_dataset.data = filtered_data\n        train_size = int(0.8 * len(curr_dataset))\n        val_size = len(curr_dataset) - train_size\n        train_dataset, val_dataset = torch.utils.data.random_split(curr_dataset, [train_size, val_size])\n        finaltrain_logger.debug(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n\n        # Data loaders\n        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n\n        # Training phase\n        model.train()\n        total_loss = 0\n        total_grad_norm = 0\n        total_blank_probs = 0\n        total_cer = 0\n        total_wer = 0\n        total_cer_prob = 0\n        total_wer_prob = 0\n        skipped_batches = 0\n        num_valid_batches = 0\n        avg_loss = 0\n        max_skipped_batches = max(1, int(0.1 * len(train_loader)))\n\n        for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n            imgs, labels = imgs.to(device), labels.to(device)\n            label_lengths = label_lengths.to(device)\n\n            # Learning rate warm-up\n            if global_step < warmup_steps:\n                lr_scale = min(1.0, float(global_step + 1) / warmup_steps)\n                for param_group in optimizer.param_groups:\n                    param_group['lr'] = learning_rate * lr_scale\n                    finaltrain_logger.debug(f\"Learning rate set to: {param_group['lr']}\")\n\n            optimizer.zero_grad()\n            max_label_length = label_lengths.max().item()\n            outputs = model(imgs, max_length=max_label_length * 2)\n            outputs = outputs / temperature\n            outputs = torch.clamp(outputs, min=-10, max=10)\n            outputs = outputs.log_softmax(2)\n\n            batch_size = imgs.size(0)\n            seq_length = min(outputs.size(0), max_label_length * 2)\n            input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n\n            # Dynamic blank penalty\n            blank_probs = outputs[:, :, 0].exp().mean().item()\n            dynamic_blank_penalty = ctc_blank_penalty_weight * (1 + blank_probs)\n            criterion = CTCLossWithBlankPenalty(\n                blank=0, zero_infinity=True, blank_penalty_weight=dynamic_blank_penalty,\n                entropy_weight=ctc_entropy_weight, label_smoothing=ctc_label_smoothing\n            )\n\n            loss = criterion(outputs, labels, input_lengths, label_lengths)\n\n            # Compute gradient norm before clipping\n            grad_norm_before = compute_gradient_norm(model.parameters())\n\n            # Dynamic loss threshold\n            dynamic_threshold = max(40, avg_loss * 2) if num_valid_batches > 0 else 40\n\n            if torch.isnan(loss) or torch.isinf(loss):\n                finaltrain_logger.warning(f\"NaN or Inf loss at batch {batch_idx}. Skipping...\")\n                writer.add_scalar('Skipped_Batches/NaN_Inf', 1, global_step)\n                skipped_batches += 1\n            elif grad_norm_before > gradient_norm_threshold:\n                finaltrain_logger.warning(f\"High gradient norm {grad_norm_before:.4f} at batch {batch_idx}. Skipping...\")\n                writer.add_scalar('Skipped_Batches/High_Gradient', 1, global_step)\n                skipped_batches += 1\n            elif loss.item() > dynamic_threshold:\n                finaltrain_logger.warning(f\"High loss {loss.item():.4f} at batch {batch_idx}. Adjusting learning rate...\")\n                for param_group in optimizer.param_groups:\n                    param_group['lr'] *= 0.9\n                    finaltrain_logger.debug(f\"Learning rate adjusted to: {param_group['lr']}\")\n                writer.add_scalar('Skipped_Batches/High_Loss', 1, global_step)\n                skipped_batches += 1\n            else:\n                loss.backward()\n                grad_norm_after = nn_utils.clip_grad_norm_(model.parameters(), max_norm=gradient_clipping_value)\n                optimizer.step()\n                scheduler.step()\n\n                total_loss += loss.item()\n                total_grad_norm += grad_norm_after\n                total_blank_probs += blank_probs\n                num_valid_batches += 1\n                avg_loss = total_loss / num_valid_batches if num_valid_batches > 0 else 0\n\n                # Compute CER/WER\n                with torch.no_grad():\n                    pred_texts = beam_search_decode(\n                        output=outputs,\n                        idx_to_char=idx_to_char,\n                        target_lengths=label_lengths,\n                        beam_width=bsd_beam_width,\n                        blank_penalty=bsd_blank_penalty,\n                        length_penalty=bsd_length_penalty,\n                        global_step=global_step\n                    )\n                    label_sequences = split_labels(labels, label_lengths)\n                    ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                    for label_seq in label_sequences]\n                    cer = compute_cer(pred_texts, ground_truth)\n                    wer = compute_wer(pred_texts, ground_truth)\n                    cer_prob, wer_prob = compute_cer_wer_probability(outputs, pred_texts, ground_truth, idx_to_char)\n                    total_cer += cer\n                    total_wer += wer\n                    total_cer_prob += cer_prob\n                    total_wer_prob += wer_prob\n\n            if skipped_batches > max_skipped_batches:\n                finaltrain_logger.warning(f\"Too many skipped batches ({skipped_batches}/{max_skipped_batches}) in epoch {epoch+1}\")\n                writer.add_text(\n                    'Training/Details',\n                    f\"Stopped at epoch {epoch+1}, batch {batch_idx}. Skipped batches: {skipped_batches}\",\n                    global_step\n                )\n                break\n\n            global_step += 1\n\n            # Log metrics every NUMBER_OF_BATCH_REPORT batches\n            if batch_idx % NUMBER_OF_BATCH_REPORT == 0:\n                with torch.no_grad():\n                    pred_texts = beam_search_decode(\n                        output=outputs,\n                        idx_to_char=idx_to_char,\n                        target_lengths=label_lengths,\n                        beam_width=bsd_beam_width,\n                        blank_penalty=bsd_blank_penalty,\n                        length_penalty=bsd_length_penalty\n                    )\n                    raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n                    label_sequences = split_labels(labels, label_lengths)\n                    ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                    for label_seq in label_sequences[:3]]\n                    probs = outputs.exp().flatten()\n\n                    writer.add_scalar('Loss/train_batch', loss.item(), global_step)\n                    writer.add_scalar('Blank_Probability/train_batch', blank_probs, global_step)\n                    writer.add_scalar('Gradient_Norm/train_batch', grad_norm_after.item() if num_valid_batches > 0 else 0, global_step)\n                    writer.add_scalar('CER/train_batch', cer, global_step)\n                    writer.add_scalar('WER/train_batch', wer, global_step)\n                    writer.add_scalar('CER_Probability/train_batch', cer_prob, global_step)\n                    writer.add_scalar('WER_Probability/train_batch', wer_prob, global_step)\n\n                    if not (torch.isnan(probs).any() or torch.isinf(probs).any() or torch.unique(probs).numel() <= 1):\n                        writer.add_histogram('Logits/train_probs', probs, global_step)\n                    writer.add_histogram('Raw_Outputs/train_argmax', raw_outputs.flatten(), global_step)\n                    writer.add_text('Raw_Outputs/train_text', f\"Raw train outputs (argmax):\\n{str(raw_outputs)}\", global_step)\n                    token_counts = Counter(raw_outputs.flatten())\n                    writer.add_text('Raw_Outputs/train_token_counts', f\"Token counts: {token_counts}\", global_step)\n\n                    finaltrain_logger.debug(f\"Batch {batch_idx}, Loss: {loss.item():.4f}, CER: {cer:.4f}, WER: {wer:.4f}\")\n\n        # Compute epoch averages\n        if num_valid_batches == 0:\n            finaltrain_logger.warning(f\"All batches skipped in epoch {epoch+1}\")\n            break\n\n        avg_loss = total_loss / num_valid_batches\n        avg_grad_norm = total_grad_norm / num_valid_batches\n        avg_blank_probs = total_blank_probs / num_valid_batches\n        avg_cer = total_cer / num_valid_batches\n        avg_wer = total_wer / num_valid_batches\n        avg_cer_prob = total_cer_prob / num_valid_batches\n        avg_wer_prob = total_wer_prob / num_valid_batches\n\n        writer.add_scalar('Loss/train_epoch', avg_loss, epoch)\n        writer.add_scalar('Gradient_Norm/train_epoch', avg_grad_norm, epoch)\n        writer.add_scalar('Blank_Probability/train_epoch', avg_blank_probs, epoch)\n        writer.add_scalar('CER/train_epoch', avg_cer, epoch)\n        writer.add_scalar('WER/train_epoch', avg_wer, epoch)\n        writer.add_scalar('CER_Probability/train_epoch', avg_cer_prob, epoch)\n        writer.add_scalar('WER_Probability/train_epoch', avg_wer_prob, epoch)\n        finaltrain_logger.info(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, CER: {avg_cer:.4f}, WER: {avg_wer:.4f}\")\n\n        # Validation phase\n        model.eval()\n        val_loss = 0\n        val_blank_probs = 0\n        val_cer = 0\n        val_wer = 0\n        val_cer_prob = 0\n        val_wer_prob = 0\n        val_num_batches = 0\n        with torch.no_grad():\n            for batch_idx, (imgs, labels, label_lengths) in enumerate(val_loader):\n                imgs, labels = imgs.to(device), labels.to(device)\n                label_lengths = label_lengths.to(device)\n                outputs = model(imgs)\n                outputs = outputs.log_softmax(2)\n                seq_length = outputs.size(0)\n                input_lengths = torch.full((imgs.size(0),), seq_length, dtype=torch.long).to(device)\n                val_loss += criterion(outputs, labels, input_lengths, label_lengths).item()\n                val_blank_probs += outputs[:, :, 0].exp().mean().item()\n\n                # Compute CER/WER\n                pred_texts = beam_search_decode(\n                    output=outputs,\n                    idx_to_char=idx_to_char,\n                    target_lengths=label_lengths,\n                    beam_width=bsd_beam_width,\n                    blank_penalty=bsd_blank_penalty,\n                    length_penalty=bsd_length_penalty,\n                    global_step=epoch\n                )\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences]\n                cer = compute_cer(pred_texts, ground_truth)\n                wer = compute_wer(pred_texts, ground_truth)\n                cer_prob, wer_prob = compute_cer_wer_probability(outputs, pred_texts, ground_truth, idx_to_char)\n                val_cer += cer\n                val_wer += wer\n                val_cer_prob += cer_prob\n                val_wer_prob += wer_prob\n                val_num_batches += 1\n\n                # Log first batch\n                if batch_idx == 0:\n                    if not (outputs.numel() == 0 or torch.isnan(outputs).any() or torch.isinf(outputs).any()):\n                        raw_outputs = outputs.argmax(2).cpu().numpy()\n                        writer.add_histogram('Raw_Outputs/val_argmax', raw_outputs.flatten(), global_step=epoch)\n                        writer.add_text('Raw_Outputs/val_text', f\"Raw validation outputs (argmax):\\n{str(raw_outputs[:5])}\", global_step=epoch)\n                        token_counts = Counter(raw_outputs.flatten())\n                        writer.add_text('Raw_Outputs/val_token_counts', f\"Token counts: {token_counts}\", global_step=epoch)\n                        logits_first_step = outputs[0].cpu().numpy()\n                        writer.add_histogram('Raw_Outputs/val_logits_first_step', logits_first_step.flatten(), global_step=epoch)\n                        writer.add_histogram('Logits/val_probs', torch.softmax(outputs[0], dim=-1).flatten(), global_step)\n\n        val_loss /= val_num_batches\n        val_blank_probs /= val_num_batches\n        val_cer /= val_num_batches\n        val_wer /= val_num_batches\n        val_cer_prob /= val_num_batches\n        val_wer_prob /= val_num_batches\n\n        harmonic_mean = compute_harmonic_mean(val_cer, val_wer)\n\n        writer.add_scalar('Loss/val_epoch', val_loss, epoch)\n        writer.add_scalar('Blank_Probability/val_epoch', val_blank_probs, epoch)\n        writer.add_scalar('CER/val_epoch', val_cer, epoch)\n        writer.add_scalar('WER/val_epoch', val_wer, epoch)\n        writer.add_scalar('CER_Probability/val_epoch', val_cer_prob, epoch)\n        writer.add_scalar('WER_Probability/val_epoch', val_wer_prob, epoch)\n        writer.add_scalar('Harmonic_mean/val_epoch', harmonic_mean, epoch)\n        writer.add_text('Predictions/val', f\"Validation Predictions: {pred_texts[:5]}\", epoch)\n        writer.add_text('Ground_Truth/val', f\"Ground Truth: {ground_truth[:5]}\", epoch)\n        finaltrain_logger.info(f\"Validation Loss: {val_loss:.4f}, CER: {val_cer:.4f}, WER: {val_wer:.4f}, Harmonic Mean: {harmonic_mean:.4f}\")\n\n        plateau_scheduler.step(val_loss)\n\n        # Save best model with full checkpoint for resuming training\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            checkpoint = {\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict(),\n                'plateau_scheduler_state_dict': plateau_scheduler.state_dict(),\n                'epoch': epoch,\n                'best_val_loss': best_val_loss,\n                'config_model': config_model,\n                'hyperparameters': {\n                    'learning_rate': learning_rate,\n                    'weight_decay': weight_decay,\n                    'warmup_steps': warmup_steps,\n                    'temperature': temperature,\n                    'ctc_entropy_weight': ctc_entropy_weight,\n                    'ctc_label_smoothing': ctc_label_smoothing,\n                    'ctc_blank_penalty_weight': ctc_blank_penalty_weight,\n                    'bsd_beam_width': bsd_beam_width,\n                    'bsd_blank_penalty': bsd_blank_penalty,\n                    'bsd_length_penalty': bsd_length_penalty,\n                    'gradient_clipping_value': gradient_clipping_value,\n                    'gradient_norm_threshold': gradient_norm_threshold\n                }\n            }\n            torch.save(checkpoint, os.path.join(MODEL_DIR, 'best_ocr_model_final.pth'))\n            finaltrain_logger.info(\"Saved best model checkpoint\")\n\n        # Store final metrics from the last epoch\n        if epoch == num_epochs - 1:\n            final_val_cer = val_cer\n            final_val_wer = val_wer\n            final_harmonic_mean = harmonic_mean\n\n        finaltrain_logger.info(f\"Epoch {epoch+1}/{num_epochs} completed\")\n\n    # Save final model with minimal checkpoint for production\n    checkpoint = {\n        'model_state_dict': model.state_dict(),\n        'config_model': config_model\n    }\n    torch.save(checkpoint, os.path.join(MODEL_DIR, 'final_ocr_model_final.pth'))\n    finaltrain_logger.info(\"Saved final model checkpoint for production\")\n\n    # Export final model to ONNX\n    model.eval()\n    try:\n        # Create a sample input tensor (batch_size=1, channels=1, height=IMG_HEIGHT, width=IMG_WIDTH)\n        sample_input = torch.randn(1, 1, IMG_HEIGHT, IMG_WIDTH).to(device)\n        onnx_path = os.path.join(MODEL_DIR, 'final_ocr_model_final.onnx')\n\n        # Export the model to ONNX\n        torch.onnx.export(\n            model,\n            sample_input,\n            onnx_path,\n            export_params=True,\n            opset_version=11,  # Compatible with most ONNX runtimes\n            do_constant_folding=True,\n            input_names=['input'],\n            output_names=['output'],\n            dynamic_axes={\n                'input': {0: 'batch_size', 3: 'width'},  # Dynamic batch size and width\n                'output': {0: 'sequence_length', 1: 'batch_size'}  # Dynamic sequence length and batch size\n            }\n        )\n        finaltrain_logger.info(f\"Exported final model to ONNX at {onnx_path}\")\n    except Exception as e:\n        finaltrain_logger.error(f\"Failed to export model to ONNX: {str(e)}\")\n\n    # Log final metrics\n    finaltrain_logger.info(\n        f\"Final training metrics: \"\n        f\"Best Validation Loss: {best_val_loss:.4f}, \"\n        f\"Final Validation CER: {final_val_cer:.4f}, \"\n        f\"Final Validation WER: {final_val_wer:.4f}, \"\n        f\"Final Harmonic Mean: {final_harmonic_mean:.4f}\"\n    )\n    writer.add_scalar('Final/Loss', best_val_loss, global_step)\n    writer.add_scalar('Final/CER', final_val_cer, global_step)\n    writer.add_scalar('Final/WER', final_val_wer, global_step)\n    writer.add_scalar('Final/Harmonic_mean', final_harmonic_mean, global_step)\n\n    # Display final metrics for preview\n    print(\n        f\"\\nTraining completed!\\n\"\n        f\"Final metrics:\\n\"\n        f\"  Best Validation Loss: {best_val_loss:.4f}\\n\"\n        f\"  Final Validation CER: {final_val_cer:.4f}\\n\"\n        f\"  Final Validation WER: {final_val_wer:.4f}\\n\"\n        f\"  Final Harmonic Mean: {final_harmonic_mean:.4f}\\n\"\n    )\n\n    writer.close()\n\n    return best_val_loss, final_val_cer, final_val_wer, final_harmonic_mean","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.877239Z","iopub.execute_input":"2025-05-12T06:09:55.877571Z","iopub.status.idle":"2025-05-12T06:09:55.91966Z","shell.execute_reply.started":"2025-05-12T06:09:55.877543Z","shell.execute_reply":"2025-05-12T06:09:55.918783Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Inference (prediction)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def decode_prediction(output, idx_to_char):\n    \"\"\"\n    Decodes the output of an OCR model into readable text.\n\n    This function takes the raw output from an OCR model and converts it into a list of decoded text strings. \n    It applies a softmax function to the output to obtain probabilities for each character at each time step. It then uses a dynamic threshold based on the 75th percentile of these probabilities to filter out low-confidence predictions. The decoded text is constructed by mapping character indices to their corresponding characters using a provided dictionary.\n\n    Args:\n        output (torch.Tensor): The raw output tensor from the OCR model, typically of shape (T, N, C), \n        where T is the time steps, N is the batch size, and C is the number of classes (characters).\n        idx_to_char (dict): A dictionary mapping index values to their corresponding characters.\n\n    Returns:\n        list of str: A list of decoded text strings, one for each sequence in the batch. \n        If a sequence is empty after decoding, it is represented as '<empty>'.\n\n    The function prints the raw predictions and the dynamic threshold used for filtering, \n    providing insights into the decoding process.\n    \"\"\"\n    probs = output.softmax(2)\n    max_probs, preds = probs.max(dim=2)\n    preds = preds.cpu().numpy()\n    max_probs = max_probs.cpu().numpy()\n    texts = []\n    for i, (pred, prob) in enumerate(zip(preds.T, max_probs.T)):\n        #print(f\"Raw prediction {i} (pre-filter): {pred}, Max probs: {prob}\")\n        function_logger.debug(f\"Raw prediction {i} (pre-filter): {pred}, Max probs: {prob}\")\n        # Dynamic threshold: 75th percentile of max probs in this sequence\n        threshold = np.percentile(prob, 75)\n        #print(f\"Dynamic threshold for prediction {i}: {threshold:.4f}\")\n        function_logger.debug(f\"Dynamic threshold for prediction {i}: {threshold:.4f}\")\n        pred_text = []\n        prev = -1\n        for idx, p in zip(pred, prob):\n            if idx != 0 and idx != prev and p > threshold:\n                pred_text.append(idx_to_char.get(idx, ''))\n            prev = idx\n        decoded = ''.join(pred_text)\n        texts.append(decoded if decoded else '<empty>')\n    return texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.920524Z","iopub.execute_input":"2025-05-12T06:09:55.920831Z","iopub.status.idle":"2025-05-12T06:09:55.937209Z","shell.execute_reply.started":"2025-05-12T06:09:55.920801Z","shell.execute_reply":"2025-05-12T06:09:55.936384Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Objective function for Optuna with full TensorBoard logging</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def objective(trial: optuna.trial.Trial):\n    # Global constants\n    global LEARNING_RATE, WEIGHT_DECAY, WARMUP_STEPS, TEMPERATURE\n    global CTC_ENTROPY_WEIGHT, CTC_LABEL_SMOOTHING, CTC_BLANK_PENALTY_WEIGHT\n    global BSD_BEAM_WIDTH, BSD_BLANK_PENALTY, BSD_LENGTH_PENALTY, GRADIENT_NORM_TRESHOLD\n\n    # Suggest hyperparameters to optimize\n    LEARNING_RATE = trial.suggest_float('learning_rate', 1e-5, 3e-3, log=True)\n    WEIGHT_DECAY = trial.suggest_float('weight_decay',1e-6, 1e-3, log=True)\n    WARMUP_STEPS = trial.suggest_int('warmup_steps', 500, 3000)\n    TEMPERATURE = trial.suggest_float('temperature', 0.8, 1.2)\n    CTC_ENTROPY_WEIGHT = trial.suggest_float('ctc_entropy_weight', 0.1, 0.3)\n    CTC_LABEL_SMOOTHING = trial.suggest_float('ctc_label_smoothing', 0.0, 0.2)\n    CTC_BLANK_PENALTY_WEIGHT = trial.suggest_float('ctc_blank_penalty_weight', 0.0, 0.4)\n    BSD_BEAM_WIDTH = trial.suggest_int('bsd_beam_width', 5, 50)\n    BSD_BLANK_PENALTY = trial.suggest_float('bsd_blank_penalty', -0.4, 0)\n    BSD_LENGTH_PENALTY = trial.suggest_float('bsd_length_penalty', -1.5, 0)\n    GRADIENT_CLIPPING_VALUE = trial.suggest_float('gradient_clipping_value', 1.0, 10.0)\n    GRADIENT_NORM_TRESHOLD = trial.suggest_int('gradient_norm_treshold', 200, 400)\n\n    optuna_logger.info('Optimalization hyperparameters was set.')\n\n    # Suggest model architecture parameters\n    config_model = {\n        'cnn_layers': [\n            {'type': 'conv', 'out_channels': trial.suggest_int('cnn_out_channels_1', 32, 128), ': kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu', 'dropout'trial.suggest_float('cnn_dropout_1', 0.1, 0.3)},\n            {'type': 'pool', 'kernel_size': 2, 'stride': 2},\n            {'type': 'conv', 'out_channels': trial.suggest_int('cnn_out_channels_2', 64, 256), 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu', 'dropout': trial.suggest_float('cnn_dropout_2', 0.1, 0.3)},\n            {'type': 'pool', 'kernel_size': 2, 'stride': 2},\n            {'type': 'conv', 'out_channels': trial.suggest_int('cnn_out_channels_3', 128, 512), 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu'},\n            {'type': 'pool', 'kernel_size': (2, 2), 'stride': (2, 1), 'padding': (0, 1)},  # CRNN pooling\n            {'type': 'conv', 'out_channels': trial.suggest_int('cnn_out_channels_4', 256, 768), 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu'},\n            {'type': 'pool', 'kernel_size': (2, 2), 'stride': (2, 1), 'padding': (0, 1)},  # CRNN pooling\n        ],\n        'rnn_type': 'lstm',\n        'rnn_layers': trial.suggest_int('rnn_layers', 1, 3),\n        'hidden_size': trial.suggest_int('hidden_size', 128, 512),\n        'bidirectional': True,\n        'dropout': trial.suggest_float('rnn_dropout', 0.1, 0.4),\n        'fc_layers': [num_chars],  # One layer for OCR\n    }\n\n    optuna_logger.info('Optimalization parameters of neural net model was set.')\n\n    # Clean the labels file\n    valid_chars = set(CHARSET)\n    clean_labels_file(LABELS_FILE, valid_chars)\n    optuna_logger.info('Validation of LABELS_FILE was done.')\n\n    # Initialize the TensorBoard writer for this trial\n    log_dir = os.path.join(TENSORBOARD_DIR, f\"ocr_experiment_trial_{trial.number}\")\n    optuna_logger.info(f\"Start train of trial number: {trial.number}\")\n\n    global writer  # We use a global writer to make it available in train_model and elsewhere\n\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    writer = SummaryWriter(log_dir)\n\n    # Log the config_model settings to TensorBoard\n    config_text = \"\\n\".join([f\"{k}: {v}\" for k, v in config_model.items()])\n    writer.add_text('Config/model', config_text, 0)\n\n    print(f\"Model configuration:\\n {config_model} \\n\")\n    optuna_logger.debug(f\"Model configuration:\\n {config_model} \\n\")\n\n    # Device setup\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Dataset setup (we assume that synthetic data is already generated)\n    full_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n    optuna_logger.info(\"Was load synthetic data of dataset.\")\n\n    for i in range(5):\n        img, label, length = full_dataset[i]\n        plt.imshow(img.squeeze(), cmap='gray')\n        plt.title(''.join([idx_to_char.get(idx.item(), '') for idx in label[:length]]))\n        plt.show()\n\n    if len(full_dataset) == 0:\n        print(\"Dataset is empty! Check labels.txt or image directory.\")\n        optuna_logger.error(\"Dataset is empty! Check labels.txt or image directory.\")\n\n        if not font_files:\n            print(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n            optuna_logger.error(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n        else:\n            # Clean the labels file\n            valid_chars = set(CHARSET)\n            clean_labels_file(LABELS_FILE, valid_chars)\n            optuna_logger.info('Validation of LABELS_FILE was done.')\n            \n            create_synthetic_dataset(NUM_SAMPLES)\n            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n            full_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n    else:\n        for i in range(5):\n            img, label, length = full_dataset[i]\n            plt.imshow(img.squeeze(), cmap='gray')\n            plt.title(''.join([idx_to_char.get(idx.item(), '') for idx in label[:length]]))\n            plt.show()\n\n        optuna_logger.info(\"Samples of data was shown.\")\n        \n        # Curriculum phases with pre-filtering\n        model = OCRModel(config=config_model).to(device)\n\n        # Log the model graph to TensorBoard\n        try:\n            # Create a sample input tensor with the same shape as your dataset images\n            sample_input = torch.randn(1, 1, IMG_HEIGHT, IMG_WIDTH).to(device)  # Shape: (batch_size, channels, height, width)\n            writer.add_graph(model, sample_input)\n            #print(f\"Logged model graph to TensorBoard for trial {trial.number}.\")\n            optuna_logger.info(f\"Logged model graph to TensorBoard for trial {trial.number}.\")\n        except Exception as e:\n            #print(f\"Failed to log model graph to TensorBoard for trial {trial.number}: {str(e)}\")\n            optuna_logger.warning(f\"Failed to log model graph to TensorBoard for trial {trial.number}: {str(e)}\")\n\n        \n        criterion = CTCLossWithBlankPenalty(\n            blank=0, zero_infinity=True, blank_penalty_weight=CTC_BLANK_PENALTY_WEIGHT,\n            entropy_weight=CTC_ENTROPY_WEIGHT, label_smoothing=CTC_LABEL_SMOOTHING\n        )\n\n        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n\n        optuna_logger.info(\"Model, Criterion, Optimizer, Scheduler was set.\")\n        \n        best_val_loss = float('inf')\n        avg_grad_norm = 0\n        avg_blank_probs = 0\n        avg_loss = 0  # Initialize avg_loss\n\n        for epoch in range(EPOCHS):\n            optuna_logger.info(f\"Start epoch number: {epoch}\")\n            label_lengths = [lbl_len for _, _, lbl_len in full_dataset.data]\n            #print(f\"Label lengths: {label_lengths}\")\n            optuna_logger.debug(f\"Label lengths: {label_lengths}\")\n            # Filter full dataset based on curriculum phase\n            if epoch < 5:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 10]\n                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]  # lbl is a string\n                #print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n                optuna_logger.debug(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n            elif epoch < 10:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 15]\n                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]\n                #print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n                optuna_logger.debug(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n            else:\n                filtered_data = full_dataset.data\n                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]\n                #print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n                optuna_logger.debug(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n\n            # Create a new dataset with filtered data\n            curr_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n            curr_dataset.data = filtered_data  # Overwrite with filtered data\n\n            # Split into train and validation\n            train_size = int(0.8 * len(curr_dataset))\n            val_size = len(curr_dataset) - train_size\n            train_dataset, val_dataset = torch.utils.data.random_split(curr_dataset, [train_size, val_size])\n            #print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n            optuna_logger.debug(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n\n            # Create data loaders\n            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n            val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n\n            skipped_batches = 0\n\n            # Training with TensorBoard logging\n            model.train()\n            optuna_logger.info('Start Train process.')\n            total_loss = 0\n            total_grad_norm = 0\n            total_blank_probs = 0\n            total_cer = 0  # Initialize total_cer\n            total_wer = 0  # Initialize total_wer\n            total_cer_prob = 0  # Initialize total_cer_prob\n            total_wer_prob = 0  # Initialize total_wer_prob\n            max_skipped_batches = max(1, int(0.1 * len(train_loader)))  # Allow up to 10% of batches to be skipped\n            avg_loss = 0  # Track average loss for dynamic threshold\n            num_valid_batches = 0\n            \n            global_step = epoch * len(train_loader)\n            \n            for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n                imgs, labels = imgs.to(device), labels.to(device)\n                label_lengths = label_lengths.to(device)\n\n                if global_step < WARMUP_STEPS:\n                    lr_scale = min(1.0, float(global_step + 1) / WARMUP_STEPS)\n                    for param_group in optimizer.param_groups:\n                        param_group['lr'] = LEARNING_RATE * lr_scale\n                        optuna_logger.debug(f\"Learning rate set at value: {param_group['lr']}\")\n\n                optimizer.zero_grad()\n                max_label_length = label_lengths.max().item()\n                outputs = model(imgs, max_length=max_label_length * 2)\n                outputs = outputs / TEMPERATURE\n                outputs = torch.clamp(outputs, min=-10, max=10)  # Clipping for stability\n                outputs = outputs.log_softmax(2)\n\n                batch_size = imgs.size(0)\n                seq_length = min(outputs.size(0), max_label_length * 2)\n                input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n\n                # Dynamic penalty for blank tokens\n                blank_probs = outputs[:, :, 0].exp().mean().item()\n                dynamic_blank_penalty = CTC_BLANK_PENALTY_WEIGHT * (1 + blank_probs)\n                criterion = CTCLossWithBlankPenalty(\n                    blank=0, zero_infinity=True, blank_penalty_weight=dynamic_blank_penalty,\n                    entropy_weight=CTC_ENTROPY_WEIGHT, label_smoothing=CTC_LABEL_SMOOTHING\n                )\n\n                loss = criterion(outputs, labels, input_lengths, label_lengths)\n\n                # Calculating the gradient norm before clipping\n                grad_norm_before = compute_gradient_norm(model.parameters())\n\n                # Dynamic threshold based on average loss of previous batches\n                dynamic_threshold = max(40, avg_loss * 2) if num_valid_batches > 0 else 40  # Dynamic threshold\n                \n                if torch.isnan(loss) or torch.isinf(loss):\n                    #print(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n                    optuna_logger.warning(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n                    writer.add_scalar('Skipped_Batches/NaN_Inf', 1, global_step)\n                    skipped_batches += 1\n                elif grad_norm_before > GRADIENT_NORM_TRESHOLD:  # Gradient norm threshold\n                    #print(f\"Warning: High gradient norm {grad_norm_before:.4f} at batch {batch_idx}. Skipping...\")\n                    optuna_logger.warning(f\"Warning: High gradient norm {grad_norm_before:.4f} at batch {batch_idx}. Skipping...\")\n                    writer.add_scalar('Skipped_Batches/High_Gradient', 1, global_step)\n                    skipped_batches += 1\n                elif loss.item() > dynamic_threshold:\n                    #print(f\"Warning: High loss {loss.item():.4f} at batch {batch_idx}. Adjusting learning rate...\")\n                    optuna_logger.warning(f\"Warning: High loss {loss.item():.4f} at batch {batch_idx}. Adjusting learning rate...\")\n                    # Gradually reduce the learning rate\n                    for param_group in optimizer.param_groups:\n                        param_group['lr'] *= 0.9  # Reduce learning rate by 10%\n                        optuna_logger.debug(f\"Learning rate set at value: {param_group['lr']}\")\n                    writer.add_scalar('Skipped_Batches/High_Loss', 1, global_step)\n                    skipped_batches += 1\n                else:\n                    loss.backward()\n\n                    # Gradient clipping with a reasonable max_norm value\n                    grad_norm_after = nn_utils.clip_grad_norm_(model.parameters(), max_norm=GRADIENT_CLIPPING_VALUE)\n\n                    # Logging gradient norms\n                    #print(f\"Epoch {epoch+1}, Batch {batch_idx}, Gradient Norm Before: {grad_norm_before:.4f}, After: {grad_norm_after:.4f}\")\n                    optuna_logger.debug(f\"Epoch {epoch+1}, Batch {batch_idx}, Gradient Norm Before: {grad_norm_before:.4f}, After: {grad_norm_after:.4f}\")\n                    writer.add_scalar('Gradient_Norm/train_batch', grad_norm_after.item(), global_step)\n                \n                    optimizer.step()\n                    total_loss += loss.item()\n                    total_grad_norm += grad_norm_after.item()\n                    total_blank_probs += blank_probs\n                    num_valid_batches += 1\n                    avg_loss = total_loss / num_valid_batches if num_valid_batches > 0 else 0\n\n                    # Compute CER, WER, and CER/WER probability\n                    with torch.no_grad():\n                        pred_texts = beam_search_decode(\n                            output=outputs,\n                            idx_to_char=idx_to_char,\n                            target_lengths=label_lengths,\n                            beam_width=BSD_BEAM_WIDTH,\n                            blank_penalty=BSD_BLANK_PENALTY,\n                            length_penalty=BSD_LENGTH_PENALTY,\n                            global_step=global_step\n                        )\n                        label_sequences = split_labels(labels, label_lengths)\n                        ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                        for label_seq in label_sequences]\n\n                        cer = compute_cer(pred_texts, ground_truth)\n                        wer = compute_wer(pred_texts, ground_truth)\n                        cer_prob, wer_prob = compute_cer_wer_probability(outputs, pred_texts, ground_truth, idx_to_char)\n\n                        total_cer += cer\n                        total_wer += wer\n                        total_cer_prob += cer_prob\n                        total_wer_prob += wer_prob\n\n                # Prune trial if too many batches are skipped\n                if skipped_batches > max_skipped_batches:\n                    #print(f\"Too many skipped batches ({skipped_batches}/{max_skipped_batches}) in epoch {epoch+1}. Pruning trial.\")\n                    optuna_logger.warning(f\"Too many skipped batches ({skipped_batches}/{max_skipped_batches}) in epoch {epoch+1}. Pruning trial.\")\n                    writer.add_text(\n                        'Pruning/Details',\n                        f\"Pruned at epoch {epoch+1}, batch {batch_idx}. Skipped batches: {skipped_batches}, \"\n                        f\"Input lengths: {input_lengths.tolist()}, Label lengths: {label_lengths.tolist()}\",\n                        global_step\n                    )\n                    optuna_logger.debug(f'Trial {trial.number} break in epoch {epoch+1}')\n                    raise optuna.TrialPruned()\n                \n                global_step += 1\n\n                \n                # Log additional metrics\n                if batch_idx % NUMBER_OF_BATCH_REPORT == 0:\n                    with torch.no_grad():\n                        pred_texts = beam_search_decode(\n                                        output=outputs,\n                                        idx_to_char=idx_to_char,\n                                        target_lengths=label_lengths,\n                                        beam_width=BSD_BEAM_WIDTH,\n                                        blank_penalty=BSD_BLANK_PENALTY,\n                                        length_penalty=BSD_LENGTH_PENALTY\n                                    )\n                        raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n                        blank_probs = outputs[:, :, 0].exp().mean().item()\n                        label_sequences = split_labels(labels, label_lengths)\n                        ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                        for label_seq in label_sequences[:3]]\n                        \n                        probs = outputs.exp().flatten()\n                        #print(f\"Probs min: {probs.min().item()}, max: {probs.max().item()}, mean: {probs.mean().item()}\")\n                        optuna_logger.debug(f\"Probs min: {probs.min().item()}, max: {probs.max().item()}, mean: {probs.mean().item()}\")\n                        #print(f\"Probs unique values: {torch.unique(probs).numel()}\")\n                        optuna_logger.debug(f\"Probs unique values: {torch.unique(probs).numel()}\")\n                        if torch.isnan(probs).any() or torch.isinf(probs).any():\n                            #print(\"Warning: NaN or Inf values in probs\")\n                            optuna_logger.warning(\"Warning: NaN or Inf values in probs\")\n\n                        # Logging into TensorBoard\n                        writer.add_scalar('Loss/train_batch', loss.item(), global_step)\n                        writer.add_scalar('Blank_Probability/train_batch', blank_probs, global_step)\n                        writer.add_scalar('Gradient_Norm/train_batch', grad_norm_after.item(), global_step)\n                        writer.add_scalar('CER/train_batch', cer, global_step)\n                        writer.add_scalar('WER/train_batch', wer, global_step)\n                        writer.add_scalar('CER_Probability/train_batch', cer_prob, global_step)\n                        writer.add_scalar('WER_Probability/train_batch', wer_prob, global_step)\n                        \n                        if torch.isnan(probs).any() or torch.isinf(probs).any() or torch.unique(probs).numel() <= 1:\n                            #print(\"Skipping histogram logging due to invalid or degenerate data\")\n                            optuna_logger.warning(\"Skipping histogram logging due to invalid or degenerate data\")\n                        else:\n                            writer.add_histogram('Logits/train_probs', probs, global_step)\n\n                        # Adding raw outputs\n                        writer.add_histogram('Raw_Outputs/train_argmax', raw_outputs.flatten(), global_step)\n                        writer.add_text('Raw_Outputs/train_text', f\"Raw train outputs (argmax):\\n{str(raw_outputs)}\", global_step)\n\n                        # Token frequency calculation and logging\n                        token_counts = Counter(raw_outputs.flatten())\n                        writer.add_text(\n                            'Raw_Outputs/train_token_counts',\n                            f\"Token counts: {token_counts}\",\n                            global_step\n                        )\n\n                        #print(f\"Batch {batch_idx}, Gradient norm: {grad_norm_after.item():.4f}\")\n                        optuna_logger.debug(f\"Batch {batch_idx}, Gradient norm: {grad_norm_after.item():.4f}\")\n                        #print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n                        optuna_logger.debug(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n                        #print(f\"Avg Blank Probability: {blank_probs:.4f}\")\n                        optuna_logger.debug(f\"Avg Blank Probability: {blank_probs:.4f}\")\n                        #print(f\"CER: {cer:.4f}, WER: {wer:.4f}\")\n                        optuna_logger.debug(f\"CER: {cer:.4f}, WER: {wer:.4f}\")\n                        #print(f\"CER Probability: {cer_prob:.4f}, WER Probability: {wer_prob:.4f}\")\n                        optuna_logger.debug(f\"CER Probability: {cer_prob:.4f}, WER Probability: {wer_prob:.4f}\")\n                        #print(f\"Sample predictions: {pred_texts[:3]}\")\n                        optuna_logger.debug(f\"Sample predictions: {pred_texts[:3]}\")\n                        #print(f\"Ground Truth (first 3): {ground_truth}\")\n                        optuna_logger.debug(f\"Ground Truth (first 3): {ground_truth}\")\n                        #print(f\"Raw outputs (first 3): {raw_outputs}\")\n                        optuna_logger.debug(f\"Raw outputs (first 3): {raw_outputs}\")\n                        #print(f\"Input length: {seq_length}, Label lengths: {label_lengths[:3].tolist()}\")\n                        optuna_logger.debug(f\"Input length: {seq_length}, Label lengths: {label_lengths[:3].tolist()}\")\n                        #print(f\"Number of skipped batches: {skipped_batches}\")\n                        optuna_logger.debug(f\"Number of skipped batches: {skipped_batches}\")\n\n            # Compute epoch averages\n            if num_valid_batches == 0:\n                #print(\"All batches skipped in this epoch. Pruning trial.\")\n                optuna_logger.warning(\"All batches skipped in this epoch. Pruning trial.\")\n                raise optuna.TrialPruned()\n\n            avg_loss = total_loss / len(train_loader)\n            avg_grad_norm = total_grad_norm / len(train_loader)\n            avg_blank_probs = total_blank_probs / len(train_loader)\n            avg_cer = total_cer / num_valid_batches\n            avg_wer = total_wer / num_valid_batches\n            avg_cer_prob = total_cer_prob / num_valid_batches\n            avg_wer_prob = total_wer_prob / num_valid_batches\n\n                    \n            writer.add_scalar('Loss/train_epoch', avg_loss, epoch)\n            writer.add_scalar('Gradient_Norm/train_epoch', avg_grad_norm, epoch)\n            writer.add_scalar('Blank_Probability/train_epoch', avg_blank_probs, epoch)\n            writer.add_scalar('CER/train_epoch', avg_cer, epoch)\n            writer.add_scalar('WER/train_epoch', avg_wer, epoch)\n            writer.add_scalar('CER_Probability/train_epoch', avg_cer_prob, epoch)\n            writer.add_scalar('WER_Probability/train_epoch', avg_wer_prob, epoch)\n            print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.4f}\")\n            print(f\"Avg CER: {avg_cer:.4f}, Avg WER: {avg_wer:.4f}\")\n            print(f\"Avg CER Probability: {avg_cer_prob:.4f}, Avg WER Probability: {avg_wer_prob:.4f}\")\n            optuna_logger.info(f\"Train process finished: Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.4f}\")\n            optuna_logger.info(f\"Avg CER: {avg_cer:.4f}, Avg WER: {avg_wer:.4f}\")\n            optuna_logger.info(f\"Avg CER Probability: {avg_cer_prob:.4f}, Avg WER Probability: {avg_wer_prob:.4f}\")\n\n            # Validation with TensorBoard logging\n            model.eval()\n            optuna_logger.info('Start Evaluation process.')\n            val_loss = 0\n            val_blank_probs = 0\n            val_cer = 0\n            val_wer = 0\n            val_cer_prob = 0\n            val_wer_prob = 0\n            val_num_batches = 0\n            with torch.no_grad():\n                for batch_idx, (imgs, labels, label_lengths) in enumerate(val_loader):\n                    imgs, labels = imgs.to(device), labels.to(device)\n                    label_lengths = label_lengths.to(device)\n                    outputs = model(imgs)\n                    outputs = outputs.log_softmax(2)\n                    seq_length = outputs.size(0)\n                    input_lengths = torch.full((imgs.size(0),), seq_length, dtype=torch.long).to(device)\n                    val_loss += criterion(outputs, labels, input_lengths, label_lengths).item()\n                    val_blank_probs += outputs[:, :, 0].exp().mean().item()\n\n                    # Compute CER, WER, and CER/WER probability\n                    pred_texts = beam_search_decode(\n                        output=outputs,\n                        idx_to_char=idx_to_char,\n                        target_lengths=label_lengths,\n                        beam_width=BSD_BEAM_WIDTH,\n                        blank_penalty=BSD_BLANK_PENALTY,\n                        length_penalty=BSD_LENGTH_PENALTY,\n                        global_step=epoch\n                    )\n                    label_sequences = split_labels(labels, label_lengths)\n                    ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                    for label_seq in label_sequences]\n\n                    cer = compute_cer(pred_texts, ground_truth)\n                    wer = compute_wer(pred_texts, ground_truth)\n                    cer_prob, wer_prob = compute_cer_wer_probability(outputs, pred_texts, ground_truth, idx_to_char)\n\n                    val_cer += cer\n                    val_wer += wer\n                    val_cer_prob += cer_prob\n                    val_wer_prob += wer_prob\n                    val_num_batches += 1\n       \n                    # Logging raw outputs for the first batch\n                    if batch_idx == 0:  # We only log the first batch to save space\n\n                        # Control of the form and content of outputs\n                        #print(f\"Outputs shape: {outputs.shape}, Outputs[0] shape: {outputs[0].shape}\")\n                        optuna_logger.debug(f\"Outputs shape: {outputs.shape}, Outputs[0] shape: {outputs[0].shape}\")\n                        if outputs.numel() == 0 or torch.isnan(outputs).any() or torch.isinf(outputs).any():\n                            #print(\"Warning: Outputs contains invalid values (empty, NaN, or Inf). Skipping histogram logging.\")\n                            optuna_logger.warning(\"Warning: Outputs contains invalid values (empty, NaN, or Inf). Skipping histogram logging.\")\n                            continue\n\n                        # 1. Histogram of the distribution of predicted tokens (argmax)\n                        raw_outputs = outputs.argmax(2).cpu().numpy()  # [seq_length, batch_size]\n                        writer.add_histogram(\n                            'Raw_Outputs/val_argmax',\n                            raw_outputs.flatten(),  # We convert to a 1D array for the histogram\n                            global_step=epoch\n                        )\n\n                        # 2. Text listing of raw outputs (first 5 sequences)\n                        raw_outputs_text = str(raw_outputs[:5])  # First 5 sequences as text\n                        writer.add_text(\n                            'Raw_Outputs/val_text',\n                            f\"Raw validation outputs (argmax) for first batch:\\n{raw_outputs_text}\",\n                            global_step=epoch\n                        )\n\n                        # 3. Calculating token frequency and logging to TensorBoard\n                        token_counts = Counter(raw_outputs.flatten())\n                        writer.add_text(\n                            'Raw_Outputs/val_token_counts',\n                            f\"Token counts: {token_counts}\",\n                            global_step=epoch\n                        )\n\n                        # 4. (Optional) Logit histogram for specific tokens (e.g. first time step)\n                        logits_first_step = outputs[0].cpu().numpy()  # [batch_size, num_chars]\n                        writer.add_histogram(\n                            'Raw_Outputs/val_logits_first_step',\n                            logits_first_step.flatten(),\n                            global_step=epoch\n                        )\n\n                        logits_first_step = outputs[0].cpu().numpy()\n                        writer.add_histogram('Logits/val_probs', torch.softmax(outputs[0], dim=-1).flatten(), global_step)\n\n                val_loss /= len(val_loader)\n                val_blank_probs /= len(val_loader)\n                val_cer /= val_num_batches\n                val_wer /= val_num_batches\n                val_cer_prob /= val_num_batches\n                val_wer_prob /= val_num_batches\n\n                harmonic_mean = compute_harmonic_mean(val_cer, val_wer)\n\n                #if val_cer + val_wer == 0:\n                #    harmonic_mean = 0.0\n                #else:\n                #    harmonic_mean = 2 / (1 / (val_cer + 1e-9) + 1 / (val_wer + 1e-9))\n                \n                pred_texts = beam_search_decode(\n                                output=outputs,\n                                idx_to_char=idx_to_char,\n                                target_lengths=label_lengths,\n                                beam_width=BSD_BEAM_WIDTH,\n                                blank_penalty=BSD_BLANK_PENALTY,\n                                length_penalty=BSD_LENGTH_PENALTY\n                            )\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:5]]\n\n                # Calculating edit distance\n                edit_distances = []\n                for pred, gt in zip(pred_texts, ground_truth):\n                    edit_distances.append(levenshtein_distance(pred, gt))\n                avg_edit_distance = sum(edit_distances) / len(edit_distances) if edit_distances else 0\n\n                \n                # Validation logging to TensorBoard\n                writer.add_scalar('Loss/val_epoch', val_loss, epoch)\n                writer.add_scalar('Blank_Probability/val_epoch', val_blank_probs, epoch)\n                writer.add_scalar('CER/val_epoch', val_cer, epoch)\n                writer.add_scalar('WER/val_epoch', val_wer, epoch)\n                writer.add_scalar('CER_Probability/val_epoch', val_cer_prob, epoch)\n                writer.add_scalar('WER_Probability/val_epoch', val_wer_prob, epoch)\n                writer.add_scalar('Harmonic_mean/val_epoch', harmonic_mean, epoch)\n                writer.add_text('Predictions/val', f\"Validation Predictions: {pred_texts[:5]}\", epoch)\n                writer.add_text('Ground_Truth/val', f\"Ground Truth: {ground_truth}\", epoch)\n                print(f\"Validation Loss: {val_loss:.4f}\")\n                optuna_logger.debug(f\"Validation Loss: {val_loss:.4f}\")\n                print(f\"Validation CER: {val_cer:.4f}, Validation WER: {val_wer:.4f}\")\n                optuna_logger.debug(f\"Validation CER: {val_cer:.4f}, Validation WER: {val_wer:.4f}\")\n                print(f\"Validation CER Probability: {val_cer_prob:.4f}, Validation WER Probability: {val_wer_prob:.4f}\")\n                optuna_logger.debug(f\"Validation CER Probability: {val_cer_prob:.4f}, Validation WER Probability: {val_wer_prob:.4f}\")\n                #print(\"Validation Predictions:\", pred_texts[:5])\n                optuna_logger.debug(f\"Validation Predictions: {pred_texts[:5]}\")\n                #print(\"Ground Truth:\", ground_truth)\n                optuna_logger.debug(f\"Ground Truth: {ground_truth}\")\n                print(\"Harmonic mean:\", harmonic_mean)\n                optuna_logger.debug(f\"Harmonic mean: {harmonic_mean}\")\n\n            scheduler.step(val_loss)\n\n            current_lr = scheduler.get_last_lr()[0]  # get_last_lr() returns a list.\n            #print(f\"Current Learning Rate: {current_lr}\")\n            optuna_logger.debug(f\"Current Learning Rate: {current_lr}\")\n\n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                torch.save(model.state_dict(), os.path.join(MODEL_DIR, f'best_ocr_model_{trial.number}.pth'))\n                optuna_logger.info(f\"Best model was saved: best_ocr_model_{trial.number}.pth\")\n\n            optuna_logger.info(f\"Validation process finished: Epoch {epoch+1}/{EPOCHS}, Loss: {val_loss:.4f}\")\n            \n        torch.save(model.state_dict(), os.path.join(MODEL_DIR, f'final_ocr_model_{trial.number}.pth'))\n        optuna_logger.info(f\"Final model was saved: final_ocr_model_{trial.number}.pth\")\n\n    avg_grad_norm /= EPOCHS\n    avg_blank_probs /= EPOCHS\n\n    trial.set_user_attr(\"best_val_cer\", best_val_loss)\n    trial.set_user_attr(\"avg_grad_norm\", avg_grad_norm)\n    trial.set_user_attr(\"val_cer_prob\", val_cer_prob)\n    trial.set_user_attr(\"val_wer_prob\", val_wer_prob)\n    trial.set_user_attr(\"avg_blank_probs\", val_blank_probs)\n    trial.set_user_attr(\"harmonic_mean\", harmonic_mean)\n\n    # Closing the TensorBoard writer\n    writer.close()\n\n    return val_cer_prob, val_wer_prob, avg_blank_probs, harmonic_mean  # Metric to minimize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:55.938202Z","iopub.execute_input":"2025-05-12T06:09:55.938502Z","iopub.status.idle":"2025-05-12T06:09:56.254628Z","shell.execute_reply.started":"2025-05-12T06:09:55.938464Z","shell.execute_reply":"2025-05-12T06:09:56.253635Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function to run Optuna Dashboard in the background</font>**","metadata":{}},{"cell_type":"code","source":"def run_optuna_dashboard(storage_path):\n    print(f\"Starting Optuna Dashboard with storage: {storage_path}\")\n    os.system(f\"optuna-dashboard sqlite:///{storage_path} --host 0.0.0.0 --port 8080 &\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:56.255282Z","iopub.execute_input":"2025-05-12T06:09:56.255545Z","iopub.status.idle":"2025-05-12T06:09:56.273551Z","shell.execute_reply.started":"2025-05-12T06:09:56.255524Z","shell.execute_reply":"2025-05-12T06:09:56.272765Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function create model from optuna optimizations trial parameters</font>**","metadata":{}},{"cell_type":"code","source":"def construct_config_model(trial_params):\n    \"\"\"Construct config_model from Optuna trial parameters.\"\"\"\n    return {\n        'cnn_layers': [\n            {'type': 'conv', 'out_channels': trial_params['cnn_out_channels_1'], 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu', 'dropout': trial_params['cnn_dropout_1']},\n            {'type': 'pool', 'kernel_size': 2, 'stride': 2},\n            {'type': 'conv', 'out_channels': trial_params['cnn_out_channels_2'], 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu', 'dropout': trial_params['cnn_dropout_2']},\n            {'type': 'pool', 'kernel_size': 2, 'stride': 2},\n            {'type': 'conv', 'out_channels': trial_params['cnn_out_channels_3'], 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu'},\n            {'type': 'pool', 'kernel_size': (2, 2), 'stride': (2, 1), 'padding': (0, 1)},\n            {'type': 'conv', 'out_channels': trial_params['cnn_out_channels_4'], 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu'},\n            {'type': 'pool', 'kernel_size': (2, 2), 'stride': (2, 1), 'padding': (0, 1)},\n        ],\n        'rnn_type': 'lstm',\n        'rnn_layers': trial_params['rnn_layers'],\n        'hidden_size': trial_params['hidden_size'],\n        'bidirectional': True,\n        'dropout': trial_params['rnn_dropout'],\n        'fc_layers': [len(CHARSET)],  # Adjust based on your num_chars\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:56.274374Z","iopub.execute_input":"2025-05-12T06:09:56.27465Z","iopub.status.idle":"2025-05-12T06:09:56.29348Z","shell.execute_reply.started":"2025-05-12T06:09:56.274615Z","shell.execute_reply":"2025-05-12T06:09:56.292663Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function for calculation of balance metric</font>**","metadata":{}},{"cell_type":"code","source":"# Select best trial (minimize |val_cer - val_wer| first, then best_val_loss)\ndef balance_metric(t):\n    val_cer = t.user_attrs.get('val_cer', float('inf'))\n    val_wer = t.user_attrs.get('val_wer', float('inf'))\n    balance = abs(val_cer - val_wer)  # Absolute difference for CER-WER balance\n    return (balance, t.values[0])  # Balance first, then val_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:56.294275Z","iopub.execute_input":"2025-05-12T06:09:56.294575Z","iopub.status.idle":"2025-05-12T06:09:56.307687Z","shell.execute_reply.started":"2025-05-12T06:09:56.294545Z","shell.execute_reply":"2025-05-12T06:09:56.306807Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Main function</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Synthetic data generation (same as originally)\n    if not font_files:\n        print(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n        main_logger.error(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n    else:\n        create_synthetic_dataset(NUM_SAMPLES)\n        main_logger.info(\"Synthetic dataset generated.\")\n\n    # Path to Optuna database\n    storage_path = os.path.join(OPTUNA_DIR, 'optuna_study.db')\n    storage = f\"sqlite:///{storage_path}\"\n    main_logger.info(f\"Optuna database set at {storage_path}\")\n\n    # Device setup\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    if not FINAL_TRAINING:\n        # Multi-objective study\n        study = optuna.create_study(\n            directions=[\"minimize\", \"minimize\", \"minimize\", \"maximize\"],  # Validation loss, grad_norm, blank_probs\n            storage=storage,\n            study_name=\"ocr_multiobjective\",\n            load_if_exists=True\n        )\n        main_logger.info(\"Set & Run Optuna optimalization.\")\n        study.optimize(objective, n_trials=NUMBER_OF_OPTUNA_TRIALS) # You can adjust the number of trials\n\n        # Log best trials (Pareto front)\n        #print(\"Best trials (Pareto front):\")\n        main_logger.info(\"Best trials (Pareto front):\")\n        for trial in study.best_trials:\n            #print(f\"  Trial {trial.number}:\")\n            main_logger.debug(f\"Trial {trial.number}:\")\n            #print(f\"    Values: val_loss={trial.values[0]}, grad_norm={trial.values[1]}, blank_probs={trial.values[2]}\")\n            main_logger.debug(f\"Values: val_loss={trial.values[0]}, grad_norm={trial.values[1]}, blank_probs={trial.values[2]}\")\n            #print(f\"    Params: {trial.params}\")\n            main_logger.debug(f\"Params: {trial.params}\")\n\n        # Running Optuna Dashboard in the background\n        dashboard_thread = threading.Thread(target=run_optuna_dashboard, args=(storage_path,))\n        dashboard_thread.start()\n    else:\n        # Load study for final training\n        main_logger.info(\"Starting final training with predefined hyperparameters and model configuration.\")\n        pretrained_model_path = PRETRAINED_MODEL_PATH\n        \n        # Construct config_model from best trial parameters\n        config_model_train = config_model\n\n        # Load dataset\n        full_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n        main_logger.info(\"Loaded dataset for final training.\")\n\n        # Run final training\n        best_val_loss, final_val_cer, final_val_wer, final_harmonic_mean = train(\n            full_dataset=full_dataset,\n            device=device,\n            config_model=config_model_train,\n            pretrained_model_path=PRETRAINED_MODEL_PATH,\n            num_epochs=FINAL_EPOCHS,\n            learning_rate=LEARNING_RATE,\n            weight_decay=WEIGHT_DECAY,\n            warmup_steps=WARMUP_STEPS,\n            temperature=TEMPERATURE,\n            ctc_entropy_weight=CTC_ENTROPY_WEIGHT,\n            ctc_label_smoothing=CTC_LABEL_SMOOTHING,\n            ctc_blank_penalty_weight=CTC_BLANK_PENALTY_WEIGHT,\n            bsd_beam_width=BSD_BEAM_WIDTH,\n            bsd_blank_penalty=BSD_BLANK_PENALTY,\n            bsd_length_penalty=BSD_LENGTH_PENALTY,\n            gradient_clipping_value=GRADIENT_CLIPPING_VALUE,\n            gradient_norm_threshold=GRADIENT_NORM_TRESHOLD\n        )\n        \n        main_logger.info(\n            f\"Final training completed: \"\n            f\"Best Validation Loss: {best_val_loss:.4f}, \"\n            f\"Final Validation CER: {final_val_cer:.4f}, \"\n            f\"Final Validation WER: {final_val_wer:.4f}, \"\n            f\"Final Harmonic Mean: {final_harmonic_mean:.4f}\"\n        )\n\n    # Close the file after logging is complete\n    rotating_json_file_handler.close()","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-05-12T06:09:56.308595Z","iopub.execute_input":"2025-05-12T06:09:56.308866Z","iopub.status.idle":"2025-05-12T07:30:06.77826Z","shell.execute_reply.started":"2025-05-12T06:09:56.308843Z","shell.execute_reply":"2025-05-12T07:30:06.77756Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Check final ONNX model</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"# Load ONNX model\nif FINAL_TRAINING:\n    onnx_model = onnx.load(os.path.join(MODEL_DIR, 'final_ocr_model_final.onnx'))\n    onnx.checker.check_model(onnx_model)\n    print(\"ONNX model is valid\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T07:30:06.77919Z","iopub.execute_input":"2025-05-12T07:30:06.779437Z","iopub.status.idle":"2025-05-12T07:30:06.845263Z","shell.execute_reply.started":"2025-05-12T07:30:06.779412Z","shell.execute_reply":"2025-05-12T07:30:06.844537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run inference\nif FINAL_TRAINING:\n    ort_session = ort.InferenceSession(os.path.join(MODEL_DIR, 'final_ocr_model_final.onnx'))\n    sample_input = np.random.randn(1, 1, IMG_HEIGHT, IMG_WIDTH).astype(np.float32)\n    outputs = ort_session.run(None, {'input': sample_input})\n    print(\"ONNX inference successful, output shape:\", outputs[0].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T07:30:06.84604Z","iopub.execute_input":"2025-05-12T07:30:06.846291Z","iopub.status.idle":"2025-05-12T07:30:06.885065Z","shell.execute_reply.started":"2025-05-12T07:30:06.846256Z","shell.execute_reply":"2025-05-12T07:30:06.88421Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Download results</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def zip_folder_with_shutil(source_folder, output_path):\n    '''Function for zip dir data'''\n    shutil.make_archive(output_path, 'zip', source_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T07:30:06.885976Z","iopub.execute_input":"2025-05-12T07:30:06.886296Z","iopub.status.idle":"2025-05-12T07:30:06.897784Z","shell.execute_reply.started":"2025-05-12T07:30:06.886264Z","shell.execute_reply":"2025-05-12T07:30:06.897059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/backgrounds', '/kaggle/working/backgrounds')\nzip_folder_with_shutil('/kaggle/working/synthetic_data', '/kaggle/working/synthetic_data')\nzip_folder_with_shutil('/kaggle/working/model_dir', '/kaggle/working/model_dir')\nzip_folder_with_shutil('/kaggle/working/runs', '/kaggle/working/runs')\nzip_folder_with_shutil('/kaggle/working/optuna', '/kaggle/working/optuna')\nzip_folder_with_shutil('/kaggle/working/logs', '/kaggle/working/logs')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T07:30:06.898537Z","iopub.execute_input":"2025-05-12T07:30:06.898772Z","iopub.status.idle":"2025-05-12T07:30:12.378752Z","shell.execute_reply.started":"2025-05-12T07:30:06.898751Z","shell.execute_reply":"2025-05-12T07:30:12.377798Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!tensorboard --logdir=/kaggle/working/runs --port 6006\n#!optuna-dashboard sqlite:///kaggle/working/optuna/optuna_study.db","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T07:30:12.379624Z","iopub.execute_input":"2025-05-12T07:30:12.379956Z","iopub.status.idle":"2025-05-12T07:30:12.383283Z","shell.execute_reply.started":"2025-05-12T07:30:12.379925Z","shell.execute_reply":"2025-05-12T07:30:12.382641Z"}},"outputs":[],"execution_count":null}]}