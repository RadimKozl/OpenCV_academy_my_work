{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10911708,"sourceType":"datasetVersion","datasetId":6783030}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---------------\n\n# **<font style=\"color:Black\">Create OCR by PyTorch</font>**\n-------------------\n-----------------","metadata":{}},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Installation and import libraries</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"!pip install  pillow \n!pip install opencv-python\n!pip install matplotlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:07.460856Z","iopub.execute_input":"2025-03-07T11:39:07.461189Z","iopub.status.idle":"2025-03-07T11:39:21.855789Z","shell.execute_reply.started":"2025-03-07T11:39:07.461161Z","shell.execute_reply":"2025-03-07T11:39:21.854338Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.20->matplotlib) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport random\nfrom PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter\nimport numpy as np\nimport cv2\n\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F  # Add this import\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:21.857280Z","iopub.execute_input":"2025-03-07T11:39:21.857684Z","iopub.status.idle":"2025-03-07T11:39:29.983489Z","shell.execute_reply.started":"2025-03-07T11:39:21.857655Z","shell.execute_reply":"2025-03-07T11:39:29.982197Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Hyperparameters</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"seed = 3\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:29.984835Z","iopub.execute_input":"2025-03-07T11:39:29.985420Z","iopub.status.idle":"2025-03-07T11:39:30.002287Z","shell.execute_reply.started":"2025-03-07T11:39:29.985390Z","shell.execute_reply":"2025-03-07T11:39:30.000401Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x784aa4066e50>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"OUTPUT_DIR = os.path.join('/kaggle','working','synthetic_data','images')\nMODEL_DIR = os.path.join('/kaggle','working','model_dir')\nLABELS_FILE = os.path.join('/kaggle','working','synthetic_data','labels.txt')\nNUM_SAMPLES = 5120  # Number of images generated\nIMG_WIDTH = 128\nIMG_HEIGHT = 32\nBATCH_SIZE = 32\nEPOCHS = 20\nLEARNING_RATE = 1e-7 \nWEIGHT_DECAY = 1e-4  \nWARMUP_STEPS = 1000  \nENTROPY_WEIGHT = 2.0\nTEMPERATURE = 0.3\nDROPOUT = 0.7\nBEAM_WIDTH = 10\nLABEL_SMOOTHING = 0.2\nBLANK_PENALTY_WEIGHT = 3.0\nMAX_SEQ_LENGTH = 15\nCHARSET = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-*\"  # Group characters\nMAX_TEXT_LENGTH = 10  # Maximum length of text in an image\nFONT_DIR = os.path.join('/kaggle','input','google-fonts','GoogleFontScripts') # Folder with TrueType fonts (.ttf)\nBACKGROUND_DIR = os.path.join('/kaggle','working','backgrounds')  # New folder for background (optional)\nNUMBER_BACKGROUND_IMAGE = 1000","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:30.004100Z","iopub.execute_input":"2025-03-07T11:39:30.004906Z","iopub.status.idle":"2025-03-07T11:39:30.025942Z","shell.execute_reply.started":"2025-03-07T11:39:30.004854Z","shell.execute_reply":"2025-03-07T11:39:30.024738Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Utils support functions</font>**\n-------------------","metadata":{}},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Create output folders</font>**","metadata":{}},{"cell_type":"code","source":"os.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(BACKGROUND_DIR, exist_ok=True)\n\n# Creates a new file\nwith open(LABELS_FILE, 'w') as fp:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:30.027522Z","iopub.execute_input":"2025-03-07T11:39:30.027982Z","iopub.status.idle":"2025-03-07T11:39:30.045152Z","shell.execute_reply.started":"2025-03-07T11:39:30.027942Z","shell.execute_reply":"2025-03-07T11:39:30.043879Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load the font list (add the paths to the .ttf files to the \"fonts\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"font_files = [\n    os.path.join(FONT_DIR, f) for f in os.listdir(FONT_DIR) \n    if f.endswith('.ttf') and os.path.isfile(os.path.join(FONT_DIR, f))\n]\nif not font_files:\n    raise FileNotFoundError(\"No fonts found in 'fonts' folder. Add .ttf files!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:30.048344Z","iopub.execute_input":"2025-03-07T11:39:30.048686Z","iopub.status.idle":"2025-03-07T11:39:32.045296Z","shell.execute_reply.started":"2025-03-07T11:39:30.048660Z","shell.execute_reply":"2025-03-07T11:39:32.044206Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generating a simple gradient background</font>**","metadata":{}},{"cell_type":"code","source":"def generate_gradient_background(filename, size=(128, 32)):\n    img = Image.new('L', size, color=230)  # Lighter gray as a base\n    draw = ImageDraw.Draw(img)\n    for y in range(size[1]):\n        # Soft gradient with low contrast\n        color = int(230 - 20 * (y / size[1]))  # From light gray to slightly darker\n        draw.line([(0, y), (size[0], y)], fill=color)\n    # Background blur\n    img = img.filter(ImageFilter.GaussianBlur(radius=2))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:32.047419Z","iopub.execute_input":"2025-03-07T11:39:32.047825Z","iopub.status.idle":"2025-03-07T11:39:32.054422Z","shell.execute_reply.started":"2025-03-07T11:39:32.047781Z","shell.execute_reply":"2025-03-07T11:39:32.053159Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generate a background with noise (paper texture)</font>**","metadata":{}},{"cell_type":"code","source":"def generate_paper_texture(filename, size=(128, 32)):\n    img = Image.new('L', size, color=220)  # Lighter gray\n    noise = np.random.normal(0, 5, size).astype(np.uint8)  # Less noise\n    noise_img = Image.fromarray(noise)\n    img.paste(noise_img, (0, 0), noise_img)\n    # Blur for a softer effect\n    img = img.filter(ImageFilter.GaussianBlur(radius=1.5))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:32.055824Z","iopub.execute_input":"2025-03-07T11:39:32.056263Z","iopub.status.idle":"2025-03-07T11:39:32.077643Z","shell.execute_reply.started":"2025-03-07T11:39:32.056202Z","shell.execute_reply":"2025-03-07T11:39:32.076338Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Creating multiple backgrounds</font>**","metadata":{}},{"cell_type":"code","source":"for i in range(NUMBER_BACKGROUND_IMAGE):\n    generate_gradient_background(f\"gradient_{i}.png\")\n    generate_paper_texture(f\"paper_{i}.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:32.078839Z","iopub.execute_input":"2025-03-07T11:39:32.079172Z","iopub.status.idle":"2025-03-07T11:39:33.288386Z","shell.execute_reply.started":"2025-03-07T11:39:32.079138Z","shell.execute_reply":"2025-03-07T11:39:33.287335Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load backgrounds (optional, add images to the \"backgrounds\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"background_files = (\n    [os.path.join(BACKGROUND_DIR, f) for f in os.listdir(BACKGROUND_DIR) \n     if f.endswith(('.png', '.jpg', '.jpeg'))] if os.path.exists(BACKGROUND_DIR) else []\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.289910Z","iopub.execute_input":"2025-03-07T11:39:33.290296Z","iopub.status.idle":"2025-03-07T11:39:33.300110Z","shell.execute_reply.started":"2025-03-07T11:39:33.290246Z","shell.execute_reply":"2025-03-07T11:39:33.298862Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Random text generation function</font>**","metadata":{}},{"cell_type":"code","source":"def generate_random_text(max_length):\n    length = random.randint(1, max_length)\n    return ''.join(random.choice(CHARSET) for _ in range(length))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.301024Z","iopub.execute_input":"2025-03-07T11:39:33.301285Z","iopub.status.idle":"2025-03-07T11:39:33.314225Z","shell.execute_reply.started":"2025-03-07T11:39:33.301263Z","shell.execute_reply":"2025-03-07T11:39:33.313128Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Functions for adding noise and distortions</font>**","metadata":{}},{"cell_type":"code","source":"def add_noise_and_distortion(img):\n    img_array = np.array(img)\n    # Mild Gaussian noise with lower intensity\n    if random.random() > 0.5:  # 50% šance\n        noise = np.random.normal(0, random.randint(5, 15), img_array.shape).astype(np.uint8)\n        img_array = cv2.add(img_array, noise)\n    # Subtle perspective distortion\n    rows, cols = img_array.shape\n    src_points = np.float32([[0, 0], [cols-1, 0], [0, rows-1], [cols-1, rows-1]])\n    dst_points = np.float32([\n        [random.uniform(0, 3), random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), random.uniform(0, 3)],\n        [random.uniform(0, 3), rows-1-random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), rows-1-random.uniform(0, 3)]\n    ])\n    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n    img_array = cv2.warpPerspective(img_array, matrix, (cols, rows))\n    return Image.fromarray(img_array)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.315350Z","iopub.execute_input":"2025-03-07T11:39:33.315693Z","iopub.status.idle":"2025-03-07T11:39:33.331328Z","shell.execute_reply.started":"2025-03-07T11:39:33.315659Z","shell.execute_reply":"2025-03-07T11:39:33.330285Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Improved image generation feature</font>**","metadata":{}},{"cell_type":"code","source":"def generate_synthetic_image(text, font_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n    # Pozadí\n    if background_files:\n        bg_path = random.choice(background_files)\n        img = Image.open(bg_path).convert('L').resize(img_size)\n    else:\n        img = Image.new('L', img_size, color=230)\n        draw = ImageDraw.Draw(img)\n        for y in range(img_size[1]):\n            color = int(230 - 20 * (y / img_size[1]))\n            draw.line([(0, y), (img_size[0], y)], fill=color)\n        img = img.filter(ImageFilter.GaussianBlur(radius=2))\n\n    draw = ImageDraw.Draw(img)\n\n    # Iterativní úprava fontu a textu\n    font_size = random.randint(20, min(IMG_HEIGHT-2, 28))\n    max_attempts = 5  # Omezení počtu pokusů\n    for attempt in range(max_attempts):\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n        if text_width <= IMG_WIDTH - 10:  # Text vejde\n            break\n        elif len(text) > 1:  # Zkrať text, pokud je příliš dlouhý\n            text = text[:len(text)//2]\n        else:  # Sniž velikost fontu\n            font_size = max(10, font_size - 5)  # Minimální velikost 10\n\n    # Pokud se nepodaří, použij minimální font a jednopísmený text\n    if text_width > IMG_WIDTH - 10:\n        text = text[0]  # Použij první písmeno\n        font_size = 10\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n    # Pozice textu\n    x = random.randint(5, max(5, IMG_WIDTH - text_width - 5))\n    y = random.randint(5, max(5, IMG_HEIGHT - text_height - 5))\n\n    # Zvýraznění textu\n    text_color = random.randint(0, 50)\n    outline_color = 200\n    for offset_x in [-1, 0, 1]:\n        for offset_y in [-1, 0, 1]:\n            if offset_x != 0 or offset_y != 0:\n                draw.text((x + offset_x, y + offset_y), text, font=font, fill=outline_color)\n    draw.text((x, y), text, font=font, fill=text_color)\n\n    # Šum a deformace\n    img = add_noise_and_distortion(img)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.332755Z","iopub.execute_input":"2025-03-07T11:39:33.333199Z","iopub.status.idle":"2025-03-07T11:39:33.357418Z","shell.execute_reply.started":"2025-03-07T11:39:33.333159Z","shell.execute_reply":"2025-03-07T11:39:33.356096Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function for splitting labels</font>**","metadata":{}},{"cell_type":"code","source":"def split_labels(labels, label_lengths):\n    \"\"\"Split a flat tensor of labels into a list of label sequences based on lengths.\"\"\"\n    split_labels = []\n    start = 0\n    for length in label_lengths:\n        split_labels.append(labels[start:start + length])\n        start += length\n    return split_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.358704Z","iopub.execute_input":"2025-03-07T11:39:33.359031Z","iopub.status.idle":"2025-03-07T11:39:33.378480Z","shell.execute_reply.started":"2025-03-07T11:39:33.359007Z","shell.execute_reply":"2025-03-07T11:39:33.377271Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function of Beam search decoding</font>**","metadata":{}},{"cell_type":"code","source":"def beam_search_decode(output, idx_to_char, target_lengths=None, beam_width=10, blank_penalty=-0.5, length_penalty=-0.5):\n    probs = output.softmax(2).cpu().numpy()\n    T, B, C = probs.shape\n    predictions = []\n    \n    for b in range(B):\n        sequence_probs = [(0.0, [], 1.0)]\n        max_length = target_lengths[b].item() * 2 if target_lengths is not None else T  # Cap at 2x target length\n        for t in range(T):\n            new_sequences = []\n            for log_prob, seq, prob in sequence_probs:\n                if len(seq) >= max_length:\n                    new_sequences.append((log_prob, seq, prob))\n                    continue\n                top_k_probs, top_k_idx = torch.topk(torch.tensor(probs[t, b]), beam_width)\n                for k_prob, k_idx in zip(top_k_probs, top_k_idx):\n                    new_seq = seq + [k_idx.item()]\n                    new_prob = prob * k_prob.item()\n                    new_log_prob = log_prob + np.log(k_prob.item())\n                    if k_idx.item() == 0:\n                        new_log_prob += blank_penalty\n                    new_log_prob += length_penalty * len(new_seq)\n                    new_sequences.append((new_log_prob, new_seq, new_prob))\n            sequence_probs = sorted(new_sequences, key=lambda x: x[0], reverse=True)[:beam_width]\n        \n        best_seq = sequence_probs[0][1]\n        decoded = []\n        prev = -1\n        for idx in best_seq:\n            if idx != 0 and idx != prev:\n                decoded.append(idx_to_char.get(idx, ''))\n            prev = idx\n        predictions.append(''.join(decoded) if decoded else '<empty>')\n    \n    token_counts = Counter(best_seq)\n    print(f\"Token distribution (Batch {b}): {dict(token_counts)}\")\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.379799Z","iopub.execute_input":"2025-03-07T11:39:33.380223Z","iopub.status.idle":"2025-03-07T11:39:33.396059Z","shell.execute_reply.started":"2025-03-07T11:39:33.380135Z","shell.execute_reply":"2025-03-07T11:39:33.394857Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Custom collate function</font>**","metadata":{}},{"cell_type":"code","source":"def custom_collate_fn(batch):\n    images, labels, label_lengths = zip(*batch)\n    # Stack images (all same size)\n    images = torch.stack(images, dim=0)\n    # Concatenate labels into a flat tensor\n    labels = torch.cat(labels, dim=0)\n    # Convert label_lengths to tensor\n    label_lengths = torch.tensor(label_lengths, dtype=torch.long)\n    return images, labels, label_lengths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.397170Z","iopub.execute_input":"2025-03-07T11:39:33.397474Z","iopub.status.idle":"2025-03-07T11:39:33.418158Z","shell.execute_reply.started":"2025-03-07T11:39:33.397434Z","shell.execute_reply":"2025-03-07T11:39:33.416886Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generování datasetu</font>**","metadata":{}},{"cell_type":"code","source":"def create_synthetic_dataset(num_samples):\n    labels = []\n    for i in range(num_samples):\n        text = generate_random_text(MAX_TEXT_LENGTH)\n        if not text:\n            continue\n        font_path = random.choice(font_files)\n        img = generate_synthetic_image(text, font_path)\n        img_name = f\"img_{i:05d}.png\"\n        img_path = os.path.join(OUTPUT_DIR, img_name)\n        img.save(img_path)\n        labels.append(f\"{img_name}\\t{text}\")  # Use tab (\\t) instead of space\n        if i % 100 == 0:\n            print(f\"Generated {i}/{num_samples} images\")\n\n    if labels:\n        with open(LABELS_FILE, 'w') as f:\n            f.write(\"\\n\".join(labels))\n        print(f\"Dataset generated! Images saved in '{OUTPUT_DIR}', labels in '{LABELS_FILE}'\")\n    else:\n        print(\"No labels generated!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.419829Z","iopub.execute_input":"2025-03-07T11:39:33.420259Z","iopub.status.idle":"2025-03-07T11:39:33.439848Z","shell.execute_reply.started":"2025-03-07T11:39:33.420222Z","shell.execute_reply":"2025-03-07T11:39:33.438537Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Mapping characters to indices and back</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"char_to_idx = {char: idx + 1 for idx, char in enumerate(CHARSET)}  # 0 is reserved for blank (CTC)\nidx_to_char = {idx: char for char, idx in char_to_idx.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.441242Z","iopub.execute_input":"2025-03-07T11:39:33.441638Z","iopub.status.idle":"2025-03-07T11:39:33.458687Z","shell.execute_reply.started":"2025-03-07T11:39:33.441598Z","shell.execute_reply":"2025-03-07T11:39:33.457291Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom dataset</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRDataset(Dataset):\n    def __init__(self, image_dir, labels_file):\n        self.image_dir = image_dir\n        self.labels_file = labels_file\n        self.data = []\n        with open(labels_file, 'r') as f:\n            for line in f:\n                if not line.strip():  # Skip empty lines\n                    continue\n                image_path, label = line.strip().split('\\t')\n                label_length = len(label)\n                self.data.append((image_path, label, label_length))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_path, label, label_length = self.data[idx]\n        image = Image.open(os.path.join(self.image_dir, image_path)).convert('L')\n        image = transforms.ToTensor()(image)\n        label_encoded = torch.tensor([char_to_idx[c] for c in label], dtype=torch.long)\n        return image, label_encoded, label_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.460016Z","iopub.execute_input":"2025-03-07T11:39:33.460332Z","iopub.status.idle":"2025-03-07T11:39:33.472602Z","shell.execute_reply.started":"2025-03-07T11:39:33.460306Z","shell.execute_reply":"2025-03-07T11:39:33.471326Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom CTC Loss with Blank Penalty</font>**\n-------------------\n> CTC Loss with Entropy Regularization","metadata":{}},{"cell_type":"code","source":"class CTCLossWithBlankPenalty(nn.Module):\n    def __init__(self, blank=0, zero_infinity=True, blank_penalty_weight=1.0, entropy_weight=1.0, label_smoothing=0.2):\n        super().__init__()\n        self.ctc_loss = nn.CTCLoss(blank=blank, zero_infinity=zero_infinity)\n        self.blank_penalty_weight = blank_penalty_weight\n        self.entropy_weight = entropy_weight\n        self.label_smoothing = label_smoothing\n\n    def forward(self, log_probs, targets, input_lengths, target_lengths):\n        ctc_loss = self.ctc_loss(log_probs, targets, input_lengths, target_lengths)\n        blank_probs = log_probs[:, :, 0].exp().mean()\n        blank_penalty = -torch.log(1 - blank_probs + 1e-6) * self.blank_penalty_weight\n        entropy = -(log_probs.exp() * log_probs).sum(dim=-1).mean()  # Negative entropy\n        total_loss = ctc_loss + blank_penalty + self.entropy_weight * entropy\n        return total_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.476595Z","iopub.execute_input":"2025-03-07T11:39:33.476972Z","iopub.status.idle":"2025-03-07T11:39:33.499489Z","shell.execute_reply.started":"2025-03-07T11:39:33.476944Z","shell.execute_reply":"2025-03-07T11:39:33.498262Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Model definition (CNN + RNN + CTC)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRModel(nn.Module):\n    def __init__(self, num_chars):\n        super(OCRModel, self).__init__()\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.rnn = nn.LSTM(128 * (IMG_HEIGHT // 4), 256, num_layers=2, bidirectional=True, dropout=DROPOUT)\n        self.fc = nn.Linear(256 * 2, num_chars)\n        self.dropout = nn.Dropout(DROPOUT)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        batch, channels, height, width = x.size()\n        x = x.view(batch, channels * height, width).permute(2, 0, 1)\n        x = x[:MAX_SEQ_LENGTH]  # Truncate to MAX_SEQ_LENGTH\n        x, _ = self.rnn(x)\n        x = self.dropout(x)\n        x = self.fc(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.501053Z","iopub.execute_input":"2025-03-07T11:39:33.501418Z","iopub.status.idle":"2025-03-07T11:39:33.519822Z","shell.execute_reply.started":"2025-03-07T11:39:33.501385Z","shell.execute_reply":"2025-03-07T11:39:33.518580Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Training</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, device, epoch, warmup_steps=WARMUP_STEPS):\n    model.train()\n    total_loss = 0\n    global_step = epoch * len(train_loader)\n    for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n        imgs, labels = imgs.to(device), labels.to(device)\n        label_lengths = label_lengths.to(device)\n\n        if global_step < warmup_steps:\n            lr_scale = min(1.0, float(global_step + 1) / warmup_steps)\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = LEARNING_RATE * lr_scale\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        outputs = outputs / TEMPERATURE\n        outputs = outputs.log_softmax(2)\n\n        batch_size = imgs.size(0)\n        seq_length = outputs.size(0)\n        input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n\n        loss = criterion(outputs, labels, input_lengths, label_lengths)\n        if torch.isnan(loss) or torch.isinf(loss):\n            print(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n            continue\n\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)  # Tightened\n        optimizer.step()\n        total_loss += loss.item()\n        global_step += 1\n\n        if batch_idx % 10 == 0:\n            with torch.no_grad():\n                pred_texts = beam_search_decode(outputs, idx_to_char, label_lengths)\n                raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n                blank_probs = outputs[:, :, 0].exp().mean().item()\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:3]]\n                print(f\"Batch {batch_idx}, Gradient norm: {grad_norm.item():.4f}\")\n                print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n                print(f\"Avg Blank Probability: {blank_probs:.4f}\")\n                print(f\"Sample predictions: {pred_texts[:3]}\")\n                print(f\"Ground Truth (first 3): {ground_truth}\")\n                print(f\"Raw outputs (first 3): {raw_outputs}\")\n                print(f\"Input length: {seq_length}, Label lengths: {label_lengths[:3].tolist()}\")\n\n    return total_loss / len(train_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.521294Z","iopub.execute_input":"2025-03-07T11:39:33.521687Z","iopub.status.idle":"2025-03-07T11:39:33.545056Z","shell.execute_reply.started":"2025-03-07T11:39:33.521656Z","shell.execute_reply":"2025-03-07T11:39:33.543819Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Inference (prediction)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def decode_prediction(output, idx_to_char):\n    probs = output.softmax(2)\n    max_probs, preds = probs.max(dim=2)\n    preds = preds.cpu().numpy()\n    max_probs = max_probs.cpu().numpy()\n    texts = []\n    for i, (pred, prob) in enumerate(zip(preds.T, max_probs.T)):\n        print(f\"Raw prediction {i} (pre-filter): {pred}, Max probs: {prob}\")\n        # Dynamic threshold: 75th percentile of max probs in this sequence\n        threshold = np.percentile(prob, 75)\n        print(f\"Dynamic threshold for prediction {i}: {threshold:.4f}\")\n        pred_text = []\n        prev = -1\n        for idx, p in zip(pred, prob):\n            if idx != 0 and idx != prev and p > threshold:\n                pred_text.append(idx_to_char.get(idx, ''))\n            prev = idx\n        decoded = ''.join(pred_text)\n        texts.append(decoded if decoded else '<empty>')\n    return texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.546243Z","iopub.execute_input":"2025-03-07T11:39:33.546621Z","iopub.status.idle":"2025-03-07T11:39:33.571641Z","shell.execute_reply.started":"2025-03-07T11:39:33.546586Z","shell.execute_reply":"2025-03-07T11:39:33.570444Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Main launch</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    if not font_files:\n        print(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n    else:\n        create_synthetic_dataset(NUM_SAMPLES)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    full_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n\n    for i in range(5):\n        img, label, length = full_dataset[i]\n        plt.imshow(img.squeeze(), cmap='gray')\n        plt.title(''.join([idx_to_char.get(idx.item(), '') for idx in label[:length]]))\n        plt.show()\n    \n    if len(full_dataset) == 0:\n        print(\"Dataset is empty! Check labels.txt or image directory.\")\n    else:\n        # Curriculum phases with pre-filtering\n        model = OCRModel(num_chars=len(CHARSET)).to(device)\n        criterion = CTCLossWithBlankPenalty(blank=0, zero_infinity=True, blank_penalty_weight=BLANK_PENALTY_WEIGHT, entropy_weight=ENTROPY_WEIGHT, label_smoothing=LABEL_SMOOTHING)\n        \n        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n\n        best_loss = float('inf')\n        for epoch in range(EPOCHS):\n            # Filter full dataset based on curriculum phase\n            if epoch < 10:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 5]\n                print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {[lbl for _, lbl, _ in filtered_data[:3]]}\")\n            elif epoch < 15:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 7]\n            else:\n                filtered_data = full_dataset.data\n\n            # Create a new dataset with filtered data\n            curr_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n            curr_dataset.data = filtered_data  # Overwrite with filtered data\n\n            # Split into train and validation\n            train_size = int(0.8 * len(curr_dataset))\n            val_size = len(curr_dataset) - train_size\n            train_dataset, val_dataset = torch.utils.data.random_split(curr_dataset, [train_size, val_size])\n            print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n            \n            # Create data loaders\n            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n            val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n            \n            loss = train_model(model, train_loader, criterion, optimizer, device, epoch)\n            print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss:.4f}\")\n\n            # Validation\n            model.eval()\n            val_loss = 0\n            with torch.no_grad():\n                for imgs, labels, label_lengths in val_loader:\n                    imgs, labels = imgs.to(device), labels.to(device)\n                    label_lengths = label_lengths.to(device)\n                    outputs = model(imgs)\n                    outputs = outputs.log_softmax(2)\n                    seq_length = outputs.size(0)\n                    input_lengths = torch.full((imgs.size(0),), seq_length, dtype=torch.long).to(device)\n                    val_loss += criterion(outputs, labels, input_lengths, label_lengths).item()\n                \n                val_loss /= len(val_loader)\n                pred_texts = beam_search_decode(outputs, idx_to_char)\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:5]]\n                print(f\"Validation Loss: {val_loss:.4f}\")\n                print(\"Validation Predictions:\", pred_texts[:5])\n                print(\"Ground Truth:\", ground_truth)\n\n            model.train()\n            scheduler.step()\n            print(f\"Current Learning Rate: {optimizer.param_groups[0]['lr']}\")\n\n            if val_loss < best_loss:\n                best_loss = val_loss\n                torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'best_ocr_model.pth'))\n\n        torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'final_ocr_model.pth'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:39:33.573151Z","iopub.execute_input":"2025-03-07T11:39:33.573562Z","iopub.status.idle":"2025-03-07T11:57:22.494352Z","shell.execute_reply.started":"2025-03-07T11:39:33.573517Z","shell.execute_reply":"2025-03-07T11:57:22.492970Z"}},"outputs":[{"name":"stdout","text":"Generated 0/5120 images\nGenerated 100/5120 images\nGenerated 200/5120 images\nGenerated 300/5120 images\nGenerated 400/5120 images\nGenerated 500/5120 images\nGenerated 600/5120 images\nGenerated 700/5120 images\nGenerated 800/5120 images\nGenerated 900/5120 images\nGenerated 1000/5120 images\nGenerated 1100/5120 images\nGenerated 1200/5120 images\nGenerated 1300/5120 images\nGenerated 1400/5120 images\nGenerated 1500/5120 images\nGenerated 1600/5120 images\nGenerated 1700/5120 images\nGenerated 1800/5120 images\nGenerated 1900/5120 images\nGenerated 2000/5120 images\nGenerated 2100/5120 images\nGenerated 2200/5120 images\nGenerated 2300/5120 images\nGenerated 2400/5120 images\nGenerated 2500/5120 images\nGenerated 2600/5120 images\nGenerated 2700/5120 images\nGenerated 2800/5120 images\nGenerated 2900/5120 images\nGenerated 3000/5120 images\nGenerated 3100/5120 images\nGenerated 3200/5120 images\nGenerated 3300/5120 images\nGenerated 3400/5120 images\nGenerated 3500/5120 images\nGenerated 3600/5120 images\nGenerated 3700/5120 images\nGenerated 3800/5120 images\nGenerated 3900/5120 images\nGenerated 4000/5120 images\nGenerated 4100/5120 images\nGenerated 4200/5120 images\nGenerated 4300/5120 images\nGenerated 4400/5120 images\nGenerated 4500/5120 images\nGenerated 4600/5120 images\nGenerated 4700/5120 images\nGenerated 4800/5120 images\nGenerated 4900/5120 images\nGenerated 5000/5120 images\nGenerated 5100/5120 images\nDataset generated! Images saved in '/kaggle/working/synthetic_data/images', labels in '/kaggle/working/synthetic_data/labels.txt'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {32: 2, 34: 1, 11: 1, 42: 1, 1: 2, 19: 1}\nBatch 0, Gradient norm: 15.1902\nEpoch 1, Batch 0/66, Loss: 30.6595\nAvg Blank Probability: 0.0148\nSample predictions: ['lv2a', 'elj3faja', 'kv-jaG']\nGround Truth (first 3): ['Up', '4Kv4', 'OFf']\nRaw outputs (first 3): [[12  5 11 11 19 12  6 47  1 27  1  1  1 50  1 19 56 10 10 56 10 34 27  1\n  32 33 32 10 43 42 34 32]\n [22 12 22  5 27 32  1 10 56  1 24 56  8  1  1 32 11  1 42 62  4 24 44 19\n  57 50  1  6  1 27 23 34]\n [55 10 63 34 19 56 47 11 48  1  1 42 24  1  1 43 12 32  1 10 34 56  1  1\n  48  1 22 24  1  1  1 11]]\nInput length: 15, Label lengths: [2, 4, 3]\nToken distribution (Batch 31): {56: 1, 17: 1}\nBatch 10, Gradient norm: 18.0034\nEpoch 1, Batch 10/66, Loss: 32.6020\nAvg Blank Probability: 0.0147\nSample predictions: ['Qj', '3a', 'asvlPj']\nGround Truth (first 3): ['X', 'K', '6eE']\nRaw outputs (first 3): [[43 56  1 12  6  1 36 43 29  6 13 30 12  4 25 12 10 63 14  1 29  6  4 56\n  34 11 42  6  1 43  1 56]\n [10  1 19  1  1 60 61  6  1 16  1  1 48 34 10  5 63 22 42 43 24 24  1  1\n  47 30 47  1 19  1 56 17]\n [ 1 34 22 10  1 32 12 10 43 56 42  1 10 32  2 50 22  6 12 62 47  1 43 34\n  22 30  6 43  1 47  1 10]]\nInput length: 15, Label lengths: [1, 1, 3]\nToken distribution (Batch 31): {4: 2, 1: 1, 5: 1}\nBatch 20, Gradient norm: 241.5722\nEpoch 1, Batch 20/66, Loss: 27.3610\nAvg Blank Probability: 0.0145\nSample predictions: ['UfADyQUlAj', 'HIFsFyml', 'sflVd2asa']\nGround Truth (first 3): ['u6XUi', 'qUYe', '*afWc']\nRaw outputs (first 3): [[47 34 19 14 24 42 12  6 47  1 10  6  1  1  1 12 22  8 63  6 63  6  1  6\n  56  1 56 45  1 32  1  4]\n [ 6 35 19 34 19 17 57 47  5 19 10 56 47  1 24 24  1 43  1 63 10 47 27 10\n   5 27 24 43  7 10 32  4]\n [27  0  6 32 22 34 32  1 16 19 12 11 56 11 47 50 35 47  5  1 25 47 22 10\n  13  1 16 10 13  6  1  1]]\nInput length: 15, Label lengths: [5, 4, 5]\nToken distribution (Batch 31): {4: 1, 47: 1, 33: 1, 35: 1}\nBatch 30, Gradient norm: 18.0214\nEpoch 1, Batch 30/66, Loss: 32.7863\nAvg Blank Probability: 0.0146\nSample predictions: ['HjyU', 'ayFLv8FrFH', 'HQaUHaFgda']\nGround Truth (first 3): ['9K', 'jEXUx', '8aW40']\nRaw outputs (first 3): [[34  1 34 10  1  6 50 20 56  5 35 32  1 27  4  1  1 48 63 21 19  1 10  1\n  34 10 34  6 11 10  1  4]\n [10 25 43 47  1 30 11  1 32  7  4 22 32  6 12 11  1 34 11 56 32 56 25  6\n  32 10 63 10 47 55 11 47]\n [25 32  1 34  7  1 63 50 60 14  1 47  1  1 30 19 11 63 11 61 63 34  4  6\n  32 36 41 34  1 10 47 33]]\nInput length: 15, Label lengths: [2, 5, 5]\nToken distribution (Batch 31): {10: 2, 11: 2, 12: 1, 1: 1, 50: 1, 5: 1, 35: 1, 19: 1}\nBatch 40, Gradient norm: 26.4014\nEpoch 1, Batch 40/66, Loss: 32.3080\nAvg Blank Probability: 0.0148\nSample predictions: ['Aj', 'kd', 'HaXyaI2']\nGround Truth (first 3): ['K', 'z', '5*m2']\nRaw outputs (first 3): [[27 11 34 19 34 34 11 19 34  1 34 48 10 12  1 43 22  1 11  2 11 11  1 56\n  10 55 10 10  1 10 32 10]\n [10  4  1 47 48 47 47  1 25 22 35  4  6  8 35  1 12 32  5  6  1  6 47  1\n  43  1 29 19 16 11 10 11]\n [29 55  1 20  1  1 47 56 63 34  1 59 10 32  1  1 27 32 10 43 35 12 32  6\n   5 10  1 10  1 19  1 11]]\nInput length: 15, Label lengths: [1, 1, 4]\nToken distribution (Batch 31): {1: 2, 42: 1, 10: 1}\nBatch 50, Gradient norm: 20.6410\nEpoch 1, Batch 50/66, Loss: 35.5469\nAvg Blank Probability: 0.0150\nSample predictions: ['a3', 'ka', 'HUkHd3FU']\nGround Truth (first 3): ['0', '3', 'Ox9Z']\nRaw outputs (first 3): [[ 1 11 34  1 10 24  1 10 42 22  1 63 24 12  1 19 16 50 10 47 63  1 24 32\n  32 10 25 10  1 19 56  1]\n [56  1 47  6  1 42 22  6 32 24 22 47 10  5 22 33  1 19  4 23  1 48  1  1\n   5 27 12  2  6 12 12  1]\n [10  7 11  1  1 32 10  1 10  1 11 34  1 10 34 19 35 56 11  5  1  6 32 32\n   1 56  4 46  4  1 48 42]]\nInput length: 15, Label lengths: [1, 1, 4]\nToken distribution (Batch 31): {11: 1, 50: 1, 19: 1, 1: 1}\nBatch 60, Gradient norm: 1420.5110\nEpoch 1, Batch 60/66, Loss: 31.4952\nAvg Blank Probability: 0.0147\nSample predictions: ['jdP-XFd-sa', 'fsakeaVAPA', 'k8Fa']\nGround Truth (first 3): ['p46O6', 'oChe-', 'Jf']\nRaw outputs (first 3): [[10  6 11  6  1 34  4 46 56 12 35 24 43 43  1  1 10 22  1 11 11 47 33 34\n   4 34 25 63 42  1 11 11]\n [ 4 19 61 63  1 10  1 35 12 10 11 19 42  4  4  1  4 47 10 43  1 32 19 27\n   1  1 10 34 27  1 10 50]\n [42  1 32  4 34 25 56 32  1  4  1 12 42  1 50 10  9 22 19 34 27  1  1  1\n   1  1  1 12 19  4 12 19]]\nInput length: 15, Label lengths: [5, 5, 2]\nEpoch 1/20, Loss: 33.5864\nToken distribution (Batch 8): {1: 15}\nValidation Loss: 32.6090\nValidation Predictions: ['aj', 'aj', 'aj', 'a', 'aj']\nGround Truth: ['Ems', 'Dt', '4z', 'OdrNd', '8QWWA']\nCurrent Learning Rate: 1.2715201226395052e-08\nEpoch 2, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {1: 2, 43: 1, 34: 1}\nBatch 0, Gradient norm: 14.2620\nEpoch 2, Batch 0/66, Loss: 27.4165\nAvg Blank Probability: 0.0149\nSample predictions: ['pyjaQJea', 'UeFeaw', 'fPj3']\nGround Truth (first 3): ['VNbV', 'pn9', 'K3']\nRaw outputs (first 3): [[16 47  6  1 11  6  5  1 12 11  1 34 34 16  1 12 33 47 56 11 56 11 11 22\n  22 22 56 32 57 34 12  1]\n [25  5 42 37 12  1 10 11 56 22  1 12 33  1 50 10 12 10 10  1 10 57  1 10\n  35 42  1 16  5  4 50 43]\n [10 32 10  1  5 47 11 19 16 10 42 11 50  6 11 56 56 20 35  1 27 11  1  5\n   5 11  4 25  1  1 34  1]]\nInput length: 15, Label lengths: [4, 3, 2]\nToken distribution (Batch 31): {63: 1, 43: 1, 35: 1, 42: 1}\nBatch 10, Gradient norm: 18.8263\nEpoch 2, Batch 10/66, Loss: 34.6207\nAvg Blank Probability: 0.0149\nSample predictions: ['jI4vsf', 'eskjkaUk', 'a']\nGround Truth (first 3): ['CVN', '76rX', 'w']\nRaw outputs (first 3): [[10  5  1  4  1  1 34 42  1  1 11 12 10 11 12 34 11  4  1  5  6  1 10 47\n  12 10  1 63 14  4 10 63]\n [35 19  1 22 12 25 14 22  1 19  1  1 60  6 10 10 47 56  1 16 48 32  1 35\n   1 43  1 10  4 34 10 43]\n [57 11 19 12  1 11 10 10  9 34  1 22 11 32 35 10 47 11 10 34 35 34  4 11\n  22 25 48 27 32 43  1 35]]\nInput length: 15, Label lengths: [3, 4, 1]\nToken distribution (Batch 31): {34: 2, 6: 1, 1: 3, 32: 1, 19: 1, 10: 1, 7: 1}\nBatch 20, Gradient norm: 13.1902\nEpoch 2, Batch 20/66, Loss: 26.7744\nAvg Blank Probability: 0.0148\nSample predictions: ['ksajXHyVaC', 'aVdjaVDj', 'yUajsjsH']\nGround Truth (first 3): ['4hA6-', 'qLqg', 'LE5c']\nRaw outputs (first 3): [[11  1 25  1 47 56  1  1  1  1 47 42 10 16 22 43 10 50 24 43 10 63 10 63\n  16 63 34 12 24 56  1 34]\n [19 48 47 34 22 56 50 22 47  1 12 10 42 10  1 10  1 21 11 38  4 56 11 10\n  16 32 35 46 55 43  1  6]\n [ 1  4  1 10 60  1 22  4  1 10  1 32  1 10 32 24  1 56  1 24  4 25 50 10\n  22  4 11 12  1 32  1  1]]\nInput length: 15, Label lengths: [5, 4, 4]\nToken distribution (Batch 31): {63: 1, 47: 1, 12: 1, 42: 1, 51: 1, 34: 1}\nBatch 30, Gradient norm: 20.3020\nEpoch 2, Batch 30/66, Loss: 35.9964\nAvg Blank Probability: 0.0148\nSample predictions: ['jaFsvUad', 'AasP', 'da']\nGround Truth (first 3): ['3CFh', 'TK', 'B']\nRaw outputs (first 3): [[10 27  4 10 11 35 42  6 47 42 11 11 10 14  1 34 63 63 10 63 47 19  1  1\n   4 11 63 34 34  1 35 63]\n [ 1  1  1 12 35 20 34 19  1 47 42 35 57 63  4 32 56 25 10 42  1 47  1 34\n  28  1 35 25 32 32 13 47]\n [32 19  1 57  1 19 34 32  1 28 42 32 11  1 56 32 10  9 38 56 32 11 27 47\n  11 11 10  1 34 22  1 12]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {25: 1, 43: 1, 4: 2, 30: 1, 10: 1, 1: 1, 12: 1, 19: 1, 55: 1}\nBatch 40, Gradient norm: 27.7130\nEpoch 2, Batch 40/66, Loss: 43.2392\nAvg Blank Probability: 0.0148\nSample predictions: ['g642Udxde', 'kPFp', 'aRk']\nGround Truth (first 3): ['-Bk62', 'Ad', '7-']\nRaw outputs (first 3): [[ 7 11  1  1 11 35 10  4 11 60 30  5 11 10  1  1 19  1 22 10  1 34  1  1\n  56 34 34 11 25 35 43 25]\n [ 7 42 44  1 12 56 10 34 32 10 47 11  1 63  6 42 34  4 10 34 19 27 16 27\n  19  1  5 33 42 34  5 43]\n [59 32 11 47 43 33  1  1  1 61 42  6 12  1 24  6 12 19  1 42  1  1 42 27\n  30 10  1 22 56 10 11  4]]\nInput length: 15, Label lengths: [5, 2, 2]\nToken distribution (Batch 31): {1: 2, 4: 1, 11: 1, 34: 1, 22: 1}\nBatch 50, Gradient norm: 13.9800\nEpoch 2, Batch 50/66, Loss: 28.6022\nAvg Blank Probability: 0.0148\nSample predictions: ['kakfjav', 'aiXsaVU', 'Da']\nGround Truth (first 3): ['3uam', 'A6TT', 'E']\nRaw outputs (first 3): [[11  1 30 63 25  1 56  6 63 43 12  1  1  6  1 63  1 11  1 11  1 13 10 22\n  32  1 24  1 19 11  6  1]\n [ 1  9  1  6 47 56 47  1 34 19 10 61 19  1  1 50  0  9  4 34  4 43 10 12\n  32  2  5 11  4 35 10  1]\n [11 50 48 56 42  1  4 18  1 34  1 34  1  5  1 16 16  1 34 42  1 56  1 22\n  11 24 25 19 33 47 47  4]]\nInput length: 15, Label lengths: [4, 4, 1]\nToken distribution (Batch 31): {10: 1, 11: 1}\nBatch 60, Gradient norm: 242.5891\nEpoch 2, Batch 60/66, Loss: 39.1211\nAvg Blank Probability: 0.0148\nSample predictions: ['3ajn', 'FAPsjAkH', 'ajeFey8U']\nGround Truth (first 3): ['tP', 'orH2', 'jxG9']\nRaw outputs (first 3): [[56 32  1 28 14 10 19 19 34 11 10 16  6 56 10 56  1 34  1  1  6 34 19 12\n  56 43 12 24 56  1  4  0]\n [ 1 27 10 10  5  1  1  1  1 43 47  1  1 42  1 60 59  1  1  5  1 34  1 32\n  43 32  6 35 55 50  1 11]\n [10 42  5 55 57 32 25 28 43 34 48  1 50  1  6 32  5 47 50 10 43 47 33  1\n   1  6  1  5 47 48 48 10]]\nInput length: 15, Label lengths: [2, 4, 4]\nEpoch 2/20, Loss: 33.1515\nToken distribution (Batch 8): {1: 13, 10: 2}\nValidation Loss: 33.0653\nValidation Predictions: ['a', 'aj', 'a', 'aj', 'aj']\nGround Truth: ['nxOD', 'DYK', 'kXK', 'Bw', '*4VnO']\nCurrent Learning Rate: 3.138609259860176e-08\nEpoch 3, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {11: 1, 47: 1, 1: 2}\nBatch 0, Gradient norm: 19.6190\nEpoch 3, Batch 0/66, Loss: 34.5811\nAvg Blank Probability: 0.0147\nSample predictions: ['fIDaEa', '3ajk', 'aj']\nGround Truth (first 3): ['NXr', 'Ii', 'Z']\nRaw outputs (first 3): [[ 6 56  1 34 34  1  4 63 12 10  4 24 47 32 57 56  4  5  1 43 34 63  1 35\n  35  6 22 22 10  4 12 11]\n [35  1 10 11  1 35 13 11 42 34  1  1 16 48  1  1 63  1 56 22 47 43 12 22\n  57  1  1 34  4 32 24 47]\n [30 10 34 11 34 56  1 35 47  1  5 19  1 11 19 46 43 28  1 42  1 56  1 55\n  47 56 35  1  4  1 57  1]]\nInput length: 15, Label lengths: [3, 2, 1]\nToken distribution (Batch 31): {56: 1, 35: 1, 24: 1, 4: 1, 18: 1, 6: 1, 27: 1, 1: 3}\nBatch 10, Gradient norm: 232.4690\nEpoch 3, Batch 10/66, Loss: 40.4470\nAvg Blank Probability: 0.0149\nSample predictions: ['yjs2jsja', 'aX', 'HekladQjA']\nGround Truth (first 3): ['2b6t', 'z', 'UM8yk']\nRaw outputs (first 3): [[25  1 34 12  5 35 10 24  5 63 34  1 22 11 19 61  1 25  6 10 35  1 43 11\n  63  6 11  1  6 10  4 56]\n [10 50 34 10 35 56 32 34  1 47 56 32 10 10 32 25  1 61  6 35  1 10 30 35\n   6  1 40  0 32 10 56 35]\n [19  1  5 10  1 22 30 10  1  9 34 32 11  1 32 12 34  1 24 56  4 11 63 32\n   1  6 32 24 47 25 10 24]]\nInput length: 15, Label lengths: [4, 1, 5]\nToken distribution (Batch 31): {1: 2, 42: 2, 34: 1, 22: 1}\nBatch 20, Gradient norm: 927.2052\nEpoch 3, Batch 20/66, Loss: 31.5521\nAvg Blank Probability: 0.0148\nSample predictions: ['fA-s3ja8', 'jnaIxa', 'VFtaQ']\nGround Truth (first 3): ['AaGy', 'JnBX', 'QVW']\nRaw outputs (first 3): [[ 6 10 48 12  1  4  1  1  1 10  6 56 11 30 43  4 47 63 11 47 42 56 35 30\n  63 11 63 16  6 16  1  1]\n [27 14 32  7 34  4 35  1  6  1 22 57 11  6 56 35 19 28 11 30  4 55  1 12\n  30  1  4 32 16  1 10 42]\n [63  1 20 10 45 47 43  5 32 27 10  4 11 35 56  1  6 42 50 56 11 30  4 56\n   1 11 56 32 11  1  6 42]]\nInput length: 15, Label lengths: [4, 4, 3]\nToken distribution (Batch 31): {4: 1, 6: 1}\nBatch 30, Gradient norm: 14.2561\nEpoch 3, Batch 30/66, Loss: 29.3485\nAvg Blank Probability: 0.0146\nSample predictions: ['dF2ageU', '4Qva', 'kA']\nGround Truth (first 3): ['yz2K', 'Pn', 'd']\nRaw outputs (first 3): [[ 4 57 11  4 12 27 14 16 12  4 11 12 34  5 56 42 24 42  1  1 25  1 25 30\n   1  1  1  1 44 10 34  4]\n [32 43 27 24 42  1 24 32  1 32 22 30 10 35 34  1 22 12 47  6 22 12 10 19\n   1 19  4  5  1  5 47  6]\n [32 22  7 19 11  9 10 32 61 51 47 32 22 10 56 32 46 59 28 63 10  1  1 24\n  22 35 33  1 10  1 63  1]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {47: 1, 22: 1}\nBatch 40, Gradient norm: 19.5503\nEpoch 3, Batch 40/66, Loss: 35.5240\nAvg Blank Probability: 0.0149\nSample predictions: ['Pjl3', 'vald3tUl-', 'F2']\nGround Truth (first 3): ['HJ', 'lCXSq', 's']\nRaw outputs (first 3): [[42 22 32  1 34  1  4 48 14  4 34 56 32  1  1  4 10  6 34 26 10 25 63 12\n  12 61  1  1 63 56  1 47]\n [10  1 55  1 10 17 10  5 63  1  1 22 24 12  4 48  1  1 11 12 42  1 19  1\n   1 12 25 13 42 22  1 22]\n [12  1  1 22  6 34 33  4 35 36 32 17 10 51  1 47 35 43 11 32 43  1  1 32\n  10 32  1 14  1  6  1 47]]\nInput length: 15, Label lengths: [2, 5, 1]\nToken distribution (Batch 31): {1: 2, 50: 1, 10: 1, 11: 2, 27: 2, 34: 1, 19: 1}\nBatch 50, Gradient norm: 20.2527\nEpoch 3, Batch 50/66, Loss: 36.6801\nAvg Blank Probability: 0.0148\nSample predictions: ['qs', 'QjyE2Pwka', 'jI']\nGround Truth (first 3): ['h', 'HzLVh', 'P']\nRaw outputs (first 3): [[17 43 10 42 19  4  1  4  1 10  4  1 32  6 56 16 11  1 42 60 34 19 10  6\n   1 16 22 63 48 32 63  1]\n [19 10 35  1 47 50 10  1  1  1 25 47 11 10 42 35 47 43 50  1 27 22 56  1\n  63 55 22 11 35  1 34 50]\n [ 6 25 27  4 30 10 25 48  1  1  1 30 57  1 12 10 47 27  1 47  4  1 42  1\n  42 12 10 63  1  1 11 10]]\nInput length: 15, Label lengths: [1, 5, 1]\nToken distribution (Batch 31): {56: 1, 1: 3, 6: 1, 21: 1, 29: 1, 22: 1, 14: 1, 32: 1}\nBatch 60, Gradient norm: 21.1282\nEpoch 3, Batch 60/66, Loss: 33.2739\nAvg Blank Probability: 0.0149\nSample predictions: ['-fxU', 'a3OsaftV', 'j3ekagAs']\nGround Truth (first 3): ['x*', 'z2xI', 'ddhf']\nRaw outputs (first 3): [[63  1 10 47 34  1  4  1  4 22 35 56 10  1 24 57  1 11  1 30  0  1 34 48\n  10 22 12 12  6 63  1 56]\n [ 6 56 56 11  1  1 12 63  5 16 32  1 56 18 12 22 34  1 19 24 46 31  6 16\n  56  1  1 10  1 11  4  1]\n [24 41  5 48 22 30  4  1 10  1 19 22  4 11 10 11 10 22  1 13 35  1 35 47\n  32  4 47 34 35 34  1  1]]\nInput length: 15, Label lengths: [2, 4, 4]\nEpoch 3/20, Loss: 33.1390\nToken distribution (Batch 8): {1: 15}\nValidation Loss: 32.6300\nValidation Predictions: ['aj', 'aj', 'aj', 'aj', 'aj']\nGround Truth: ['XgM1X', 'UVE', 'oChe-', 'NjDj6', 'i9ud8']\nCurrent Learning Rate: 4.996878382120998e-08\nEpoch 4, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {5: 1, 18: 1, 19: 1, 10: 1, 27: 1, 55: 2, 35: 1, 9: 1, 50: 1}\nBatch 0, Gradient norm: 20.5255\nEpoch 4, Batch 0/66, Loss: 36.6797\nAvg Blank Probability: 0.0146\nSample predictions: ['IafvFAX', 'e-df', 'fV']\nGround Truth (first 3): ['r8lu', 'Xf', '-']\nRaw outputs (first 3): [[35  5  6 56 10 16 47  1  1  1  1 61  4  4 27 35  1 56 10 10 20  1 11 30\n  19  1 22  1  1 63 32  5]\n [ 1 63 48 35 34 16 10 47 34 56 22 27 12 47 32 34  4 10 35 32 25 32 10 47\n  11 47 11 25 30 12 63 18]\n [ 6  4  1 19  4 48 50 22 61 43 40  1 11  1 19 12 11  1 55 35  1 10 63 61\n  19  5  1 14 34 35 10 19]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {6: 2}\nBatch 10, Gradient norm: 22.6122\nEpoch 4, Batch 10/66, Loss: 38.0737\nAvg Blank Probability: 0.0148\nSample predictions: ['HFrUaU3a', 'vfa', 'fadja32a']\nGround Truth (first 3): ['zypb', 'P0', 'hrNK']\nRaw outputs (first 3): [[34 22  6 32  1 30 42  4  6 10 32 12 42 12  1 10  1  6 63 63 22 32 12 34\n   1 35  1 13 63  1 10  6]\n [32  6  1  1 22  1 47 32 32  4 43 34 19 47 10  1 11 10  6 30 24  1  6  1\n  48 56 30 12 34 12 42  6]\n [18  1  4 24 32 22  1  5  1  4 10 34 20 10  1  2  1 10  6 10  1  1  7  1\n  10 10 10 24 42 11 16  1]]\nInput length: 15, Label lengths: [4, 2, 4]\nToken distribution (Batch 31): {1: 2, 10: 1, 22: 1}\nBatch 20, Gradient norm: 18.1798\nEpoch 4, Batch 20/66, Loss: 32.6942\nAvg Blank Probability: 0.0147\nSample predictions: ['-UjI', 'tHQauBaPFa', 'avdQ']\nGround Truth (first 3): ['WJ', 'tgEPL', '-k']\nRaw outputs (first 3): [[63 20  1 56 10 34 27 19 13 10 47 33 19 47 62 12 63  1 24  6  1 12 11 27\n  28  1  6 22 43 10  1  1]\n [47 34 22  6 52 63 35 63 43  1 16  4  1  5  1  1 56 47 10 33  1  1  1 42\n   1 24 42 32 61 34  4 10]\n [10 43  4 55 35  4  6 20 56 32  8  4 34 10 47 38 10  1  1 19 16  1 11 47\n  34  1 11  6 32 30  1  1]]\nInput length: 15, Label lengths: [2, 5, 2]\nToken distribution (Batch 31): {1: 1, 55: 1, 42: 1, 34: 2, 9: 1}\nBatch 30, Gradient norm: 18.6321\nEpoch 4, Batch 30/66, Loss: 33.7584\nAvg Blank Probability: 0.0147\nSample predictions: ['Asa3aj', 'ajy', '2HFaFHaX']\nGround Truth (first 3): ['DwBi', 'G5', 'SqlG']\nRaw outputs (first 3): [[27  1 55  1 23 30 32  1 10 34 47 12 50  4  6 25 22 56 47  1 47 24 42 48\n  10 35  1 43 63 12 11  1]\n [19 10 34  6 19 43 16 63 47 56  1 33 35 22 12 10 47 22  1 63 42 12 19 13\n   5  1 12 10  1  6 19 55]\n [ 1 10 32  1 19 27 50 60 10  5 33  1 10 33 56 22  1 27 10 48 19 42  4 19\n  55 12 18 41 34 11 27 42]]\nInput length: 15, Label lengths: [4, 2, 4]\nToken distribution (Batch 31): {14: 1, 1: 1}\nBatch 40, Gradient norm: 99.9746\nEpoch 4, Batch 40/66, Loss: 33.5089\nAvg Blank Probability: 0.0148\nSample predictions: ['Vl', 'fF', 'aHvI']\nGround Truth (first 3): ['o', 'D', 'ce']\nRaw outputs (first 3): [[48  6  1 10 32 22 33  1 30 43 32 10 32 24  4  1  6 32 47  1 29 63 42 43\n   1 51 12 63  1 11  4 14]\n [12 32 34 56 35  1 35 10 24 35 32  4 10 16 63 34 48 30 24  1 34  1 22  1\n  10 56 34 10 10 32  1  1]\n [ 1 56 22  5 57  1  1 42 30 56  1 24  1 55  6  1  1 34  1 11  1 42 27 46\n  11 22  1  1 43 47  1  1]]\nInput length: 15, Label lengths: [1, 1, 2]\nToken distribution (Batch 31): {10: 1, 1: 2, 32: 1, 22: 1, 47: 1, 6: 1, 26: 1}\nBatch 50, Gradient norm: 45.7858\nEpoch 4, Batch 50/66, Loss: 37.0997\nAvg Blank Probability: 0.0148\nSample predictions: ['kax7faE3', 'jaFQ', 'ap']\nGround Truth (first 3): ['V6lI', '55', '3']\nRaw outputs (first 3): [[11 10  1 30  6 10  1 47 25  1 34  5 25 19  6 27 30 63 56 16 22 32 19 56\n  63  4 27 10 24  6 32 10]\n [ 1  1 16  9 42 55 56 12 34 19 12  1 12  4 32 34 10  6  1  1  1  1  1  1\n   1  1 10 20 22 10 43  1]\n [24 32  1 16 34  1 10 20 10 63 56 12 32 42 22 19 32 10 12 10 47 11 13 56\n  12 11 27 19 22  1  1  1]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {35: 1, 1: 1, 22: 2}\nBatch 60, Gradient norm: 14.7192\nEpoch 4, Batch 60/66, Loss: 29.5033\nAvg Blank Probability: 0.0149\nSample predictions: ['a2jAvUj', 'QaXUjtaIjX', '3HirFHav']\nGround Truth (first 3): ['TDXV', 'jfCBl', 'vOUX']\nRaw outputs (first 3): [[ 1 43 56 12 34 61 56 34 25 11  6 24 33 10 48 61  1 10 34 10  6 10  5 10\n   6 33 57 22 47 56 63 35]\n [ 1  1 34  1 32 10 43  1 11  6 63 32 33  1 43 32  1  5  1  1 10 22 42 34\n  30 25 12  1 10  1 63  1]\n [55 50  9 12  1 48  1  1 38 21  1 50  1  1 50 42 24  7 11 11 27 34 19 47\n  11 34 32  1 32  1 63 22]]\nInput length: 15, Label lengths: [4, 5, 4]\nEpoch 4/20, Loss: 33.3000\nToken distribution (Batch 8): {1: 14, 10: 1}\nValidation Loss: 33.0897\nValidation Predictions: ['aj', 'aj', 'aj', 'aj', 'aj']\nGround Truth: ['sIU', 'Dt', 'w19', 'h44Q', 'VjYzO']\nCurrent Learning Rate: 6.861297240664338e-08\nEpoch 5, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {35: 1, 1: 1}\nBatch 0, Gradient norm: 21.1295\nEpoch 5, Batch 0/66, Loss: 35.1851\nAvg Blank Probability: 0.0150\nSample predictions: ['kHiFjFk', 'kAj3kQ', 'akAIjH3ega']\nGround Truth (first 3): ['*m4W', 'FZD', '*glGz']\nRaw outputs (first 3): [[11 11  1 63 12 11 10 10  1 12 61 11 56 11  6 22 61 47 19 63 43 10 63  1\n  22  1 48  4 32 57 34 35]\n [34 27 11 12 10  1 10 42  1 34 34 19 32  1 50  4 10  1  1 11  1 63 16 11\n  34 32 34 24 56 20 11  1]\n [ 9 10 27 25  1 10 35 48  6 47  6 14  1 35 56 47 25  1 20  4  1 47 34 19\n  63 32 32  4 12 34  1 19]]\nInput length: 15, Label lengths: [4, 3, 5]\nToken distribution (Batch 31): {23: 1, 32: 1}\nBatch 10, Gradient norm: 14.4885\nEpoch 5, Batch 10/66, Loss: 28.6912\nAvg Blank Probability: 0.0150\nSample predictions: ['kjUsPVLilI', 'aUjljQaflr', 'kCpIkj']\nGround Truth (first 3): ['4ylL0', 'xDoww', 'Azb']\nRaw outputs (first 3): [[11  1 11  5 50 24 42  1  1 63 42  1 12  1  6 10  4  1 34 11 34  1  1  1\n   1  1 32  1 24 35 36 23]\n [10 47 29  1 25 48  1  7 22 47  1 12 35  0  1 55 23  1 24 34  4  4 16  1\n  56 11 46  6  1 34 56 32]\n [47 10 16 61 32 34 34  1 43  6 10 30  1 42 42  1 11  1  6  1 42 30 34 32\n  27 22 43 38 22  1 48  1]]\nInput length: 15, Label lengths: [5, 5, 3]\nToken distribution (Batch 31): {19: 1, 1: 1}\nBatch 20, Gradient norm: 18.4073\nEpoch 5, Batch 20/66, Loss: 32.9201\nAvg Blank Probability: 0.0147\nSample predictions: ['aUyHPa', 'fvaP', 'D3a28ia2k']\nGround Truth (first 3): ['FqIm', 'by', '-RY61']\nRaw outputs (first 3): [[ 1  6 30 63 56 13 24 22  1 11 35  1 43  1 14  1 47  1 24 10  4 43 10 42\n   4 16  5 19 56  1  1 19]\n [47 22 56 19 56  1 35 10 56 30 16 48 19  1 43  1  1 34  1 30 47 56  1 43\n  32  6 43 34 12  1  6  1]\n [25  1  1 22 56 10 35 10 48  6 11 11 22 56  6  4 32  1  1 34  1  1 27 34\n  10 22 12  1 10 32 22 50]]\nInput length: 15, Label lengths: [4, 2, 5]\nToken distribution (Batch 31): {4: 1, 43: 2, 63: 1, 6: 1, 5: 2, 32: 1, 10: 1, 28: 1}\nBatch 30, Gradient norm: 20.5389\nEpoch 5, Batch 30/66, Loss: 35.1592\nAvg Blank Probability: 0.0151\nSample predictions: ['kHavlHU', 'jaj', 'HkjarfsFxH']\nGround Truth (first 3): ['uJJX-', 'Pv', 'xM7tm']\nRaw outputs (first 3): [[11 10 34  1 10 11 12 50  4 50 47  1  4 22  1  1 34 12 24  1  4 61  6 10\n  11 12 19  1  6 34  1  4]\n [34 10 11 34 11  4 32  6 34 42 29 42  6 11  1 14  4  1 63 10 56 19  1 33\n  14 22  1 47 10 24 42 43]\n [34  1 10 32  1 27  1 27 34 19 28  1 22 25 32  1 10  1 19 32 34  4 43 42\n  11  1 10 44 12 27 19 63]]\nInput length: 15, Label lengths: [5, 2, 5]\nToken distribution (Batch 31): {63: 1, 34: 1, 24: 1, 50: 1}\nBatch 40, Gradient norm: 344.2265\nEpoch 5, Batch 40/66, Loss: 31.3882\nAvg Blank Probability: 0.0149\nSample predictions: ['aHFgsIla', 'avf3VjH', 'kjt9sH']\nGround Truth (first 3): ['ZXrt', '7SGL', 'Q5C']\nRaw outputs (first 3): [[ 1  1 11 42 34 56  1 34 10 43 10 63 25 44  1 11  1 24 25  1  1  6  1 10\n  34 56 10 42 11 33 42 63]\n [34 22 10 43 43 32 34  1 47  4 24 18 43 30 32 43 16 34 35 12 56 47 51 34\n   1 43  1 10 48 32  1 34]\n [32  6 20 22  6 19 47 10 22  5 56 22 34  1 35 34 22  1 22  1 19 42  1 35\n   1 35 10 30  1 48 47 24]]\nInput length: 15, Label lengths: [4, 4, 3]\nToken distribution (Batch 31): {22: 1, 1: 3, 35: 1, 12: 1, 5: 1, 11: 1}\nBatch 50, Gradient norm: 16.3837\nEpoch 5, Batch 50/66, Loss: 29.4341\nAvg Blank Probability: 0.0150\nSample predictions: ['vIUh', '4j', 'jPa2P']\nGround Truth (first 3): ['36', 'p', 'L2B']\nRaw outputs (first 3): [[22 57 10 43  1 18  1  1 10 63 18 32 10 12 42  1  1  1 43  4 24 56 47 10\n   1 13 42  1 34 11 56 22]\n [35 10 10 10 30 47  6  1  1  1  1 11 10 63 32 18 11  5 12 63  4 10 56 47\n  42  4 22 47 35 27  6  1]\n [47 32 42  1 11 48  1  1 10 14 10  1 19 20 35 32 43 11 48 56  1  5  5 43\n  55 46 10 57  1  1 10 35]]\nInput length: 15, Label lengths: [2, 1, 3]\nToken distribution (Batch 31): {61: 1, 1: 2, 34: 1, 25: 1, 47: 2, 7: 1}\nBatch 60, Gradient norm: 18.1546\nEpoch 5, Batch 60/66, Loss: 31.3771\nAvg Blank Probability: 0.0151\nSample predictions: ['pa', 'PjDijrA-l', 'spHjUpjHjv']\nGround Truth (first 3): ['4z', 'b4YLU', 'VjYzO']\nRaw outputs (first 3): [[16 42 19 34  5 43  4 12 12 43 56  1  6 50 61  1 10  1 10 16  1 42 48 10\n  32 10 11 13  6  1  6 61]\n [ 1 10 16 63 47 32 19 32  1 19  1  4 25 22 10  1  1  1 50  1 47  4 10 11\n   1  1  6 32  6  1 34  1]\n [ 1 10 34  1 19  1  1 19 13 34 16 32 43 35 27 10 57 42 23 10  1  1 11  1\n  10 19  6  1 45 47  4 34]]\nInput length: 15, Label lengths: [2, 5, 5]\nEpoch 5/20, Loss: 32.9038\nToken distribution (Batch 8): {1: 14, 10: 1}\nValidation Loss: 34.9585\nValidation Predictions: ['aj', 'a', 'aj', 'a', 'a']\nGround Truth: ['rFyEG', '8', 'A5', 'F*y3i', 'K']\nCurrent Learning Rate: 8.747553917935012e-08\nEpoch 6, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {56: 1, 11: 1, 1: 3, 47: 1}\nBatch 0, Gradient norm: 1539.1562\nEpoch 6, Batch 0/66, Loss: 35.1273\nAvg Blank Probability: 0.0148\nSample predictions: ['fa', 'jwValgaH', 'aVU2']\nGround Truth (first 3): ['4F', 'tKd4F', 'IC']\nRaw outputs (first 3): [[ 6 10  1  1 16  4 63 33 34 10  4 32 11  1  1 19  1 11 50 11 12 10 22 56\n   4 24 42 34 10 63 32 56]\n [ 1 10 48 22  1 10 12 10 11  6 27 48  1 32  1 22  5 11  7  1 57  1 56 10\n  10 61  4 12 35  1 11 11]\n [ 1 23 47 32  6  1  1 19 12  1 32  4 10 25 32  1  4 63 10 43 32 27  1 56\n   8  6 31 50 19  1 16  1]]\nInput length: 15, Label lengths: [2, 5, 2]\nToken distribution (Batch 31): {1: 1, 4: 1, 56: 1, 32: 1}\nBatch 10, Gradient norm: 27.4648\nEpoch 6, Batch 10/66, Loss: 31.2333\nAvg Blank Probability: 0.0148\nSample predictions: ['auU', 'xHF2VFap', 'v-mj']\nGround Truth (first 3): ['p9', '7SGL', 'yN']\nRaw outputs (first 3): [[ 1 24 22 10 42  4 35 25  1 57  6 57 10 63 47 63  6 35 34  1  6 56 32  1\n   1 35 16 47 10 35 14  1]\n [ 1 34 63 16 48 56 22 24 55  6  1  1 34 56  1 11  1 34 35 55 10 10 56 12\n  11 13 34  1  1 11 47  4]\n [21 32 13 10 11 10 34 35  1 25  1 19 47 61 22 32 23 10 10 12  1 25 47  1\n  35 16 22  6  1 12 22 56]]\nInput length: 15, Label lengths: [2, 4, 2]\nToken distribution (Batch 31): {34: 1, 55: 1, 35: 1, 42: 2, 19: 1, 25: 1, 43: 1, 1: 2}\nBatch 20, Gradient norm: 47.5236\nEpoch 6, Batch 20/66, Loss: 32.7905\nAvg Blank Probability: 0.0147\nSample predictions: ['-aAlPk', 'dfUl', 'ajAaIH']\nGround Truth (first 3): ['Os7', 'RS', '7lDV']\nRaw outputs (first 3): [[63  4  1 12 56 42  1 12  1 35 35 32 63 22 42  1 11 20 10 22  4 55 63 25\n   1 11 33 22  6 42  5 34]\n [ 1  6  0 22 22 10 10 42  1 35  9 10  1 59 10 19 35 11  6 50  1 34 32 55\n  47 36 12 42 14 10 55 55]\n [27 47 10 34 11  1  7 35  1 43 42 25  1 35  1 63 35 34 10 34 12  1 32  1\n  42 48  1 10  1 56  1 35]]\nInput length: 15, Label lengths: [3, 2, 4]\nToken distribution (Batch 31): {34: 2, 24: 1, 27: 1, 21: 1, 4: 1, 47: 1, 55: 1}\nBatch 30, Gradient norm: 19.2060\nEpoch 6, Batch 30/66, Loss: 33.6941\nAvg Blank Probability: 0.0149\nSample predictions: ['ca', 'HAa2H', 'jpayaydk']\nGround Truth (first 3): ['kX', 'uHJ', 'AaGy']\nRaw outputs (first 3): [[ 3 34 10 16 56 18 63 34  1  4 14 11 34 42 34 34  1 32  1 12  1 12 10 10\n   1 56 10 10 56  1 34 34]\n [ 1 27 16 34  1  1 34  1 50  1 10  1  1 10 56  1 40 56  1 22 10  1 11 10\n   6 34  9 43 12 10 48 34]\n [ 1  1  1 12 56 32  6 12  1 32 36  1  1 56  1 50 34 55 56  1  4  1 12  5\n  32  6 22  1 19 42 43 24]]\nInput length: 15, Label lengths: [2, 3, 4]\nToken distribution (Batch 31): {63: 1, 16: 1, 23: 1, 5: 1}\nBatch 40, Gradient norm: 14.2593\nEpoch 6, Batch 40/66, Loss: 28.3273\nAvg Blank Probability: 0.0150\nSample predictions: ['aAsPsa', 'aIdak-', 'j3v2Flxjd4']\nGround Truth (first 3): ['S65', '8NA', 'dX*TW']\nRaw outputs (first 3): [[ 1  1 10  1 24 47 19  1 32  1  1 35 27 42 56 12  1 11  6 20 63 32 10 32\n  11 34  4 42 19 11 20 63]\n [27 35 56 35 19 34 12 47  1 50 19 61 47 42 11 22 50 48 12 56 11 19 56  1\n  32 30 32 42 56 42 23 16]\n [19  4 22  1 10  1 19  1 32 24 43  1 42 42  1  1  1 12 32 48 11 43 47 43\n   1  1  1 19 19 56 23 23]]\nInput length: 15, Label lengths: [3, 3, 5]\nToken distribution (Batch 31): {32: 3, 4: 1, 24: 1, 19: 1}\nBatch 50, Gradient norm: 22.9863\nEpoch 6, Batch 50/66, Loss: 37.8674\nAvg Blank Probability: 0.0149\nSample predictions: ['akPHFj', 'x2vIdpjHjU', 'ak']\nGround Truth (first 3): ['sLL', 'c6jM0', 'I']\nRaw outputs (first 3): [[ 1 24  1 14  1 32 43 48 12 34 34 11 10 42 22 50 34 29 11 11 13  4 32 30\n   1  1  1 48  1 22 56 32]\n [11 55 11  1 48  1 32  1 42 10  1  4 10 50 56 42 10 56 56  1 21  1  9  4\n  12 42 32  1 42 34 32  4]\n [42 22  1 19 63 63 46  1  1 19 19 23 43 50 57 10  4  1 35 12 34 35 42 10\n  16  1  1 19 11 11 10 24]]\nInput length: 15, Label lengths: [3, 5, 1]\nToken distribution (Batch 31): {1: 2, 43: 1, 34: 1, 19: 1, 23: 1}\nBatch 60, Gradient norm: 19.6688\nEpoch 6, Batch 60/66, Loss: 34.1045\nAvg Blank Probability: 0.0151\nSample predictions: ['-t', '-aFjAP', 'FIsd']\nGround Truth (first 3): ['R', 'GHo', 'YT']\nRaw outputs (first 3): [[63 63 32  1 19  1  1 32 32 63  6 63 34 35 10  1 24 29  1 19 10 34 10  1\n  32 10 50 42 10  1  1  1]\n [20  1 35 11 43 10 32 12  6 25 32  1 19 55 34 22  4 36  6 27  1 10 25 56\n   1 34  1 42  1 12 42  1]\n [63 32 19 12 43 11 32 25  1 56  5 32  6  6 19 27 10  5  1 12 27 34 11 47\n  47 32  1 48 12 27 34 43]]\nInput length: 15, Label lengths: [1, 3, 2]\nEpoch 6/20, Loss: 33.1463\nToken distribution (Batch 8): {1: 15}\nValidation Loss: 32.8094\nValidation Predictions: ['aj', 'aj', 'a', 'aj', 'aj']\nGround Truth: ['CFS', 'efa8', 'Z*', 'JkOF3', '55Gq']\nCurrent Learning Rate: 1.0672901478267059e-07\nEpoch 7, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {1: 1, 13: 1}\nBatch 0, Gradient norm: 21.9688\nEpoch 7, Batch 0/66, Loss: 36.1380\nAvg Blank Probability: 0.0150\nSample predictions: ['aF4jas', 'aV-alays', 'HfX']\nGround Truth (first 3): ['jNX', '68hng', 'Pv']\nRaw outputs (first 3): [[ 1  1 34 22  1  1 43 35 34  6  1  1 10  1 10 46 43 11 10 47 32 14  6 10\n   1  1  9  6  1  1 25  1]\n [32 48  6 30 48 43 19 47  6 30  1 42 11 11  1  1 10  7  1 35  4 56 34 56\n  27 25 10 34 22  1 19 13]\n [57 63 50 22  1 63 50  1 30 16  4 34  6 10 10 19 19 20  1  9 48  1  1 34\n   4 61 35  1 40 47 32  4]]\nInput length: 15, Label lengths: [3, 5, 2]\nToken distribution (Batch 31): {1: 2, 42: 1, 27: 1, 22: 2, 10: 2, 32: 1, 25: 1}\nBatch 10, Gradient norm: 21.7184\nEpoch 7, Batch 10/66, Loss: 36.8911\nAvg Blank Probability: 0.0151\nSample predictions: ['jpsjaj3Vf', 'aHlpsa3', '-Pfl']\nGround Truth (first 3): ['E0V2k', 'VudB', 'Q*']\nRaw outputs (first 3): [[10  1 63 34 20 19 20 19  1 35 47 34 50 32  1  1 10 12 19 35 11 19 11 48\n   1 56 11  1 10 34 10  1]\n [16  1 42 22 32  1 23 47 34 34  5  4 46 27 12 11 34  4  1  1 42  1 36  8\n   5 24 18  1 56  1 10  1]\n [19 34  6  4  1  6 42  1  1  1 32 10  1  4 30 47  1 34  4  1  1 43 47 30\n  30  5  1 47 40 32  1 42]]\nInput length: 15, Label lengths: [5, 4, 2]\nToken distribution (Batch 31): {19: 1, 22: 1, 10: 1, 17: 1, 34: 2, 1: 1, 6: 1}\nBatch 20, Gradient norm: 16.7981\nEpoch 7, Batch 20/66, Loss: 27.4187\nAvg Blank Probability: 0.0150\nSample predictions: ['UvPFs', 'as', 'mylHID']\nGround Truth (first 3): ['Ufo', 'a', 'KV2']\nRaw outputs (first 3): [[47  1 13 32 42 34 32  6  1  1 43 16  1  1 50 61 23  1 10 56  1  6  4 22\n  56 25  4 23 56  1 34 19]\n [47 19 25  1  1 34 47 10  1 22 22 32 35  1  1 12 50 20 22 56 22 21 11 34\n  22  1 35 55  1 56 21 22]\n [22 24 12 35  1  4 32 10 11  1  1  1  1 50 33 61 12 27 35 55 42 19 22  6\n  63 22 35 34  1  1  1 10]]\nInput length: 15, Label lengths: [3, 1, 3]\nToken distribution (Batch 31): {19: 1, 34: 1, 33: 1, 32: 1, 1: 1, 50: 1}\nBatch 30, Gradient norm: 18.0934\nEpoch 7, Batch 30/66, Loss: 31.8381\nAvg Blank Probability: 0.0149\nSample predictions: ['lasFaeUFdw', 'ajaIas', '-adF2vU']\nGround Truth (first 3): ['U7Dtf', 'ZxKU', 'dWi3']\nRaw outputs (first 3): [[12  1 63 43 10 10 34 11 47 25  6 12 25 50 10  4 56 10 10 12  1 10 13 12\n   1 10  1 12  6 56 22 19]\n [ 1 10  1 36  1  1 23 22 34 19 42 24 19  1 12 56 10 11 30  1 56 63 13 43\n  11  1 16  1  1 16  6 34]\n [19  1  1  1 22 42 10 34  1  1  1 11 47 10 34 48 35 43 22 42  4 43 47 10\n  34 10  4 35  1 12 56 33]]\nInput length: 15, Label lengths: [5, 4, 4]\nToken distribution (Batch 31): {22: 1, 18: 1}\nBatch 40, Gradient norm: 20.0294\nEpoch 7, Batch 40/66, Loss: 29.7419\nAvg Blank Probability: 0.0151\nSample predictions: ['afUaFse-Q', 'HIsUa3v3va', 'paIskVQAU']\nGround Truth (first 3): ['uJJX-', 'wSqWA', 'xl1Yx']\nRaw outputs (first 3): [[ 1 34 16 11 34 35 34  1  1  1  1 43  4 10 47 10  1 56 10 47 10 47  1 11\n  16  1 56  1  4 34  1 22]\n [ 6 35  1 56  1 25 35 24  5  4  1 30  1 56 46  4 34 10 33 47  1 55 36  4\n  43 10  6 20 35 28  1 18]\n [47 19 35 51  4 30 10 34  1 27 50 47  1  1 10 32  1  1 14  1 35 25  4 34\n   1 63  1 16 47 42 56 22]]\nInput length: 15, Label lengths: [5, 5, 5]\nToken distribution (Batch 31): {56: 2}\nBatch 50, Gradient norm: 19.6855\nEpoch 7, Batch 50/66, Loss: 33.6579\nAvg Blank Probability: 0.0151\nSample predictions: ['HaHgiate', 'HaDaFa', 's-HysIFE']\nGround Truth (first 3): ['nQD9O', 'L2B', 'bFM5']\nRaw outputs (first 3): [[34 34 19 47 32 10 25  1  1  9  1 11 11 11 63  1 59 10 10 56 56 34 11 63\n  55  5 56  1  1  1  1 56]\n [ 1  1 63 22 12 12 46 60 32 11 34 18 16 35 10 56 10 43  1 27 56 47 24 16\n  55 19  1  1  6 34 56 56]\n [34 30 34 32 50  5 60  4  1 27 27 19 27  1 56 55  5 48  1 19 48  1  5  1\n  24  1 56  4 34 55 19 56]]\nInput length: 15, Label lengths: [5, 3, 4]\nToken distribution (Batch 31): {43: 1, 47: 1, 6: 1, 35: 1, 50: 1, 19: 1, 1: 1, 42: 1}\nBatch 60, Gradient norm: 19.0273\nEpoch 7, Batch 60/66, Loss: 33.1688\nAvg Blank Probability: 0.0152\nSample predictions: ['ICNav', 'kFlI', 'peAsATdyAs']\nGround Truth (first 3): ['RD6', 'iF', 'n3jVe']\nRaw outputs (first 3): [[35 11 16 12  1  1 47  1 22 10 42 10 24 20  1 11  1 11 11 11 32 10 32 56\n   1 27 32  5 22  1 18 43]\n [29 32  5 28 10 47 22 22 57  4  1 35 56  1 43 56 10 10  1  1  4 56  6  1\n  10 57 34 43  1 28  4 47]\n [40 12 27 50  1  1  1 32 12 50  1 30 27 47 30 27 11 30 27 24  1 10 35 30\n   1  1 43 34 32 50 21  6]]\nInput length: 15, Label lengths: [3, 2, 5]\nEpoch 7/20, Loss: 32.8169\nToken distribution (Batch 8): {1: 14, 10: 1}\nValidation Loss: 34.0584\nValidation Predictions: ['a', 'a', 'aj', 'a', 'aj']\nGround Truth: ['Yvw', 'j4CGh', 'L', 'PuL', 'Ocf0']\nCurrent Learning Rate: 1.2657197398119848e-07\nEpoch 8, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {22: 1, 6: 1, 56: 1, 42: 1}\nBatch 0, Gradient norm: 15.2956\nEpoch 8, Batch 0/66, Loss: 29.5277\nAvg Blank Probability: 0.0152\nSample predictions: ['xAIadPyvr', '3mPV', 'daVj']\nGround Truth (first 3): ['MJOdz', '05', '5I8']\nRaw outputs (first 3): [[24 56  4  1 34 35 25 56  1 48 56 22 10 32 11 35 34  1  1  1  1  1 35 34\n  32 22 56 43 42 19  4 22]\n [27 13  1 22 24 47 34 10  1 34  1  4 47 10 56 35 35  1 34 47  1 50 11 11\n  22 43 34 12  1 42  1  6]\n [35 42 48 34  5 43 12 56  7 22 19 42 43  1 11 12 50  1  7  1  1  5  1  6\n  22  6  1 27 32 32  1 56]]\nInput length: 15, Label lengths: [5, 2, 3]\nToken distribution (Batch 31): {32: 1, 1: 1}\nBatch 10, Gradient norm: 21.3594\nEpoch 8, Batch 10/66, Loss: 31.6677\nAvg Blank Probability: 0.0152\nSample predictions: ['dFPzh3Gpa', 'FHy', '-kjs323']\nGround Truth (first 3): ['t0K4D', 'TK', 'ALMJ']\nRaw outputs (first 3): [[ 4 32 63  1 43 46 10  4 10 12 50 16 57  1 24 35 11 12  1  6 12  1 10 32\n  34  1 47 12  6 11  6 32]\n [32 34 11  9 19 12 43  6 12 42 11 22 63 11 35 11 38 32 22 19 32  1 32 43\n  19  1 63 47 42  1 11  1]\n [42 25 10 20 34 10 47  5 10  6 10  1 10 11  1 32 11 35 40  6 24 56  1 50\n  19  1  1 10  4 43 11 12]]\nInput length: 15, Label lengths: [5, 2, 4]\nToken distribution (Batch 31): {11: 1, 6: 1, 63: 1, 56: 2, 12: 1, 5: 1, 7: 1}\nBatch 20, Gradient norm: 17.5882\nEpoch 8, Batch 20/66, Loss: 31.7824\nAvg Blank Probability: 0.0149\nSample predictions: ['dvaUf', 'UQk2', 'deUa']\nGround Truth (first 3): ['T-F', '9W', 'IG']\nRaw outputs (first 3): [[ 4 47  4  1  4 19 34 25  1 63 61 56 12 10  1 25 19 10  4  6 11 32 16  1\n  10  4  5  6 47 25 10 11]\n [22 43  5 22 28 20 10 34  1  1 11 32  4 32  6  1 10 27  1 12  1 57  1 32\n   1  1 12 50 32  5 19  6]\n [ 1 11 47 35 19 10 10 34  1 10 50 43 32 47  5 43 61 27  1  1 34  1 10 19\n  11 19 16 43 45  1  1 63]]\nInput length: 15, Label lengths: [3, 2, 2]\nToken distribution (Batch 31): {34: 1, 48: 1, 47: 1, 1: 2, 18: 1, 25: 1, 12: 1}\nBatch 30, Gradient norm: 59.1515\nEpoch 8, Batch 30/66, Loss: 31.3596\nAvg Blank Probability: 0.0151\nSample predictions: ['jajva-', 'jajI-', '8jadfj']\nGround Truth (first 3): ['KqsU', 'F6Y', '8MW']\nRaw outputs (first 3): [[10 10 61 10 11  1 10  1 19 25 35 22 32 42 22 35 10  6 19 11 32 56 12  4\n  56 24  1 57 16 10  6 34]\n [ 1  1 10 34  1 22 12  4  1 32  1 11 10 47 56 30 42 10 56 63 12 12  1 20\n  10 19 10  1 12 19 10 48]\n [10 10  1  6  6  5 12 61 26 18 50 10 13 32 19 47 16  1  1 32  1 56  1 22\n  36 22  1  1  1 30 48 47]]\nInput length: 15, Label lengths: [4, 3, 3]\nToken distribution (Batch 31): {1: 1, 32: 1}\nBatch 40, Gradient norm: 19.7725\nEpoch 8, Batch 40/66, Loss: 35.1837\nAvg Blank Probability: 0.0151\nSample predictions: ['jQjsxg', '-j2dj', 'ksHdDljy3j']\nGround Truth (first 3): ['lAV', '5Lpu', 'L-eej']\nRaw outputs (first 3): [[10 63 11  1  5  1  1  1 63 50 34  5  6  6 10  4 22  1 19 61  1 12  4 19\n  12 50 30  5 32 63  4  1]\n [43 10 19 10 34 10  1  6  1  5 56  1  1  1 47 34 43 32 29 47 56 11 22  1\n  22 56 22 27  1  1  5 32]\n [10 55 34  6  1 35 20 32 11 19 42  4  4 42 34  6 48 20 55 63 48 24  1 48\n   5  5  1 35  1 34  1 10]]\nInput length: 15, Label lengths: [3, 4, 5]\nToken distribution (Batch 31): {56: 1, 34: 2, 1: 2, 63: 1, 24: 1, 32: 1, 10: 1, 11: 1}\nBatch 50, Gradient norm: 77.7384\nEpoch 8, Batch 50/66, Loss: 32.9425\nAvg Blank Probability: 0.0150\nSample predictions: ['Qv', 'fkga', 'kX']\nGround Truth (first 3): ['G', 'Q*', 'K']\nRaw outputs (first 3): [[43  6 11 12 32 43 34  1 11 11 10 19  4  1  1 32 34  1  9 12 45 63 19  1\n  10 42  1 12 34 25 42 56]\n [22 11 50 33 35  4 11 28 11 27  1  4 10  1 10  5  4 33 19  1 42 34  1 11\n  47  6 10 34  1  7 22 34]\n [48  7 10  1 34 33 35 32 12 55 21 56 34 55 43  1 60 12 56  6 12 34 47 32\n  19 11 43 34 61 10 20 34]]\nInput length: 15, Label lengths: [1, 2, 1]\nToken distribution (Batch 31): {34: 2, 19: 1, 35: 1, 12: 1, 32: 1, 42: 1, 7: 1, 5: 1, 25: 1}\nBatch 60, Gradient norm: 26.0701\nEpoch 8, Batch 60/66, Loss: 40.1988\nAvg Blank Probability: 0.0151\nSample predictions: ['ja', 'ay3QfeiaU', 'aj']\nGround Truth (first 3): ['l', 'ZrSBq', 'c']\nRaw outputs (first 3): [[10  1  1 32 25  4 61  4 50 10  1  6  1 35  9  1  1 27  1 63  1 10  1 30\n  27  1 50 27 62 19 10 34]\n [ 1 25 10 11 56  1 11 43 16  1 33 12 19 10 22 63 33  1  5  1 42 10 10 32\n   1 10 22 63 19 13 19 34]\n [24 56 10 34 27  1 22 19 56  1  1 32 50 11 12 34 19  1 14  4 56 43  0  1\n  10  6  1 22 18  4 19 19]]\nInput length: 15, Label lengths: [1, 5, 1]\nEpoch 8/20, Loss: 33.4892\nToken distribution (Batch 8): {1: 15}\nValidation Loss: 34.0240\nValidation Predictions: ['aj', 'aj', 'aj', 'a', 'a']\nGround Truth: ['r*dU-', 'On', '2hT', 'iE3z5', 'q']\nCurrent Learning Rate: 1.472427795820856e-07\nEpoch 9, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {47: 1, 42: 1, 10: 2, 50: 1, 1: 1}\nBatch 0, Gradient norm: 216.1941\nEpoch 9, Batch 0/66, Loss: 34.0053\nAvg Blank Probability: 0.0151\nSample predictions: ['4V', 'aFIjg', 'HFXjajza']\nGround Truth (first 3): ['HT', 'Hlb', 'L7Vk']\nRaw outputs (first 3): [[57  1 34 32 19 10 11 33 43 63  1 24 22 34 10 48 63 10 47 16  1 22  4 22\n  11  1  1 10  1 56  1 47]\n [57  1 32  5  1 56 25 10  0 30  1 22 12 42 10  1  6 42  1 11 56 19 10 11\n   1 42  5  1 56 32 42 42]\n [57 32 50 56 35 10 22 56 32 11  1  6  1 63 11  1 11  1 19 43  1 50  1  1\n   6  1 12  6  1 10 32 10]]\nInput length: 15, Label lengths: [2, 3, 4]\nToken distribution (Batch 31): {1: 5, 7: 1, 27: 2, 47: 1, 56: 1}\nBatch 10, Gradient norm: 1522.5142\nEpoch 9, Batch 10/66, Loss: 34.4504\nAvg Blank Probability: 0.0154\nSample predictions: ['ada', 'klk2azVz', '-Ha3ea']\nGround Truth (first 3): ['ad', 'mQxk', 'YhVSr']\nRaw outputs (first 3): [[ 1 11 63 27 43 12 63 56 63 27  1 57  1 11  1 50 20  1  1  4 12 43  1 43\n  30 11 10  1  6  4 19  1]\n [ 4 12 34 19  1 33 35  1  7  6 22  4 34 11  1  1 56 19  6 17 35  1 50 36\n  11  1 24 24 34  1  1  1]\n [ 1 11  1 19 34 47 13 13  1 33  4 43 56 14 56  1 19  4 32 22 11  5 28 43\n  42  1  1 43 11 32 40  7]]\nInput length: 15, Label lengths: [2, 4, 5]\nToken distribution (Batch 31): {1: 1, 19: 1}\nBatch 20, Gradient norm: 543.9641\nEpoch 9, Batch 20/66, Loss: 30.5753\nAvg Blank Probability: 0.0154\nSample predictions: ['HafaHF', 'jUFAjIHa', 'jsaIdkDQ']\nGround Truth (first 3): ['0*T', '-zp9', 'DwBi']\nRaw outputs (first 3): [[34 10 10  1  1 50  4  6  1 30  6 25 56 42 50 16  1 17 10 35  6  1 42 43\n  19 47 22 11 63 19 50  1]\n [ 1 47 19  1  1  6 35 34 10 12  1  1 27 11 22  1  1 22 10  6  4 42  6  4\n  19 12 32  1  1 57 35 19]\n [ 6 32  1 47 42 55 35 56 32  1  1  4 10 34 47 35  1 11 10  1 56 22  1  4\n   1 34 34  1 56  6 11 32]]\nInput length: 15, Label lengths: [3, 4, 4]\nToken distribution (Batch 31): {32: 1, 52: 1, 22: 2, 34: 1, 42: 2, 26: 1}\nBatch 30, Gradient norm: 53.1693\nEpoch 9, Batch 30/66, Loss: 29.7118\nAvg Blank Probability: 0.0152\nSample predictions: ['Fxke', '3Qa', '4jQaU']\nGround Truth (first 3): ['dm', 's0', 'K2s']\nRaw outputs (first 3): [[32 56 57  1  1 11  4  4 12 10 43  5 12  1 16 24  1 30 24 35 63  1  1  4\n  47 47 57 10 10 61 43 32]\n [24 43 10  1 34 27  6  1 22  9 47  5  1  1 10  4 24 34  6 12  4  6 42  1\n  10 35 12 60 12 35 32 52]\n [11  1 10  1 32  4 10 61 47  1  1 10 25  5 60 12 47 32  6  0 11 48  5  6\n  57 63  1 50 11 47 22 22]]\nInput length: 15, Label lengths: [2, 2, 3]\nToken distribution (Batch 31): {32: 1, 19: 1}\nBatch 40, Gradient norm: 18.8755\nEpoch 9, Batch 40/66, Loss: 33.3470\nAvg Blank Probability: 0.0151\nSample predictions: ['Pa', 'lnasfA', 'sU']\nGround Truth (first 3): ['z', 'g8X', 'Z']\nRaw outputs (first 3): [[42 12 19 16 24  1 34 13  6 34  1 34 42 27 47 10 48 47 10 11  1 10 12 34\n  19 11 34  4 48  1 23 32]\n [ 1 14 47 11 13 25 25  1 42 10 11 56 27  6 30 32  1 47 56 11 46 35 63  4\n   4  1 19 11 19 32 19 19]\n [10  1 34  1  1  1 30  4 32 27  1  1 32 47 56  1  1 34  7 19  4  1 11 55\n  34 35 42  5 32 46 10 48]]\nInput length: 15, Label lengths: [1, 3, 1]\nToken distribution (Batch 31): {22: 1, 63: 1}\nBatch 50, Gradient norm: 39.6586\nEpoch 9, Batch 50/66, Loss: 35.2534\nAvg Blank Probability: 0.0150\nSample predictions: ['aXa4PIlX', '-Us3ava', 'd2jFde']\nGround Truth (first 3): ['KbANC', 'xj3G', 'T5Y']\nRaw outputs (first 3): [[ 1 63  4 43  1 10  1 56 22 56  1  1  1  1 19  1  5 32 11 10 10 46 34 47\n  34  4 22 47  1 29  1 22]\n [50 47 55  6 10  1 47 34  1  9 56 19 11  1 34 34  1  6 27 42  1  4 11 30\n  48 19  4 32 63 11 14 63]\n [ 1 19 10 50 19 55 19 10 22 43  1 42  1 32 35 32 34 34 19 30 61 27 12 11\n   5 47 30 32  1 19 28 10]]\nInput length: 15, Label lengths: [5, 4, 3]\nToken distribution (Batch 31): {1: 3, 5: 1, 11: 1, 48: 1, 56: 1, 10: 1}\nBatch 60, Gradient norm: 18.3271\nEpoch 9, Batch 60/66, Loss: 30.1342\nAvg Blank Probability: 0.0152\nSample predictions: ['HX', 'aX', 'alAy']\nGround Truth (first 3): ['8', 'w1', 'Mk']\nRaw outputs (first 3): [[34  1  1  1 42 63  1  6 63 19  1 34 12 48 47 25 19 10  1 43 34 10  6  1\n   4 42 10 11 42 32  6  1]\n [50  1 12 11  1 47 10  0 24  6 34  1  1 43  1  4 19 10 32  1  1 25 35  1\n  10 12 21  1 30  6 48  1]\n [33  1 27 10 16 10 33 22  1 32 34  5 14 35 10  1 22 32 16 56  1  4 32 12\n  19 42 10  1  1 19 34  1]]\nInput length: 15, Label lengths: [1, 2, 2]\nEpoch 9/20, Loss: 33.1870\nToken distribution (Batch 8): {1: 14, 10: 1}\nValidation Loss: 33.1555\nValidation Predictions: ['a', 'a', 'aj', 'aj', 'aj']\nGround Truth: ['*B', 'EG', 'L2B', 'XSpH', 'DK']\nCurrent Learning Rate: 1.690388570270353e-07\nEpoch 10, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {24: 1, 56: 2, 5: 1, 12: 1, 50: 1, 9: 1, 4: 1}\nBatch 0, Gradient norm: 13.1780\nEpoch 10, Batch 0/66, Loss: 26.9571\nAvg Blank Probability: 0.0153\nSample predictions: ['dUaDFa', 'fIXjaU3a', 'aA']\nGround Truth (first 3): ['3U6', 'Nsc6', 'p']\nRaw outputs (first 3): [[ 4  6  0 10 12 34 34 12 56 10  1  6  1 27 42 63 42 30 22  6 11 20  1 32\n   1 27 48 42  4 34  1 24]\n [47 35 27  4 22  4  4 34  5  1 19 10  1  1 24 11 12 22 11 42 10 35 47 14\n  43  1 48 11 22 34 47 56]\n [ 1 50 12 32 47 19  1 47 16  1 43  1 25 23  5 11  1 11 22 11 50 42 11  1\n  48 10 30 35 55  7  4  5]]\nInput length: 15, Label lengths: [3, 4, 1]\nToken distribution (Batch 31): {11: 1, 32: 1, 34: 1, 63: 1}\nBatch 10, Gradient norm: 17.2976\nEpoch 10, Batch 10/66, Loss: 31.3247\nAvg Blank Probability: 0.0154\nSample predictions: ['x3j3xIkdP', 'AU', '3a']\nGround Truth (first 3): ['ahDQZ', 'A', 'f']\nRaw outputs (first 3): [[24 27 56 11 12 10  1 12 50  1  1 34  1 34  1 47  4  1 43 34 19 42 30  0\n  20  1  4 12 12 10 61 11]\n [56 47  1 43 47 24 12 63 42  4 47  6  1 22  1 34 47 25 47 11 34 14 47  4\n   1 43 21 32  4 27 10 32]\n [10 47  1 13 47 23 34 32 47  6 34 32  6 34 32 32 21 10  4 35  1 22 27  5\n  47  1 25 55 25 42  1 34]]\nInput length: 15, Label lengths: [5, 1, 1]\nToken distribution (Batch 31): {4: 1, 14: 1, 32: 1, 13: 1, 1: 1, 12: 1}\nBatch 20, Gradient norm: 608.3317\nEpoch 10, Batch 20/66, Loss: 31.0865\nAvg Blank Probability: 0.0153\nSample predictions: ['aU4UdAH', '3yeAFaUd', 'aIjav2k']\nGround Truth (first 3): ['o68L', 'bneT', 'O5al']\nRaw outputs (first 3): [[ 1 56  1  1 32  1 23 56  1 10 43 33  1  4 55 12 23 56 27 47 42  1 22 56\n   1 12 19 20 10  6  1  4]\n [ 1 25 35 25  6 12 11 19 19 63  1 10  1  1  4 42 10 12  5  1 42  1 50 55\n  27  2  6 27  1 63  1 14]\n [47  5 10  1 10  6 47 10  1 22  1 47 63 32  4 43 10  1  1 55 42 25 19 32\n  22  1 25 47  1 10 12 32]]\nInput length: 15, Label lengths: [4, 4, 4]\nToken distribution (Batch 31): {19: 1, 51: 1, 1: 1, 10: 1}\nBatch 30, Gradient norm: 19.9678\nEpoch 10, Batch 30/66, Loss: 34.6411\nAvg Blank Probability: 0.0152\nSample predictions: ['kFfkj2tjaX', 'vHaX43jH3H', 'DP2kF2']\nGround Truth (first 3): ['j-D*x', 'c8sos', 'FLP']\nRaw outputs (first 3): [[11 22 30 32 11 32  4 18  6  6 11 10  1 10  6 10 63 63 10 32 12 34  1  1\n  10 11 32 56 10 22 47 19]\n [32 34 42 19 11 11 34 24  5  6 10 16 48  4 56  5 25 10 47 55 12 10 47  6\n   1  1  1 43 43  1 63 51]\n [ 6  1 55 63  1 10 48 42 33  5  1 10 25 32 21 55 32  1  1 35 11 43 63 63\n  34 22 22 11 43 12 50  1]]\nInput length: 15, Label lengths: [5, 5, 3]\nToken distribution (Batch 31): {47: 1, 1: 1, 10: 1, 50: 1, 30: 1, 32: 1}\nBatch 40, Gradient norm: 23.1972\nEpoch 10, Batch 40/66, Loss: 33.4168\nAvg Blank Probability: 0.0153\nSample predictions: ['-aHVHjQ', 'jTadHy', 'HaFIFaF']\nGround Truth (first 3): ['hACa', '5Za', 'oiUh']\nRaw outputs (first 3): [[63 10 34 30 10 35  1  1  1  1 30 11 56 43 10 42 11 56 10 34 10  1 56 47\n  25 63  1  6 34 48 10 47]\n [ 1 46  1 19 32 25  1 22 16 19 42 27  1 19 32 34 22 56 10 19 56 47  1 22\n  56 47 10 47 57  1 43  1]\n [ 1  1 32  1 18 55  1 22 43 11 48 48  1  6 14 11  1  1 24 34 20 47 34 48\n  43 43 47 34  1 28 56 10]]\nInput length: 15, Label lengths: [4, 3, 4]\nToken distribution (Batch 31): {14: 1, 1: 1}\nBatch 50, Gradient norm: 640.2003\nEpoch 10, Batch 50/66, Loss: 35.9299\nAvg Blank Probability: 0.0153\nSample predictions: ['fPl3paFAaF', 'ja', 'jyIy']\nGround Truth (first 3): ['jY*7c', '5', 's0']\nRaw outputs (first 3): [[ 6 10 10  1 56 10  1  6  6 34 10 12 22  1 16 10 22 11  4 50  1  1 12  4\n  56 42  6  4 12 56 35 14]\n [42  1 25 61  6  5  5 50 10 32 19 50 10 24 47 42 24  1  4 11 20 32  1 22\n  24  1  6  1  4 34 35  1]\n [12  1 35 38 27 63 35  6  9 19  5 12 10 56 27 10  4  5  1  6 34 24  1 55\n  35 10  1 34 10  1  1  6]]\nInput length: 15, Label lengths: [5, 1, 2]\nToken distribution (Batch 31): {11: 1, 47: 1}\nBatch 60, Gradient norm: 18.9996\nEpoch 10, Batch 60/66, Loss: 32.5844\nAvg Blank Probability: 0.0151\nSample predictions: ['laHF2UeFeP', 'IaVajuIt', 'Iaga-y']\nGround Truth (first 3): ['pRXvu', 'oZROy', 'n4LAz']\nRaw outputs (first 3): [[12 35 35 30 24  4  5 63 10 35  1 27  6 34 22 43 43 56 20 10 19 25  1  1\n   1 56 32 19 34 11 11 11]\n [ 1  1  1 10 10  1 56  6  1 56 12  4 22 11 42 43 43 63 32 24 34  6 10 20\n  19 63  1 56 32 23 10 47]\n [34  1  1 32 27  4 19  1 11 56 56 35 35  1  1 22 43 63 30  1 20 19 11 34\n   1  1 27 22 16  4 34 10]]\nInput length: 15, Label lengths: [5, 5, 5]\nEpoch 10/20, Loss: 33.1108\nToken distribution (Batch 8): {1: 14, 10: 1}\nValidation Loss: 33.9385\nValidation Predictions: ['a', 'aj', 'a', 'aj', 'aj']\nGround Truth: ['Ck', 'R', 'En', 'jAh4', 'Du38J']\nCurrent Learning Rate: 1.9234506732942514e-07\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {35: 1, 47: 3, 43: 1, 1: 1, 4: 1, 13: 1}\nBatch 0, Gradient norm: 13.1553\nEpoch 11, Batch 0/91, Loss: 26.7823\nAvg Blank Probability: 0.0153\nSample predictions: ['3ajzj', 'yd', '-lkvjsHk']\nGround Truth (first 3): ['uCYo', 'P', 'wx-je']\nRaw outputs (first 3): [[56 25 63 34 10 10 63 56 19  1 25 10 10 43  4 22  1  4  1  4 35  1  1 25\n   1  6 11  1 35 10 10 35]\n [ 1  4 12 20 35 63  1  1 19  1 47 50 35 19 10  1 51 48 48 10  1  5  4 43\n   6  1 19 19 32 63  4 47]\n [ 1 12 11 34 34 47 62 35  4 16  6  7 47  1  4 43  5 47 35 40 10 34 42 42\n  32  6  1 19  1  6 50 43]]\nInput length: 15, Label lengths: [4, 1, 5]\nToken distribution (Batch 31): {10: 2, 27: 1, 1: 1}\nBatch 10, Gradient norm: 16.1452\nEpoch 11, Batch 10/91, Loss: 30.6435\nAvg Blank Probability: 0.0149\nSample predictions: ['ajkHkaHa23f', 'AkagaHBvaj', 'yaH3']\nGround Truth (first 3): ['RqAgCd', 'biTha', '93']\nRaw outputs (first 3): [[ 1 27 25 11 32  1 63 32 34 11 19 56 34 35 16  1 10 19 34  1  1 56 22 34\n  32  1 42  1 11  1 47 10]\n [10 11  1 56 47  1 42 43  1  5  5 56 19 12  1 22 35 14 10 11  1 10  1  1\n   1  1 14  5 35 12 27 27]\n [10  1 34  1 10  1 32  4 48  6  4  1 50 32 48 35  1  1  4 32 27 12  1  1\n  24 19 27 34 59 63 19  1]]\nInput length: 15, Label lengths: [6, 5, 2]\nToken distribution (Batch 31): {11: 1, 42: 1, 1: 3, 55: 1, 30: 1, 32: 1}\nBatch 20, Gradient norm: 51.3794\nEpoch 11, Batch 20/91, Loss: 22.9937\nAvg Blank Probability: 0.0156\nSample predictions: ['3a3UfQjljDbt', 'aJiQa3UiP', 'Hvaf3a-vyPjkF']\nGround Truth (first 3): ['gSGYn-', 'T9vty', '4haKGSo']\nRaw outputs (first 3): [[56  1 34 10 24 12 47 17  4 22 42 40 32 47 48 10 34 10  5 50  4  6  4 34\n   1  4  1 56 11 30 11 11]\n [ 1  1 22  5  1 47  5  1 24 17 22 34 35 63  5 47  1  1 43  1  1 63 25 10\n   4  4 35 34 35 22  4 42]\n [56 36  1 30 10 10 26  4 11 34 34 34  1 50 34 34  6  5  4 30 24 47  1 12\n  34 22 60 12  1  5  4  1]]\nInput length: 15, Label lengths: [6, 5, 7]\nToken distribution (Batch 31): {1: 3, 6: 1, 47: 2, 34: 1, 43: 1, 10: 2}\nBatch 30, Gradient norm: 7359.8008\nEpoch 11, Batch 30/91, Loss: 30.2426\nAvg Blank Probability: 0.0154\nSample predictions: ['aKHaHaHkugPI2s', 'dk', 'kXaD']\nGround Truth (first 3): ['Oqb511L', 'P', 'SF']\nRaw outputs (first 3): [[ 1  4 11 43  6 11  4  1  4 10  1 12 42  1 20 43  1  1 42  1  1 12 16  4\n   1  1 22 10  4 63  1  1]\n [37 11 50  1 35 27 32 17  1 12 19 47 55  4  1 63 34  4 47  1 27 32 10  6\n  22 57 12 47 32  4 22  1]\n [34  1  1 43 28  1 19 43 11 32  1  9 20  4  4 56  7  1 32  1 34 27 32 33\n  19 47  1 34 55 33 13  6]]\nInput length: 15, Label lengths: [7, 1, 2]\nToken distribution (Batch 31): {19: 1, 1: 3, 22: 1, 55: 1, 5: 1, 21: 1, 7: 1, 10: 1, 50: 1, 12: 1, 4: 1, 56: 1}\nBatch 40, Gradient norm: 28.4686\nEpoch 11, Batch 40/91, Loss: 24.0025\nAvg Blank Probability: 0.0154\nSample predictions: ['UHFegfaHsa', '-aBaPkdHj', 'Us3LesSaIxglYU']\nGround Truth (first 3): ['aIZk9O', '30Ez6', 'K8vUvMN']\nRaw outputs (first 3): [[47 63 47 10  1 43  1 27 10 10 19 50 42 19  1  1 43  1 24 57 22 12  4 56\n   1 30 32 32 22  1 10 19]\n [34  1 19 34 56 12 32 20 32 34  5 11 10 33 34 30 50 12 32 16 27  1 11 11\n   1  1 63 22  5 10  1  1]\n [32  1 56 10 38  1 34 35  1 12  1 43 32  4 27 20 35 19 35  6 25 63 56 63\n  34  1 27 43 11  1 31  1]]\nInput length: 15, Label lengths: [6, 5, 7]\nToken distribution (Batch 31): {10: 1, 32: 1, 34: 1, 6: 2, 22: 1, 56: 1, 4: 1}\nBatch 50, Gradient norm: 15.3902\nEpoch 11, Batch 50/91, Loss: 28.7799\nAvg Blank Probability: 0.0154\nSample predictions: ['jHvpaP', 'FjaQlvaeaja', 'mjnakv']\nGround Truth (first 3): ['7ZZ', 'uWA78n0', 'dNm']\nRaw outputs (first 3): [[10 32 13 11 56 12 34 56 56  1 22  1 32 29  1 32 10 56  1 16 48 35  4 10\n  47 19 42 22  4 63  1 10]\n [34 10 10 42 10 22 19 10 56  1  4 30  1 19 34 11 43  1  1 25 12 13 56 32\n   7 43  4 22 24  1  1 32]\n [22 10 14 34 32  6  1 10  1 32 47  1 11 22 11 27 22  1 57  4 46 27 32 10\n  11 56 55 20 34 30 48 34]]\nInput length: 15, Label lengths: [3, 7, 3]\nToken distribution (Batch 31): {11: 1, 6: 1, 35: 1, 10: 1, 61: 1, 32: 1}\nBatch 60, Gradient norm: 129.6693\nEpoch 11, Batch 60/91, Loss: 32.5138\nAvg Blank Probability: 0.0154\nSample predictions: ['anaUHI', '3j', 'ljkPG3I']\nGround Truth (first 3): ['I*0', 'l', '3uam']\nRaw outputs (first 3): [[ 1 56 12  6  4 32  1  1 43  4 19 18 43  1 10 10 19 34  1 10 35 48 10  8\n   1 48  1 42 56 43  4 11]\n [14 10 10 11  1 24  1 11 10 34 16 22 61 27 34 22 25 32 19 34 47  1 22 43\n   5 34 34 11 56 10  5  6]\n [ 1 56 11  5 10 42 56 42 30  1 10 10  5  1  1  1 56 43 27  5 47 25 12 63\n   5  4 56 11 27 22 46 35]]\nInput length: 15, Label lengths: [3, 1, 4]\nToken distribution (Batch 31): {1: 1, 34: 1}\nBatch 70, Gradient norm: 15.3251\nEpoch 11, Batch 70/91, Loss: 28.9177\nAvg Blank Probability: 0.0155\nSample predictions: ['lfaH', 'xv3aHUvaXAaja', 'fiXja2sFHQaA']\nGround Truth (first 3): ['hQ', 'iikgJBB', 'ZyI9z8r']\nRaw outputs (first 3): [[12 24  6 13 56  1 19 24 43 22 11  5  1 20  1 10 43 10 43  0 22  1 34  1\n  56 30 10  1 56  7 24  1]\n [ 6 22  9  1  4  1 34  1 56 63  1 11  5 47 56 34 11 34 47 11 28 50 10 32\n  22 50 35  4 19 42  6 34]\n [ 1 56 50  1 34  1  5 47  5 47 31 32 16 63 10 19 47 12  1 60 53 23 11  5\n  13  4 34  1 12 10 27  1]]\nInput length: 15, Label lengths: [2, 7, 7]\nToken distribution (Batch 31): {19: 1, 34: 1, 1: 4, 55: 1, 22: 1, 11: 1, 42: 1}\nBatch 80, Gradient norm: 16.4531\nEpoch 11, Batch 80/91, Loss: 30.4259\nAvg Blank Probability: 0.0152\nSample predictions: ['Xf', 'rjtjFjfXk', 'avFIFf5aHI']\nGround Truth (first 3): ['3', 'd40XO', 'UeXm8Z']\nRaw outputs (first 3): [[50 18  1 34  1 33 56  4 10 32 48 30 22  1 20 32 10 42 10 43  4 57 32 25\n  63 32 12 22 42  4  1 19]\n [ 6 10 22 43 12 32 20 43 14  1 47 35 10 19 10 19 10  5 10 47 57 11  5 56\n  25 63  1  5 56 19  1 34]\n [ 6 20 32  1  9 47 11 50 11 32  1  6 34 11  1 22 11  1  4  6 63 48 22  1\n  12 24 32 48 34 61 32  1]]\nInput length: 15, Label lengths: [1, 5, 6]\nToken distribution (Batch 15): {1: 4, 22: 1, 40: 1, 6: 1, 12: 1, 9: 1, 63: 1}\nBatch 90, Gradient norm: 13.0671\nEpoch 11, Batch 90/91, Loss: 25.8812\nAvg Blank Probability: 0.0154\nSample predictions: ['Xvsa', 'kajlxifvejkXjs', 'la-aAasjFTk']\nGround Truth (first 3): ['HL', '9vQ54v5', 'TBnHM5*']\nRaw outputs (first 3): [[50 11 12 14 10 57 47  1 35  1 19 12 34  1  6  1]\n [22  1  1 34  1  7 42 50 27  1 19  1 56  1 22 22]\n [19 10  1 56  4  4 27 19  1 10 22  6 16 13 48 40]]\nInput length: 15, Label lengths: [2, 7, 7]\nEpoch 11/20, Loss: 28.4976\nToken distribution (Batch 19): {1: 14, 10: 1}\nValidation Loss: 27.6337\nValidation Predictions: ['a', 'aj', 'a', 'aj', 'aj']\nGround Truth: ['bLBIm9', 'h65z19', 'Noe', 'U-xr4', 'dh8hotR']\nCurrent Learning Rate: 2.4079101853620755e-07\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {1: 1, 43: 1}\nBatch 0, Gradient norm: 1609.9500\nEpoch 12, Batch 0/91, Loss: 30.8224\nAvg Blank Probability: 0.0154\nSample predictions: ['veaHPfIzaFRwVa', 'DvkdQHda', 'F']\nGround Truth (first 3): ['h7epS8M', 'O-ir', 'c']\nRaw outputs (first 3): [[22 30 32 56 34  1 27 10  4 56 12  1 11 43  1  4 10 48  1  1 22 36 35 57\n  57  1  1 11  5 12  1  1]\n [ 5 22 32 40  1 12  6 10 24 56 19 11  4 38 32 27  1 32  1 30  6 63  1 46\n  10 48 10 34 12 34 63 43]\n [ 1 11 32 19 56 26  1 36 19 24 34 32 48  1 10 19  4 47 21 55 10 63 19 24\n   1 32 56  1  1  1 19 10]]\nInput length: 15, Label lengths: [7, 4, 1]\nToken distribution (Batch 31): {25: 1, 1: 3, 6: 1, 22: 1, 61: 1, 42: 1, 35: 1, 10: 1, 26: 1, 12: 1, 30: 1, 7: 1}\nBatch 10, Gradient norm: 17.3643\nEpoch 12, Batch 10/91, Loss: 30.6827\nAvg Blank Probability: 0.0156\nSample predictions: ['ajDFIvald', 'ma', 'dja']\nGround Truth (first 3): ['QGLe0', 'er', 'lm']\nRaw outputs (first 3): [[ 1 13  4 11 34 20 42 11  1 32  8  6 12 32 13 43  1 12  1 34 32 43  1 22\n  35 61 47 10 56 10  4 25]\n [10  1 10  4  4 32 10 42  1  5 19 19 56 10  1  6  5 35  6 33 32  4  1 47\n  43  1 10  6 10  4 25  1]\n [30  1  1  5 35  5 40  1 38  1  4 12  1 61 16  1 41 14 12 12 20 56 16  1\n   5  6 61 56  1 19 11  1]]\nInput length: 15, Label lengths: [5, 2, 2]\nToken distribution (Batch 31): {19: 1, 42: 1, 32: 3, 50: 1, 33: 1, 27: 2, 48: 1, 34: 2, 1: 1, 7: 1}\nBatch 20, Gradient norm: 14.7590\nEpoch 12, Batch 20/91, Loss: 27.0190\nAvg Blank Probability: 0.0156\nSample predictions: ['-ArjXjFAa3', 'A-ajXjHvyFVAjg', 'HI-']\nGround Truth (first 3): ['kHfqx', 'wn4a7rf', '1N']\nRaw outputs (first 3): [[63 27 34  1 34  4  1  1 32 35 35 34  1  1 56 63 34 63 32  1  1 22  1  1\n  47  6  1 18 34 47 10 19]\n [27 63 34 10  1  4  1 11 42  1 25 34  9  1  1 13 23 55 32 12 34 34 12 50\n  48 24 11  1 23 11 32 42]\n [18  1 35 30 27 10 47 32  1 22 10  1  1  1 32  1 22 19 32 47 42 34  1 50\n  11  1 47 32 57  1 22 32]]\nInput length: 15, Label lengths: [5, 7, 2]\nToken distribution (Batch 31): {63: 2, 43: 1, 35: 1, 34: 1, 30: 1, 10: 1, 1: 1, 7: 1, 32: 1}\nBatch 30, Gradient norm: 12.1229\nEpoch 12, Batch 30/91, Loss: 25.0912\nAvg Blank Probability: 0.0157\nSample predictions: ['-HF34', 'jQUv', 'afafFI']\nGround Truth (first 3): ['Yvw', 'rT', 'yGW']\nRaw outputs (first 3): [[63 10  1 22 11  6 24 63 11 11 63 63 12 11 35 19 32 32 11 23 11 25 32 16\n  24  4 25  1 43  1 11 63]\n [34 43  6  1 21 12 30 32 35 63 11  4  1 47 22  4  1 45  1  4 22  1 43 47\n   1 34 32 61 47 47  1 43]\n [32 47  1 47  1 32 11 35  1 34 12 33 56 10 24  1 32  1  1  6 47 27 56  1\n  13 33  6 19 56  7  1 35]]\nInput length: 15, Label lengths: [3, 2, 3]\nToken distribution (Batch 31): {1: 3, 25: 1, 56: 1, 35: 1, 22: 2}\nBatch 40, Gradient norm: 14.6815\nEpoch 12, Batch 40/91, Loss: 27.5242\nAvg Blank Probability: 0.0157\nSample predictions: ['advatd3Aas', 'yPUFUdaA', 'lktU']\nGround Truth (first 3): ['q6gTu', 'Ocf0', '02']\nRaw outputs (first 3): [[ 1 25 12 12 12 56 35 32 19 32 35 32  1 11 22 13 56 11 19 42 10 18 22 20\n  16 42  1 19  5 32 36  1]\n [ 4 42 11 10  6 47 25 47 34 21  1 12  1  1 25 56 19  6  5  1 33  6 35  4\n  19 10  1 48 56 47 13 25]\n [22 47 20 30  4  5  1 13  1 23 10 11  4  4  1 32 35  5  7 13 22 10  1 34\n   1  4 10  5  7 55 10  1]]\nInput length: 15, Label lengths: [5, 4, 2]\nToken distribution (Batch 31): {13: 1, 6: 1, 11: 1, 63: 1, 22: 1, 4: 1}\nBatch 50, Gradient norm: 13.6567\nEpoch 12, Batch 50/91, Loss: 26.2765\nAvg Blank Probability: 0.0158\nSample predictions: ['Jk4aUdAPUVHQUt', '-DgxashAa', 'dsaUa2fD']\nGround Truth (first 3): ['yeZBt6x', 'WJ3im', 'rj2Y']\nRaw outputs (first 3): [[36 63  4 32 43 10 25 57 11 56 11 10  6 10 34 63 25 56 42  1 63 12  1  4\n  50  1 34 27 10 63 63 13]\n [11 30 19 10 11  1 23 10 25 56  5 11 19 11  6 47 10 30  0 43  1 11 10  1\n   1 34 22 56  1 32  1  6]\n [57  7  1  6 32  5  1 11  1 10 48 44 10 47 22 27  5 50 16 10 32 14 63 19\n  50 21 47 50 11 63 56 11]]\nInput length: 15, Label lengths: [7, 5, 4]\nToken distribution (Batch 31): {34: 2, 7: 1, 10: 1, 43: 1, 6: 1, 32: 1, 19: 1, 27: 1, 56: 1}\nBatch 60, Gradient norm: 509.8043\nEpoch 12, Batch 60/91, Loss: 27.3758\nAvg Blank Probability: 0.0158\nSample predictions: ['nPUgwa', 'FesF4HavjsuA', '-x']\nGround Truth (first 3): ['2JT', 'nQoAFh', 'q']\nRaw outputs (first 3): [[14 32 63 56  1 56 57  1 35 47  1 12 32 32 12  1  1 10 10 63  4 16  6 10\n  56  4 22 11  4  6 22 34]\n [42  5 24 47 34 43 35  1  1 12 27 25 50 10 12  4  4 13 10 12  6 47  1 19\n   1 56  5 56  1  1 34 34]\n [47 19 25 47 32 32 11  1 34  4 22  1 55 12  6 11 25 36  5 30 24  1 10 19\n  43  6 47  1  1 19  1  7]]\nInput length: 15, Label lengths: [3, 6, 1]\nToken distribution (Batch 31): {10: 1, 27: 1, 16: 1, 11: 1}\nBatch 70, Gradient norm: 44.7200\nEpoch 12, Batch 70/91, Loss: 26.4559\nAvg Blank Probability: 0.0159\nSample predictions: ['sH', '2QIJ', 'faFej3gehvjm']\nGround Truth (first 3): ['k', 'T1', 'XaGhKvP']\nRaw outputs (first 3): [[19 55  6  1 11 25  6  6  3 47  1 34  1  1 10 22 14 24 34 56 32  5 22  1\n  11 34 47 10 10  1 16 10]\n [34 43  6 10 21 12 34 43 10 35 13 63 42 47 47 10  0 28 10 11 47 61  4 10\n  11 21 47 63 19  6 35 27]\n [ 1 35  1  5  1 42 14 20  1 32 10  1 34  1 10  1 32 22  5 25 27  1 10 32\n  10 42 12 24  1 48  4 16]]\nInput length: 15, Label lengths: [1, 2, 7]\nToken distribution (Batch 31): {1: 3, 9: 1, 10: 1, 5: 1}\nBatch 80, Gradient norm: 12.4457\nEpoch 12, Batch 80/91, Loss: 25.6247\nAvg Blank Probability: 0.0158\nSample predictions: ['lsAa-aPmIsis', '2asHfvjFsUsFH', 'AadVak']\nGround Truth (first 3): ['YWmFk6', 'AjNIAzj', 'xe5']\nRaw outputs (first 3): [[12 55 27 63 22  1  6 63 34  1 16 47  4  4 47 32  4  1  1 27 32 22 30 48\n   1 56  1 19  1 55 56  1]\n [19  1  1  6 12  4 32 20 24 32  1 42  4 10  1 29 11  4 32 32 10 32 11 34\n  19  1 43 22 22 28 47  9]\n [27  1  4  1  1 34 50 28 47 10 42 34  6  6  1 30 19 11  1  1  4 30 34 22\n  10 32 47 24  5 42 56 10]]\nInput length: 15, Label lengths: [6, 7, 3]\nToken distribution (Batch 15): {10: 2, 1: 4, 56: 1, 50: 1, 42: 1, 35: 1, 5: 1, 24: 1}\nBatch 90, Gradient norm: 13.2485\nEpoch 12, Batch 90/91, Loss: 25.0750\nAvg Blank Probability: 0.0160\nSample predictions: ['aH', '-FaH', '3tPjaHIHaQX4FT']\nGround Truth (first 3): ['3', 'BQ', 'j39MjIY']\nRaw outputs (first 3): [[ 1 63 56 22 22  1  1  1 60 32 56 34 63  1  0 10]\n [34 32 20 14 42 12 32  5  4 19  1 22  1 47 32  1]\n [ 1  1 42 30 12  1  1 14 34  0  4 48 32 10 19 56]]\nInput length: 15, Label lengths: [1, 2, 7]\nEpoch 12/20, Loss: 28.3863\nToken distribution (Batch 19): {1: 15}\nValidation Loss: 27.8705\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['uduag5', 'v', 'kXK', '4oAo', 'Xgg*r']\nCurrent Learning Rate: 3.781152949374526e-07\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {56: 2, 11: 1, 5: 1, 13: 1, 22: 1, 7: 1, 10: 1, 1: 2, 35: 1, 34: 2, 12: 1}\nBatch 0, Gradient norm: 25.9346\nEpoch 13, Batch 0/91, Loss: 29.3601\nAvg Blank Probability: 0.0160\nSample predictions: ['valI2jed', 'jePHUds2xkAeP', 'Fvxv-avjAjaHD']\nGround Truth (first 3): ['DMYT*', '2m09p04', 'rsJczXz']\nRaw outputs (first 3): [[22 10 32 56 48 43 11 32 32 42 43 34 57 25 44 17  6  4  6 11 10  1 35  1\n  63  1 10 14  1  1 63 56]\n [ 1  5 22 56  1  1 34 22  1 61 27  6 10 61  4  1 34 12  1 10 43 34 46  1\n  56  6 10 43 34 10  1 11]\n [ 1  5 24 12 29  1  4  0 32 19 61 22 18 32 43 30  1 25 56 55  5  2 42  1\n  34 55 12 47  1  5  5  5]]\nInput length: 15, Label lengths: [5, 7, 7]\nToken distribution (Batch 31): {63: 1, 24: 1, 27: 2, 11: 1, 32: 1, 13: 1, 5: 1, 14: 1, 12: 1}\nBatch 10, Gradient norm: 14.9299\nEpoch 13, Batch 10/91, Loss: 27.8948\nAvg Blank Probability: 0.0161\nSample predictions: ['XvnkjF', 'jakAoaFkdgBH', 'QlfwaPfj3IjavQ']\nGround Truth (first 3): ['Zax', 'GblpNE', 'AO5O8Xz']\nRaw outputs (first 3): [[50 10 43 34 27 16 34 22 34  1  1  1 56 61 34 10 22  1 19 30  1  1 63 30\n  32 47  1 47 56  1 11 63]\n [22  1 12  1 42  5  1  1 48 43  1 18  1  1 35  5 19 42 43 24  1  5 47 19\n  24 35 34  4 30  0 11 24]\n [14 11  6 24 34  1 32 10 47  1  1  1 42 57 19 63  1 13  1 42 19 27  1  1\n  20 10 50 19 32  1 35 27]]\nInput length: 15, Label lengths: [3, 6, 7]\nToken distribution (Batch 31): {34: 1, 1: 2, 10: 2, 11: 1, 27: 1, 43: 1}\nBatch 20, Gradient norm: 56.3935\nEpoch 13, Batch 20/91, Loss: 31.4427\nAvg Blank Probability: 0.0161\nSample predictions: ['a', '4Dj', 'UFaz']\nGround Truth (first 3): ['c', 'DZ', 'yE']\nRaw outputs (first 3): [[ 1 57 47  1 43 19 11  1 47  1 11  1  1 32 47 42 50 11 63  4 10  4 63  1\n  34 34 19 10 34 22  1 34]\n [ 1 30 32 56  1 56 35 47 34  6 35 43 56 10 10  1 47 34 35 35 10 10  6  0\n  34  1 56 10 29 10 61  1]\n [10 10  1 18  4 32 63 42 25 12 11 11 19 19  1 24  6 60 63 22 32 10  1 47\n  47 34  6  1  1 11 10  1]]\nInput length: 15, Label lengths: [1, 2, 2]\nToken distribution (Batch 31): {25: 1, 4: 1, 6: 1, 5: 1, 1: 1, 47: 1, 21: 1, 42: 1}\nBatch 30, Gradient norm: 251.8621\nEpoch 13, Batch 30/91, Loss: 27.2728\nAvg Blank Probability: 0.0165\nSample predictions: ['fHajF3-A', 'jfUHI2gamH', 'fU8j-a']\nGround Truth (first 3): ['Gpz4l', 'gHBHK', 'wL7']\nRaw outputs (first 3): [[ 6 10  6 34 11 34 32  5  6  1  1 32  1 35 43  1  4 46 47  1  1  4  1  4\n   1  4 34 63 34 28 47 25]\n [34  6 47 22 11 12 32  4 63  1  1 30 10 32  4  1 34 10 10  4 19  0 43 35\n  32 24 48 19  1 22 63  4]\n [34 47 61 16 11  1  5  1 55 34  4 35  1 19 19 57 24 10 10 48  1  1 33  1\n  18 24  1 48  1  1 42  6]]\nInput length: 15, Label lengths: [5, 5, 3]\nToken distribution (Batch 31): {32: 1, 11: 1, 10: 2, 1: 4, 6: 1, 7: 1, 24: 1, 34: 1}\nBatch 40, Gradient norm: 17.4292\nEpoch 13, Batch 40/91, Loss: 28.8166\nAvg Blank Probability: 0.0163\nSample predictions: ['XsEkCaFdV', 'XH', '3FDvUl']\nGround Truth (first 3): ['xM7tm', '-', '7BJ']\nRaw outputs (first 3): [[50 50 56 16 19 47 22 12 10  1 34 19 32 17 30 34  1 20 19 19 27 11 32 50\n   1 42 12  1 25  6 47 32]\n [19 34 32 10 63  4 22  6  4  1 12 34 19 34  7 12  4  4 47 19  4 11 16 23\n  32 22 19 10 35 27 32 11]\n [31  6 30 32 34  1  1  1  6 35  1 19 23  1 47 19 48  4  0  6  6 38 10 34\n   1  5 48 17 51 35  1 10]]\nInput length: 15, Label lengths: [5, 1, 3]\nToken distribution (Batch 31): {20: 1, 10: 2, 27: 1, 1: 1, 56: 1, 43: 1, 32: 1, 24: 1, 12: 1}\nBatch 50, Gradient norm: 17.9163\nEpoch 13, Batch 50/91, Loss: 29.8738\nAvg Blank Probability: 0.0164\nSample predictions: ['ajH3Qa3ek', 'at', 'jlVdVD']\nGround Truth (first 3): ['3cT-U7', 'R', '2XR']\nRaw outputs (first 3): [[ 1  1 10  1 11 19  1 46  1 56 35 11  1 11 10  4 33 19 19 22  1  1  1 22\n  24 32 10 11 10  1  6 20]\n [ 1 20 12  6 47  4 43 42  1 42 63  1 19  1  1 27 19 33 24  1 22 12  1 36\n   6  1 12 19 11  1 20 10]\n [10 56 48 42  6  6  5  1 10 32 19 51 35 16 27 11  6  1  4 47  5 63  1  1\n   0  1  6 43  1 32  7 27]]\nInput length: 15, Label lengths: [6, 1, 3]\nToken distribution (Batch 31): {10: 1, 11: 2, 1: 2, 27: 1}\nBatch 60, Gradient norm: 15.5729\nEpoch 13, Batch 60/91, Loss: 27.1283\nAvg Blank Probability: 0.0165\nSample predictions: ['maeHavaVCag3es', 'dHvkedCax', 'aUePQA']\nGround Truth (first 3): ['vYIU0WD', 'v8Nha', 'G4R']\nRaw outputs (first 3): [[13  4  1 47  1 10 34  6 22 27 33  1 56  1 47  1 63  4  4  1 50 42  6 56\n  32 35  1 56 11  9  6 10]\n [ 1 34 47  5 63 19  0 47  1 47 47  1 10  1 30 12  1 11  1 11 47  4 10 19\n  11 10 16  6 56 25 11 11]\n [ 5 22  5  1  1 57  7 34  1  1 34  6  5 10 35 11 22  1 42 16  1  5  1 35\n   1  1  1 47  5  1  1 11]]\nInput length: 15, Label lengths: [7, 5, 3]\nToken distribution (Batch 31): {19: 2, 32: 4, 22: 1, 9: 1, 5: 1, 35: 1, 53: 1, 1: 2, 10: 1}\nBatch 70, Gradient norm: 35.2724\nEpoch 13, Batch 70/91, Loss: 29.1531\nAvg Blank Probability: 0.0166\nSample predictions: ['3PfFasa2Q', 'ejkefxkBa', 'afaskvOyasIfak']\nGround Truth (first 3): ['RdZ1x', 'WOr3O', 'BVzm05v']\nRaw outputs (first 3): [[56  5  1  1  1 47 35 63 10 13 20  6 56 10  1 35 63  1  5  1 43 22 24  1\n  63  4 47 56  1  1 10 19]\n [42 10  6 10 22 35 50 32 10 32  1 11  6  1 55 10 19  1 25 30 11 27 47 34\n  25 19  4 32 22 22 43 32]\n [ 6 11  1 19 20 24  1 34  0 47 27 34  1 47  1 12 10 27 10  6  1  1 11 32\n   9 16 25 34  4  0 35 32]]\nInput length: 15, Label lengths: [5, 5, 7]\nToken distribution (Batch 31): {35: 1, 24: 1}\nBatch 80, Gradient norm: 24.0720\nEpoch 13, Batch 80/91, Loss: 28.1196\nAvg Blank Probability: 0.0166\nSample predictions: ['aUga', 'jHpI3xaGaklav', 'UaejFjt']\nGround Truth (first 3): ['oe', 'eKSRDzi', 'bxDZ']\nRaw outputs (first 3): [[ 1 10 47  1 10 10 57 56  1 63 24 19  1 12  4 11 24 42 47 10 56 10  1 63\n   0 19  1  1 47 47 34 35]\n [47 34  1  1 34 10 56 30 11 10  1 43  1 63 11 35 10 35 32  1 63 47  1 18\n  20 12  1  1 10 43 11 24]\n [ 7 16  5 11 22 19 22 28 11 47 27  1 26 12  5 25 47 57  0  1  5  4  1  0\n  35 11  7  1 10 42 32  1]]\nInput length: 15, Label lengths: [2, 7, 4]\nToken distribution (Batch 15): {22: 1, 35: 1}\nBatch 90, Gradient norm: 19.3383\nEpoch 13, Batch 90/91, Loss: 31.4708\nAvg Blank Probability: 0.0166\nSample predictions: ['kHPaFSjG', 'Hfva2ayUQlaUse', 'FaBfsU']\nGround Truth (first 3): ['FqXD', 't5ttxVy', 'LkN']\nRaw outputs (first 3): [[11 34 32  4 12 47 35  1  1 63  1  1 32 56 25 22]\n [34  6  1  1 19 23 42 34 16 63  4 32 42 47 35 35]\n [42 22 28 22  1 10 32 32  5 10 27 63  1  6 19  1]]\nInput length: 15, Label lengths: [4, 7, 3]\nEpoch 13/20, Loss: 28.2814\nToken distribution (Batch 19): {1: 15}\nValidation Loss: 27.9748\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['oiUh', 'PfCU3-m', 'n', 'o*N', 'C']\nCurrent Learning Rate: 5.08591449765592e-07\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {63: 1, 26: 1, 55: 1, 34: 2, 1: 3, 42: 1, 48: 1, 50: 1, 10: 2, 35: 1}\nBatch 0, Gradient norm: 17.8801\nEpoch 14, Batch 0/91, Loss: 29.4068\nAvg Blank Probability: 0.0168\nSample predictions: ['vj', 'yUdaU23adajaj', 'afajaBIUtFaedf']\nGround Truth (first 3): ['e', 'E6RxizT', 'QjW7gxl']\nRaw outputs (first 3): [[22 25  1 19 32 42 24 32  1 48 34 24 56 47 11  1  1  1  4  1 20  0  1 56\n  35 22  1 11 34 56 12 63]\n [10 47  6 11 11  5 27 34  1 10  1 25 24  1 11  1  1 22 34 60 32 56 32  1\n  46 11 11 56 25  1 25 26]\n [56  4  1  1 22  1 47 61 12 34 32 32 27  1  1  1  1 20  1 22  6 47 56  6\n  12 22 36  1 56 38 56 55]]\nInput length: 15, Label lengths: [1, 7, 7]\nToken distribution (Batch 31): {4: 1, 22: 1, 27: 1, 19: 1, 57: 1, 6: 1, 36: 1, 1: 2, 42: 1}\nBatch 10, Gradient norm: 497.6886\nEpoch 14, Batch 10/91, Loss: 23.1944\nAvg Blank Probability: 0.0170\nSample predictions: ['afFajAj', 'hDdH', 'laPaQa']\nGround Truth (first 3): ['7N7d', '0D', 'ixDqn']\nRaw outputs (first 3): [[ 1  8 12  1 35 56 32  1 19 25 61 11  1 30 10  4  1 46 63 34 22 35  6 22\n   0 11 11 11 32  4  4  4]\n [ 6 30  1 32  5  5  1 10 21 11 63 28 32 10 34  5  1  1  1  1  1 12 33  1\n  12 34 20 20 57 61 48 22]\n [32  4  1 43  5 34 63 10 35 56 22 10 57 34 10 30 11 42  4  1  1 34 32  5\n   1 47 42 35  1 12 56 27]]\nInput length: 15, Label lengths: [4, 2, 5]\nToken distribution (Batch 31): {6: 1, 56: 1}\nBatch 20, Gradient norm: 20.2361\nEpoch 14, Batch 20/91, Loss: 28.5535\nAvg Blank Probability: 0.0172\nSample predictions: ['mtHjaJIfFv', 'aIjFjQ', 'VjftgHaHUl']\nGround Truth (first 3): ['tKd4F', 'tkL', 'V*czz']\nRaw outputs (first 3): [[13  1 48 43  4 25 12 10 47 34 43  1 34  1 10 12 10 63  1 28  4 13 56 11\n  10 11 32  1 11 10 50  6]\n [20 35 10 20  1 16 11  1 19  1 34  0 32 32 56 10  6  4 11 35 43 10 19 22\n  11  1 47  1 47 34 55 56]\n [34 10  6  1 16  5 47 56 35 19 19 10 19  1  1 19 42 11 11 35 42 18  1 19\n   1  1 11 29 12 56 50 35]]\nInput length: 15, Label lengths: [5, 3, 5]\nToken distribution (Batch 31): {1: 2, 12: 1, 42: 1, 11: 1, 24: 1}\nBatch 30, Gradient norm: 15.7552\nEpoch 14, Batch 30/91, Loss: 26.3233\nAvg Blank Probability: 0.0176\nSample predictions: ['FfaIdUajfaP', 'kaUv', 'FVvaRVjVHvaj-k']\nGround Truth (first 3): ['XaGhKvP', 'VQ', 'PVS8nuq']\nRaw outputs (first 3): [[32 11 32  4 43 22 42  1 14  1  4  4  1 11 22 43 43 10  7  1 22  1  4 11\n   1  1 22 34  9  0  1  1]\n [ 6  1 48  1 25  0 20  1 34 34  1 10 42  1  4  4 10  1 10 27 55 32 24 42\n  11  1 11 34  1 32 12 12]\n [ 1 47 22  1  1  1 55 32  6 10 35  0 32 55 56 12 43 35 10 30  1 12  1  1\n  19 43 21 24 32 48  6 42]]\nInput length: 15, Label lengths: [7, 2, 7]\nToken distribution (Batch 31): {24: 2, 11: 1, 47: 1, 34: 1, 1: 2, 35: 1, 30: 1, 10: 1}\nBatch 40, Gradient norm: 10.2971\nEpoch 14, Batch 40/91, Loss: 22.4541\nAvg Blank Probability: 0.0171\nSample predictions: ['aFHaUPHiskA', 'Gwfk3s', 'Hj2eldsa']\nGround Truth (first 3): ['DQsMZ9', 'TAi', 'Q8dF']\nRaw outputs (first 3): [[ 1 33 34 42 32 11  6  4  1  4 10 34  1  1  1 22  6 48 22 22 32 10 12 34\n  30 27 11  1  1  1  1 24]\n [32 23 10 36 34 33  1 25 10 47 34 22  5 55 32  1 24 10 34 25  1 56 35 35\n   1 32  5 23 19  1  1 11]\n [34  6 55 47  1 57 34  1 11  0 32  1 22 61  1 34  1 34 34 48 24 42 19  1\n   1  6  1 11  1 32  6 47]]\nInput length: 15, Label lengths: [6, 3, 4]\nToken distribution (Batch 31): {1: 1, 12: 1, 42: 1, 4: 1, 16: 1, 63: 1, 11: 1, 34: 2, 10: 1, 47: 3, 22: 1}\nBatch 50, Gradient norm: 13.7151\nEpoch 14, Batch 50/91, Loss: 22.0615\nAvg Blank Probability: 0.0176\nSample predictions: ['-a3alksF', 'jxfFg3A2Ua', 'njaHUyagfe']\nGround Truth (first 3): ['*tIE', 'bVwNB', '19VXY']\nRaw outputs (first 3): [[63 10 14 43 47 32  1  1 10  1  1 32 12 11  1  1 19 50  1 34 34  1  5 50\n  27 32 32  1  6 63 34  1]\n [ 1 24 10 47 54 42 34 12 32 47 42 63 12 12 24 63  4  1  1 48 63  1 14 43\n  10  1  1 48 19 11  1 12]\n [56  6  1 19  6  1  6 13  1 10  0  9  6 44 34 12 48 16 43  1  1  1 10  1\n  19  6 63 25 47 48 56 42]]\nInput length: 15, Label lengths: [4, 5, 5]\nToken distribution (Batch 31): {1: 4, 32: 1, 5: 1, 40: 1, 10: 2, 33: 1, 34: 1, 9: 1}\nBatch 60, Gradient norm: 34.9353\nEpoch 14, Batch 60/91, Loss: 31.3943\nAvg Blank Probability: 0.0177\nSample predictions: ['a', 'HDAv', 'ak']\nGround Truth (first 3): ['u', '37', '6']\nRaw outputs (first 3): [[ 1 34  1  1 34  1 63  5 22  1 24 57 42 11 10  1  6  6  1  4  4 22  6 56\n  22  1 35 35 63 42  1  1]\n [ 1 30 11  1 19 32 12  0  4  1 13 55  1 27 32  1 43  1  1 36  1  1 10  1\n  10  1 10  6 27 27 34 32]\n [47 27  1 55 42  5 50  1  1 12  5 56  1  1 10 11 47 25  4 19 43 22 32 19\n   5 57  1 47 32 32 22  5]]\nInput length: 15, Label lengths: [1, 2, 1]\nToken distribution (Batch 31): {35: 1, 32: 2, 1: 1, 22: 1, 10: 2, 5: 1, 55: 1, 56: 1, 48: 1, 4: 1}\nBatch 70, Gradient norm: 167.7957\nEpoch 14, Batch 70/91, Loss: 29.4561\nAvg Blank Probability: 0.0177\nSample predictions: ['j3', 'fhamya', '2H']\nGround Truth (first 3): ['h', 'UVE', 'j']\nRaw outputs (first 3): [[10  6 55 63 13 32  1  6 10 24  0  1 35 63 15 11 47  6 48 10 24  1 12 56\n  11 32  1  1 32 19  1 35]\n [56  8 34  5 10 11  5  0 12 12 56  1 47  0 56 27 22  1 55 10  7 27 10 25\n  19 47 51 12 20  4 10 32]\n [ 1  1 19 22 25 12  5 32 63 47  4 10 43 43  1 10  1 47 47 32  0  1 30 27\n  24  1 10 35 16  6  1  1]]\nInput length: 15, Label lengths: [1, 3, 1]\nToken distribution (Batch 31): {1: 3, 56: 1, 32: 1, 11: 1, 34: 1, 7: 1}\nBatch 80, Gradient norm: 27.2944\nEpoch 14, Batch 80/91, Loss: 30.3023\nAvg Blank Probability: 0.0179\nSample predictions: ['3jv-Hfav3e', 'lUia2HAraFa', 'UaU']\nGround Truth (first 3): ['6JT6A', '*ukzOg', 'ks']\nRaw outputs (first 3): [[56 12 47 34 47  1  1  0 42  1 42 47  1 19 25 32  6 56 61  0 19  1  1  1\n  13 34 50 30 22 48  6  1]\n [10 47  1 10 30  1 48 47 63  1  1  4  1 61 42 12  1 42 56  4  1  1 47 42\n  42 43  0 42 27 10  6  1]\n [22  9  1  1 33  1  4 10  6 24 11 32 32 20  3  4  1  1 35 43 10 11 11 32\n  21  4 47 50  1 10  4 56]]\nInput length: 15, Label lengths: [5, 6, 2]\nToken distribution (Batch 15): {23: 1, 1: 3, 35: 1, 4: 1}\nBatch 90, Gradient norm: 16.3542\nEpoch 14, Batch 90/91, Loss: 24.7165\nAvg Blank Probability: 0.0180\nSample predictions: ['FdyFU-sUDa', 'kjPjnv', 'jadfV']\nGround Truth (first 3): ['b3OhG', 'yn*', 'rOq']\nRaw outputs (first 3): [[32 11 10 47 42 32 34 10 13 48 33 22 30 11 10 23]\n [ 4 10 10 19 34 25 10  1 34 47  4 50  7  6 10  1]\n [25 42  1  4  4 48 47 47 10 32 34  1  0  4  1 35]]\nInput length: 15, Label lengths: [5, 3, 3]\nEpoch 14/20, Loss: 28.0501\nToken distribution (Batch 19): {1: 15}\nValidation Loss: 27.9410\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['exRVivK', '1', 'zLD', 'ALMJ', '32']\nCurrent Learning Rate: 6.290067270632257e-07\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {42: 1, 12: 1, 1: 4, 6: 2, 4: 1, 25: 1}\nBatch 0, Gradient norm: 103.3147\nEpoch 15, Batch 0/91, Loss: 27.8825\nAvg Blank Probability: 0.0181\nSample predictions: ['3vjH', 'dlaHXv8VaAFd', 'a3J']\nGround Truth (first 3): ['Ub', '7VLzPb', '-k']\nRaw outputs (first 3): [[56  4  1 47 35 47 47 19  1 24 42 63 35 56 12 12  1  1  1 34 10 63 47 11\n   4 56  1 33 34  1  1 42]\n [22 12  1 12 32 24 29  1 22 47  0 35 42 48 47 12  0  1 27  4 35  1 30 42\n  10 24  1 22 36 34 10 12]\n [10  1 56 25 16 12  1 11 22 25  1  1 33  1 56 32 11 43  0  1 61 25  5  1\n  35  1  6 34  0  1 47  1]]\nInput length: 15, Label lengths: [2, 6, 2]\nToken distribution (Batch 31): {22: 2, 43: 1, 34: 1, 1: 2, 19: 1, 48: 1}\nBatch 10, Gradient norm: 19.5963\nEpoch 15, Batch 10/91, Loss: 26.8581\nAvg Blank Probability: 0.0183\nSample predictions: ['-vF4agxajU', 'la3ra', 'H4lI']\nGround Truth (first 3): ['HlfFN', '5hb', 'Hl']\nRaw outputs (first 3): [[63 12 34 30 22  0  1  1 63  1 47 50 63 32  1 10 11  5 13  6 35  1  9  1\n  18 47  4  4  1 50 56 22]\n [22  1 57 10 44  4  8  1 27  1 11  1  1  4 10 47 43 34 27 47 27  1 20 54\n  48 11 22 35  1  4  1 43]\n [32  1 12  1 10 14  0  1  1 56 32  1 22  1  6 11  4  1 10  0 10  6 22  0\n  48 50 35 42 56 35 47 34]]\nInput length: 15, Label lengths: [5, 3, 2]\nToken distribution (Batch 31): {47: 1, 22: 1, 12: 1, 1: 3, 19: 2, 40: 1, 10: 1, 5: 1, 35: 1, 27: 1, 6: 1}\nBatch 20, Gradient norm: 568.1194\nEpoch 15, Batch 20/91, Loss: 27.1006\nAvg Blank Probability: 0.0183\nSample predictions: ['aHzyjeyXaHQf', 'aldaFHls', '-a3axayH']\nGround Truth (first 3): ['7Ifh9Q', 'UuGt', 'W4WB']\nRaw outputs (first 3): [[ 1  1 63  1 32 19  5 34 50 32 42 57  0  1 10 63  1 19  1  1 11 42  1  1\n  32 10 42  1 11  1 43 47]\n [ 0 12  1 35 11  1  6 28 55  4 25  1 19  5 13 48  6 47  0 11 12 62 34  1\n  32 20  4  1 22 35 11  0]\n [26  4 56 42 22 24 43 10 47 22 27  1 63 40 34 13 24 12 34  0 10 11 63 10\n  10 12  1 50 11  0 20 12]]\nInput length: 15, Label lengths: [6, 4, 4]\nToken distribution (Batch 31): {22: 1, 30: 1}\nBatch 30, Gradient norm: 24.7843\nEpoch 15, Batch 30/91, Loss: 31.1961\nAvg Blank Probability: 0.0185\nSample predictions: ['aUda2Ha', 'a3jXdkd', 'a']\nGround Truth (first 3): ['TA9pm', 'EItm', 'C']\nRaw outputs (first 3): [[ 1  1  1 22 19 11 27  1  1 10 47  4 27 11 32 34  0 42 10 12  4 48 11 10\n  35  1 11 24 32 22  4 22]\n [ 1 56  1 56  1 10 34 22  1 47 30 48  4 35 47 12 24  6 34 47  1 34 43 11\n  11 34 32  4 57  4  1 30]\n [47 10  1 11  1 56 56  0 10  1 27  1 32  6  6 12 22 47 25 12  1  1  1  1\n  22  1  1  0 47 34 10 30]]\nInput length: 15, Label lengths: [5, 4, 1]\nToken distribution (Batch 31): {5: 1, 10: 1, 27: 2}\nBatch 40, Gradient norm: 660.5499\nEpoch 15, Batch 40/91, Loss: 28.3359\nAvg Blank Probability: 0.0186\nSample predictions: ['aHpHadaHFaej', 'F3FaUH', 'fdSkU']\nGround Truth (first 3): ['ViIigG', '9k0', 'PCa']\nRaw outputs (first 3): [[ 1 32  6  1 34  0 43  1 30 12 16  4  1  4 63  6  1 43 32 61 16 50 63  1\n  10 34 30 63 22  1  1  5]\n [34 56  4  1  1  0 19 63 63 56  1 22  4 34  0 34  6 55 30  1 50 50  1  0\n   0 11  5 61 22 11  1 10]\n [16 32 45 12 28 34 10 21 32 33 10  1 42 12 19 27  1  1 19 35  1 11  1 56\n   5  4 12  0 10  1 50 27]]\nInput length: 15, Label lengths: [6, 3, 3]\nToken distribution (Batch 31): {1: 2, 47: 1, 4: 1, 32: 1, 42: 2, 22: 1, 10: 2}\nBatch 50, Gradient norm: 20.9971\nEpoch 15, Batch 50/91, Loss: 30.1067\nAvg Blank Probability: 0.0189\nSample predictions: ['pj', '3k', 'dAUjakgvAUeF']\nGround Truth (first 3): ['v', 'u', 'cCNy0u1']\nRaw outputs (first 3): [[16 56  4 48 63  1 10 42 35 48 24  1  4 12  1 24  0  4 11  1  6 13 47 63\n  25  4 22  1  4 63  1  1]\n [10 11 27 34 32 34 22  1 34  1 22  1 56 34 22  4 30  4  1 29  9  1 11  1\n  14  4 48  6  1 10 12 47]\n [47 48 47  6 10 35 12  4 32 27 27 27 32  1 42 47  1 24 27 56  0  0  1 56\n   0 48  0  5 57  1 34  4]]\nInput length: 15, Label lengths: [1, 1, 7]\nToken distribution (Batch 31): {12: 1, 33: 1, 57: 1, 10: 2, 1: 2, 35: 1, 56: 3, 6: 1, 32: 1, 27: 1}\nBatch 60, Gradient norm: 20.9213\nEpoch 15, Batch 60/91, Loss: 29.1975\nAvg Blank Probability: 0.0191\nSample predictions: ['afUHyaHC', 'CUjF-f', 'pXFgHaFgAHl3fA']\nGround Truth (first 3): ['n3jVe', 'Sbl', 'HEu9kyT']\nRaw outputs (first 3): [[ 1 29  0  5  1  1 56 56 12 56 63 42 13  1 56  4 47 25  0 32  1  1  1  1\n  42  1 19  1  1 19 56 12]\n [ 6 47 50 32  6 11 10 19  4 47 10 11 63 20  1 10  1  0  1  1 56 47 34 22\n  19 35 34 34  1 32  0 33]\n [ 0 10 32  1  6 34 12 47 32  1 46  0 12 24 59 34 57 34 12 35  0 50 47 36\n  63  1 47 22 24 27 24 57]]\nInput length: 15, Label lengths: [5, 3, 7]\nToken distribution (Batch 31): {4: 1, 12: 1, 56: 1, 22: 1}\nBatch 70, Gradient norm: 18.9857\nEpoch 15, Batch 70/91, Loss: 28.1419\nAvg Blank Probability: 0.0196\nSample predictions: ['ve-dHafI', 'valvk3dP', 'jwAY3']\nGround Truth (first 3): ['uwYu', 'ZEvd7', 'N94']\nRaw outputs (first 3): [[22 22 10 63  1 56 10  6  1  6  1  1 10  4 32 10 10  1 34 19 12 19 11  1\n  24  5 48 34 19 63 11  4]\n [ 5  1 10 32 47 12 22 25 48  1 22 47 43  0 48 42  1 47  1  1  4  1 30 11\n   1 56  1  1  5  0 50 12]\n [ 0  1 23 12  1 34  1 16 10 34 27  0 35  0 34 50 47 27 35  1 11  4 42 48\n   4 32 29  1  1  1 32 56]]\nInput length: 15, Label lengths: [4, 5, 3]\nToken distribution (Batch 31): {42: 1, 47: 3, 9: 1, 14: 1, 35: 1, 10: 1, 1: 1, 4: 1}\nBatch 80, Gradient norm: 429.6917\nEpoch 15, Batch 80/91, Loss: 31.3325\nAvg Blank Probability: 0.0199\nSample predictions: ['vFUa', 'fXavHQ', 'dAXF']\nGround Truth (first 3): ['Zg', 'Uw0', 'fA']\nRaw outputs (first 3): [[22  6  4 15 47 63  1 12 34  0 47 19 61 63 32 10  1 10 19 11 19 63  0 11\n  12 10 34 34 43 10 63 42]\n [32 50 27  0  1  1  0  0  1 44  1 10  6 27 47 10  1  6 27 34  1 35 35 35\n   1 27 42 63  1 47 11 47]\n [47  1  0 32  1  0  7  1 12  1 19  1 32  0 34 11  1  0 47  1  1  0 56 48\n  10  0 20 11 10  1  5 47]]\nInput length: 15, Label lengths: [2, 3, 2]\nToken distribution (Batch 15): {35: 1, 10: 1}\nBatch 90, Gradient norm: 20.4975\nEpoch 15, Batch 90/91, Loss: 28.5774\nAvg Blank Probability: 0.0198\nSample predictions: ['FaIVF', 'vHUFadHdQd', 'af4lHF']\nGround Truth (first 3): ['6Ki', 'uVaQJ', 'cqS']\nRaw outputs (first 3): [[32 22  1 11  0 10 10  0 12 19 35  1  0 63 32 35]\n [ 1 34  6 35 22 32 50  5 50 14 10 63  1  1 11 10]\n [35 47 57 34 48  0 19  1 32  1 28 32 34 11 35 10]]\nInput length: 15, Label lengths: [3, 5, 3]\nEpoch 15/20, Loss: 27.4488\nToken distribution (Batch 19): {1: 15}\nValidation Loss: 29.4204\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['G', 'Wa131', 'q', 'SdH', 'mSQ']\nCurrent Learning Rate: 7.363961030678927e-07\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {6: 1, 1: 3, 32: 1, 47: 1, 19: 1, 7: 1}\nBatch 0, Gradient norm: 17.5891\nEpoch 16, Batch 0/128, Loss: 24.8879\nAvg Blank Probability: 0.0198\nSample predictions: ['ak', 'dFdaHlfFjks', 'H2a']\nGround Truth (first 3): ['v', 'xpYZA5', 'Ub']\nRaw outputs (first 3): [[ 1  4 34 50 32 16 35 47  4 10  5 11  1  0 12  0 27 57  1 35 63 47 34 10\n  16 47  0 27 12  1  1  6]\n [11  4  0  6 10  1  1  0 63 42  1  1  7 47  1 34 11 63 63  0  1 20 48 10\n   6 12  6  0  0 35 24  1]\n [10 32  0  0 32  0  6 34 11  4  1 22 47 11 48 23  0 56  5  0  7 35 32 63\n  47  0 19 34  1 55 11 32]]\nInput length: 15, Label lengths: [1, 6, 2]\nToken distribution (Batch 31): {12: 1, 42: 1, 46: 1, 10: 2, 22: 1, 1: 1, 9: 1, 50: 1, 23: 1}\nBatch 10, Gradient norm: 9.7638\nEpoch 16, Batch 10/128, Loss: 20.1734\nAvg Blank Probability: 0.0200\nSample predictions: ['kaPtseFAlkea', 'kLHUXas', 'jIFa']\nGround Truth (first 3): ['ubsoqa', 'blCQ', 'pX']\nRaw outputs (first 3): [[11 11 10  1  1 34  6 12 25  4 22 10 35  6 34 63 27 12 12  1  1  6 20  4\n   1 34  1 30  0  0 47 12]\n [ 1 38 35 56  1  0  5  5 10 10 34 22 11  1  1  0  6 12 32  1  1  1 19  4\n   1  1 25 13  6  1 20 42]\n [42 34 32 48  1 47 12 42 10 42 42 34 11 27 10 11  6  1 56  1 12 55 47 43\n  19  1 18 12  0  0  1  0]]\nInput length: 15, Label lengths: [6, 4, 2]\nToken distribution (Batch 31): {16: 1, 4: 2, 47: 1, 10: 1, 27: 1}\nBatch 20, Gradient norm: 37.0747\nEpoch 16, Batch 20/128, Loss: 21.4044\nAvg Blank Probability: 0.0207\nSample predictions: ['fDnPaU', 'j2jeAajf', 'ta-IaHjAf']\nGround Truth (first 3): ['2JJ', 'ZGrO', 'xFfxJd']\nRaw outputs (first 3): [[ 6 10 20 10 25  6 11  1  1  4 42  1 11  6  0  1  1 11 32 35  0 56 48 48\n  10  0  0 11  1 10 47 16]\n [30 55  1 35 11 32  1 12 47  4 32  0  1 10 35 29 50  0  1 47  4 12 12  1\n  42 22  0 47  0 10  5  4]\n [14 10  1  1 27  1 10  7 51  1  1 27  0  0 47 34  1 23 10 22 29  1  0  0\n  47 19 25  0  5  1  0 47]]\nInput length: 15, Label lengths: [3, 4, 6]\nToken distribution (Batch 31): {34: 2, 35: 1, 1: 2, 16: 1, 22: 2, 63: 1, 10: 1}\nBatch 30, Gradient norm: 15.0143\nEpoch 16, Batch 30/128, Loss: 23.8056\nAvg Blank Probability: 0.0204\nSample predictions: ['jVaAdaAXiPae', 'vI-d', 'k-FUXkXakFa']\nGround Truth (first 3): ['xXf5uZ', 'lw', 'I0kNxv']\nRaw outputs (first 3): [[10 22 11  4 11  1  1 42  1 19  1 27  1 42  6 11 42  1 11 22  0 11 10  1\n  34 34 47 47  4  4 12 34]\n [ 0  0 63  5 25  5 34  0 19 43 47 12  1  1 10  1 47  1 47  1  6  0 47  4\n   6 12  1  6  5 10  1 35]\n [ 1 63 32 10 45  5  4  0  6  1  1  1 35  0 33  1 22 43 34 32  1 34  1  1\n   1 47 50 42 56 50 12  1]]\nInput length: 15, Label lengths: [6, 2, 6]\nToken distribution (Batch 31): {1: 3, 32: 2, 34: 3, 11: 2, 61: 1, 56: 1, 10: 1, 7: 1, 6: 1}\nBatch 40, Gradient norm: 22.4410\nEpoch 16, Batch 40/128, Loss: 21.5084\nAvg Blank Probability: 0.0206\nSample predictions: ['UjFaUHQHla2ka', 'kalsvjasjaeF', 'xHlAHFe6']\nGround Truth (first 3): ['Y1amuTnSp', 'w2kXVHIec', 'BahV']\nRaw outputs (first 3): [[47 11 24 12 20 30 12  1 10 10 56 48 12 11  4  6  1 30 34  1 61  0 50  1\n  12  1 12 12  4  0 25  1]\n [10  1 34  0  1 10  0 35  1 10 43 32  0 48 38 11 57 34  4 24 32  1 35 43\n  42  1  1 34 32 55 10  1]\n [32 12 12  1 10 63 55 63  5 19  5  0 19 19  1  0  0  0 55  1 56 22  1 10\n   1 47 21 25 47  0  1 32]]\nInput length: 15, Label lengths: [9, 9, 4]\nToken distribution (Batch 31): {22: 1, 35: 1}\nBatch 50, Gradient norm: 572.9627\nEpoch 16, Batch 50/128, Loss: 24.7069\nAvg Blank Probability: 0.0211\nSample predictions: ['PjszAaQFaPJad-e', 'aL', 'ay2FaFAyeU']\nGround Truth (first 3): ['V90V682C', 'L', 'QUXKSN']\nRaw outputs (first 3): [[42  1  1 27 11 56 10  1 19 12 12  1  1  1  1  4 19 43  1 24 35  1 22  4\n  11 32 11  0 34  0  0 22]\n [ 0 38  0 50 25 48  4  1  1  6 20  1  1 22  0 25  5 10 30  1 36 36 32 11\n   1  1 34 12 43 22 47 35]\n [19 11 25  1 56 32 24  0 34  0 34  0 27  1 34  1  0  1 10  0 50 32  1 29\n   0 47 22 43 19  0  1 11]]\nInput length: 15, Label lengths: [8, 1, 6]\nToken distribution (Batch 31): {11: 1, 1: 2, 57: 1, 34: 1, 22: 1, 47: 1, 50: 1, 56: 2, 30: 1, 10: 1, 5: 1, 32: 1}\nBatch 60, Gradient norm: 20.3663\nEpoch 16, Batch 60/128, Loss: 23.4314\nAvg Blank Probability: 0.0214\nSample predictions: ['d3IjajHaFa', 'dUjQatavxgQAaV', 'aFaVQaTHa3s']\nGround Truth (first 3): ['oPE*cz', 'RlxA*QNSli', 'fWbbc6']\nRaw outputs (first 3): [[ 4  4  1 47  1  0  6 19  4 32  1 32 10 42  4 50 32 42  0 56 12 35 27 10\n  33  6 10 56  1 19  0 11]\n [56 47 32  0 56 47  0 41  6 42 32  1 63 13 11 11  1 56 56 47  1  0 22  0\n  30  6  1  0 56 12 20  1]\n [35  0  1 47  1 10  0  0  0 63  7 12  4 32 16  5  0 10  7  6 47  0 23 35\n  10 10  1  4  0  1  0 57]]\nInput length: 15, Label lengths: [6, 10, 6]\nToken distribution (Batch 31): {24: 1, 56: 1, 47: 3, 13: 1, 10: 1, 1: 1, 19: 1, 43: 1, 50: 1, 34: 1}\nBatch 70, Gradient norm: 16.0549\nEpoch 16, Batch 70/128, Loss: 23.6599\nAvg Blank Probability: 0.0220\nSample predictions: ['ajl', 'jValNXHfaFsaHe', 'adagaGUAFa']\nGround Truth (first 3): ['56', 'v*LHo0TY', 'lSPYJWf']\nRaw outputs (first 3): [[ 1 10  1  1  6  6  0  0 20 10 27 32 56 34 35 10  4  0 63  1 25  4 30 50\n  61  1  1 13 19 63  6 24]\n [10 48  1  1 47  1 11  0 10  0  7 10 63  0  6 34 34 47 22 48  6 10 10 47\n  47  1  1 35  4 27  4 56]\n [10  0  0 29 50 32  1 35  1  1 22 13  0  5  0 48 32  1  0  1 55  0  0  4\n   0 42  0  1  6 43  0 47]]\nInput length: 15, Label lengths: [2, 8, 7]\nToken distribution (Batch 31): {11: 1, 10: 3, 5: 1, 56: 1, 19: 1, 24: 1}\nBatch 80, Gradient norm: 15.6532\nEpoch 16, Batch 80/128, Loss: 23.0851\nAvg Blank Probability: 0.0221\nSample predictions: ['ja', 'kjk3U', 'jFaQtaPpAHepP']\nGround Truth (first 3): ['iA', 'Yp5', '5rxkXtyka']\nRaw outputs (first 3): [[10 11 10 11 19 10  6 34 42  0 42  1  1  4 35 12 10  1  4  1  1  5  0 14\n  11 56 16 56  0 48 10  0]\n [ 1  0  0 27 50 11  1  1 10 12  1 27  0 24  1 32  1  4 19 47  1 12 27 19\n  34 10  0 11 24 10  0 10]\n [ 1 10  1  0  1 63  0  2  0  1 47  4 43  1 19 32 47  0  1  4  0 12  1  1\n  12 34 32 34 29 24  1 10]]\nInput length: 15, Label lengths: [2, 3, 9]\nToken distribution (Batch 31): {47: 2, 1: 2, 32: 1, 4: 1, 34: 1, 24: 1, 5: 1, 12: 2, 10: 1}\nBatch 90, Gradient norm: 15.3563\nEpoch 16, Batch 90/128, Loss: 22.8316\nAvg Blank Probability: 0.0223\nSample predictions: ['FsvFsf', '3sajaBj', 'asal']\nGround Truth (first 3): ['tkg', 'Ocf0', 'Qi']\nRaw outputs (first 3): [[32 56  1  1 34  0 47 11 47 11 12  0  1  6  1 20  0 34  0 11 47 12 14 34\n  48 22  1 50  0  0 47 47]\n [19  0 19  0  0  0 21  0  1 48 61 47 56  0 27 32 19 34 34  0 47  4 43 50\n  63  0  1  0 10  0 19  1]\n [22  1  1  1  0  0  0 12 45 11 35  1 22 12  1  1  1  0  0 11 12 22 34  0\n   0 50 35  0 29 35  1 32]]\nInput length: 15, Label lengths: [3, 4, 2]\nToken distribution (Batch 31): {22: 1, 27: 1, 1: 3, 10: 2, 12: 1}\nBatch 100, Gradient norm: 534.7772\nEpoch 16, Batch 100/128, Loss: 21.1582\nAvg Blank Probability: 0.0230\nSample predictions: ['jsdHAFdUa3jg3jF', 'deljek2H', 'a3dalFj-aj3xXa']\nGround Truth (first 3): ['EqtUXBUD', 'RMii', 'rQVG7a8bAn']\nRaw outputs (first 3): [[10  4  0  0  4 27 48 42 32 43 10  4 34  0 10  5 12  0 35  5 56 11 12 34\n   6  1 20  4 10  1 11 22]\n [19  5 56 11 11  0  5  0  1 34  5 32  0  0 47  0 63 47 12 32 11  0 63 19\n  34 11  1  0  1 42  0  0]\n [ 0 12  4 34 35 47 42  0 10 11  4  0  1  0 27  5  0  1  1  6 63 11 11  6\n   0  0  0  0 29  6  0  0]]\nInput length: 15, Label lengths: [8, 4, 10]\nToken distribution (Batch 31): {34: 1, 19: 1}\nBatch 110, Gradient norm: 44.3257\nEpoch 16, Batch 110/128, Loss: 26.8559\nAvg Blank Probability: 0.0229\nSample predictions: ['jUeaHakXd', 'l3xj', 'vafvkxeaHUF3Xj']\nGround Truth (first 3): ['eMBEWR', 'xd', 'YiJn5tka6z']\nRaw outputs (first 3): [[10 12 22  1 47  0  0 57  6 12  0 32  0 12  1  5 22 34 34 34  6 19 25 32\n   1  1  1 22 24 10  4  0]\n [47 56  1  0  0 32  0  0 35 27  0 13  1  1  4  5 47  0  1  0 50  0 56  0\n  34 21 47 32  0 22 19  0]\n [ 5 24  0  0  1  0  1  6  1  0 47 13  1  1  0 10  1  0  1  4 34  0 27 19\n   5 34 28  1 47 22 50 34]]\nInput length: 15, Label lengths: [6, 2, 10]\nToken distribution (Batch 31): {32: 2, 47: 1, 20: 1, 7: 1, 48: 1, 46: 1, 56: 1, 35: 1, 63: 1}\nBatch 120, Gradient norm: 40.2465\nEpoch 16, Batch 120/128, Loss: 25.2876\nAvg Blank Probability: 0.0234\nSample predictions: ['F-Hvtas3ua2vaPH', 'fa', 'jUsXUf6alAFf3y']\nGround Truth (first 3): ['UKi-iSUyo', 'Q', 'ooEkgjnB']\nRaw outputs (first 3): [[32  6 10  0  1  6  6 12 47 35 10  4 11  0 10 63 34  1  1  0  0 20 10 51\n   0 47 22 11  0 11 24 32]\n [63  1 47 27  1  0 47  1  4 28  0  0 35 42  1  0  1 22  0 24  1 34 19 47\n  35 28  0 22  0 10  0 47]\n [ 0 56  0 11  1  0  0  1  1  0  6  0  1 47 10  0 34  0  0 55  1 63 62 19\n  12 10  0  0 12  4  0  0]]\nInput length: 15, Label lengths: [9, 1, 8]\nEpoch 16/20, Loss: 23.4354\nToken distribution (Batch 31): {1: 15}\nValidation Loss: 23.7837\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['5N0ju', 'MDVk', 'PbuH2h-L38', 'rdC-', '0bL-p5o']\nCurrent Learning Rate: 8.281152949374526e-07\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {47: 2, 7: 2, 33: 1, 21: 1, 10: 3, 1: 1, 34: 2, 6: 1, 27: 1, 11: 1}\nBatch 0, Gradient norm: 48.5023\nEpoch 17, Batch 0/128, Loss: 23.9076\nAvg Blank Probability: 0.0238\nSample predictions: ['aAsQ', 'yaIderazVa', 'ad8AjaFVzkjs3']\nGround Truth (first 3): ['xc', 'RkYgh', 'b33h*xc-']\nRaw outputs (first 3): [[ 0 25  0 47 56 12 32 19  1 24  0 56 29  0 11  1 42  0 35 24  6  1  0 32\n   8 12  0 34 32 24  1 47]\n [ 0  0  4 12  5  0 12  0 25  0 47  0 12 19 13  0 10  0 33 50 47  1  0 22\n  10 43  0 47  0  1  1  0]\n [19 35  0  1 34 12 35  1  1 34  0  0  0 27 10  0 43  1  0  0  6 34  6  0\n   0 11  0  0 42 23 35  7]]\nInput length: 15, Label lengths: [2, 5, 8]\nToken distribution (Batch 31): {22: 1, 55: 1}\nBatch 10, Gradient norm: 20.7735\nEpoch 17, Batch 10/128, Loss: 24.3506\nAvg Blank Probability: 0.0242\nSample predictions: ['Ha', 'QadHUaIaixi', 'ajkFjcmaAHipIvd']\nGround Truth (first 3): ['S', 'NJlcyoqK', 'nkX7OoRR9E']\nRaw outputs (first 3): [[34 43  1 11 35 56 11 34  1  1  0 10  0 57  0  4  1  9 63  0  4 32 24 56\n   4 10 10 47  1 50  1 22]\n [ 1  1  0  0 47 24  1 13  1  4 43 32  0  0  4  0  6 10  0  0 19  1 22 19\n  27  0  1  0  1 25 32 55]\n [ 1  1 11  6  0 43  0  6  6  0 35 32  0  1 11  0  5 34  1 32  1  0  0  1\n   1  0 47  0  1  0 36  0]]\nInput length: 15, Label lengths: [1, 8, 10]\nToken distribution (Batch 31): {32: 2, 42: 1, 1: 3, 9: 1, 6: 1, 27: 2, 43: 1, 50: 1, 34: 1, 47: 1, 10: 1}\nBatch 20, Gradient norm: 11.9639\nEpoch 17, Batch 20/128, Loss: 20.2871\nAvg Blank Probability: 0.0243\nSample predictions: ['Hfvgc', 'xjvaFa3gvFaYHU', 'UnvdAUSvAk']\nGround Truth (first 3): ['-Bs', 'LJI8DCME', 'yuDw3']\nRaw outputs (first 3): [[34 24 47  1 34 63  6  1 11  0  1 56 34 63 20 27 36  6 47 34  1  0 20 34\n  32 11 20 47 25 10  0  0]\n [ 0 10  0 47 32  0 47 32 54  0  0  4 32  1  0  0 10 21 10 10 19  0  0  1\n   0  0  0  1  0 10  4 42]\n [22  0 22  0 27  0 12 35  0  9  1  0 32 10  1  0  0  0  1  0 34 18  0  0\n   1 42 56  1  0 24  0  1]]\nInput length: 15, Label lengths: [3, 8, 5]\nToken distribution (Batch 31): {19: 2, 47: 1, 56: 1, 14: 1, 55: 1}\nBatch 30, Gradient norm: 17.2704\nEpoch 17, Batch 30/128, Loss: 23.7351\nAvg Blank Probability: 0.0244\nSample predictions: ['HFUekuAvsI', 'ajaf', 'eFHlaI3HUF4fVUd']\nGround Truth (first 3): ['K7ebq', 'dP', '7FqjaQiPG']\nRaw outputs (first 3): [[34  1  0  0 11  1  1  4 10 47 10 42 63  6  0  6 34 63 35 16  1  0 11  1\n  16  4  0 56  0 47 11 19]\n [32  0 32  1 55 35  0  0  0 34 10  1 24  1  0 50 32  0  0 11  0 11  6 25\n   0  1  6  0  4 42 56  0]\n [ 0  1 34  0  0 42  1  0  0 32  0 32 50 34  0 32 11 10  0 11  1 34 47  0\n   0  0 47  1  0  5  1  0]]\nInput length: 15, Label lengths: [5, 2, 9]\nToken distribution (Batch 31): {34: 1, 10: 1, 1: 3, 56: 1, 47: 1, 21: 1, 25: 1, 16: 1}\nBatch 40, Gradient norm: 8.7648\nEpoch 17, Batch 40/128, Loss: 18.0518\nAvg Blank Probability: 0.0249\nSample predictions: ['HPfdBjdIl', 'jFaUAVsH', 'aviga']\nGround Truth (first 3): ['gZ9rU', 'jAh4', 'kXK']\nRaw outputs (first 3): [[ 0 10  0 35 10 47  0 34 10 11  0 12 12 50 19 10  0 11  1 10  1 12  0  1\n  12 57 63  0  1  1  6 34]\n [ 0 32 22 56 10 35  1  1 19  5  0 27 11  0 34  0 63  0  1  0  0 10  0  0\n   0 10  0  0 32  1  0 10]\n [ 6  1  9  0 12 34  1  0  0  0 32 27  0  0  0  0  1  0 47  1  0 47  0  0\n   0  5 32  0 20 33  0  1]]\nInput length: 15, Label lengths: [5, 4, 3]\nToken distribution (Batch 31): {10: 2, 1: 3, 34: 1, 12: 1, 47: 2, 5: 1, 22: 1, 32: 1, 6: 1, 56: 1, 11: 1}\nBatch 50, Gradient norm: 36.5824\nEpoch 17, Batch 50/128, Loss: 26.5399\nAvg Blank Probability: 0.0257\nSample predictions: ['fjd32aIFjaFeF', 'Hx', 'avHaIlFHa']\nGround Truth (first 3): ['HkIUAN8CPh', '6', 'WOr3O']\nRaw outputs (first 3): [[ 6 34  1  5  0 32  1  0  1 22 56  0  0 10 32 24 32  0  0  0  1 34  0  0\n   0  1 11 11  5 14  0 10]\n [ 0 24 22  6 10 10  0 56 36 25  1  1  0  1  0 12  0  0  0 20  0 35  4 13\n  50 10  0 11  0  1  0  0]\n [ 4 47 34  0  0  0  0  1  0 27 10  0  0 47  0 22  0  1  1  0  1  0 25  0\n  27  0 10  4  0  0 10 10]]\nInput length: 15, Label lengths: [10, 1, 5]\nToken distribution (Batch 31): {35: 1, 1: 1, 27: 2, 42: 1, 50: 1}\nBatch 60, Gradient norm: 25.6521\nEpoch 17, Batch 60/128, Loss: 27.6840\nAvg Blank Probability: 0.0258\nSample predictions: ['UQXUjtFyPfTaH', 'FkP-sk', 'ia']\nGround Truth (first 3): ['wCG6wX7fc', '76rX', 'w']\nRaw outputs (first 3): [[47 32  0 43 10 11  0  0  0  0 10 21  0  0  0 43  0  0  0 10 56  0 42  1\n   1 16  4  0 24  6 22  0]\n [43 32  0  6 32  0  0 35 61  1  4 36 12 12 19 22  0 55  0  1 19  0  6  1\n   1 63  1  0 34  0  0  0]\n [ 0 11  0  1  1 47 22 32  0 32  0 34 34  0  0 32  0  0  1  0 60  0 19 34\n   0  0 34  0  1  0 27  0]]\nInput length: 15, Label lengths: [9, 4, 1]\nToken distribution (Batch 31): {4: 2, 13: 1, 19: 1, 9: 1, 1: 1, 50: 2, 28: 1, 27: 1, 32: 1, 35: 1, 6: 1, 47: 1, 11: 1}\nBatch 70, Gradient norm: 14.3563\nEpoch 17, Batch 70/128, Loss: 20.4507\nAvg Blank Probability: 0.0265\nSample predictions: ['jpl3aj28LaFe', 'dQIkUliJ', 'adesdaejF']\nGround Truth (first 3): ['p1TWXUAoWG', 'VNbV', '*dgl1']\nRaw outputs (first 3): [[10  4  1 53 11  0 63  0  1  7 34  0 43 10  0  4  4 43  1  6  0 24 11 56\n   0 56 10  0 10  0  0  4]\n [ 0 43  0  4  1 56  0  4  0  1  0 50  0  6  0  0  0  0 43 32  0  0  1  0\n   0  0 19 42 13  0  0 13]\n [ 0  0  0  1  0 35 56  1 42 32  0 34  0  1  0 40  0 32  0 26  0  0 19  0\n  48  1 11 13  0  0  0  4]]\nInput length: 15, Label lengths: [10, 4, 5]\nToken distribution (Batch 31): {1: 4, 34: 4, 35: 1, 6: 1, 7: 1, 5: 1, 56: 1, 10: 1, 32: 1}\nBatch 80, Gradient norm: 16.4552\nEpoch 17, Batch 80/128, Loss: 21.6098\nAvg Blank Probability: 0.0270\nSample predictions: ['adeaHyVIzgAasas', 'UaIaBVdvaJaUdj4', 'v2Uav']\nGround Truth (first 3): ['9KxJ3uEnv4', '7ONq2*yVPG', 'LQY']\nRaw outputs (first 3): [[ 1 47 22  0 50  0 11  0  0  1 41  0  7 47 11  0  0  0 34 34 63  0  1 10\n  42 22  0  1  0 48 35  1]\n [ 0  0  0  0  0  9 19  0  0  0 32  0  0  0  1  0  0 11  0  0 32  1  0 20\n  11  1  0 32  0  0  0  0]\n [ 5  0  0  0  0  0  0  0  0  0  0  0  0  0 24  1 47  0  0  1 12  0  1 47\n   0 32 35  1  0 56  0  0]]\nInput length: 15, Label lengths: [10, 10, 3]\nToken distribution (Batch 31): {43: 1, 1: 2, 44: 1, 12: 2, 34: 1, 6: 1, 50: 1, 0: 1, 7: 1, 11: 1}\nBatch 90, Gradient norm: 19.1822\nEpoch 17, Batch 90/128, Loss: 23.1823\nAvg Blank Probability: 0.0269\nSample predictions: ['AGXF', 'XyeaAasa2aVaiQ', 'Ij']\nGround Truth (first 3): ['p9', 'Aofdh5RsDS', 'q']\nRaw outputs (first 3): [[ 0 50 35  0  1 19  0 34 24 47  6  0  0 27  0 47  1  1 11 56 34  1  0  4\n  51 48 19  0 50  0  0 43]\n [33 25 10 12  0  0  0  0  0  1  0  1  0  0  0  0 42  0 12 25 11 12  0  3\n   0 11 12  0 50 24 12  1]\n [50  0  6  0  1 25  0  0  1  0  4 42 12  1 57  0  1  0  0  0  0  4  0  0\n   0 55 38  0  0 59  0  0]]\nInput length: 15, Label lengths: [2, 10, 1]\nToken distribution (Batch 31): {6: 1, 20: 1, 1: 1, 56: 1}\nBatch 100, Gradient norm: 18.3571\nEpoch 17, Batch 100/128, Loss: 22.7325\nAvg Blank Probability: 0.0278\nSample predictions: ['vOUiAUPlzp32', 'lvDjFxFg', 'aAsafPFHaQ3f']\nGround Truth (first 3): ['NNv8U8', '60ko', '97Vu2R']\nRaw outputs (first 3): [[22 12  0 50  0 43 11 36  1  4 34 11 25 11  0 24 32  0 16  0  4 12  1 10\n   0  0 35  0 50  0 42  6]\n [ 0  0  0  0  0 32 25  0  0  1  4  1 30 10  0  0  1  0 20 34  0  0 23  0\n   4 19  0  0  0 16  0  0]\n [ 0 30  0 55  0  0  0  0 11 32  0  0  0  0  0  0  0  0  0  1  0 34  0  0\n  56  0  0 32  0  0  0  1]]\nInput length: 15, Label lengths: [6, 4, 6]\nToken distribution (Batch 31): {22: 1, 34: 1}\nBatch 110, Gradient norm: 14.1473\nEpoch 17, Batch 110/128, Loss: 20.8062\nAvg Blank Probability: 0.0290\nSample predictions: ['IaUFafFaHCaPHA', 'jFYgfljkL', 'ImglaaDQYFl3F']\nGround Truth (first 3): ['Z5bX87Rpgi', 'bVwNB', '607MvwXKzK']\nRaw outputs (first 3): [[35  0 35  0  0  0  8  0 23 47  0 56 63 11  1 12  0  7  0 19 34  0  0 56\n   6 32 30  0  0 12  0 22]\n [ 1  0 13  0 35  4  0  0  0  0  1 11  0 10  1  0  0  0 32  0  0  0  0  0\n   0 19  0  0  0 47 34 34]\n [ 0 51  0  0 33  0  1 11  0  0  0  0  0  0  0  5  0 32  0 34  0  0  0  0\n   0  0  0  1  0  0  0  0]]\nInput length: 15, Label lengths: [10, 5, 10]\nToken distribution (Batch 31): {12: 2, 25: 1, 27: 2, 1: 3, 35: 2, 32: 1, 0: 1, 4: 1, 19: 1}\nBatch 120, Gradient norm: 21.6034\nEpoch 17, Batch 120/128, Loss: 24.1600\nAvg Blank Probability: 0.0293\nSample predictions: ['av', '-fdX', 'kFfHaFskH2']\nGround Truth (first 3): ['Q', 'io', 'Y5jwp']\nRaw outputs (first 3): [[ 0 63  0  0  0 12  1 11  0  0  0  0 10  0 47  0  0 10  1  0  0  0  0  0\n   0 34  0 32 19  1 47  0]\n [22  6 32  0  0  0  0 11  0  0  0  0  1  0  0  0  0  0  1  0  6 27  0  0\n   0  0 47  0  0  0  0  0]\n [ 0  4  6  0 63  0  0 19  6  0  0  0  0  0  1  0  0  0 25  0  0 28  0  1\n   0  0  0  0 27  0 32  0]]\nInput length: 15, Label lengths: [1, 2, 5]\nEpoch 17/20, Loss: 22.9684\nToken distribution (Batch 31): {1: 15}\nValidation Loss: 23.4733\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['rn3tWG', 'Cg0k4r', 'Yp5', 'kPzmE48bf0', '8AIjG']\nCurrent Learning Rate: 9.01905871769531e-07\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {1: 2}\nBatch 0, Gradient norm: 21.8696\nEpoch 18, Batch 0/128, Loss: 22.2365\nAvg Blank Probability: 0.0296\nSample predictions: ['akajsI', 'adsajFaUesjAH', 'PUlGIaAFjIsaHQ']\nGround Truth (first 3): ['yzB', 'MFC1jnHEBt', '7FqjaQiPG']\nRaw outputs (first 3): [[ 1  1 42 11  0  0 35  0  0  1  0 13  0 12  0  0  0 63 34 11  1  0  0 50\n  47  0 47 22  0 10  0  0]\n [11  4  0  0  0  0  1  0  0  0 47  0  0  0 11  0  0  4  0 63  0  0  1  0\n  47  0 36  0 11 32  0  1]\n [ 0  0  0  0 35  0  1 34  0  0  1  0  0  0  0  0  0  0  0  0  0 34 32  0\n   0 50  0  0 11  0  0  0]]\nInput length: 15, Label lengths: [3, 10, 9]\nToken distribution (Batch 31): {5: 1, 1: 2, 10: 1, 19: 1, 22: 1, 48: 1, 34: 1, 14: 1, 50: 1}\nBatch 10, Gradient norm: 24.6817\nEpoch 18, Batch 10/128, Loss: 25.7496\nAvg Blank Probability: 0.0297\nSample predictions: ['FeI8V3sHksaeAs', 'majnlaAuIH', 'FDFAHzp']\nGround Truth (first 3): ['8SCvKN0S', 'JwDvNN', '4oAo']\nRaw outputs (first 3): [[ 0 13 32  1 10 22  0  0  0  0  0 12  0  0  0 12  0 34 25 10  0 50 19  0\n  27  0  1 32  0  0 25  5]\n [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 27  0  0  1  0 61  0  0\n  12  0  0  0  0  0 63  1]\n [ 0  0  0  0  0  1  4  4  1  0 11 27  0  0  1  0  0  0  0  0  0  0  0  0\n   0  0  1  0 27  0  0  0]]\nInput length: 15, Label lengths: [8, 6, 4]\nToken distribution (Batch 31): {1: 1, 34: 1, 35: 1, 50: 1, 4: 1, 0: 2, 32: 2, 11: 1}\nBatch 20, Gradient norm: 16.6792\nEpoch 18, Batch 20/128, Loss: 19.3606\nAvg Blank Probability: 0.0308\nSample predictions: ['kdUklav0ax', 'hlklas', 'k9Hdav']\nGround Truth (first 3): ['KtQhCC', 'k1Z', 'rf2o']\nRaw outputs (first 3): [[ 0  0 11  0 11  1  1  0  0  0 23 19  0  0 63 19 47  0 27  0  0 11 12  1\n  33  1 12  0  0  0  0  0]\n [ 0  0  0 10  0  0  0  0  0  6  0  5  0  0  0  0  0  0  0  0 27  0  0  0\n   0 32 11  0  0 11  0  0]\n [ 0  0  0  0  0  0  0 32  0 10 42  0  0 32  0  0  0  0  0  0 34  0 32  0\n   0  0  0  0  0  0  0 35]]\nInput length: 15, Label lengths: [6, 3, 4]\nToken distribution (Batch 31): {11: 1, 24: 1, 1: 1, 47: 1}\nBatch 30, Gradient norm: 25.8647\nEpoch 18, Batch 30/128, Loss: 22.4653\nAvg Blank Probability: 0.0310\nSample predictions: ['alPHeelajaXAp', 'U-l32', 'FUA4Fg']\nGround Truth (first 3): ['PwC8ai3', 'zBv', 'K0b']\nRaw outputs (first 3): [[ 1 47 32 16  1  1 63  0  6  0 32 34  0  0 48  0  0 10 42 34  0  0  0  0\n   0 48  0 35  1 34  0  0]\n [ 0 63 47  4  1  0  0 10  0  0  0 34  0  0  0  0  0  0  0  0  0  0  0  0\n  10 13 32  0 34 35  0 24]\n [42  0  0  1 32  0  0 20 32 11  1  0  0  0 32  0  0  0  0 19  0  0  0  0\n   0  0 10  0  0  0 34  0]]\nInput length: 15, Label lengths: [7, 3, 3]\nToken distribution (Batch 31): {11: 1, 0: 2, 22: 2, 45: 1, 49: 1, 27: 2, 34: 1, 25: 1, 1: 1}\nBatch 40, Gradient norm: 22.3727\nEpoch 18, Batch 40/128, Loss: 22.6024\nAvg Blank Probability: 0.0319\nSample predictions: ['dAUlXU', 'aIfaxHeavf', 'aeafjdsjAxaj']\nGround Truth (first 3): ['TOI', 'bVwNB', 'IsX3zLd']\nRaw outputs (first 3): [[ 0  1  1 48  0  0  0 48  0  0 25  0  0  0  0 10  0  0  1  0  0 34  0  0\n   0 12  1  0 10  0  0 11]\n [ 0  0  0 35  0  0  0  0 27  0  0 27  0  0  0  0 22  0  5  0  0  0  0  1\n   0  0  0  0  0  0  0  0]\n [47  6  1  0  0  0  0 32  0  0  0  0  0  0 32  0  0 47 48  1  0  0  0  0\n   0  0 47  0  0  0  0  0]]\nInput length: 15, Label lengths: [3, 5, 7]\nToken distribution (Batch 31): {12: 1, 11: 1, 1: 4, 19: 1, 32: 2, 4: 1, 34: 1, 27: 1, 56: 1, 10: 1}\nBatch 50, Gradient norm: 20.2841\nEpoch 18, Batch 50/128, Loss: 21.5452\nAvg Blank Probability: 0.0328\nSample predictions: ['aBUefgPkal7a2', 'dUFayAkfUelA', 'lHktsS3yXPea']\nGround Truth (first 3): ['WpNtD7cz', 'E6HnJZsVV', 'eQ8pMyQp']\nRaw outputs (first 3): [[ 0  0  0  0  0  0 34  0  1  0 11  1  0 34  0  0  0  0  0  1  0  0  0  0\n  36  1  0  0  1  0  0  0]\n [ 0  0  0  0  0  0 11  1  4  5  0  1 34  0  0  0  0  0  0  0  0  0  0 47\n  27  0 10 50  0  0  0  0]\n [ 0  0  0  0 47  0  0  1 44  0  0 11  0  0  0  0  0  0  0 63  0  1  0  0\n   0  0  0  0  0  0 32  0]]\nInput length: 15, Label lengths: [8, 9, 8]\nToken distribution (Batch 31): {12: 1, 42: 1, 51: 1, 1: 1, 61: 1, 34: 1}\nBatch 60, Gradient norm: 19.0070\nEpoch 18, Batch 60/128, Loss: 20.3513\nAvg Blank Probability: 0.0334\nSample predictions: ['iaHfdasHPuva', 'sHX', 'lfga']\nGround Truth (first 3): ['5yccyJ', 'Bq', '0x']\nRaw outputs (first 3): [[ 0  0 12 10 11  0  0  0  0 25  1  0 11  0 56  0 12  0  0  0  4  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 1  0  0  0  0  0  0  0  0  0 56  0  0  0 34  0 34  0 11 47 32  0  0  0\n   0  0 47  0  0  0  0 42]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 43  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [6, 2, 2]\nToken distribution (Batch 31): {10: 2, 0: 2, 32: 2, 12: 1, 1: 1, 6: 1, 11: 1, 9: 1, 43: 1, 34: 1, 30: 1}\nBatch 70, Gradient norm: 35.8372\nEpoch 18, Batch 70/128, Loss: 27.3195\nAvg Blank Probability: 0.0344\nSample predictions: ['Rjcdas', 'xalUIUaHaesd', 'efIUaUUavkgjAH']\nGround Truth (first 3): ['JfCY', 'CZfOCe9FV', '4yILIwOF']\nRaw outputs (first 3): [[ 0  0  0  0  0  1  1 34 33  0  0  0  0  0  0  0  0  0 11  0  6  0  0 12\n   0  0  1  0 55  1 33  0]\n [ 0  0  6  0  1  0 35  0  0  0 56  0  0  0  0  0  0  0  0  1 34  0  0  0\n   0  1  0  0 48  0  0 10]\n [ 0  0 35  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0 25  0  0  0  1\n   0  1  0  0  0 50  0  0]]\nInput length: 15, Label lengths: [4, 9, 8]\nToken distribution (Batch 31): {27: 1, 22: 2, 10: 1}\nBatch 80, Gradient norm: 19.7380\nEpoch 18, Batch 80/128, Loss: 21.6402\nAvg Blank Probability: 0.0350\nSample predictions: ['HyazUFAyAyF', '3aH8axH', 'Fg3vHRFjHP']\nGround Truth (first 3): ['kAWIPaZw4', '7lDV', 'zninSN1y7G']\nRaw outputs (first 3): [[ 0 56 32  0  0  0  0 11  0 10 32  1 36 11  0  1 27  0  0  1  0  0  0  0\n   0  0  0  0  0  1  0  0]\n [ 0  1  0  1  1  0  4  0  6  0  0  0  4  0  0  1  0 56  0  0  0  1 10  0\n   0  0  0  0  0 11  0  0]\n [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 34  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [9, 4, 10]\nToken distribution (Batch 31): {22: 1, 35: 1, 1: 5, 0: 1, 25: 1, 34: 1}\nBatch 90, Gradient norm: 17.5558\nEpoch 18, Batch 90/128, Loss: 20.6030\nAvg Blank Probability: 0.0360\nSample predictions: ['XIaFXUakNetAPd', 'kjaz', 'ilHd2vV']\nGround Truth (first 3): ['3JuRA61mc', '2f', 'P7QbB']\nRaw outputs (first 3): [[50  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 47  1 47 10\n  27  1  0  0  1  0 24 22]\n [ 0  0  0  0  0  0  0  0  0  0  0 63  0  0  0  0  0  0  1  0  0 34  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0 32  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  1]]\nInput length: 15, Label lengths: [9, 2, 5]\nToken distribution (Batch 31): {20: 1, 47: 1, 32: 1, 0: 1}\nBatch 100, Gradient norm: 99.3254\nEpoch 18, Batch 100/128, Loss: 21.7554\nAvg Blank Probability: 0.0364\nSample predictions: ['vHfjkaHf', 'ajXiVXerFkjU', 'aFa']\nGround Truth (first 3): ['2UiKEQ', '5JsDVGajf', '56']\nRaw outputs (first 3): [[ 0  1  0  0  0  0  4  0  0  0  0  0  0  6  0 11 32  0  0  0  0  0 50  0\n   0  6  0  0 59  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0\n   0 50  0 11  0  0  0 47]\n [ 0  0  0 32  0  0  0  1  0  0  0  0  0 56  0  0  0 27  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [6, 9, 2]\nToken distribution (Batch 31): {34: 3, 32: 1, 0: 2, 50: 1, 1: 1}\nBatch 110, Gradient norm: 21.6205\nEpoch 18, Batch 110/128, Loss: 19.6734\nAvg Blank Probability: 0.0373\nSample predictions: ['HIvfa0afeG', 'aUlHHlidU', 'Fk20a']\nGround Truth (first 3): ['b005xtkb', 'X9rqrpSp', 'zOxS']\nRaw outputs (first 3): [[34  1  0  0  0  0  0  0  0  0  0  0  0 10  0 11  0 12  0  0  0 32  0  0\n  47  0 27  0  0 34  0 34]\n [ 0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0 12 20  0\n   0  0  0  0  0  0  0 32]\n [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  25  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [8, 8, 4]\nToken distribution (Batch 31): {32: 1, 1: 3, 7: 1, 29: 1, 56: 2, 0: 1, 4: 1, 19: 1, 30: 1, 9: 1, 6: 1, 12: 1}\nBatch 120, Gradient norm: 64.8502\nEpoch 18, Batch 120/128, Loss: 19.0683\nAvg Blank Probability: 0.0378\nSample predictions: ['aLUl', 'jAUaHuUHaHFke', 'BHbaxFdzH']\nGround Truth (first 3): ['r5y8', 'JHJlmh0i', 'NS7KJL6']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0 10 59  0  0  0 11  0  0  0  0  0  0  5  0  1  0 28\n   0  0  0  0  0 11 47  0]\n [ 0  0  0  1  0  1  0  0  0  0  0  0  0  0  0  1  0 41  0  0  1  1  0  0\n   0  0  0  0  0  0  0  0]\n [47 47  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 63  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [4, 8, 7]\nEpoch 18/20, Loss: 22.2286\nToken distribution (Batch 31): {1: 15}\nValidation Loss: 23.4006\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['nq', 'fxHGS', '9IIwuwWAr', 'nwEPlz6V', '4rz']\nCurrent Learning Rate: 9.559508646656382e-07\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {6: 1, 1: 4, 0: 3, 10: 1, 20: 1}\nBatch 0, Gradient norm: 23.6943\nEpoch 19, Batch 0/128, Loss: 22.5239\nAvg Blank Probability: 0.0388\nSample predictions: ['iF', 'J32IXsa', 'avAv']\nGround Truth (first 3): ['Y', 'vpIY', 'AfNS6']\nRaw outputs (first 3): [[ 0  0  0  0  0  2  0  0  0  0  0  0  1  6  0 34  0  0  0  1  0  0  0  0\n   0  0  0  0  0  0 12  6]\n [32  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [50  0  0  0  0  1  0  0  0  0  0  0  0  0  0 34  0  0  0  0  0  0  0  0\n   0  0  0  0  0 56  0  0]]\nInput length: 15, Label lengths: [1, 4, 5]\nToken distribution (Batch 31): {50: 1, 25: 1}\nBatch 10, Gradient norm: 49.0075\nEpoch 19, Batch 10/128, Loss: 25.0548\nAvg Blank Probability: 0.0399\nSample predictions: ['PAVFsaaAaP', 'lfFIlIlUas', 'a8H3lXaAd']\nGround Truth (first 3): ['rMdg2h0uii', 'M*li4jM', 'KFJJ7Egd']\nRaw outputs (first 3): [[42 12  1  0  0  0  0  4  1  0  0  0  1  0 29  0  0 12  0  0  0  0  0  0\n   0  0  0  0 50  0 11 50]\n [ 0  0  0  0  0 11  0  0  0  0 34  0  0  0  6  0  0 43  0  0  0  0  0  0\n   0  0  0 34 35  0  0  0]\n [ 0 32  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  1  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [10, 7, 8]\nToken distribution (Batch 31): {19: 2, 36: 2, 32: 1, 34: 2, 1: 4, 47: 1, 8: 1, 6: 1, 4: 1}\nBatch 20, Gradient norm: 27.5272\nEpoch 19, Batch 20/128, Loss: 23.7599\nAvg Blank Probability: 0.0406\nSample predictions: ['lGGdlEi', 'aFXIaIa', 'UAUaHsaXF']\nGround Truth (first 3): ['CYefHF', '1BaHucs7', '45t061hgf9']\nRaw outputs (first 3): [[ 0  0  0 22  0  0 33 10  0  0  0 56 27  0  1  0  0  0  0  4  0  0  0  0\n   0  0  0 42  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [6, 8, 10]\nToken distribution (Batch 31): {1: 2, 0: 9, 34: 1, 27: 1, 12: 1}\nBatch 30, Gradient norm: 23.7294\nEpoch 19, Batch 30/128, Loss: 20.3563\nAvg Blank Probability: 0.0436\nSample predictions: ['jHAIF', 'ka3kDaHT', 'DasfiEaJ3aQd']\nGround Truth (first 3): ['uduag5', 'fr1jAmXu', 'RMaR5*7p']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0  0  0  0\n   0  0  0  0 19  0 10  1]\n [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [6, 8, 8]\nToken distribution (Batch 31): {42: 1, 59: 1}\nBatch 40, Gradient norm: 152.1613\nEpoch 19, Batch 40/128, Loss: 20.1920\nAvg Blank Probability: 0.0437\nSample predictions: ['HaY', 'sjXmfTFae', 'AamH']\nGround Truth (first 3): ['7zV', '-i6LwZrz47', 'lj1']\nRaw outputs (first 3): [[ 0  0 27  0  1  0  0  0  0 35  0  0  0  0 32  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0 10  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n   5  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [3, 10, 3]\nToken distribution (Batch 31): {12: 1, 0: 4, 35: 1, 21: 1, 1: 4, 48: 1, 22: 1, 62: 1, 47: 1}\nBatch 50, Gradient norm: 75.9468\nEpoch 19, Batch 50/128, Loss: 27.0283\nAvg Blank Probability: 0.0452\nSample predictions: ['V', 'UQIaQ', 'f2']\nGround Truth (first 3): ['1', '0pQUIWd', '4RpW']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0 10 30  0 12  0  0  0  0  0  0  0  0  0  0  0 63\n   0  0  0  4  0  0 32  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  34 42  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0 12  0  0  0  0]]\nInput length: 15, Label lengths: [1, 7, 4]\nToken distribution (Batch 31): {32: 1, 35: 2, 43: 1, 0: 7, 5: 1, 47: 1, 14: 1}\nBatch 60, Gradient norm: 22.1272\nEpoch 19, Batch 60/128, Loss: 20.2284\nAvg Blank Probability: 0.0445\nSample predictions: ['vPad', 'xnQUd', 'akA3jj']\nGround Truth (first 3): ['NkE9', 'GRgo5', 'MRrU']\nRaw outputs (first 3): [[ 0 24  0  0  0  0  0  0  0  0  0  0  0  0 47 19  0  0  0  0 63  0  0  0\n   0  0  0  0  0  0  0 32]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  1  0  0  0  0  0  0  0 34  0  0  1  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [4, 5, 4]\nToken distribution (Batch 31): {1: 3, 12: 1, 0: 7, 32: 1, 47: 1, 10: 1}\nBatch 70, Gradient norm: 35.8772\nEpoch 19, Batch 70/128, Loss: 20.5884\nAvg Blank Probability: 0.0484\nSample predictions: ['a', 'UiP', 'j']\nGround Truth (first 3): ['waV', 'Mx', 'yn*']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0 47\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0 43  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [3, 2, 3]\nToken distribution (Batch 31): {27: 2, 6: 1, 12: 2, 11: 1, 0: 3, 43: 1, 1: 1, 4: 1}\nBatch 80, Gradient norm: 65.8175\nEpoch 19, Batch 80/128, Loss: 24.3539\nAvg Blank Probability: 0.0489\nSample predictions: ['v', 'fsaXl4', 'laEa']\nGround Truth (first 3): ['O', 'C5Wdy4c', 'WLe']\nRaw outputs (first 3): [[ 0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [1, 7, 3]\nToken distribution (Batch 31): {4: 1, 0: 1}\nBatch 90, Gradient norm: 28.0077\nEpoch 19, Batch 90/128, Loss: 22.2292\nAvg Blank Probability: 0.0498\nSample predictions: ['FI', 'SadaFa3', 'da8UicHHF']\nGround Truth (first 3): ['lZ2TUT', 'q9zklSaiuC', 'AXtKCJ05k']\nRaw outputs (first 3): [[ 0  0  0  0  0 47  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0\n  19  0  0 11  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [6, 10, 9]\nToken distribution (Batch 31): {1: 4, 0: 7, 34: 1, 28: 1, 27: 1, 24: 1}\nBatch 100, Gradient norm: 28.7197\nEpoch 19, Batch 100/128, Loss: 21.8951\nAvg Blank Probability: 0.0520\nSample predictions: ['ua0ia', 'FAUj4a', 'I']\nGround Truth (first 3): ['P5-Gz9K', 'zYARCOeb', '2j']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0 47  0  0  0  0  0  6  0  0 32  0  0  0  0  0 34  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [7, 8, 2]\nToken distribution (Batch 31): {56: 1, 3: 1, 0: 8, 9: 1, 27: 1, 57: 1, 34: 1, 47: 1}\nBatch 110, Gradient norm: 22.0279\nEpoch 19, Batch 110/128, Loss: 20.0330\nAvg Blank Probability: 0.0536\nSample predictions: ['alak', 'av', 'lH']\nGround Truth (first 3): ['hACa', 'g', 'kOnkX']\nRaw outputs (first 3): [[ 0  0  0  0  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [4, 1, 5]\nToken distribution (Batch 31): {35: 2, 42: 1, 0: 4, 27: 1}\nBatch 120, Gradient norm: 21.7154\nEpoch 19, Batch 120/128, Loss: 19.1006\nAvg Blank Probability: 0.0543\nSample predictions: ['fd', 'jI', 'HklFaHl3']\nGround Truth (first 3): ['**GKC5p', 'MI', 'Ql1pa--3']\nRaw outputs (first 3): [[ 6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [7, 2, 8]\nEpoch 19/20, Loss: 21.3408\nToken distribution (Batch 31): {1: 15}\nValidation Loss: 22.8038\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['Tn', 'zypb', 'U6LgEHC8oW', 'c', 'NXr']\nCurrent Learning Rate: 9.889195065356238e-07\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {43: 1, 0: 11, 55: 1, 12: 1}\nBatch 0, Gradient norm: 32.9654\nEpoch 20, Batch 0/128, Loss: 23.5156\nAvg Blank Probability: 0.0549\nSample predictions: ['asa3P', 'sHYFe', 'IaHej']\nGround Truth (first 3): ['PDeSdwlOT', 'kPAyIFQu', 'fForlf']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0 32  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [9, 8, 6]\nToken distribution (Batch 31): {63: 1, 0: 11, 27: 1, 22: 1, 42: 1}\nBatch 10, Gradient norm: 224.3549\nEpoch 20, Batch 10/128, Loss: 18.8071\nAvg Blank Probability: 0.0584\nSample predictions: ['AlF', 'maga', 'P-']\nGround Truth (first 3): ['pOTlc0P5pw', 'u6XUi', 'n']\nRaw outputs (first 3): [[ 0 13  0  0  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  34  0  0  0  0  0  0  0]\n [ 0  0  0  0 47  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [10, 5, 1]\nToken distribution (Batch 31): {4: 1, 0: 3}\nBatch 20, Gradient norm: 19.3132\nEpoch 20, Batch 20/128, Loss: 18.0129\nAvg Blank Probability: 0.0600\nSample predictions: ['<empty>', 'U', 'I']\nGround Truth (first 3): ['6', '7N7d', 'g']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 4, 1]\nToken distribution (Batch 31): {1: 1, 0: 11, 11: 1, 32: 1, 34: 1}\nBatch 30, Gradient norm: 133.6774\nEpoch 20, Batch 30/128, Loss: 21.6633\nAvg Blank Probability: 0.0611\nSample predictions: ['a', 'IF', '<empty>']\nGround Truth (first 3): ['T6', 'AE', 'q']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 2, 1]\nToken distribution (Batch 31): {10: 1, 0: 7}\nBatch 40, Gradient norm: 19.9875\nEpoch 20, Batch 40/128, Loss: 17.9653\nAvg Blank Probability: 0.0664\nSample predictions: ['aA', 'Ase', 'ela']\nGround Truth (first 3): ['MmvXqd05', '55kxoPw', 'K9']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n   0  0  0 34  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [8, 7, 2]\nToken distribution (Batch 31): {11: 1, 0: 7}\nBatch 50, Gradient norm: 149.0872\nEpoch 20, Batch 50/128, Loss: 20.6555\nAvg Blank Probability: 0.0671\nSample predictions: ['IJJ', 'Vlai', 'P']\nGround Truth (first 3): ['9KaMuuhtgy', 'RQz0Sj', '8']\nRaw outputs (first 3): [[ 0  0  0 32  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  1  0  0  0  0]]\nInput length: 15, Label lengths: [10, 6, 1]\nToken distribution (Batch 31): {0: 15}\nBatch 60, Gradient norm: 163.7120\nEpoch 20, Batch 60/128, Loss: 20.6045\nAvg Blank Probability: 0.0676\nSample predictions: ['<empty>', 'Ak', 'aF']\nGround Truth (first 3): ['Q', '1qwdH4orZZ', 'b0sr']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 47  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [1, 10, 4]\nToken distribution (Batch 31): {0: 15}\nBatch 70, Gradient norm: 29.2084\nEpoch 20, Batch 70/128, Loss: 20.0743\nAvg Blank Probability: 0.0722\nSample predictions: ['Aak', 'l', 'aUla']\nGround Truth (first 3): ['zapD0Ga3q', 'hjpH', 'H9Ih-81']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [9, 4, 7]\nToken distribution (Batch 31): {35: 1, 34: 1, 0: 13}\nBatch 80, Gradient norm: 2541.3623\nEpoch 20, Batch 80/128, Loss: 19.3230\nAvg Blank Probability: 0.0739\nSample predictions: ['q', 'a', 'eH']\nGround Truth (first 3): ['bUNq', '*m4W', 'BGcfsHl0j6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 4, 10]\nToken distribution (Batch 31): {27: 1, 0: 1}\nBatch 90, Gradient norm: 26.7620\nEpoch 20, Batch 90/128, Loss: 19.0776\nAvg Blank Probability: 0.0801\nSample predictions: ['la', '<empty>', '<empty>']\nGround Truth (first 3): ['1', 'OWs', '2UiKEQ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 3, 6]\nToken distribution (Batch 31): {34: 1, 0: 13, 33: 1}\nBatch 100, Gradient norm: 492.9152\nEpoch 20, Batch 100/128, Loss: 20.1357\nAvg Blank Probability: 0.0787\nSample predictions: ['<empty>', '<empty>', '-a']\nGround Truth (first 3): ['09Vsfm3', 'k1Z', 'A8Be2f']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 3, 6]\nToken distribution (Batch 31): {0: 2}\nBatch 110, Gradient norm: 44.5269\nEpoch 20, Batch 110/128, Loss: 22.7071\nAvg Blank Probability: 0.0793\nSample predictions: ['<empty>', 'j', 'jk']\nGround Truth (first 3): ['uBJcLx', 'l', '*mfyDLwx']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 1, 8]\nToken distribution (Batch 31): {1: 1, 0: 3}\nBatch 120, Gradient norm: 35.3496\nEpoch 20, Batch 120/128, Loss: 21.0614\nAvg Blank Probability: 0.0860\nSample predictions: ['n', '<empty>', '<empty>']\nGround Truth (first 3): ['UtXibJFR', 'GMTm', '65GcR']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 4, 5]\nEpoch 20/20, Loss: 19.8968\nToken distribution (Batch 31): {12: 1, 1: 6, 0: 8}\nValidation Loss: 23.3549\nValidation Predictions: ['laa', 'aHa', 'a', 'laa', 'laa']\nGround Truth: ['K7ebq', 'GXX3PhE', 'kuG', 'Bw', 'DV14']\nCurrent Learning Rate: 1e-06\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"def zip_folder_with_shutil(source_folder, output_path):\n    '''Function for zip dir data'''\n    shutil.make_archive(output_path, 'zip', source_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:57:22.495823Z","iopub.execute_input":"2025-03-07T11:57:22.496175Z","iopub.status.idle":"2025-03-07T11:57:22.502472Z","shell.execute_reply.started":"2025-03-07T11:57:22.496136Z","shell.execute_reply":"2025-03-07T11:57:22.501119Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/backgrounds', '/kaggle/working/backgrounds')\nzip_folder_with_shutil('/kaggle/working/synthetic_data', '/kaggle/working/synthetic_data')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:57:22.503789Z","iopub.execute_input":"2025-03-07T11:57:22.504078Z","iopub.status.idle":"2025-03-07T11:57:23.835063Z","shell.execute_reply.started":"2025-03-07T11:57:22.504054Z","shell.execute_reply":"2025-03-07T11:57:23.834004Z"}},"outputs":[],"execution_count":26}]}