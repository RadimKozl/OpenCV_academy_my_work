{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/radimkzl/pytorch-ocr?scriptVersionId=240789166\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"7e299dd8","metadata":{"papermill":{"duration":0.016624,"end_time":"2025-05-20T09:33:07.667721","exception":false,"start_time":"2025-05-20T09:33:07.651097","status":"completed"},"tags":[]},"source":["---------------\n","\n","# **<font style=\"color:Black\">Create OCR by PyTorch</font>**\n","-------------------\n","-----------------"]},{"cell_type":"code","execution_count":1,"id":"6f15f5be","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:33:07.699743Z","iopub.status.busy":"2025-05-20T09:33:07.699369Z","iopub.status.idle":"2025-05-20T09:33:32.113433Z","shell.execute_reply":"2025-05-20T09:33:32.1124Z"},"papermill":{"duration":24.431543,"end_time":"2025-05-20T09:33:32.11523","exception":false,"start_time":"2025-05-20T09:33:07.683687","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting python-Levenshtein\r\n","  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\r\n","Collecting Levenshtein==0.27.1 (from python-Levenshtein)\r\n","  Downloading levenshtein-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\r\n","Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\r\n","  Downloading rapidfuzz-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n","Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\r\n","Downloading levenshtein-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/161.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading rapidfuzz-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\r\n","Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.13.0\r\n","Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.2.1)\r\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.1)\r\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\r\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\r\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\r\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\r\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\r\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\r\n","Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\r\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\r\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\r\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.3.8)\r\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.2.4)\r\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (0.1.1)\r\n","Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2025.0.1)\r\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2022.0.0)\r\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2.4.1)\r\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\r\n","Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2024.2.0)\r\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2022.0.0)\r\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->optuna) (2024.2.0)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.2/104.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hCollecting structlog\r\n","  Downloading structlog-25.3.0-py3-none-any.whl.metadata (8.0 kB)\r\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from structlog) (4.12.2)\r\n","Downloading structlog-25.3.0-py3-none-any.whl (68 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hInstalling collected packages: structlog\r\n","Successfully installed structlog-25.3.0\r\n","Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\r\n","Collecting onnxruntime\r\n","  Downloading onnxruntime-1.22.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\r\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\r\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\r\n","Collecting coloredlogs (from onnxruntime)\r\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\r\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\r\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.2)\r\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\r\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (1.3.8)\r\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (1.2.4)\r\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (0.1.1)\r\n","Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (2025.0.1)\r\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (2022.0.0)\r\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (2.4.1)\r\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\r\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\r\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\r\n","Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->onnx) (2024.2.0)\r\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->onnx) (2022.0.0)\r\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->onnx) (1.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.20->onnx) (2024.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.20->onnx) (2024.2.0)\r\n","Downloading onnxruntime-1.22.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\r\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.22.0\r\n"]}],"source":["!pip install python-Levenshtein\n","!pip install optuna\n","!pip install optuna-dashboard --quiet\n","!pip install --upgrade structlog\n","!pip install onnx onnxruntime"]},{"cell_type":"code","execution_count":2,"id":"19185806","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:33:32.15307Z","iopub.status.busy":"2025-05-20T09:33:32.152784Z","iopub.status.idle":"2025-05-20T09:33:56.667609Z","shell.execute_reply":"2025-05-20T09:33:56.666488Z"},"papermill":{"duration":24.535422,"end_time":"2025-05-20T09:33:56.669412","exception":false,"start_time":"2025-05-20T09:33:32.13399","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-05-20 09:33:37.102590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n","2025-05-20 09:33:37.563092: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n","2025-05-20 09:33:37.690471: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n","I0000 00:00:1747733633.779612      64 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\n","I0000 00:00:1747733633.780029      64 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\n","I0000 00:00:1747733635.141761      64 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\n","I0000 00:00:1747733635.142203      64 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\n","I0000 00:00:1747733635.142508      64 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\n","I0000 00:00:1747733635.144373      64 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\n","2.17.1\r\n"]}],"source":["#!pip install tensorboard\n","!tensorboard --version"]},{"cell_type":"code","execution_count":3,"id":"a07ab762","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:33:56.705994Z","iopub.status.busy":"2025-05-20T09:33:56.705729Z","iopub.status.idle":"2025-05-20T09:34:13.970956Z","shell.execute_reply":"2025-05-20T09:34:13.970174Z"},"papermill":{"duration":17.285022,"end_time":"2025-05-20T09:34:13.972505","exception":false,"start_time":"2025-05-20T09:33:56.687483","status":"completed"},"tags":[]},"outputs":[],"source":["import os\n","import sys\n","import shutil\n","import random\n","import time\n","import datetime\n","import math\n","import re\n","import string\n","import getpass\n","import threading\n","from PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter\n","import numpy as np\n","import cv2\n","\n","import logging\n","import structlog\n","import json\n","\n","from typing import Iterator, Tuple\n","\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","\n","from tqdm import tqdm\n","\n","from Levenshtein import distance as levenshtein_distance\n","\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F  # Add this import\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import torch.nn.utils as nn_utils\n","\n","import optuna\n","from optuna.trial import Trial\n","from optuna import visualization \n","from optuna_dashboard import run_server\n","\n","import onnx\n","import onnxruntime as ort"]},{"cell_type":"markdown","id":"f21d9e68","metadata":{"papermill":{"duration":0.016372,"end_time":"2025-05-20T09:34:14.006264","exception":false,"start_time":"2025-05-20T09:34:13.989892","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Logger settings</font>**\n","-------------------"]},{"cell_type":"code","execution_count":4,"id":"52b73722","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:14.041174Z","iopub.status.busy":"2025-05-20T09:34:14.040631Z","iopub.status.idle":"2025-05-20T09:34:14.044756Z","shell.execute_reply":"2025-05-20T09:34:14.044056Z"},"papermill":{"duration":0.022669,"end_time":"2025-05-20T09:34:14.045971","exception":false,"start_time":"2025-05-20T09:34:14.023302","status":"completed"},"tags":[]},"outputs":[],"source":["LOGS_DIR = os.path.join(\"/kaggle\",\"working\",\"logs\")\n","os.makedirs(LOGS_DIR, exist_ok=True)\n","log_file_path = os.path.join(LOGS_DIR, \"train_logs.json\")"]},{"cell_type":"code","execution_count":5,"id":"d42a61c8","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:14.079936Z","iopub.status.busy":"2025-05-20T09:34:14.079679Z","iopub.status.idle":"2025-05-20T09:34:14.086967Z","shell.execute_reply":"2025-05-20T09:34:14.086276Z"},"papermill":{"duration":0.025724,"end_time":"2025-05-20T09:34:14.08819","exception":false,"start_time":"2025-05-20T09:34:14.062466","status":"completed"},"tags":[]},"outputs":[],"source":["# Configuration of the main logger\n","def configure_main_logger():\n","    structlog.configure(\n","        processors=[\n","            structlog.stdlib.add_log_level,\n","            structlog.stdlib.add_logger_name,\n","            structlog.processors.TimeStamper(fmt=\"iso\"),\n","            structlog.processors.format_exc_info,\n","            structlog.processors.JSONRenderer(sort_keys=True),\n","        ],\n","        context_class=dict,\n","        logger_factory=structlog.stdlib.LoggerFactory(),\n","        wrapper_class=structlog.stdlib.BoundLogger,\n","    )\n","\n","configure_main_logger()  # Function call for configuring the main logger\n","\n","# Configuration Optuna logger\n","def configure_optuna_logger():\n","    structlog.configure(\n","        processors=[\n","            structlog.stdlib.add_log_level,\n","            structlog.stdlib.add_logger_name,\n","            structlog.processors.TimeStamper(fmt=\"iso\"),\n","            structlog.processors.format_exc_info,\n","            structlog.processors.JSONRenderer(sort_keys=True),\n","        ],\n","        context_class=dict,\n","        logger_factory=structlog.stdlib.LoggerFactory(),\n","        wrapper_class=structlog.stdlib.BoundLogger,\n","    )\n","\n","configure_optuna_logger()  # Function call for Optuna logger configuration\n","\n","# Configuration Function logger\n","def configure_function_logger():\n","    structlog.configure(\n","        processors=[\n","            structlog.stdlib.add_log_level,\n","            structlog.stdlib.add_logger_name,\n","            structlog.processors.TimeStamper(fmt=\"iso\"),\n","            structlog.processors.format_exc_info,\n","            structlog.processors.JSONRenderer(sort_keys=True),\n","        ],\n","        context_class=dict,\n","        logger_factory=structlog.stdlib.LoggerFactory(),\n","        wrapper_class=structlog.stdlib.BoundLogger,\n","    )\n","\n","configure_function_logger()  # Function call for Optuna logger configuration\n","\n","# Configuration Final Train logger\n","def configure_finaltrain_logger():\n","    \"\"\"Configures the structlog logger to provide structured JSON logs\n","    suitable for final train process.\n","\n","    This function sets up structlog with a predefined set of processors\n","    to format log messages as JSON. The configuration includes adding\n","    log level and logger name, timestamping in ISO format, formatting\n","    exception information, and rendering the final log entry as a sorted\n","    JSON string.\n","    \"\"\"    \n","    structlog.configure(\n","        processors=[\n","            structlog.stdlib.add_log_level,\n","            structlog.stdlib.add_logger_name,\n","            structlog.processors.TimeStamper(fmt=\"iso\"),\n","            structlog.processors.format_exc_info,\n","            structlog.processors.JSONRenderer(sort_keys=True),\n","        ],\n","        context_class=dict,\n","        logger_factory=structlog.stdlib.LoggerFactory(),\n","        wrapper_class=structlog.stdlib.BoundLogger,\n","    )\n","\n","configure_finaltrain_logger() # Function call for final train logger configuration"]},{"cell_type":"code","execution_count":6,"id":"ca7fa048","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:14.123926Z","iopub.status.busy":"2025-05-20T09:34:14.123692Z","iopub.status.idle":"2025-05-20T09:34:14.135102Z","shell.execute_reply":"2025-05-20T09:34:14.134085Z"},"papermill":{"duration":0.030392,"end_time":"2025-05-20T09:34:14.136567","exception":false,"start_time":"2025-05-20T09:34:14.106175","status":"completed"},"tags":[]},"outputs":[],"source":["# Custom handler for writing logs to JSON file\n","class RotatingJSONFileHandler(logging.Handler):\n","    def __init__(self, directory: str, max_bytes: int = 10*1024*1024, backup_count: int = 5, buffer_size: int = 100):\n","        \"\"\"\n","        Initializes the handler for spinning JSON logs with buffering.\n","\n","        Args:\n","            directory (str): Directory where log files are stored.\n","            max_bytes (int): Maximum file size before rotation (default: 10 MB).\n","            backup_count (int): Number of backup files (default: 5).\n","            buffer_size (int): Buffer size before writing to disk (default: 100 records).\n","        \"\"\"\n","        super().__init__()\n","        self.directory = directory\n","        self.max_bytes = max_bytes\n","        self.backup_count = backup_count\n","        self.buffer_size = buffer_size\n","        self.buffer = []  # Buffer pre log záznamy\n","        self.filename = self._get_filename()\n","        self.file = open(self.filename, \"a\", encoding=\"utf-8\")\n","        os.makedirs(directory, exist_ok=True)  # Zabezpečí vytvorenie adresára\n","\n","    def _get_filename(self) -> str:\n","        \"\"\"Generates a file name with a timestamp.\"\"\"\n","        timestamp = time.strftime(\"%Y%m%d%H%M%S\")\n","        return os.path.join(self.directory, f\"train_{timestamp}.json\")\n","\n","    def _should_rotate(self) -> bool:\n","        \"\"\"Checks whether a file needs to be rotated based on its size.\"\"\"\n","        self.file.flush()\n","        try:\n","            return os.path.getsize(self.filename) > self.max_bytes\n","        except OSError:\n","            return False  # Ak súbor neexistuje alebo nie je dostupný, nerotujeme\n","\n","    def _do_rotate(self) -> None:\n","        \"\"\"Performs file rotation.\"\"\"\n","        self.file.close()\n","        base_name = self.filename.split('.')[0]\n","        \n","        # Posun starých súborov (napr. train_xxx_1.json -> train_xxx_2.json)\n","        for i in range(self.backup_count - 1, 0, -1):\n","            old_file = f\"{base_name}_{i}.json\"\n","            new_file = f\"{base_name}_{i+1}.json\"\n","            if os.path.exists(old_file):\n","                os.rename(old_file, new_file)\n","        \n","        # Premenovanie aktuálneho súboru na _1\n","        if os.path.exists(self.filename):\n","            os.rename(self.filename, f\"{base_name}_1.json\")\n","        \n","        self.filename = self._get_filename()\n","        self.file = open(self.filename, \"a\", encoding=\"utf-8\")\n","\n","    def emit(self, record: logging.LogRecord) -> None:\n","        \"\"\"\n","        It processes the log record and adds it to the buffer. If the buffer is full or the record is critical, \n","        it writes the buffer to disk.\n","        \"\"\"\n","        try:\n","            log_entry = self._format_record(record)\n","            self.buffer.append(log_entry + \"\\n\")\n","\n","            # Zápis bufferu na disk, ak je plný alebo ide o varovanie/chybu\n","            if len(self.buffer) >= self.buffer_size or record.levelno >= logging.WARNING:\n","                self._flush_buffer()\n","\n","        except Exception as e:\n","            print(f\"Error in RotatingJSONFileHandler.emit: {e}\")\n","\n","    def _format_record(self, record: logging.LogRecord) -> str:\n","        \"\"\"Formats the log record into a JSON string.\"\"\"\n","        try:\n","            # Pokúsi sa parsovať správu ako JSON, ak už je v správnom formáte\n","            log_entry = record.getMessage()\n","            json.loads(log_entry)\n","            return log_entry\n","        except json.JSONDecodeError:\n","            # Ak nie je JSON, vytvorí štruktúrovaný JSON záznam\n","            return json.dumps({\n","                \"timestamp\": record.created,\n","                \"level\": record.levelname,\n","                \"logger\": record.name,\n","                \"message\": str(record.msg),\n","                \"args\": record.args if record.args else None,\n","                \"exc_info\": str(record.exc_info) if record.exc_info else None\n","            }, ensure_ascii=False)\n","\n","    def _flush_buffer(self) -> None:\n","        \"\"\"Writes the contents of the buffer to disk and flushes it.\"\"\"\n","        if not self.buffer:\n","            return\n","        \n","        if self._should_rotate():\n","            self._do_rotate()\n","\n","        try:\n","            self.file.writelines(self.buffer)\n","            self.file.flush()\n","        except IOError as e:\n","            print(f\"Error writing to file {self.filename}: {e}\")\n","        \n","        self.buffer = []\n","\n","    def close(self) -> None:\n","        \"\"\"Closes the handler and writes the remaining buffer.\"\"\"\n","        self._flush_buffer()\n","        self.file.close()\n","        super().close()"]},{"cell_type":"code","execution_count":7,"id":"e8551bf2","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:14.171709Z","iopub.status.busy":"2025-05-20T09:34:14.171458Z","iopub.status.idle":"2025-05-20T09:34:14.176966Z","shell.execute_reply":"2025-05-20T09:34:14.176168Z"},"papermill":{"duration":0.023711,"end_time":"2025-05-20T09:34:14.17809","exception":false,"start_time":"2025-05-20T09:34:14.154379","status":"completed"},"tags":[]},"outputs":[],"source":["# Create the main logger\n","main_logger = structlog.get_logger(\"mainlog\")\n","\n","# Creating an Optuna logger\n","optuna_logger = structlog.get_logger(\"optunalog\")\n","\n","# Creating an Function logger\n","function_logger = structlog.get_logger(\"functionlog\")\n","\n","# Creating an Final Train logger\n","finaltrain_logger = structlog.get_logger(\"finaltrainlog\")\n","\n","# Set levels for each logger\n","logging.getLogger(\"mainlog\").setLevel(logging.DEBUG) # main_logger\n","logging.getLogger(\"optunalog\").setLevel(logging.DEBUG) # optuna_logger\n","logging.getLogger(\"functionlog\").setLevel(logging.DEBUG) # function_logger\n","logging.getLogger(\"finaltrainlog\").setLevel(logging.DEBUG) # finaltrain_logger\n","\n","# Creating a RotatingJSONFileHandler\n","rotating_json_file_handler = RotatingJSONFileHandler(directory=LOGS_DIR, max_bytes=10*1024*1024, backup_count=5, buffer_size=50)\n","\n","# Adding RotatingJSONFileHandler to the root logger\n","logging.getLogger().addHandler(rotating_json_file_handler)"]},{"cell_type":"code","execution_count":8,"id":"b481d9eb","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:14.212091Z","iopub.status.busy":"2025-05-20T09:34:14.211833Z","iopub.status.idle":"2025-05-20T09:34:14.215143Z","shell.execute_reply":"2025-05-20T09:34:14.214407Z"},"papermill":{"duration":0.021768,"end_time":"2025-05-20T09:34:14.216445","exception":false,"start_time":"2025-05-20T09:34:14.194677","status":"completed"},"tags":[]},"outputs":[],"source":["main_logger.info('Star process of notebook.')"]},{"cell_type":"markdown","id":"4468562b","metadata":{"papermill":{"duration":0.016984,"end_time":"2025-05-20T09:34:14.250598","exception":false,"start_time":"2025-05-20T09:34:14.233614","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Hyperparameters</font>**\n","-------------------"]},{"cell_type":"code","execution_count":9,"id":"63b2744b","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:14.284716Z","iopub.status.busy":"2025-05-20T09:34:14.284471Z","iopub.status.idle":"2025-05-20T09:34:14.298966Z","shell.execute_reply":"2025-05-20T09:34:14.298316Z"},"papermill":{"duration":0.032774,"end_time":"2025-05-20T09:34:14.300141","exception":false,"start_time":"2025-05-20T09:34:14.267367","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x79d84b0d5190>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["seed = 3\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)"]},{"cell_type":"code","execution_count":10,"id":"55685309","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:14.335086Z","iopub.status.busy":"2025-05-20T09:34:14.334756Z","iopub.status.idle":"2025-05-20T09:34:14.340721Z","shell.execute_reply":"2025-05-20T09:34:14.339874Z"},"papermill":{"duration":0.024826,"end_time":"2025-05-20T09:34:14.342034","exception":false,"start_time":"2025-05-20T09:34:14.317208","status":"completed"},"tags":[]},"outputs":[],"source":["FINAL_TRAINING = True  # Set to True for final training, False for Optuna optimization\n","PRETRAINED_MODEL_PATH = None\n","OUTPUT_DIR = os.path.join('/kaggle','working','synthetic_data','images')\n","TENSORBOARD_DIR = os.path.join('/kaggle','working','runs')\n","OPTUNA_DIR = os.path.join('/kaggle','working','optuna')\n","MODEL_DIR = os.path.join('/kaggle','working','model_dir')\n","LABELS_FILE = os.path.join('/kaggle','working','synthetic_data','labels.txt')\n","NUM_SAMPLES = 10240  # Number of images generated\n","IMG_WIDTH = 128\n","IMG_HEIGHT = 32\n","BATCH_SIZE = 32\n","EPOCHS = 5\n","FINAL_EPOCHS = 20\n","LEARNING_RATE = 1.0922352314924757e-08\n","WEIGHT_DECAY =  0.13795013169033923\n","WARMUP_STEPS = 1716\n","TEMPERATURE =  1.2815668434403469\n","CTC_ENTROPY_WEIGHT = 0.6614983830823002\n","CTC_LABEL_SMOOTHING = 0.17806825952573493\n","CTC_BLANK_PENALTY_WEIGHT = 0.21682821416617992\n","BSD_BEAM_WIDTH = 10\n","BSD_BLANK_PENALTY =  -0.1321899101293788\n","BSD_LENGTH_PENALTY = -0.1965145243302787\n","GRADIENT_CLIPPING_VALUE = 4.557349321760741\n","MAX_SEQ_LENGTH = None\n","CHARSET = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789- \"  # Characters used in license plates\n","FONT_DIR = os.path.join('/kaggle','input','google-fonts','GoogleFontScripts') # Folder with TrueType fonts (.ttf)\n","BACKGROUND_DIR = os.path.join('/kaggle','working','backgrounds')  # New folder for background (optional)\n","NUMBER_BACKGROUND_IMAGE = 4000\n","NUMBER_OF_OPTUNA_TRIALS = 3\n","GRADIENT_NORM_TRESHOLD = 294\n","NUMBER_OF_BATCH_REPORT = 25"]},{"cell_type":"code","execution_count":11,"id":"eaae0728","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:14.376601Z","iopub.status.busy":"2025-05-20T09:34:14.376378Z","iopub.status.idle":"2025-05-20T09:34:14.379646Z","shell.execute_reply":"2025-05-20T09:34:14.378885Z"},"papermill":{"duration":0.021597,"end_time":"2025-05-20T09:34:14.38079","exception":false,"start_time":"2025-05-20T09:34:14.359193","status":"completed"},"tags":[]},"outputs":[],"source":["main_logger.info('Set Base hyperparameters.')"]},{"cell_type":"markdown","id":"4bd687c7","metadata":{"papermill":{"duration":0.016909,"end_time":"2025-05-20T09:34:14.414389","exception":false,"start_time":"2025-05-20T09:34:14.39748","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Utils support functions</font>**\n","-------------------"]},{"cell_type":"markdown","id":"4ac047c3","metadata":{"papermill":{"duration":0.016785,"end_time":"2025-05-20T09:34:14.448337","exception":false,"start_time":"2025-05-20T09:34:14.431552","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Create output folders</font>**"]},{"cell_type":"code","execution_count":12,"id":"4dab1021","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:14.482727Z","iopub.status.busy":"2025-05-20T09:34:14.482504Z","iopub.status.idle":"2025-05-20T09:34:14.486464Z","shell.execute_reply":"2025-05-20T09:34:14.485888Z"},"papermill":{"duration":0.02273,"end_time":"2025-05-20T09:34:14.487682","exception":false,"start_time":"2025-05-20T09:34:14.464952","status":"completed"},"tags":[]},"outputs":[],"source":["os.makedirs(OUTPUT_DIR, exist_ok=True)\n","os.makedirs(MODEL_DIR, exist_ok=True)\n","os.makedirs(BACKGROUND_DIR, exist_ok=True)\n","os.makedirs(TENSORBOARD_DIR, exist_ok=True)\n","os.makedirs(OPTUNA_DIR, exist_ok=True)\n","\n","# Creates a new file\n","with open(LABELS_FILE, 'w') as fp:\n","    pass"]},{"cell_type":"code","execution_count":13,"id":"2ce24e24","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:14.559152Z","iopub.status.busy":"2025-05-20T09:34:14.558886Z","iopub.status.idle":"2025-05-20T09:34:14.562224Z","shell.execute_reply":"2025-05-20T09:34:14.561559Z"},"papermill":{"duration":0.058642,"end_time":"2025-05-20T09:34:14.563481","exception":false,"start_time":"2025-05-20T09:34:14.504839","status":"completed"},"tags":[]},"outputs":[],"source":["main_logger.info('Create dirs structure.')"]},{"cell_type":"markdown","id":"7595d467","metadata":{"papermill":{"duration":0.016467,"end_time":"2025-05-20T09:34:14.597756","exception":false,"start_time":"2025-05-20T09:34:14.581289","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Load the font list (add the paths to the .ttf files to the \"fonts\" folder)</font>**"]},{"cell_type":"code","execution_count":14,"id":"7cbf4f9e","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:14.631495Z","iopub.status.busy":"2025-05-20T09:34:14.63128Z","iopub.status.idle":"2025-05-20T09:34:17.668526Z","shell.execute_reply":"2025-05-20T09:34:17.667814Z"},"papermill":{"duration":3.055575,"end_time":"2025-05-20T09:34:17.670029","exception":false,"start_time":"2025-05-20T09:34:14.614454","status":"completed"},"tags":[]},"outputs":[],"source":["font_files = [\n","    os.path.join(FONT_DIR, f) for f in os.listdir(FONT_DIR) \n","    if f.endswith('.ttf') and os.path.isfile(os.path.join(FONT_DIR, f))\n","]\n","if not font_files:\n","    raise FileNotFoundError(\"No fonts found in 'fonts' folder. Add .ttf files!\")\n","    main_logger.error(\"No fonts found in 'fonts' folder. Add .ttf files!\")"]},{"cell_type":"code","execution_count":15,"id":"e443688e","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:17.705879Z","iopub.status.busy":"2025-05-20T09:34:17.705645Z","iopub.status.idle":"2025-05-20T09:34:17.709003Z","shell.execute_reply":"2025-05-20T09:34:17.708379Z"},"papermill":{"duration":0.022124,"end_time":"2025-05-20T09:34:17.710142","exception":false,"start_time":"2025-05-20T09:34:17.688018","status":"completed"},"tags":[]},"outputs":[],"source":["main_logger.info('Load google-fonts files from dataset.')"]},{"cell_type":"markdown","id":"69112850","metadata":{"papermill":{"duration":0.017244,"end_time":"2025-05-20T09:34:17.744791","exception":false,"start_time":"2025-05-20T09:34:17.727547","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Generating a simple gradient background</font>**"]},{"cell_type":"code","execution_count":16,"id":"9161cc2d","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:17.77956Z","iopub.status.busy":"2025-05-20T09:34:17.779346Z","iopub.status.idle":"2025-05-20T09:34:17.783897Z","shell.execute_reply":"2025-05-20T09:34:17.783182Z"},"papermill":{"duration":0.02347,"end_time":"2025-05-20T09:34:17.785066","exception":false,"start_time":"2025-05-20T09:34:17.761596","status":"completed"},"tags":[]},"outputs":[],"source":["def generate_gradient_background(filename, size=(128, 32)):\n","    \"\"\"\n","    Generates a gradient background image and saves it to a specified file.\n","\n","    This function creates a grayscale image with a soft gradient effect, where the color transitions\n","    from a lighter gray at the top to a slightly darker gray at the bottom. The image is then blurred\n","    to create a smooth background effect.\n","\n","    Args:\n","        filename (str): The name of the file where the generated image will be saved.\n","        size (tuple, optional): The dimensions (width, height) of the generated image. Defaults to (128, 32).\n","\n","    The function uses the Python Imaging Library (PIL) to create and manipulate the image.\n","    \"\"\"\n","    img = Image.new('L', size, color=230)  # Lighter gray as a base\n","    draw = ImageDraw.Draw(img)\n","    for y in range(size[1]):\n","        # Soft gradient with low contrast\n","        color = int(230 - 20 * (y / size[1]))  # From light gray to slightly darker\n","        draw.line([(0, y), (size[0], y)], fill=color)\n","    # Background blur\n","    img = img.filter(ImageFilter.GaussianBlur(radius=2))\n","    img.save(os.path.join(BACKGROUND_DIR, filename))"]},{"cell_type":"markdown","id":"d5afaa32","metadata":{"papermill":{"duration":0.01728,"end_time":"2025-05-20T09:34:17.819204","exception":false,"start_time":"2025-05-20T09:34:17.801924","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Generate a background with noise (paper texture)</font>**"]},{"cell_type":"code","execution_count":17,"id":"e982a3e9","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:17.853825Z","iopub.status.busy":"2025-05-20T09:34:17.853482Z","iopub.status.idle":"2025-05-20T09:34:17.858084Z","shell.execute_reply":"2025-05-20T09:34:17.857419Z"},"papermill":{"duration":0.023221,"end_time":"2025-05-20T09:34:17.859285","exception":false,"start_time":"2025-05-20T09:34:17.836064","status":"completed"},"tags":[]},"outputs":[],"source":["def generate_paper_texture(filename, size=(128, 32)):\n","    img = Image.new('L', size, color=220)  # Lighter gray\n","    noise = np.random.normal(0, 5, size).astype(np.uint8)  # Less noise\n","    noise_img = Image.fromarray(noise)\n","    img.paste(noise_img, (0, 0), noise_img)\n","    # Blur for a softer effect\n","    img = img.filter(ImageFilter.GaussianBlur(radius=1.5))\n","    img.save(os.path.join(BACKGROUND_DIR, filename))"]},{"cell_type":"markdown","id":"1976223c","metadata":{"papermill":{"duration":0.016454,"end_time":"2025-05-20T09:34:17.892835","exception":false,"start_time":"2025-05-20T09:34:17.876381","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Creating multiple backgrounds</font>**"]},{"cell_type":"code","execution_count":18,"id":"609509bc","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:17.927321Z","iopub.status.busy":"2025-05-20T09:34:17.927118Z","iopub.status.idle":"2025-05-20T09:34:21.801382Z","shell.execute_reply":"2025-05-20T09:34:21.800717Z"},"papermill":{"duration":3.893396,"end_time":"2025-05-20T09:34:21.803118","exception":false,"start_time":"2025-05-20T09:34:17.909722","status":"completed"},"tags":[]},"outputs":[],"source":["for i in range(NUMBER_BACKGROUND_IMAGE):\n","    generate_gradient_background(f\"gradient_{i}.png\")\n","    generate_paper_texture(f\"paper_{i}.png\")"]},{"cell_type":"code","execution_count":19,"id":"f014c12e","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:21.839294Z","iopub.status.busy":"2025-05-20T09:34:21.839052Z","iopub.status.idle":"2025-05-20T09:34:21.842213Z","shell.execute_reply":"2025-05-20T09:34:21.84165Z"},"papermill":{"duration":0.022079,"end_time":"2025-05-20T09:34:21.843452","exception":false,"start_time":"2025-05-20T09:34:21.821373","status":"completed"},"tags":[]},"outputs":[],"source":["main_logger.info('Background images was generated.')"]},{"cell_type":"markdown","id":"d1896a7a","metadata":{"papermill":{"duration":0.016796,"end_time":"2025-05-20T09:34:21.87828","exception":false,"start_time":"2025-05-20T09:34:21.861484","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Load backgrounds (optional, add images to the \"backgrounds\" folder)</font>**"]},{"cell_type":"code","execution_count":20,"id":"a64e75f6","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:21.91273Z","iopub.status.busy":"2025-05-20T09:34:21.912407Z","iopub.status.idle":"2025-05-20T09:34:21.929028Z","shell.execute_reply":"2025-05-20T09:34:21.928045Z"},"papermill":{"duration":0.035208,"end_time":"2025-05-20T09:34:21.930341","exception":false,"start_time":"2025-05-20T09:34:21.895133","status":"completed"},"tags":[]},"outputs":[],"source":["background_files = (\n","    [os.path.join(BACKGROUND_DIR, f) for f in os.listdir(BACKGROUND_DIR) \n","     if f.endswith(('.png', '.jpg', '.jpeg'))] if os.path.exists(BACKGROUND_DIR) else []\n",")"]},{"cell_type":"code","execution_count":21,"id":"ee2cfb32","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:21.965031Z","iopub.status.busy":"2025-05-20T09:34:21.964801Z","iopub.status.idle":"2025-05-20T09:34:21.9683Z","shell.execute_reply":"2025-05-20T09:34:21.96748Z"},"papermill":{"duration":0.022226,"end_time":"2025-05-20T09:34:21.969555","exception":false,"start_time":"2025-05-20T09:34:21.947329","status":"completed"},"tags":[]},"outputs":[],"source":["main_logger.info('Background images was loaded for useing.')"]},{"cell_type":"markdown","id":"795c410b","metadata":{"papermill":{"duration":0.016392,"end_time":"2025-05-20T09:34:22.002813","exception":false,"start_time":"2025-05-20T09:34:21.986421","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">List of setting type of formats</font>**"]},{"cell_type":"code","execution_count":22,"id":"4a59bc2b","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.038079Z","iopub.status.busy":"2025-05-20T09:34:22.037847Z","iopub.status.idle":"2025-05-20T09:34:22.053381Z","shell.execute_reply":"2025-05-20T09:34:22.052461Z"},"papermill":{"duration":0.035086,"end_time":"2025-05-20T09:34:22.054693","exception":false,"start_time":"2025-05-20T09:34:22.019607","status":"completed"},"tags":[]},"outputs":[],"source":["formats = {\n","    \"Czech Republic\": [\n","        {\n","            \"regex\": r\"[A-Z]\\d[A-Z]{5}\",\n","            \"description\": \"One letter, one digit, five letters\",\n","            \"weight\": 0.95  # Kept the same\n","        },\n","        {\n","            \"regex\": r\"[A-Z]\\d-[A-Z]{5}\",\n","            \"description\": \"One letter, one digit, dash, five letters\",\n","            \"weight\": 0.05  # Kept the same\n","        }\n","    ],\n","    \"Germany\": [\n","        {\n","            \"regex\": r\"[A-Z]-[A-Z]{2} \\d{3}\",\n","            \"description\": \"One letter, dash, two letters, space, three digits\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce space and dash frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{4}\\d{2}\",\n","            \"description\": \"Four letters, two digits\",\n","            \"weight\": 0.15  # Increased from 0.1 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{5}\\d{1}\",\n","            \"description\": \"Five letters, one digit\",\n","            \"weight\": 0.7  # Kept the same\n","        }\n","    ],\n","    \"France\": [\n","        {\n","            \"regex\": r\"[A-Z]{2}-\\d{3}-[A-Z]{2}\",\n","            \"description\": \"Two letters, dash, three digits, dash, two letters\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{2} \\d{3} [A-Z]{2}\",\n","            \"description\": \"Two letters, space, three digits, space, two letters\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{2}\\d{3}[A-Z]{2}\",\n","            \"description\": \"Two letters, three digits, two letters\",\n","            \"weight\": 0.15  # Increased from 0.1 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{4}\\d{2}\",\n","            \"description\": \"Four letters, two digits\",\n","            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{5}\\d{1}\",\n","            \"description\": \"Five letters, one digit\",\n","            \"weight\": 0.45  # Kept the same\n","        }\n","    ],\n","    \"United Kingdom\": [\n","        {\n","            \"regex\": r\"[A-Z]{2}\\d{2} [A-Z]{3}\",\n","            \"description\": \"Two letters, two digits, space, three letters\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{2}\\d{2}[A-Z]{3}\",\n","            \"description\": \"Two letters, two digits, three letters\",\n","            \"weight\": 0.15  # Increased from 0.1 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{4}\\d{1}\",\n","            \"description\": \"Four letters, one digit\",\n","            \"weight\": 0.7  # Kept the same\n","        }\n","    ],\n","    \"Brazil\": [\n","        {\n","            \"regex\": r\"\\d{3}[A-Z]{4}\",\n","            \"description\": \"Three digits, four letters\",\n","            \"weight\": 0.35  # Increased from 0.3 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{4}\\d{2}\",\n","            \"description\": \"Four letters, two digits\",\n","            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{3}-\\d{2}-[A-Z]{2}\",\n","            \"description\": \"Three letters, dash, two digits, dash, two letters\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{5}\\d{1}\",\n","            \"description\": \"Five letters, one digit\",\n","            \"weight\": 0.4  # Reduced from 0.45 to balance overall distribution\n","        }\n","    ],\n","    \"Australia\": [\n","        {\n","            \"regex\": r\"[A-Z]{3}-\\d{3}\",\n","            \"description\": \"Three letters, dash, three digits\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{3} \\d{3}\",\n","            \"description\": \"Three letters, space, three digits\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{4}\\d{2}\",\n","            \"description\": \"Four letters, two digits\",\n","            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{5}\\d{1}\",\n","            \"description\": \"Five letters, one digit\",\n","            \"weight\": 0.6  # Increased from 0.55 to maintain letter frequency\n","        }\n","    ],\n","    \"Austria\": [\n","        {\n","            \"regex\": r\"\\d[A-Z]{4}\\d{2}\",\n","            \"description\": \"One digit, four letters, two digits\",\n","            \"weight\": 0.35  # Increased from 0.3 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{5}\\d{1}\",\n","            \"description\": \"Five letters, one digit\",\n","            \"weight\": 0.5  # Kept the same\n","        },\n","        {\n","            \"regex\": r\"\\d-[A-Z]{4}-\\d{2}\",\n","            \"description\": \"One digit, dash, four letters, dash, two digits\",\n","            \"weight\": 0.05  # Reduced from 0.1 to reduce dash frequency\n","        },\n","        {\n","            \"regex\": r\"\\d [A-Z]{4} \\d{2}\",\n","            \"description\": \"One digit, space, four letters, space, two digits\",\n","            \"weight\": 0.1  # Kept the same\n","        }\n","    ],\n","    \"Italy\": [\n","        {\n","            \"regex\": r\"[A-Z]{2} \\d{3}[A-Z]{2}\",\n","            \"description\": \"Two letters, space, three digits, space, two letters\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{2}-\\d{3}[A-Z]{2}\",\n","            \"description\": \"Two letters, dash, three digits, two letters\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{2}\\d{3}[A-Z]{2}\",\n","            \"description\": \"Two letters, three digits, two letters\",\n","            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{4}\\d{2}\",\n","            \"description\": \"Four letters, two digits\",\n","            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{5}\\d{1}\",\n","            \"description\": \"Five letters, one digit\",\n","            \"weight\": 0.5  # Kept the same\n","        }\n","    ],\n","    \"Belgium\": [\n","        {\n","            \"regex\": r\"\\d-[A-Z]{3}-\\d{3}\",\n","            \"description\": \"One digit, dash, three letters, dash, three digits\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{4}\\d{2}\",\n","            \"description\": \"Four letters, two digits\",\n","            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{5}\\d{1}\",\n","            \"description\": \"Five letters, one digit\",\n","            \"weight\": 0.55  # Kept the same\n","        },\n","        {\n","            \"regex\": r\"[A-Z] \\d{3} [A-Z]{3}\",\n","            \"description\": \"One letter, space, three digits, space, three letters\",\n","            \"weight\": 0.2  # Kept the same\n","        }\n","    ],\n","    \"Spain\": [\n","        {\n","            \"regex\": r\"[A-Z]{4}\\d{3}\",\n","            \"description\": \"Four letters, three digits\",\n","            \"weight\": 0.35  # Increased from 0.3 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{4}-\\d{2}-[A-Z]\",\n","            \"description\": \"Four letters, dash, two digits, dash, one letter\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{5}\\d{1}\",\n","            \"description\": \"Five letters, one digit\",\n","            \"weight\": 0.4  # Kept the same\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{4} \\d{2} [A-Z]\",\n","            \"description\": \"Four letters, space, two digits, space, one letter\",\n","            \"weight\": 0.1  # Kept the same\n","        }\n","    ],\n","    \"Hungary\": [\n","        {\n","            \"regex\": r\"[A-Z] \\d{2} [A-Z]{3}\",\n","            \"description\": \"One letter, space, two digits, space, three letters\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]\\d{2}[A-Z]{3}\",\n","            \"description\": \"One letter, two digits, three letters\",\n","            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{4}\\d{1}\",\n","            \"description\": \"Four letters, one digit\",\n","            \"weight\": 0.65  # Kept the same\n","        },\n","        {\n","            \"regex\": r\"[A-Z]\\d-[A-Z]{3}-\\d\",\n","            \"description\": \"One letter, one digit, dash, three letters, dash, one digit\",\n","            \"weight\": 0.1  # Kept the same\n","        }\n","    ],\n","    \"Norway\": [\n","        {\n","            \"regex\": r\"\\d{2}[A-Z]{5}\",\n","            \"description\": \"Two digits, five letters\",\n","            \"weight\": 0.35  # Increased from 0.3 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{2}-\\d{2}-[A-Z]{3}\",\n","            \"description\": \"Two letters, dash, two digits, dash, three letters\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{2} \\d{2} [A-Z]{3}\",\n","            \"description\": \"Two letters, space, two digits, space, three letters\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{5}\\d{1}\",\n","            \"description\": \"Five letters, one digit\",\n","            \"weight\": 0.35  # Increased from 0.3 to maintain letter frequency\n","        }\n","    ],\n","    \"Sweden\": [\n","        {\n","            \"regex\": r\"[A-Z]{3} \\d{3}\",\n","            \"description\": \"Three letters, space, three digits\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{4}\\d{2}\",\n","            \"description\": \"Four letters, two digits\",\n","            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{5}\\d{1}\",\n","            \"description\": \"Five letters, one digit\",\n","            \"weight\": 0.75  # Kept the same\n","        }\n","    ],\n","    \"Netherlands\": [\n","        {\n","            \"regex\": r\"[A-Z]{2}-\\d{2}-[A-Z]{2}\",\n","            \"description\": \"Two letters, dash, two digits, dash, two letters\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{2}\\d{2}[A-Z]{2}\",\n","            \"description\": \"Two letters, two digits, two letters\",\n","            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{4}\\d{1}\",\n","            \"description\": \"Four letters, one digit\",\n","            \"weight\": 0.55  # Kept the same\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{2} \\d{2} [A-Z]{2}\",\n","            \"description\": \"Two letters, space, two digits, space, two letters\",\n","            \"weight\": 0.2  # Reduced from 0.2 to maintain balance\n","        }\n","    ],\n","    \"Serbia\": [\n","        {\n","            \"regex\": r\"[A-Z]{2} \\d{3}-[A-Z]{2}\",\n","            \"description\": \"Two letters, space, three digits, dash, two letters\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce space and dash frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{2}\\d{3}[A-Z]{2}\",\n","            \"description\": \"Two letters, three digits, two letters\",\n","            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{4}\\d{2}\",\n","            \"description\": \"Four letters, two digits\",\n","            \"weight\": 0.05  # Kept the same\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{5}\\d{1}\",\n","            \"description\": \"Five letters, one digit\",\n","            \"weight\": 0.7  # Kept the same\n","        }\n","    ],\n","    \"Ukraine\": [\n","        {\n","            \"regex\": r\"\\d{2}[A-Z]{4}\\d{2}\",\n","            \"description\": \"Two digits, four letters, two digits\",\n","            \"weight\": 0.35  # Increased from 0.3 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{5}\\d{1}\",\n","            \"description\": \"Five letters, one digit\",\n","            \"weight\": 0.5  # Kept the same\n","        },\n","        {\n","            \"regex\": r\"\\d{2}-[A-Z]{4}-\\d\",\n","            \"description\": \"Two digits, dash, four letters, dash, one digit\",\n","            \"weight\": 0.05  # Reduced from 0.1 to reduce dash frequency\n","        },\n","        {\n","            \"regex\": r\"\\d{2} [A-Z]{4} \\d\",\n","            \"description\": \"Two digits, space, four letters, space, one digit\",\n","            \"weight\": 0.1  # Kept the same\n","        }\n","    ],\n","    \"USA_v1\": [\n","        {\n","            \"regex\": r\"[A-Z]{4}\\d{2}\",\n","            \"description\": \"Four letters, two digits\",\n","            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{5}\\d{1}\",\n","            \"description\": \"Five letters, one digit\",\n","            \"weight\": 0.9  # Reduced from 0.95 to balance overall distribution\n","        }\n","    ],\n","    \"USA_v2\": [\n","        {\n","            \"regex\": r\"\\d{3}-[A-Z]{3}\",\n","            \"description\": \"Three digits, dash, three letters\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce dash frequency\n","        },\n","        {\n","            \"regex\": r\"\\d{3} [A-Z]{3}\",\n","            \"description\": \"Three digits, space, three letters\",\n","            \"weight\": 0.15  # Reduced from 0.2 to reduce space frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{4}\\d{2}\",\n","            \"description\": \"Four letters, two digits\",\n","            \"weight\": 0.1  # Increased from 0.05 to boost digit frequency\n","        },\n","        {\n","            \"regex\": r\"[A-Z]{5}\\d{1}\",\n","            \"description\": \"Five letters, one digit\",\n","            \"weight\": 0.6  # Increased from 0.55 to maintain letter frequency\n","        }\n","    ]\n","}"]},{"cell_type":"markdown","id":"ae480043","metadata":{"papermill":{"duration":0.017145,"end_time":"2025-05-20T09:34:22.088716","exception":false,"start_time":"2025-05-20T09:34:22.071571","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Random text generation function</font>**"]},{"cell_type":"code","execution_count":23,"id":"821a4495","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.124662Z","iopub.status.busy":"2025-05-20T09:34:22.124385Z","iopub.status.idle":"2025-05-20T09:34:22.131681Z","shell.execute_reply":"2025-05-20T09:34:22.13102Z"},"papermill":{"duration":0.026332,"end_time":"2025-05-20T09:34:22.132896","exception":false,"start_time":"2025-05-20T09:34:22.106564","status":"completed"},"tags":[]},"outputs":[],"source":["def generate_random_license_plate_from_regex(regex_format):\n","    license_plate = \"\"\n","    i = 0\n","    \n","    while i < len(regex_format):\n","        char = regex_format[i]\n","\n","        # Handle escaped sequences like \\d or \\w\n","        if char == '\\\\' and i + 1 < len(regex_format):\n","            next_char = regex_format[i + 1]\n","            repeat = 1\n","            i += 2  # Skip backslash and the next character\n","\n","            # Check for repetition pattern {n}\n","            if i < len(regex_format) and regex_format[i] == '{':\n","                match = re.match(r\"\\{(\\d+)\\}\", regex_format[i:])\n","                if match:\n","                    repeat = int(match.group(1))\n","                    i += len(match.group(0))  # Skip {n}\n","\n","            if next_char == 'd':\n","                license_plate += ''.join(random.choice(string.digits) for _ in range(repeat))\n","            elif next_char == 'w':\n","                license_plate += ''.join(random.choice(string.ascii_uppercase) for _ in range(repeat))\n","            else:\n","                license_plate += next_char  # Treat as literal if not \\d or \\w\n","\n","        # Handle character classes like [A-Z] or [0-9]\n","        elif char == '[':\n","            j = regex_format.find(']', i)\n","            if j != -1:\n","                options = regex_format[i+1:j]\n","                i = j + 1  # Move past ]\n","\n","                repeat = 1\n","                if i < len(regex_format) and regex_format[i] == '{':\n","                    match = re.match(r\"\\{(\\d+)\\}\", regex_format[i:])\n","                    if match:\n","                        repeat = int(match.group(1))\n","                        i += len(match.group(0))  # Skip {n}\n","\n","                if options == 'A-Z':\n","                    license_plate += ''.join(random.choice(string.ascii_uppercase) for _ in range(repeat))\n","                elif options == '0-9':\n","                    license_plate += ''.join(random.choice(string.digits) for _ in range(repeat))\n","                else:\n","                    license_plate += ''.join(random.choice(options) for _ in range(repeat))\n","            else:\n","                license_plate += char  # Unmatched [, treat as literal\n","\n","        # Handle literal characters (e.g., space, dash)\n","        else:\n","            license_plate += char\n","            i += 1\n","\n","    return license_plate"]},{"cell_type":"code","execution_count":24,"id":"d8161265","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.169104Z","iopub.status.busy":"2025-05-20T09:34:22.168896Z","iopub.status.idle":"2025-05-20T09:34:22.173108Z","shell.execute_reply":"2025-05-20T09:34:22.172401Z"},"papermill":{"duration":0.024346,"end_time":"2025-05-20T09:34:22.174272","exception":false,"start_time":"2025-05-20T09:34:22.149926","status":"completed"},"tags":[]},"outputs":[],"source":["def generate_random_license_plate(formats):\n","    # Choose a random country\n","    country = random.choice(list(formats.keys()))\n","    country_formats = formats[country]\n","\n","    # If the format is a list (multiple options), select by weight\n","    if isinstance(country_formats, list):\n","        weights = [fmt[\"weight\"] for fmt in country_formats]\n","        chosen_format = random.choices(country_formats, weights=weights, k=1)[0]\n","        regex_format = chosen_format[\"regex\"]\n","    else:\n","        regex_format = country_formats[\"regex\"]\n","\n","    # Generate license plate according to selected regex\n","    license_plate = generate_random_license_plate_from_regex(regex_format)\n","    return license_plate, country"]},{"cell_type":"code","execution_count":25,"id":"f223aad6","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.208229Z","iopub.status.busy":"2025-05-20T09:34:22.208015Z","iopub.status.idle":"2025-05-20T09:34:22.214986Z","shell.execute_reply":"2025-05-20T09:34:22.21414Z"},"papermill":{"duration":0.025581,"end_time":"2025-05-20T09:34:22.21629","exception":false,"start_time":"2025-05-20T09:34:22.190709","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Country: Italy, License Plate: ELTPU9\n","Country: France, License Plate: PIRHG7\n","Country: USA_v2, License Plate: PMUEH2\n","Country: USA_v1, License Plate: AVYCF9\n","Country: Germany, License Plate: AIPTX6\n","Country: Netherlands, License Plate: ZSOE5\n","Country: United Kingdom, License Plate: PG46 YUJ\n","Country: Netherlands, License Plate: MSLR9\n","Country: Netherlands, License Plate: KVAI9\n","Country: Australia, License Plate: KRSSD3\n"]}],"source":["# Test code\n","for _ in range(10):\n","    license_plate, country = generate_random_license_plate(formats)\n","    print(f\"Country: {country}, License Plate: {license_plate}\")\n","    main_logger.debug(f'Testing generation of Licence Plate text\\n: Country: {country}, License Plate: {license_plate}\\n')"]},{"cell_type":"markdown","id":"bc5220c3","metadata":{"papermill":{"duration":0.016935,"end_time":"2025-05-20T09:34:22.249648","exception":false,"start_time":"2025-05-20T09:34:22.232713","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Function for clean labels of file</font>**\n","- Open labels.txt and ensure that all labels only contain characters from CHARSET. If there are any invalid characters, clean the file:"]},{"cell_type":"code","execution_count":26,"id":"65aad406","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.284265Z","iopub.status.busy":"2025-05-20T09:34:22.284059Z","iopub.status.idle":"2025-05-20T09:34:22.289279Z","shell.execute_reply":"2025-05-20T09:34:22.288385Z"},"papermill":{"duration":0.024262,"end_time":"2025-05-20T09:34:22.290656","exception":false,"start_time":"2025-05-20T09:34:22.266394","status":"completed"},"tags":[]},"outputs":[],"source":["def clean_labels_file(labels_file, valid_chars):\n","    \"\"\"\n","    Cleans the labels file by removing invalid characters from each label.\n","\n","    Args:\n","        labels_file (str): Path to the labels file.\n","        valid_chars (set): Set of valid characters allowed in labels.\n","    \"\"\"\n","    with open(labels_file, 'r') as f:\n","        lines = f.readlines()\n","    \n","    cleaned_lines = []\n","    num_modified = 0\n","    num_removed = 0\n","    for line in lines:\n","        parts = line.strip().split('\\t')\n","        if len(parts) != 2:\n","            num_removed += 1\n","            continue\n","        img_path, label = parts\n","        cleaned_label = ''.join(c for c in label if c in valid_chars)\n","        if cleaned_label:  # Only keep non-empty labels\n","            if cleaned_label != label:\n","                num_modified += 1\n","            cleaned_lines.append(f\"{img_path}\\t{cleaned_label}\\n\")\n","        else:\n","            num_removed += 1\n","    \n","    with open(labels_file, 'w') as f:\n","        f.writelines(cleaned_lines)\n","    \n","    print(f\"Cleaned {labels_file}: {num_modified} labels modified, {num_removed} labels removed.\")\n","    function_logger.info(f\"Cleaned {labels_file}: {num_modified} labels modified, {num_removed} labels removed.\")"]},{"cell_type":"markdown","id":"ce5f820a","metadata":{"papermill":{"duration":0.016863,"end_time":"2025-05-20T09:34:22.325073","exception":false,"start_time":"2025-05-20T09:34:22.30821","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Functions for adding noise and distortions</font>**"]},{"cell_type":"code","execution_count":27,"id":"f25c1f54","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.359709Z","iopub.status.busy":"2025-05-20T09:34:22.359493Z","iopub.status.idle":"2025-05-20T09:34:22.365066Z","shell.execute_reply":"2025-05-20T09:34:22.364456Z"},"papermill":{"duration":0.023891,"end_time":"2025-05-20T09:34:22.366141","exception":false,"start_time":"2025-05-20T09:34:22.34225","status":"completed"},"tags":[]},"outputs":[],"source":["def add_noise_and_distortion(img):\n","    \"\"\"\n","    Adds random noise and distortion effects to an input image.\n","\n","    This function takes an image as input and applies random Gaussian noise, rotation, and perspective distortion to simulate real-world imperfections. \n","    The modifications are applied randomly to create variability in the output.\n","\n","    Args:\n","        img (PIL.Image.Image): The input image to which noise and distortion will be applied.\n","\n","    Returns:\n","        PIL.Image.Image: The modified image with added noise and distortion effects.\n","\n","    The function uses NumPy for array manipulations and OpenCV for image transformations.\n","    \"\"\"\n","    img_array = np.array(img)\n","\n","    # Add Gaussian noise\n","    if random.random() > 0.5:\n","        noise = np.random.normal(0, random.randint(10, 25), img_array.shape).astype(np.uint8)\n","        img_array = cv2.add(img_array, noise)\n","\n","    # Apply rotation\n","    angle = random.uniform(-5, 5)\n","    rows, cols = img_array.shape[:2]\n","    M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n","    img_array = cv2.warpAffine(img_array, M, (cols, rows))\n","\n","    # Apply perspective distortion\n","    src_points = np.float32([[0, 0], [cols-1, 0], [0, rows-1], [cols-1, rows-1]])\n","    dst_points = np.float32([\n","        [random.uniform(0, 5), random.uniform(0, 5)],\n","        [cols-1-random.uniform(0, 5), random.uniform(0, 5)],\n","        [random.uniform(0, 5), rows-1-random.uniform(0, 5)],\n","        [cols-1-random.uniform(0, 5), rows-1-random.uniform(0, 5)]\n","    ])\n","    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n","    img_array = cv2.warpPerspective(img_array, matrix, (cols, rows))\n","\n","    return Image.fromarray(img_array)"]},{"cell_type":"markdown","id":"93c8be77","metadata":{"papermill":{"duration":0.017118,"end_time":"2025-05-20T09:34:22.40007","exception":false,"start_time":"2025-05-20T09:34:22.382952","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Improved image generation feature</font>**"]},{"cell_type":"code","execution_count":28,"id":"2ad5d73f","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.43501Z","iopub.status.busy":"2025-05-20T09:34:22.434718Z","iopub.status.idle":"2025-05-20T09:34:22.443088Z","shell.execute_reply":"2025-05-20T09:34:22.44245Z"},"papermill":{"duration":0.027026,"end_time":"2025-05-20T09:34:22.444313","exception":false,"start_time":"2025-05-20T09:34:22.417287","status":"completed"},"tags":[]},"outputs":[],"source":["def generate_synthetic_image(text, font_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n","    \"\"\"\n","    Generates a synthetic image with specified text and font, optionally using a background image.\n","\n","    This function creates an image with a given text rendered using a specified font. \n","    The image can have a background selected from available background files or a generated gradient background. \n","    The text is positioned randomly within the image, and the function ensures that the text fits within the image dimensions by adjusting the font size or shortening the text if necessary. \n","    The image is then modified with noise and distortion effects to simulate real-world conditions.\n","\n","    Args:\n","        text (str): The text to be rendered on the image.\n","        font_path (str): The file path to the TrueType font to be used for rendering the text.\n","        img_size (tuple, optional): The dimensions (width, height) of the generated image. Defaults to (IMG_WIDTH, IMG_HEIGHT).\n","\n","    Returns:\n","        PIL.Image.Image: The generated synthetic image with the specified text and effects.\n","\n","    The function uses the Python Imaging Library (PIL) for image creation and manipulation, and it relies on the `add_noise_and_distortion` function to apply additional effects to the image.\n","    \"\"\"\n","    # Background\n","    if background_files:\n","        bg_path = random.choice(background_files)\n","        img = Image.open(bg_path).convert('L').resize(img_size)\n","    else:\n","        img = Image.new('L', img_size, color=230)\n","        draw = ImageDraw.Draw(img)\n","        for y in range(img_size[1]):\n","            color = int(230 - 20 * (y / img_size[1]))\n","            draw.line([(0, y), (img_size[0], y)], fill=color)\n","        img = img.filter(ImageFilter.GaussianBlur(radius=2))\n","\n","    draw = ImageDraw.Draw(img)\n","\n","    # Iterative font and text editing\n","    font_size = random.randint(20, min(IMG_HEIGHT-2, 28))\n","    max_attempts = 5  # Limiting the number of attempts\n","    for attempt in range(max_attempts):\n","        font = ImageFont.truetype(font_path, font_size)\n","        text_bbox = draw.textbbox((0, 0), text, font=font)\n","        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n","\n","        if text_width <= IMG_WIDTH - 10:  # Text will fit\n","            break\n","        elif len(text) > 1:  # Shorten the text if it is too long.\n","            text = text[:len(text)//2]\n","        else:  # Reduce font size\n","            font_size = max(10, font_size - 5)  # Minimum size 10\n","\n","    # If that doesn't work, use a minimal font and single-letter text.\n","    if text_width > IMG_WIDTH - 10:\n","        text = text[0]  # Use the first letter\n","        font_size = 10\n","        font = ImageFont.truetype(font_path, font_size)\n","        text_bbox = draw.textbbox((0, 0), text, font=font)\n","        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n","\n","    # Text position\n","    x = random.randint(5, max(5, IMG_WIDTH - text_width - 5))\n","    y = random.randint(5, max(5, IMG_HEIGHT - text_height - 5))\n","\n","    # Highlighting text\n","    text_color = random.randint(0, 50)\n","    outline_color = 200\n","    for offset_x in [-1, 0, 1]:\n","        for offset_y in [-1, 0, 1]:\n","            if offset_x != 0 or offset_y != 0:\n","                draw.text((x + offset_x, y + offset_y), text, font=font, fill=outline_color)\n","    draw.text((x, y), text, font=font, fill=text_color)\n","\n","    # Noise and distortion\n","    img = add_noise_and_distortion(img)\n","    return img"]},{"cell_type":"markdown","id":"515807b7","metadata":{"papermill":{"duration":0.016546,"end_time":"2025-05-20T09:34:22.477879","exception":false,"start_time":"2025-05-20T09:34:22.461333","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Function for splitting labels</font>**"]},{"cell_type":"code","execution_count":29,"id":"a7ecc201","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.511805Z","iopub.status.busy":"2025-05-20T09:34:22.51153Z","iopub.status.idle":"2025-05-20T09:34:22.515515Z","shell.execute_reply":"2025-05-20T09:34:22.514642Z"},"papermill":{"duration":0.022554,"end_time":"2025-05-20T09:34:22.516935","exception":false,"start_time":"2025-05-20T09:34:22.494381","status":"completed"},"tags":[]},"outputs":[],"source":["def split_labels(labels, label_lengths):\n","    \"\"\"\n","    Splits a sequence of labels into sub-sequences based on specified lengths.\n","    \n","    This function takes a single concatenated sequence of labels and splits it into multiple sub-sequences. \n","    The lengths of these sub-sequences are specified by the `label_lengths` parameter. \n","    Each sub-sequence is extracted from the `labels` sequence and appended to a list, which is then returned.\n","    \n","    Args:\n","        labels (str or list): The concatenated sequence of labels to be split. This can be a string or a list of characters/elements.\n","        label_lengths (list of int): A list of integers where each integer specifies the length of a corresponding sub-sequence to be extracted from `labels`.\n","    \n","    Returns:\n","        list: A list of sub-sequences extracted from `labels` according to the specified lengths in `label_lengths`.\n","    \n","    Example:\n","        >>> split_labels(\"abcdefgh\", [2, 3, 3])\n","        ['ab', 'cde', 'fgh']\n","    \"\"\"\n","    split_labels = []\n","    start = 0\n","    for length in label_lengths:\n","        split_labels.append(labels[start:start + length])\n","        start += length\n","    return split_labels"]},{"cell_type":"markdown","id":"d04a57a3","metadata":{"papermill":{"duration":0.017064,"end_time":"2025-05-20T09:34:22.55088","exception":false,"start_time":"2025-05-20T09:34:22.533816","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Function of Beam search decoding</font>**"]},{"cell_type":"code","execution_count":30,"id":"8de0cac7","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.58632Z","iopub.status.busy":"2025-05-20T09:34:22.586102Z","iopub.status.idle":"2025-05-20T09:34:22.593171Z","shell.execute_reply":"2025-05-20T09:34:22.592538Z"},"papermill":{"duration":0.02561,"end_time":"2025-05-20T09:34:22.594356","exception":false,"start_time":"2025-05-20T09:34:22.568746","status":"completed"},"tags":[]},"outputs":[],"source":["def beam_search_decode(output, idx_to_char, target_lengths, beam_width=5, blank_penalty=0.1, length_penalty=0.1, global_step=0):\n","    \"\"\"\n","    Performs beam search decoding on the model's output logits.\n","\n","    Args:\n","        output (torch.Tensor): Model output logits, shape (T, B, C).\n","        idx_to_char (dict): Mapping from indices to characters.\n","        target_lengths (torch.Tensor): Target label lengths for each batch.\n","        beam_width (int): Number of beams to keep during search.\n","        blank_penalty (float): Penalty for blank token.\n","        length_penalty (float): Penalty for sequence length.\n","        global_step (int): Global step for logging purposes.\n","\n","    Returns:\n","        list: List of decoded strings for each batch.\n","    \"\"\"\n","    T, B, C = output.shape\n","    output = output.softmax(2)  # Convert logits to probabilities\n","\n","    decoded_texts = []\n","    for b in range(B):\n","        # Get the probabilities for this batch\n","        probs = output[:, b, :]  # (T, C)\n","\n","        # Initialize the beam with an empty sequence\n","        beams = [([], 0.0)]  # (sequence, log_prob)\n","\n","        # For each time step\n","        for t in range(T):\n","            new_beams = []\n","            for seq, log_prob in beams:\n","                # For each possible character\n","                for c in range(C):\n","                    prob = probs[t, c].item()\n","                    if prob < 1e-10:  # Avoid log(0)\n","                        continue\n","                    new_log_prob = log_prob + math.log(prob)\n","\n","                    # Apply blank penalty\n","                    if c == 0:  # Blank token\n","                        new_log_prob += blank_penalty\n","\n","                    new_seq = seq + [c]\n","                    new_beams.append((new_seq, new_log_prob))\n","\n","            # Keep the top beam_width sequences\n","            new_beams.sort(key=lambda x: x[1], reverse=True)\n","            beams = new_beams[:beam_width]\n","\n","        # Apply length penalty to the final beams\n","        beams = [(seq, log_prob + length_penalty * len(seq)) for seq, log_prob in beams]\n","        beams.sort(key=lambda x: x[1], reverse=True)\n","        best_seq = beams[0][0]  # Best sequence\n","\n","        # Convert indices to characters, skipping blanks and duplicates\n","        decoded = []\n","        prev_char = None\n","        for idx in best_seq:\n","            if idx == 0:  # Skip blank token\n","                continue\n","            char = idx_to_char.get(idx, '')\n","            if char and char != prev_char:  # Skip duplicates\n","                decoded.append(char)\n","            prev_char = char\n","\n","        decoded_text = ''.join(decoded)\n","        decoded_texts.append(decoded_text)\n","\n","    return decoded_texts"]},{"cell_type":"markdown","id":"4fb775b2","metadata":{"papermill":{"duration":0.016787,"end_time":"2025-05-20T09:34:22.628357","exception":false,"start_time":"2025-05-20T09:34:22.61157","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Custom collate function</font>**"]},{"cell_type":"code","execution_count":31,"id":"751c61ea","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.662746Z","iopub.status.busy":"2025-05-20T09:34:22.662499Z","iopub.status.idle":"2025-05-20T09:34:22.666394Z","shell.execute_reply":"2025-05-20T09:34:22.665637Z"},"papermill":{"duration":0.022527,"end_time":"2025-05-20T09:34:22.667705","exception":false,"start_time":"2025-05-20T09:34:22.645178","status":"completed"},"tags":[]},"outputs":[],"source":["def custom_collate_fn(batch):\n","    \"\"\"\n","    Custom collate function for combining a batch of data samples into a single batch.\n","\n","    This function is used to process a batch of data samples, typically for use in a data loader during model training or evaluation. It stacks images, concatenates labels, and converts label lengths into tensors, preparing the data for efficient processing in a neural network.\n","\n","    Args:\n","        batch (list of tuples): A list where each element is a tuple containing:\n","            - An image tensor.\n","            - A label tensor.\n","            - An integer representing the length of the label.\n","\n","    Returns:\n","        tuple: A tuple containing:\n","            - images (torch.Tensor): A tensor of stacked images from the batch.\n","            - labels (torch.Tensor): A concatenated tensor of labels from the batch.\n","            - label_lengths (torch.Tensor): A tensor of label lengths from the batch.\n","\n","    The function ensures that the images, labels, and label lengths are properly formatted as tensors, making them compatible with PyTorch operations.\n","    \"\"\"\n","    images, labels, label_lengths = zip(*batch)\n","    # Stack images (all same size)\n","    images = torch.stack(images, dim=0)\n","    # Concatenate labels into a flat tensor\n","    labels = torch.cat(labels, dim=0)\n","    # Convert label_lengths to tensor\n","    label_lengths = torch.tensor(label_lengths, dtype=torch.long)\n","    return images, labels, label_lengths"]},{"cell_type":"markdown","id":"7c8d7d6e","metadata":{"papermill":{"duration":0.016831,"end_time":"2025-05-20T09:34:22.701393","exception":false,"start_time":"2025-05-20T09:34:22.684562","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Analyze dataset char frequency</font>**"]},{"cell_type":"code","execution_count":32,"id":"2371b863","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.735533Z","iopub.status.busy":"2025-05-20T09:34:22.735294Z","iopub.status.idle":"2025-05-20T09:34:22.741322Z","shell.execute_reply":"2025-05-20T09:34:22.740518Z"},"papermill":{"duration":0.024092,"end_time":"2025-05-20T09:34:22.742474","exception":false,"start_time":"2025-05-20T09:34:22.718382","status":"completed"},"tags":[]},"outputs":[],"source":["def analyze_dataset_char_frequency(labels_file, charset):\n","    \"\"\"\n","    Analyzes the character frequency in the generated dataset and displays a progress bar.\n","    \n","    Args:\n","        labels_file (str): Path to the labels file (e.g., LABELS_FILE).\n","        charset (str): String containing all possible characters (e.g., CHARSET).\n","    \n","    Returns:\n","        dict: Dictionary with character frequencies.\n","    \"\"\"\n","    if not os.path.exists(labels_file):\n","        print(f\"Error: Labels file '{labels_file}' does not exist!\")\n","        function_logger.error(f\"Error: Labels file '{labels_file}' does not exist!\")\n","        return {}\n","\n","    # Read labels and extract texts\n","    with open(labels_file, 'r') as f:\n","        labels = [line.split('\\t')[1].strip() for line in f if '\\t' in line]\n","\n","    if not labels:\n","        print(\"Error: No valid labels found in the file!\")\n","        return {}\n","\n","    # Count character frequencies\n","    all_chars = ''.join(labels)\n","    char_counts = Counter(all_chars)\n","\n","    # Prepare data for the bar plot\n","    chars = list(charset)\n","    frequencies = [char_counts.get(char, 0) for char in chars]\n","\n","    # Create a progress bar (bar plot)\n","    plt.figure(figsize=(12, 6))\n","    plt.bar(chars, frequencies, color='skyblue')\n","    plt.xlabel('Characters')\n","    plt.ylabel('Frequency')\n","    plt.title('Character Frequency in Dataset')\n","    plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n","    plt.tight_layout()\n","\n","    # Display the plot\n","    plt.show()\n","\n","    # Print summary\n","    total_chars = sum(frequencies)\n","    print(f\"Total characters analyzed: {total_chars}\")\n","    print(\"Character frequencies:\", dict(char_counts))\n","    function_logger.debug(f\"Total characters analyzed: {total_chars}\")\n","    function_logger.debug(f\"Character frequencies: {dict(char_counts)}\")\n","\n","    return dict(char_counts)"]},{"cell_type":"markdown","id":"d64c7b12","metadata":{"papermill":{"duration":0.016819,"end_time":"2025-05-20T09:34:22.776013","exception":false,"start_time":"2025-05-20T09:34:22.759194","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Generating a data file</font>**"]},{"cell_type":"code","execution_count":33,"id":"5997085d","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.810863Z","iopub.status.busy":"2025-05-20T09:34:22.810636Z","iopub.status.idle":"2025-05-20T09:34:22.818079Z","shell.execute_reply":"2025-05-20T09:34:22.817254Z"},"papermill":{"duration":0.025989,"end_time":"2025-05-20T09:34:22.819254","exception":false,"start_time":"2025-05-20T09:34:22.793265","status":"completed"},"tags":[]},"outputs":[],"source":["def create_synthetic_dataset(num_samples):\n","    \"\"\"\n","    Creates a synthetic dataset with images and corresponding labels.\n","    \n","    Args:\n","        num_samples (int): Number of images to generate.\n","    \n","    Notes:\n","        It uses global variables: OUTPUT_DIR, LABELS_FILE, font_files, MAX_TEXT_LENGTH, MIN_TEXT_LENGTH, CHARSET.\n","        It assumes the existence of the generate_synthetic_image and generate_random_license_plate functions,\n","        and access to font_files.\n","    \"\"\"\n","    # Ensure OUTPUT_DIR exists\n","    if not os.path.exists(OUTPUT_DIR):\n","        os.makedirs(OUTPUT_DIR)\n","        print(f\"Created directory: {OUTPUT_DIR}\")\n","        function_logger.info(f\"Created directory: {OUTPUT_DIR}\")\n","\n","    # Define valid characters based on CHARSET\n","    valid_chars = set(CHARSET)  # CHARSET = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789- \"\n","    \n","    labels = []\n","    for i in range(num_samples):\n","        # Generate text for a license plate\n","        text, country = generate_random_license_plate(formats)\n","        if not text:\n","            function_logger.warning(f\"Skipping sample {i}: Empty text generated.\")\n","            continue  # Skip if text is empty\n","\n","        # Ensure the generated text only contains valid characters\n","        cleaned_text = ''.join(c for c in text if c in valid_chars)\n","        if not cleaned_text:\n","            function_logger.warning(f\"Skipping sample {i}: No valid characters in text '{text}'.\")\n","            continue  # Skip if the cleaned text is empty\n","\n","        # Random font selection\n","        font_path = random.choice(font_files)\n","        \n","        # Image generation\n","        try:\n","            img = generate_synthetic_image(cleaned_text, font_path)\n","            img_name = f\"img_{i:05d}.png\"\n","            img_path = os.path.join(OUTPUT_DIR, img_name)\n","            img.save(img_path)\n","        except Exception as e:\n","            function_logger.error(f\"Failed to generate image for sample {i} (Text: {cleaned_text}): {str(e)}\")\n","            continue\n","\n","        # Save the label\n","        labels.append(f\"{img_name}\\t{cleaned_text}\")\n","        \n","        # Progress report\n","        if i % 100 == 0:\n","            print(f\"Generated {i}/{num_samples} images (Country: {country}, Text: {cleaned_text})\")\n","            function_logger.debug(f\"Generated {i}/{num_samples} images (Country: {country}, Text: {cleaned_text})\")\n","\n","    # Save labels to a file\n","    if labels:\n","        with open(LABELS_FILE, 'w') as f:\n","            f.write(\"\\n\".join(labels))\n","        print(f\"Labels written to '{LABELS_FILE}' (before cleaning).\")\n","        function_logger.debug(f\"Labels written to '{LABELS_FILE}' (before cleaning).\")\n","\n","        # Clean the labels file to ensure no invalid characters remain\n","        clean_labels_file(LABELS_FILE, valid_chars)\n","\n","        # Analyze and display character frequency\n","        analyze_dataset_char_frequency(LABELS_FILE, CHARSET)\n","        \n","        print(f\"Dataset generated! Images saved in '{OUTPUT_DIR}', labels in '{LABELS_FILE}'\")\n","        function_logger.info(f\"Dataset generated! Images saved in '{OUTPUT_DIR}', labels in '{LABELS_FILE}'\")\n","    else:\n","        print(\"No labels generated! Check the generate_random_license_plate function or font files.\")\n","        function_logger.error(\"No labels generated! Check the generate_random_license_plate function or font files.\")"]},{"cell_type":"markdown","id":"ae48472d","metadata":{"papermill":{"duration":0.016465,"end_time":"2025-05-20T09:34:22.853242","exception":false,"start_time":"2025-05-20T09:34:22.836777","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Mapping characters to indices and back</font>**\n","-------------------"]},{"cell_type":"code","execution_count":34,"id":"c7c0ca9d","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.887901Z","iopub.status.busy":"2025-05-20T09:34:22.887609Z","iopub.status.idle":"2025-05-20T09:34:22.890745Z","shell.execute_reply":"2025-05-20T09:34:22.889942Z"},"papermill":{"duration":0.02189,"end_time":"2025-05-20T09:34:22.892089","exception":false,"start_time":"2025-05-20T09:34:22.870199","status":"completed"},"tags":[]},"outputs":[],"source":["num_chars = len(CHARSET) + 1"]},{"cell_type":"code","execution_count":35,"id":"dd1935eb","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.927114Z","iopub.status.busy":"2025-05-20T09:34:22.926881Z","iopub.status.idle":"2025-05-20T09:34:22.930295Z","shell.execute_reply":"2025-05-20T09:34:22.929516Z"},"papermill":{"duration":0.022215,"end_time":"2025-05-20T09:34:22.931431","exception":false,"start_time":"2025-05-20T09:34:22.909216","status":"completed"},"tags":[]},"outputs":[],"source":["char_to_idx = {char: idx + 1 for idx, char in enumerate(CHARSET)}  # 0 is reserved for blank (CTC)\n","idx_to_char = {idx: char for char, idx in char_to_idx.items()}"]},{"cell_type":"code","execution_count":36,"id":"de4bc50b","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:22.965675Z","iopub.status.busy":"2025-05-20T09:34:22.965436Z","iopub.status.idle":"2025-05-20T09:34:22.968756Z","shell.execute_reply":"2025-05-20T09:34:22.967955Z"},"papermill":{"duration":0.021778,"end_time":"2025-05-20T09:34:22.969958","exception":false,"start_time":"2025-05-20T09:34:22.94818","status":"completed"},"tags":[]},"outputs":[],"source":["main_logger.info('Mapping characters to indices and back was done.')"]},{"cell_type":"markdown","id":"0544ba66","metadata":{"papermill":{"duration":0.01726,"end_time":"2025-05-20T09:34:23.00411","exception":false,"start_time":"2025-05-20T09:34:22.98685","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Test regex generation</font>**\n","-------------------"]},{"cell_type":"markdown","id":"37367002","metadata":{"papermill":{"duration":0.016921,"end_time":"2025-05-20T09:34:23.037726","exception":false,"start_time":"2025-05-20T09:34:23.020805","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Custom dataset</font>**\n","-------------------"]},{"cell_type":"code","execution_count":37,"id":"7805c588","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:23.07292Z","iopub.status.busy":"2025-05-20T09:34:23.072703Z","iopub.status.idle":"2025-05-20T09:34:23.078211Z","shell.execute_reply":"2025-05-20T09:34:23.077519Z"},"papermill":{"duration":0.025034,"end_time":"2025-05-20T09:34:23.07955","exception":false,"start_time":"2025-05-20T09:34:23.054516","status":"completed"},"tags":[]},"outputs":[],"source":["class OCRDataset(Dataset):\n","    \"\"\"\n","    A custom dataset class for Optical Character Recognition (OCR) tasks.\n","\n","    This class extends PyTorch's Dataset class and is used to load and preprocess images and their corresponding labels for OCR tasks. It reads image paths and labels from a file and provides methods to access the data.\n","\n","    Args:\n","        Dataset (torch.utils.data.Dataset): The base dataset class from PyTorch.\n","    \"\"\"\n","    def __init__(self, image_dir, labels_file):\n","        \"\"\"\n","        Initializes the OCRDataset with the directory containing images and the file containing labels.\n","\n","        Args:\n","            image_dir (str): The directory path where the images are stored.\n","            labels_file (str): The file path containing the labels corresponding to the images. The file should have each line formatted as 'image_path\\tlabel'.\n","        \"\"\"\n","        self.image_dir = image_dir\n","        self.labels_file = labels_file\n","        self.data = []\n","        with open(labels_file, 'r') as f:\n","            for line in f:\n","                if not line.strip():  # Skip empty lines\n","                    continue\n","                image_path, label = line.strip().split('\\t')\n","                label_length = len(label)\n","                self.data.append((image_path, label, label_length))\n","\n","    def __len__(self):\n","        \"\"\"_summary_\n","\n","        Returns:\n","            _type_: _description_\n","        \"\"\"\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        image_path, label, label_length = self.data[idx]\n","        image = Image.open(os.path.join(self.image_dir, image_path)).convert('L')\n","        image = transforms.ToTensor()(image)\n","        label_encoded = torch.tensor([char_to_idx[c] for c in label], dtype=torch.long)\n","        return image, label_encoded, label_length"]},{"cell_type":"markdown","id":"aaf810d9","metadata":{"papermill":{"duration":0.018253,"end_time":"2025-05-20T09:34:23.115983","exception":false,"start_time":"2025-05-20T09:34:23.09773","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Custom CTC Loss with Blank Penalty</font>**\n","-------------------\n","> CTC Loss with Entropy Regularization"]},{"cell_type":"code","execution_count":38,"id":"2a466425","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:23.153426Z","iopub.status.busy":"2025-05-20T09:34:23.153202Z","iopub.status.idle":"2025-05-20T09:34:23.159318Z","shell.execute_reply":"2025-05-20T09:34:23.158731Z"},"papermill":{"duration":0.0266,"end_time":"2025-05-20T09:34:23.160536","exception":false,"start_time":"2025-05-20T09:34:23.133936","status":"completed"},"tags":[]},"outputs":[],"source":["class CTCLossWithBlankPenalty(nn.Module):\n","    \"\"\"\n","    A custom loss module that extends the Connectionist Temporal Classification (CTC) loss with additional penalties.\n","\n","    This class adds penalties for blank predictions and entropy to the standard CTC loss, which is commonly used in sequence-to-sequence tasks like speech recognition and OCR. \n","    The penalties help to regularize the model and improve convergence during training.\n","\n","    Args:\n","        nn (torch.nn.Module): The base module class from PyTorch.\n","    \"\"\"\n","\n","    def __init__(self, blank=0, zero_infinity=True, blank_penalty_weight=1.0, entropy_weight=0.5, label_smoothing=0.1):\n","        \"\"\"\n","        Initializes the CTCLossWithBlankPenalty with specified parameters.\n","\n","        Args:\n","            blank (int, optional): The index of the blank label. Defaults to 0.\n","            zero_infinity (bool, optional): Whether to zero the loss of sequences with infinite loss. Defaults to True.\n","            blank_penalty_weight (float, optional): The weight of the blank penalty. Defaults to 1.0.\n","            entropy_weight (float, optional): The weight of the entropy penalty. Defaults to 0.5.\n","            label_smoothing (float, optional): The amount of label smoothing to apply. Defaults to 0.1.\n","        \"\"\"\n","        super().__init__()\n","        self.ctc_loss = nn.CTCLoss(blank=blank, reduction='mean', zero_infinity=zero_infinity)\n","        self.blank = blank  # Add blank index as an attribute\n","        self.blank_penalty_weight = blank_penalty_weight\n","        self.entropy_weight = entropy_weight  \n","        self.label_smoothing = label_smoothing\n","        self.global_step = 0\n","\n","    def update_blank_penalty(self, global_step):\n","        \"\"\"\n","        Updates the blank penalty weight based on the current global step.\n","\n","        This method gradually reduces the blank penalty weight over the first 1,000 steps to stabilize training.\n","\n","        Args:\n","            global_step (int): The current global step or iteration number.\n","        \"\"\"\n","        # Gradual reduction of penalty over the first 1,000 steps\n","        self.global_step = global_step\n","        decay_factor = max(0.1, 1.0 - self.global_step / 1000.0)\n","        self.blank_penalty_weight = 1.0 * decay_factor\n","\n","    def forward(self, log_probs, targets, input_lengths, target_lengths):\n","        \"\"\"\n","        Computes the total loss, including CTC loss, blank penalty, and entropy penalty.\n","\n","        Args:\n","            log_probs (torch.Tensor): The log probabilities output by the model, of shape (T, N, C), \n","                                      where T is the input sequence length, N is the batch size, and C is the number of classes.\n","            targets (torch.Tensor): The target sequences, of shape (N, S), where S is the target sequence length.\n","            input_lengths (torch.Tensor): The lengths of the input sequences, of shape (N,).\n","            target_lengths (torch.Tensor): The lengths of the target sequences, of shape (N,).\n","\n","        Returns:\n","            torch.Tensor: The total loss, which is the sum of the CTC loss, blank penalty, and entropy penalty.\n","        \"\"\"\n","        # Standard CTC loss\n","        ctc_loss = self.ctc_loss(log_probs, targets, input_lengths, target_lengths)\n","\n","        # Blank penalty: penalize high blank probability (updated to be proportional)\n","        blank_probs = log_probs[:, :, self.blank].exp().mean()\n","        blank_penalty = self.blank_penalty_weight * blank_probs  # Changed from -torch.log(1 - blank_probs + 1e-4) * self.blank_penalty_weight\n","\n","        # Entropy regularization\n","        probs = log_probs.exp()\n","        entropy = -torch.sum(probs * log_probs, dim=-1).mean()\n","        entropy_loss = -self.entropy_weight * entropy\n","\n","        # Total loss\n","        total_loss = ctc_loss + blank_penalty + entropy_loss\n","        return total_loss"]},{"cell_type":"markdown","id":"cb66d2ff","metadata":{"papermill":{"duration":0.017486,"end_time":"2025-05-20T09:34:23.197298","exception":false,"start_time":"2025-05-20T09:34:23.179812","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Custom functions of metrics</font>**"]},{"cell_type":"markdown","id":"e5752ce1","metadata":{"papermill":{"duration":0.018743,"end_time":"2025-05-20T09:34:23.233505","exception":false,"start_time":"2025-05-20T09:34:23.214762","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Character Error Rate (CER)</font>**\n","\n","- Measures the number of character-level errors (insertions, deletions, substitutions) between the predicted text and the ground truth, normalized by the length of the ground truth."]},{"cell_type":"code","execution_count":39,"id":"801d3b1f","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:23.271956Z","iopub.status.busy":"2025-05-20T09:34:23.271701Z","iopub.status.idle":"2025-05-20T09:34:23.275772Z","shell.execute_reply":"2025-05-20T09:34:23.274803Z"},"papermill":{"duration":0.023168,"end_time":"2025-05-20T09:34:23.276956","exception":false,"start_time":"2025-05-20T09:34:23.253788","status":"completed"},"tags":[]},"outputs":[],"source":["def compute_cer(pred_texts, ground_truth):\n","    \"\"\"\n","    Computes the Character Error Rate (CER) between predicted texts and ground truth.\n","\n","    Args:\n","        pred_texts (list of str): List of predicted texts.\n","        ground_truth (list of str): List of ground truth texts.\n","\n","    Returns:\n","        float: Average CER across the batch.\n","    \"\"\"\n","    total_errors = 0\n","    total_chars = 0\n","    for pred, gt in zip(pred_texts, ground_truth):\n","        errors = levenshtein_distance(pred, gt)\n","        total_errors += errors\n","        total_chars += len(gt)\n","    cer = total_errors / total_chars if total_chars > 0 else 0\n","    return cer"]},{"cell_type":"markdown","id":"87d88c76","metadata":{"papermill":{"duration":0.017116,"end_time":"2025-05-20T09:34:23.310565","exception":false,"start_time":"2025-05-20T09:34:23.293449","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Word Error Rate (WER)</font>**\n","\n","- Measures the number of word-level errors (insertions, deletions, substitutions) between the predicted text and the ground truth, normalized by the number of words in the ground truth."]},{"cell_type":"code","execution_count":40,"id":"d7b6779d","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:23.345104Z","iopub.status.busy":"2025-05-20T09:34:23.344827Z","iopub.status.idle":"2025-05-20T09:34:23.348997Z","shell.execute_reply":"2025-05-20T09:34:23.348145Z"},"papermill":{"duration":0.022783,"end_time":"2025-05-20T09:34:23.350206","exception":false,"start_time":"2025-05-20T09:34:23.327423","status":"completed"},"tags":[]},"outputs":[],"source":["def compute_wer(pred_texts, ground_truth):\n","    \"\"\"\n","    Computes the Word Error Rate (WER) between predicted texts and ground truth.\n","\n","    Args:\n","        pred_texts (list of str): List of predicted texts.\n","        ground_truth (list of str): List of ground truth texts.\n","\n","    Returns:\n","        float: Average WER across the batch.\n","    \"\"\"\n","    total_errors = 0\n","    total_words = 0\n","    for pred, gt in zip(pred_texts, ground_truth):\n","        pred_words = pred.split()\n","        gt_words = gt.split()\n","        errors = levenshtein_distance(pred_words, gt_words)\n","        total_errors += errors\n","        total_words += len(gt_words)\n","    wer = total_errors / total_words if total_words > 0 else 0\n","    return wer"]},{"cell_type":"markdown","id":"192f98f2","metadata":{"papermill":{"duration":0.016721,"end_time":"2025-05-20T09:34:23.385624","exception":false,"start_time":"2025-05-20T09:34:23.368903","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">CER/WER Probability</font>**\n","\n","- This could be interpreted as the probability of errors at the character or word level, often derived from the model's output probabilities. For this implementation, we'll compute it as the average probability of the predicted characters/words being incorrect, based on the model's softmax probabilities.\n","\n"]},{"cell_type":"code","execution_count":41,"id":"48b35b5f","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:23.420609Z","iopub.status.busy":"2025-05-20T09:34:23.420335Z","iopub.status.idle":"2025-05-20T09:34:23.430023Z","shell.execute_reply":"2025-05-20T09:34:23.42918Z"},"papermill":{"duration":0.028687,"end_time":"2025-05-20T09:34:23.43121","exception":false,"start_time":"2025-05-20T09:34:23.402523","status":"completed"},"tags":[]},"outputs":[],"source":["def compute_cer_wer_probability(outputs, pred_texts, ground_truth, idx_to_char):\n","    \"\"\"\n","    Computes the CER/WER probability based on the model's output probabilities.\n","\n","    Args:\n","        outputs (torch.Tensor): Model output probabilities (after softmax), shape (T, B, C).\n","        pred_texts (list of str): List of predicted texts.\n","        ground_truth (list of str): List of ground truth texts.\n","        idx_to_char (dict): Mapping from indices to characters.\n","\n","    Returns:\n","        tuple: (cer_prob, wer_prob) - Average CER and WER probabilities.\n","    \"\"\"\n","    probs = outputs.softmax(2)  # (T, B, C)\n","    T, B, C = probs.shape\n","    char_to_idx = {char: idx for idx, char in idx_to_char.items()}\n","\n","    # Verify that indices in char_to_idx are within bounds\n","    max_idx = max(char_to_idx.values())\n","    if max_idx >= C:\n","        raise ValueError(f\"char_to_idx contains an index {max_idx} that exceeds the vocabulary size {C}\")\n","\n","    cer_probs = []\n","    wer_probs = []\n","\n","    for b in range(B):\n","        pred = pred_texts[b]\n","        gt = ground_truth[b]\n","\n","        # Character-level probability (CER probability)\n","        char_error_prob = 0.0\n","        for i, (p_char, g_char) in enumerate(zip(pred, gt)):\n","            if i >= T:  # Skip if beyond sequence length\n","                break\n","            p_idx = char_to_idx.get(p_char, 0)\n","            g_idx = char_to_idx.get(g_char, 0)\n","\n","            # Handle invalid indices\n","            if g_idx >= C:\n","                print(f\"Warning: g_char '{g_char}' maps to invalid index {g_idx}. Valid range: 0 to {C-1}\")\n","                g_idx = 0  # Fallback to blank token\n","            if p_idx >= C:\n","                print(f\"Warning: p_char '{p_char}' maps to invalid index {p_idx}. Valid range: 0 to {C-1}\")\n","                p_idx = 0  # Fallback to blank token\n","\n","            p_prob = probs[i, b, p_idx].item()\n","            g_prob = probs[i, b, g_idx].item()\n","            error_prob = 1.0 - g_prob  # Probability of error for this character\n","            char_error_prob += error_prob\n","        char_error_prob = char_error_prob / len(gt) if len(gt) > 0 else 0\n","        cer_probs.append(char_error_prob)\n","\n","        # Word-level probability (WER probability)\n","        pred_words = pred.split()\n","        gt_words = gt.split()\n","        word_error_prob = 0.0\n","        for i, (p_word, g_word) in enumerate(zip(pred_words, gt_words)):\n","            p_chars = list(p_word)\n","            g_chars = list(g_word)\n","            word_prob = 0.0\n","            for j, (p_char, g_char) in enumerate(zip(p_chars, g_chars)):\n","                if i * len(p_word) + j >= T:  # Skip if beyond sequence length\n","                    break\n","                p_idx = char_to_idx.get(p_char, 0)\n","                g_idx = char_to_idx.get(g_char, 0)\n","\n","                # Handle invalid indices\n","                if g_idx >= C:\n","                    print(f\"Warning: g_char '{g_char}' maps to invalid index {g_idx}. Valid range: 0 to {C-1}\")\n","                    g_idx = 0  # Fallback to blank token\n","                if p_idx >= C:\n","                    print(f\"Warning: p_char '{p_char}' maps to invalid index {p_idx}. Valid range: 0 to {C-1}\")\n","                    p_idx = 0  # Fallback to blank token\n","\n","                p_prob = probs[i * len(p_word) + j, b, p_idx].item()\n","                g_prob = probs[i * len(p_word) + j, b, g_idx].item()\n","                error_prob = 1.0 - g_prob\n","                word_prob += error_prob\n","            word_prob = word_prob / len(g_chars) if len(g_chars) > 0 else 0\n","            word_error_prob += word_prob\n","        word_error_prob = word_error_prob / len(gt_words) if len(gt_words) > 0 else 0\n","        wer_probs.append(word_error_prob)\n","\n","    avg_cer_prob = sum(cer_probs) / len(cer_probs) if cer_probs else 0\n","    avg_wer_prob = sum(wer_probs) / len(wer_probs) if wer_probs else 0\n","    return avg_cer_prob, avg_wer_prob"]},{"cell_type":"markdown","id":"e936cc29","metadata":{"papermill":{"duration":0.0183,"end_time":"2025-05-20T09:34:23.470517","exception":false,"start_time":"2025-05-20T09:34:23.452217","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Harmonic Mean</font>**\n","\n","- Harmonic Mean is a metric that helps us find the optimal solution between the CER and WER metrics."]},{"cell_type":"code","execution_count":42,"id":"f5ec53a1","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:23.505465Z","iopub.status.busy":"2025-05-20T09:34:23.505242Z","iopub.status.idle":"2025-05-20T09:34:23.508769Z","shell.execute_reply":"2025-05-20T09:34:23.508132Z"},"papermill":{"duration":0.02221,"end_time":"2025-05-20T09:34:23.509969","exception":false,"start_time":"2025-05-20T09:34:23.487759","status":"completed"},"tags":[]},"outputs":[],"source":["def compute_harmonic_mean(val_cer, val_wer):\n","    \"\"\"\n","    Calculates the harmonic mean of the CER and WER values.\n","\n","    Args:\n","    val_cer (float): Character Error Rate value.\n","    val_wer (float): Word Error Rate value.\n","\n","    Returns:\n","    float: Harmonic mean of the CER and WER.\n","    \"\"\"\n","    if val_cer + val_wer == 0:\n","        harmonic_mean = 0.0\n","    else:\n","        harmonic_mean = 2 / (1 / (val_cer + 1e-9) + 1 / (val_wer + 1e-9))\n","    return harmonic_mean"]},{"cell_type":"markdown","id":"b78dc27b","metadata":{"papermill":{"duration":0.021487,"end_time":"2025-05-20T09:34:23.548255","exception":false,"start_time":"2025-05-20T09:34:23.526768","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Model definition (CNN + RNN + CTC)</font>**\n","-------------------"]},{"cell_type":"markdown","id":"594d6ade","metadata":{"papermill":{"duration":0.018651,"end_time":"2025-05-20T09:34:23.592849","exception":false,"start_time":"2025-05-20T09:34:23.574198","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Configuration file</font>**"]},{"cell_type":"code","execution_count":43,"id":"213ef4d6","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:23.631896Z","iopub.status.busy":"2025-05-20T09:34:23.631554Z","iopub.status.idle":"2025-05-20T09:34:23.637878Z","shell.execute_reply":"2025-05-20T09:34:23.637043Z"},"papermill":{"duration":0.027403,"end_time":"2025-05-20T09:34:23.639305","exception":false,"start_time":"2025-05-20T09:34:23.611902","status":"completed"},"tags":[]},"outputs":[],"source":["config_model = {\n","    'cnn_layers': [\n","        {'type': 'conv', 'out_channels': 49, 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu', 'dropout': 0.17978091660622308},\n","        {'type': 'pool', 'kernel_size': 2, 'stride': 2},\n","        {'type': 'conv', 'out_channels': 70, 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu', 'dropout': 0.176786371203004},\n","        {'type': 'pool', 'kernel_size': 2, 'stride': 2},\n","        {'type': 'conv', 'out_channels': 193, 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu'},\n","        {'type': 'pool', 'kernel_size': (2, 2), 'stride': (2, 1), 'padding': (0, 1)},  # CRNN pooling\n","        {'type': 'conv', 'out_channels': 262, 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu'},\n","        {'type': 'pool', 'kernel_size': (2, 2), 'stride': (2, 1), 'padding': (0, 1)},  # CRNN pooling\n","    ],\n","    'rnn_type': 'lstm',\n","    'rnn_layers': 3,\n","    'hidden_size': 174,\n","    'bidirectional': True,\n","    'dropout': 0.12696657149320914,\n","    'fc_layers': [num_chars],  # One layer for OCR\n","}\n","\n"]},{"cell_type":"markdown","id":"9712c55c","metadata":{"papermill":{"duration":0.019485,"end_time":"2025-05-20T09:34:23.678734","exception":false,"start_time":"2025-05-20T09:34:23.659249","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Model architecture</font>**"]},{"cell_type":"code","execution_count":44,"id":"a693e2a5","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:23.714944Z","iopub.status.busy":"2025-05-20T09:34:23.714697Z","iopub.status.idle":"2025-05-20T09:34:23.72551Z","shell.execute_reply":"2025-05-20T09:34:23.724916Z"},"papermill":{"duration":0.029255,"end_time":"2025-05-20T09:34:23.726632","exception":false,"start_time":"2025-05-20T09:34:23.697377","status":"completed"},"tags":[]},"outputs":[],"source":["class OCRModel(nn.Module):\n","    \"\"\"\n","    A neural network model for Optical Character Recognition (OCR) tasks.\n","    \n","    This class defines an OCR model that combines Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) to process and recognize text in images. \n","    The model architecture is configurable through a configuration dictionary.\n","    \n","    Args:\n","        nn (torch.nn.Module): The base module class from PyTorch.\n","    \"\"\"\n","    def __init__(self, config):\n","        \"\"\"\n","        Initializes the OCRModel with a given configuration.\n","\n","        Args:\n","            config (dict): A dictionary containing the configuration parameters for the model, including CNN layers, RNN type, hidden size, and more.\n","        \"\"\"\n","        super(OCRModel, self).__init__()\n","        self.cnn = self.build_cnn(config['cnn_layers'])\n","        \n","        # Calculating input size for RNN after CNN\n","        num_pools = sum(1 for layer in config['cnn_layers'] if layer['type'] == 'pool')\n","        height_after_cnn = IMG_HEIGHT // (2 ** num_pools)\n","        last_conv_out = [layer['out_channels'] for layer in config['cnn_layers'] if layer['type'] == 'conv'][-1]\n","        rnn_input_size = last_conv_out * height_after_cnn\n","        \n","        self.rnn = self.build_rnn(config, rnn_input_size)\n","        rnn_output_size = config['hidden_size'] * 2 if config['bidirectional'] else config['hidden_size']\n","        self.fc = self.build_fc(config, rnn_output_size)\n","\n","    def build_cnn(self, cnn_config):\n","        \"\"\"\n","        Builds the CNN part of the model based on the provided configuration.\n","\n","        Args:\n","            cnn_config (list of dict): A list of dictionaries, each specifying a layer in the CNN. Each dictionary contains parameters like type, out_channels, kernel_size, etc.\n","\n","        Returns:\n","            nn.Sequential: A sequential container of CNN layers.\n","        \"\"\"\n","        layers = []\n","        in_channels = 1\n","        for layer in cnn_config:\n","            if layer['type'] == 'conv':\n","                layers.append(nn.Conv2d(in_channels, layer['out_channels'], layer['kernel_size'], \n","                                        layer['stride'], layer['padding']))\n","                if layer.get('batchnorm', False):\n","                    layers.append(nn.BatchNorm2d(layer['out_channels']))\n","                if layer.get('activation') == 'relu':\n","                    layers.append(nn.ReLU())\n","                elif layer.get('activation') == 'leaky_relu':\n","                    layers.append(nn.LeakyReLU(0.2))\n","                if 'dropout' in layer:\n","                    layers.append(nn.Dropout2d(layer['dropout']))\n","                in_channels = layer['out_channels']\n","            elif layer['type'] == 'pool':\n","                layers.append(nn.MaxPool2d(layer['kernel_size'], layer['stride'], layer.get('padding', 0)))\n","        return nn.Sequential(*layers)\n","\n","    def build_rnn(self, config, input_size):\n","        \"\"\"\n","        Creates an RNN part (LSTM or GRU) according to the configuration.\n","\n","        Args:\n","            config (dict): The configuration dictionary containing RNN parameters.\n","            input_size (int): The input size for the RNN.\n","\n","        Raises:\n","            ValueError: If the RNN type specified in the configuration is unknown.\n","\n","        Returns:\n","            nn.Module: An RNN module (LSTM or GRU).\n","        \"\"\"\n","        if config['rnn_type'] == 'lstm':\n","            return nn.LSTM(input_size, config['hidden_size'], num_layers=config['rnn_layers'], \n","                          bidirectional=config['bidirectional'], dropout=config['dropout'])\n","        elif config['rnn_type'] == 'gru':\n","            return nn.GRU(input_size, config['hidden_size'], num_layers=config['rnn_layers'], \n","                         bidirectional=config['bidirectional'], dropout=config['dropout'])\n","        else:\n","            raise ValueError(\"Unknown RNN type: {}\".format(config['rnn_type']))\n","\n","    def build_fc(self, config, input_size):\n","        \"\"\"\n","        Creates output fully connected layers.\n","\n","        Args:\n","            config (dict): The configuration dictionary containing fully connected layer parameters.\n","            input_size (int): The input size for the fully connected layers.\n","\n","        Returns:\n","            nn.Sequential: A sequential container of fully connected layers.\n","        \"\"\"\n","        layers = []\n","        fc_layers = config['fc_layers']\n","        for out_features in fc_layers[:-1]:\n","            layers.append(nn.Linear(input_size, out_features))\n","            layers.append(nn.ReLU())\n","            layers.append(nn.Dropout(config['dropout']))\n","            input_size = out_features\n","        layers.append(nn.Linear(input_size, fc_layers[-1]))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, max_length=None):\n","        \"\"\"\n","        Performs a forward pass through the OCR model.\n","\n","        Args:\n","            x (torch.Tensor): The input tensor, typically an image.\n","            max_length (int, optional): The maximum length for the RNN output. Defaults to None.\n","\n","        Returns:\n","            torch.Tensor: The output tensor after passing through the CNN, RNN, and fully connected layers.\n","        \"\"\"\n","        x = self.cnn(x)\n","        batch, channels, height, width = x.size()\n","        x = x.view(batch, channels * height, width).permute(2, 0, 1)  # (width, batch, features)\n","        if max_length is not None:\n","            x = x[:max_length]\n","        x, _ = self.rnn(x)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"markdown","id":"e90137c2","metadata":{"papermill":{"duration":0.016478,"end_time":"2025-05-20T09:34:23.759905","exception":false,"start_time":"2025-05-20T09:34:23.743427","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Training</font>**\n","-------------------"]},{"cell_type":"markdown","id":"0c8b7401","metadata":{"papermill":{"duration":0.01638,"end_time":"2025-05-20T09:34:23.792979","exception":false,"start_time":"2025-05-20T09:34:23.776599","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Initializing the scales</font>**"]},{"cell_type":"code","execution_count":45,"id":"6a6d7e10","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:23.828151Z","iopub.status.busy":"2025-05-20T09:34:23.827925Z","iopub.status.idle":"2025-05-20T09:34:23.832351Z","shell.execute_reply":"2025-05-20T09:34:23.83173Z"},"papermill":{"duration":0.023401,"end_time":"2025-05-20T09:34:23.833592","exception":false,"start_time":"2025-05-20T09:34:23.810191","status":"completed"},"tags":[]},"outputs":[],"source":["def initialize_weights(model):\n","    for name, module in model.named_modules():\n","        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n","            nn.init.xavier_uniform_(module.weight)\n","            if module.bias is not None:\n","                nn.init.zeros_(module.bias)\n","        elif isinstance(module, nn.LSTM) or isinstance(module, nn.GRU):\n","            for param_name, param in module.named_parameters():\n","                if 'weight' in param_name:\n","                    nn.init.orthogonal_(param)\n","                elif 'bias' in param_name:\n","                    nn.init.zeros_(param)"]},{"cell_type":"markdown","id":"e8c7ea7d","metadata":{"papermill":{"duration":0.016777,"end_time":"2025-05-20T09:34:23.868061","exception":false,"start_time":"2025-05-20T09:34:23.851284","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Calculating the gradient norm before trimming (for logging)</font>**"]},{"cell_type":"code","execution_count":46,"id":"b8c5f61d","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:23.903477Z","iopub.status.busy":"2025-05-20T09:34:23.903226Z","iopub.status.idle":"2025-05-20T09:34:23.907319Z","shell.execute_reply":"2025-05-20T09:34:23.906643Z"},"papermill":{"duration":0.023473,"end_time":"2025-05-20T09:34:23.908426","exception":false,"start_time":"2025-05-20T09:34:23.884953","status":"completed"},"tags":[]},"outputs":[],"source":["def compute_gradient_norm(parameters: Iterator[torch.Tensor]) -> float:\n","    total_norm = 0.0\n","    for p in parameters:\n","        if p.grad is not None:\n","            # Compute the Frobenius norm (default) over all elements in the tensor\n","            param_norm = torch.linalg.norm(p.grad.detach(), ord=None)\n","            total_norm += param_norm.item() ** 2\n","    total_norm = total_norm ** 0.5\n","    return total_norm"]},{"cell_type":"markdown","id":"7885da68","metadata":{"papermill":{"duration":0.016265,"end_time":"2025-05-20T09:34:23.941355","exception":false,"start_time":"2025-05-20T09:34:23.92509","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Function of train model</font>**"]},{"cell_type":"code","execution_count":47,"id":"b01e1b4e","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:23.975537Z","iopub.status.busy":"2025-05-20T09:34:23.975325Z","iopub.status.idle":"2025-05-20T09:34:24.012373Z","shell.execute_reply":"2025-05-20T09:34:24.011744Z"},"papermill":{"duration":0.05561,"end_time":"2025-05-20T09:34:24.013608","exception":false,"start_time":"2025-05-20T09:34:23.957998","status":"completed"},"tags":[]},"outputs":[],"source":["def train(\n","    full_dataset,\n","    device,\n","    config_model,\n","    pretrained_model_path=None,\n","    num_epochs=EPOCHS,\n","    learning_rate=LEARNING_RATE,\n","    weight_decay=WEIGHT_DECAY,\n","    warmup_steps=WARMUP_STEPS,\n","    temperature=TEMPERATURE,\n","    ctc_entropy_weight=CTC_ENTROPY_WEIGHT,\n","    ctc_label_smoothing=CTC_LABEL_SMOOTHING,\n","    ctc_blank_penalty_weight=CTC_BLANK_PENALTY_WEIGHT,\n","    bsd_beam_width=BSD_BEAM_WIDTH,\n","    bsd_blank_penalty=BSD_BLANK_PENALTY,\n","    bsd_length_penalty=BSD_LENGTH_PENALTY,\n","    gradient_clipping_value=GRADIENT_CLIPPING_VALUE,\n","    gradient_norm_threshold=GRADIENT_NORM_TRESHOLD\n","):\n","    \"\"\"\n","    Train the OCR model for final training with optimized hyperparameters.\n","    Saves the best model with full training state for resuming training.\n","    Saves the final model with minimal state for production and exports it to ONNX.\n","\n","    Args:\n","        full_dataset: OCRDataset instance containing the dataset.\n","        device: Torch device (cuda or cpu).\n","        config_model: Dictionary containing model architecture configuration.\n","        pretrained_model_path: Path to pre-trained model or checkpoint (optional).\n","        num_epochs: Number of training epochs.\n","        learning_rate: Learning rate for the optimizer.\n","        weight_decay: Weight decay for the optimizer.\n","        warmup_steps: Number of warmup steps for learning rate.\n","        temperature: Temperature for scaling model outputs.\n","        ctc_entropy_weight: Weight for CTC entropy regularization.\n","        ctc_label_smoothing: Label smoothing factor for CTC loss.\n","        ctc_blank_penalty_weight: Weight for blank penalty in CTC loss.\n","        bsd_beam_width: Beam width for beam search decoding.\n","        bsd_blank_penalty: Blank penalty for beam search decoding.\n","        bsd_length_penalty: Length penalty for beam search decoding.\n","        gradient_clipping_value: Max norm for gradient clipping.\n","        gradient_norm_threshold: Threshold for skipping batches with high gradient norms.\n","\n","    Returns:\n","        tuple: (best_val_loss, final_val_cer, final_val_wer, final_harmonic_mean) from the final epoch.\n","    \"\"\"\n","    # Initialize model\n","    model = OCRModel(config=config_model).to(device)\n","\n","    # Initialize optimizer and schedulers\n","    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(1.0, step / warmup_steps))\n","    plateau_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n","\n","    # Load pre-trained model or checkpoint if provided\n","    start_epoch = 0\n","    if pretrained_model_path is not None and os.path.exists(pretrained_model_path):\n","        checkpoint = torch.load(pretrained_model_path, map_location=device)\n","        if 'model_state_dict' in checkpoint:  # Full checkpoint\n","            model.load_state_dict(checkpoint['model_state_dict'])\n","            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","            plateau_scheduler.load_state_dict(checkpoint['plateau_scheduler_state_dict'])\n","            start_epoch = checkpoint['epoch'] + 1\n","            best_val_loss = checkpoint['best_val_loss']\n","            # Restore hyperparameters (optional, as they are passed as args)\n","            learning_rate = checkpoint['hyperparameters']['learning_rate']\n","            weight_decay = checkpoint['hyperparameters']['weight_decay']\n","            warmup_steps = checkpoint['hyperparameters']['warmup_steps']\n","            temperature = checkpoint['hyperparameters']['temperature']\n","            ctc_entropy_weight = checkpoint['hyperparameters']['ctc_entropy_weight']\n","            ctc_label_smoothing = checkpoint['hyperparameters']['ctc_label_smoothing']\n","            ctc_blank_penalty_weight = checkpoint['hyperparameters']['ctc_blank_penalty_weight']\n","            bsd_beam_width = checkpoint['hyperparameters']['bsd_beam_width']\n","            bsd_blank_penalty = checkpoint['hyperparameters']['bsd_blank_penalty']\n","            bsd_length_penalty = checkpoint['hyperparameters']['bsd_length_penalty']\n","            gradient_clipping_value = checkpoint['hyperparameters']['gradient_clipping_value']\n","            gradient_norm_threshold = checkpoint['hyperparameters']['gradient_norm_threshold']\n","            finaltrain_logger.info(f\"Loaded full checkpoint from {pretrained_model_path}, resuming from epoch {start_epoch}\")\n","        else:  # Only model weights\n","            model.load_state_dict(checkpoint)\n","            best_val_loss = float('inf')\n","            finaltrain_logger.info(f\"Loaded model weights from {pretrained_model_path}\")\n","    else:\n","        initialize_weights(model)\n","        best_val_loss = float('inf')\n","        finaltrain_logger.info(\"Initialized model with random weights\")\n","\n","    # TensorBoard setup\n","    log_dir = os.path.join(TENSORBOARD_DIR, \"ocr_final_training\")\n","    if not os.path.exists(log_dir):\n","        os.makedirs(log_dir)\n","    writer = SummaryWriter(log_dir)\n","\n","    # Log model configuration\n","    config_text = \"\\n\".join([f\"{k}: {v}\" for k, v in config_model.items()])\n","    writer.add_text('Config/model', config_text, 0)\n","    finaltrain_logger.info(f\"Model configuration:\\n{config_model}\")\n","\n","    # Log model graph\n","    try:\n","        sample_input = torch.randn(1, 1, IMG_HEIGHT, IMG_WIDTH).to(device)\n","        writer.add_graph(model, sample_input)\n","        finaltrain_logger.info(\"Logged model graph to TensorBoard\")\n","    except Exception as e:\n","        finaltrain_logger.warning(f\"Failed to log model graph: {str(e)}\")\n","\n","    global_step = start_epoch * len(full_dataset) // BATCH_SIZE\n","\n","    # Initialize variables to store final metrics\n","    final_val_cer = 0.0\n","    final_val_wer = 0.0\n","    final_harmonic_mean = 0.0\n","\n","    for epoch in tqdm(range(start_epoch, num_epochs), desc=\"Epochs\"):\n","        finaltrain_logger.info(f\"Starting epoch {epoch+1}/{num_epochs}\")\n","\n","        # Curriculum learning: Filter data by label length\n","        label_lengths = [lbl_len for _, _, lbl_len in full_dataset.data]\n","        finaltrain_logger.debug(f\"Label lengths: {label_lengths}\")\n","        if epoch < 5:\n","            filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 10]\n","        elif epoch < 10:\n","            filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 15]\n","        else:\n","            filtered_data = full_dataset.data\n","        sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]\n","        finaltrain_logger.debug(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n","\n","        # Create filtered dataset\n","        curr_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n","        curr_dataset.data = filtered_data\n","        train_size = int(0.8 * len(curr_dataset))\n","        val_size = len(curr_dataset) - train_size\n","        train_dataset, val_dataset = torch.utils.data.random_split(curr_dataset, [train_size, val_size])\n","        finaltrain_logger.debug(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n","\n","        # Data loaders\n","        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n","        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n","\n","        # Training phase\n","        model.train()\n","        total_loss = 0\n","        total_grad_norm = 0\n","        total_blank_probs = 0\n","        total_cer = 0\n","        total_wer = 0\n","        total_cer_prob = 0\n","        total_wer_prob = 0\n","        skipped_batches = 0\n","        num_valid_batches = 0\n","        avg_loss = 0\n","        max_skipped_batches = max(1, int(0.1 * len(train_loader)))\n","\n","        for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            label_lengths = label_lengths.to(device)\n","\n","            # Learning rate warm-up\n","            if global_step < warmup_steps:\n","                lr_scale = min(1.0, float(global_step + 1) / warmup_steps)\n","                for param_group in optimizer.param_groups:\n","                    param_group['lr'] = learning_rate * lr_scale\n","                    finaltrain_logger.debug(f\"Learning rate set to: {param_group['lr']}\")\n","\n","            optimizer.zero_grad()\n","            max_label_length = label_lengths.max().item()\n","            outputs = model(imgs, max_length=max_label_length * 2)\n","            outputs = outputs / temperature\n","            outputs = torch.clamp(outputs, min=-10, max=10)\n","            outputs = outputs.log_softmax(2)\n","\n","            batch_size = imgs.size(0)\n","            seq_length = min(outputs.size(0), max_label_length * 2)\n","            input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n","\n","            # Dynamic blank penalty\n","            blank_probs = outputs[:, :, 0].exp().mean().item()\n","            dynamic_blank_penalty = ctc_blank_penalty_weight * (1 + blank_probs)\n","            criterion = CTCLossWithBlankPenalty(\n","                blank=0, zero_infinity=True, blank_penalty_weight=dynamic_blank_penalty,\n","                entropy_weight=ctc_entropy_weight, label_smoothing=ctc_label_smoothing\n","            )\n","\n","            loss = criterion(outputs, labels, input_lengths, label_lengths)\n","\n","            # Compute gradient norm before clipping\n","            grad_norm_before = compute_gradient_norm(model.parameters())\n","\n","            # Dynamic loss threshold\n","            dynamic_threshold = max(40, avg_loss * 2) if num_valid_batches > 0 else 40\n","\n","            if torch.isnan(loss) or torch.isinf(loss):\n","                finaltrain_logger.warning(f\"NaN or Inf loss at batch {batch_idx}. Skipping...\")\n","                writer.add_scalar('Skipped_Batches/NaN_Inf', 1, global_step)\n","                skipped_batches += 1\n","            elif grad_norm_before > gradient_norm_threshold:\n","                finaltrain_logger.warning(f\"High gradient norm {grad_norm_before:.4f} at batch {batch_idx}. Skipping...\")\n","                writer.add_scalar('Skipped_Batches/High_Gradient', 1, global_step)\n","                skipped_batches += 1\n","            elif loss.item() > dynamic_threshold:\n","                finaltrain_logger.warning(f\"High loss {loss.item():.4f} at batch {batch_idx}. Adjusting learning rate...\")\n","                for param_group in optimizer.param_groups:\n","                    param_group['lr'] *= 0.9\n","                    finaltrain_logger.debug(f\"Learning rate adjusted to: {param_group['lr']}\")\n","                writer.add_scalar('Skipped_Batches/High_Loss', 1, global_step)\n","                skipped_batches += 1\n","            else:\n","                loss.backward()\n","                grad_norm_after = nn_utils.clip_grad_norm_(model.parameters(), max_norm=gradient_clipping_value)\n","                optimizer.step()\n","                scheduler.step()\n","\n","                total_loss += loss.item()\n","                total_grad_norm += grad_norm_after\n","                total_blank_probs += blank_probs\n","                num_valid_batches += 1\n","                avg_loss = total_loss / num_valid_batches if num_valid_batches > 0 else 0\n","\n","                # Compute CER/WER\n","                with torch.no_grad():\n","                    pred_texts = beam_search_decode(\n","                        output=outputs,\n","                        idx_to_char=idx_to_char,\n","                        target_lengths=label_lengths,\n","                        beam_width=bsd_beam_width,\n","                        blank_penalty=bsd_blank_penalty,\n","                        length_penalty=bsd_length_penalty,\n","                        global_step=global_step\n","                    )\n","                    label_sequences = split_labels(labels, label_lengths)\n","                    ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n","                                    for label_seq in label_sequences]\n","                    cer = compute_cer(pred_texts, ground_truth)\n","                    wer = compute_wer(pred_texts, ground_truth)\n","                    cer_prob, wer_prob = compute_cer_wer_probability(outputs, pred_texts, ground_truth, idx_to_char)\n","                    total_cer += cer\n","                    total_wer += wer\n","                    total_cer_prob += cer_prob\n","                    total_wer_prob += wer_prob\n","\n","            if skipped_batches > max_skipped_batches:\n","                finaltrain_logger.warning(f\"Too many skipped batches ({skipped_batches}/{max_skipped_batches}) in epoch {epoch+1}\")\n","                writer.add_text(\n","                    'Training/Details',\n","                    f\"Stopped at epoch {epoch+1}, batch {batch_idx}. Skipped batches: {skipped_batches}\",\n","                    global_step\n","                )\n","                break\n","\n","            global_step += 1\n","\n","            # Log metrics every NUMBER_OF_BATCH_REPORT batches\n","            if batch_idx % NUMBER_OF_BATCH_REPORT == 0:\n","                with torch.no_grad():\n","                    pred_texts = beam_search_decode(\n","                        output=outputs,\n","                        idx_to_char=idx_to_char,\n","                        target_lengths=label_lengths,\n","                        beam_width=bsd_beam_width,\n","                        blank_penalty=bsd_blank_penalty,\n","                        length_penalty=bsd_length_penalty\n","                    )\n","                    raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n","                    label_sequences = split_labels(labels, label_lengths)\n","                    ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n","                                    for label_seq in label_sequences[:3]]\n","                    probs = outputs.exp().flatten()\n","\n","                    writer.add_scalar('Loss/train_batch', loss.item(), global_step)\n","                    writer.add_scalar('Blank_Probability/train_batch', blank_probs, global_step)\n","                    writer.add_scalar('Gradient_Norm/train_batch', grad_norm_after.item() if num_valid_batches > 0 else 0, global_step)\n","                    writer.add_scalar('CER/train_batch', cer, global_step)\n","                    writer.add_scalar('WER/train_batch', wer, global_step)\n","                    writer.add_scalar('CER_Probability/train_batch', cer_prob, global_step)\n","                    writer.add_scalar('WER_Probability/train_batch', wer_prob, global_step)\n","\n","                    if not (torch.isnan(probs).any() or torch.isinf(probs).any() or torch.unique(probs).numel() <= 1):\n","                        writer.add_histogram('Logits/train_probs', probs, global_step)\n","                    writer.add_histogram('Raw_Outputs/train_argmax', raw_outputs.flatten(), global_step)\n","                    writer.add_text('Raw_Outputs/train_text', f\"Raw train outputs (argmax):\\n{str(raw_outputs)}\", global_step)\n","                    token_counts = Counter(raw_outputs.flatten())\n","                    writer.add_text('Raw_Outputs/train_token_counts', f\"Token counts: {token_counts}\", global_step)\n","\n","                    finaltrain_logger.debug(f\"Batch {batch_idx}, Loss: {loss.item():.4f}, CER: {cer:.4f}, WER: {wer:.4f}\")\n","\n","        # Compute epoch averages\n","        if num_valid_batches == 0:\n","            finaltrain_logger.warning(f\"All batches skipped in epoch {epoch+1}\")\n","            break\n","\n","        avg_loss = total_loss / num_valid_batches\n","        avg_grad_norm = total_grad_norm / num_valid_batches\n","        avg_blank_probs = total_blank_probs / num_valid_batches\n","        avg_cer = total_cer / num_valid_batches\n","        avg_wer = total_wer / num_valid_batches\n","        avg_cer_prob = total_cer_prob / num_valid_batches\n","        avg_wer_prob = total_wer_prob / num_valid_batches\n","\n","        writer.add_scalar('Loss/train_epoch', avg_loss, epoch)\n","        writer.add_scalar('Gradient_Norm/train_epoch', avg_grad_norm, epoch)\n","        writer.add_scalar('Blank_Probability/train_epoch', avg_blank_probs, epoch)\n","        writer.add_scalar('CER/train_epoch', avg_cer, epoch)\n","        writer.add_scalar('WER/train_epoch', avg_wer, epoch)\n","        writer.add_scalar('CER_Probability/train_epoch', avg_cer_prob, epoch)\n","        writer.add_scalar('WER_Probability/train_epoch', avg_wer_prob, epoch)\n","        finaltrain_logger.info(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, CER: {avg_cer:.4f}, WER: {avg_wer:.4f}\")\n","\n","        # Validation phase\n","        model.eval()\n","        val_loss = 0\n","        val_blank_probs = 0\n","        val_cer = 0\n","        val_wer = 0\n","        val_cer_prob = 0\n","        val_wer_prob = 0\n","        val_num_batches = 0\n","        with torch.no_grad():\n","            for batch_idx, (imgs, labels, label_lengths) in enumerate(val_loader):\n","                imgs, labels = imgs.to(device), labels.to(device)\n","                label_lengths = label_lengths.to(device)\n","                outputs = model(imgs)\n","                outputs = outputs.log_softmax(2)\n","                seq_length = outputs.size(0)\n","                input_lengths = torch.full((imgs.size(0),), seq_length, dtype=torch.long).to(device)\n","                val_loss += criterion(outputs, labels, input_lengths, label_lengths).item()\n","                val_blank_probs += outputs[:, :, 0].exp().mean().item()\n","\n","                # Compute CER/WER\n","                pred_texts = beam_search_decode(\n","                    output=outputs,\n","                    idx_to_char=idx_to_char,\n","                    target_lengths=label_lengths,\n","                    beam_width=bsd_beam_width,\n","                    blank_penalty=bsd_blank_penalty,\n","                    length_penalty=bsd_length_penalty,\n","                    global_step=epoch\n","                )\n","                label_sequences = split_labels(labels, label_lengths)\n","                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n","                                for label_seq in label_sequences]\n","                cer = compute_cer(pred_texts, ground_truth)\n","                wer = compute_wer(pred_texts, ground_truth)\n","                cer_prob, wer_prob = compute_cer_wer_probability(outputs, pred_texts, ground_truth, idx_to_char)\n","                val_cer += cer\n","                val_wer += wer\n","                val_cer_prob += cer_prob\n","                val_wer_prob += wer_prob\n","                val_num_batches += 1\n","\n","                # Log first batch\n","                if batch_idx == 0:\n","                    if not (outputs.numel() == 0 or torch.isnan(outputs).any() or torch.isinf(outputs).any()):\n","                        raw_outputs = outputs.argmax(2).cpu().numpy()\n","                        writer.add_histogram('Raw_Outputs/val_argmax', raw_outputs.flatten(), global_step=epoch)\n","                        writer.add_text('Raw_Outputs/val_text', f\"Raw validation outputs (argmax):\\n{str(raw_outputs[:5])}\", global_step=epoch)\n","                        token_counts = Counter(raw_outputs.flatten())\n","                        writer.add_text('Raw_Outputs/val_token_counts', f\"Token counts: {token_counts}\", global_step=epoch)\n","                        logits_first_step = outputs[0].cpu().numpy()\n","                        writer.add_histogram('Raw_Outputs/val_logits_first_step', logits_first_step.flatten(), global_step=epoch)\n","                        writer.add_histogram('Logits/val_probs', torch.softmax(outputs[0], dim=-1).flatten(), global_step)\n","\n","        val_loss /= val_num_batches\n","        val_blank_probs /= val_num_batches\n","        val_cer /= val_num_batches\n","        val_wer /= val_num_batches\n","        val_cer_prob /= val_num_batches\n","        val_wer_prob /= val_num_batches\n","\n","        harmonic_mean = compute_harmonic_mean(val_cer, val_wer)\n","\n","        writer.add_scalar('Loss/val_epoch', val_loss, epoch)\n","        writer.add_scalar('Blank_Probability/val_epoch', val_blank_probs, epoch)\n","        writer.add_scalar('CER/val_epoch', val_cer, epoch)\n","        writer.add_scalar('WER/val_epoch', val_wer, epoch)\n","        writer.add_scalar('CER_Probability/val_epoch', val_cer_prob, epoch)\n","        writer.add_scalar('WER_Probability/val_epoch', val_wer_prob, epoch)\n","        writer.add_scalar('Harmonic_mean/val_epoch', harmonic_mean, epoch)\n","        writer.add_text('Predictions/val', f\"Validation Predictions: {pred_texts[:5]}\", epoch)\n","        writer.add_text('Ground_Truth/val', f\"Ground Truth: {ground_truth[:5]}\", epoch)\n","        finaltrain_logger.info(f\"Validation Loss: {val_loss:.4f}, CER: {val_cer:.4f}, WER: {val_wer:.4f}, Harmonic Mean: {harmonic_mean:.4f}\")\n","\n","        plateau_scheduler.step(val_loss)\n","\n","        # Save best model with full checkpoint for resuming training\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            checkpoint = {\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'scheduler_state_dict': scheduler.state_dict(),\n","                'plateau_scheduler_state_dict': plateau_scheduler.state_dict(),\n","                'epoch': epoch,\n","                'best_val_loss': best_val_loss,\n","                'config_model': config_model,\n","                'hyperparameters': {\n","                    'learning_rate': learning_rate,\n","                    'weight_decay': weight_decay,\n","                    'warmup_steps': warmup_steps,\n","                    'temperature': temperature,\n","                    'ctc_entropy_weight': ctc_entropy_weight,\n","                    'ctc_label_smoothing': ctc_label_smoothing,\n","                    'ctc_blank_penalty_weight': ctc_blank_penalty_weight,\n","                    'bsd_beam_width': bsd_beam_width,\n","                    'bsd_blank_penalty': bsd_blank_penalty,\n","                    'bsd_length_penalty': bsd_length_penalty,\n","                    'gradient_clipping_value': gradient_clipping_value,\n","                    'gradient_norm_threshold': gradient_norm_threshold\n","                }\n","            }\n","            torch.save(checkpoint, os.path.join(MODEL_DIR, 'best_ocr_model_final.pth'))\n","            finaltrain_logger.info(\"Saved best model checkpoint\")\n","\n","        # Store final metrics from the last epoch\n","        if epoch == num_epochs - 1:\n","            final_val_cer = val_cer\n","            final_val_wer = val_wer\n","            final_harmonic_mean = harmonic_mean\n","\n","        finaltrain_logger.info(f\"Epoch {epoch+1}/{num_epochs} completed\")\n","\n","    # Save final model with minimal checkpoint for production\n","    checkpoint = {\n","        'model_state_dict': model.state_dict(),\n","        'config_model': config_model\n","    }\n","    torch.save(checkpoint, os.path.join(MODEL_DIR, 'final_ocr_model_final.pth'))\n","    finaltrain_logger.info(\"Saved final model checkpoint for production\")\n","\n","    # Export final model to ONNX\n","    model.eval()\n","    try:\n","        # Create a sample input tensor (batch_size=1, channels=1, height=IMG_HEIGHT, width=IMG_WIDTH)\n","        sample_input = torch.randn(1, 1, IMG_HEIGHT, IMG_WIDTH).to(device)\n","        onnx_path = os.path.join(MODEL_DIR, 'final_ocr_model_final.onnx')\n","\n","        # Export the model to ONNX\n","        torch.onnx.export(\n","            model,\n","            sample_input,\n","            onnx_path,\n","            export_params=True,\n","            opset_version=11,  # Compatible with most ONNX runtimes\n","            do_constant_folding=True,\n","            input_names=['input'],\n","            output_names=['output'],\n","            dynamic_axes={\n","                'input': {0: 'batch_size', 3: 'width'},  # Dynamic batch size and width\n","                'output': {0: 'sequence_length', 1: 'batch_size'}  # Dynamic sequence length and batch size\n","            }\n","        )\n","        finaltrain_logger.info(f\"Exported final model to ONNX at {onnx_path}\")\n","    except Exception as e:\n","        finaltrain_logger.error(f\"Failed to export model to ONNX: {str(e)}\")\n","\n","    # Log final metrics\n","    finaltrain_logger.info(\n","        f\"Final training metrics: \"\n","        f\"Best Validation Loss: {best_val_loss:.4f}, \"\n","        f\"Final Validation CER: {final_val_cer:.4f}, \"\n","        f\"Final Validation WER: {final_val_wer:.4f}, \"\n","        f\"Final Harmonic Mean: {final_harmonic_mean:.4f}\"\n","    )\n","    writer.add_scalar('Final/Loss', best_val_loss, global_step)\n","    writer.add_scalar('Final/CER', final_val_cer, global_step)\n","    writer.add_scalar('Final/WER', final_val_wer, global_step)\n","    writer.add_scalar('Final/Harmonic_mean', final_harmonic_mean, global_step)\n","\n","    # Display final metrics for preview\n","    print(\n","        f\"\\nTraining completed!\\n\"\n","        f\"Final metrics:\\n\"\n","        f\"  Best Validation Loss: {best_val_loss:.4f}\\n\"\n","        f\"  Final Validation CER: {final_val_cer:.4f}\\n\"\n","        f\"  Final Validation WER: {final_val_wer:.4f}\\n\"\n","        f\"  Final Harmonic Mean: {final_harmonic_mean:.4f}\\n\"\n","    )\n","\n","    writer.close()\n","\n","    return best_val_loss, final_val_cer, final_val_wer, final_harmonic_mean"]},{"cell_type":"markdown","id":"b1acedd3","metadata":{"papermill":{"duration":0.024197,"end_time":"2025-05-20T09:34:24.054713","exception":false,"start_time":"2025-05-20T09:34:24.030516","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Inference (prediction)</font>**\n","-------------------"]},{"cell_type":"code","execution_count":48,"id":"feed2d76","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:24.093252Z","iopub.status.busy":"2025-05-20T09:34:24.093003Z","iopub.status.idle":"2025-05-20T09:34:24.098429Z","shell.execute_reply":"2025-05-20T09:34:24.09779Z"},"papermill":{"duration":0.024818,"end_time":"2025-05-20T09:34:24.099496","exception":false,"start_time":"2025-05-20T09:34:24.074678","status":"completed"},"tags":[]},"outputs":[],"source":["def decode_prediction(output, idx_to_char):\n","    \"\"\"\n","    Decodes the output of an OCR model into readable text.\n","\n","    This function takes the raw output from an OCR model and converts it into a list of decoded text strings. \n","    It applies a softmax function to the output to obtain probabilities for each character at each time step. It then uses a dynamic threshold based on the 75th percentile of these probabilities to filter out low-confidence predictions. The decoded text is constructed by mapping character indices to their corresponding characters using a provided dictionary.\n","\n","    Args:\n","        output (torch.Tensor): The raw output tensor from the OCR model, typically of shape (T, N, C), \n","        where T is the time steps, N is the batch size, and C is the number of classes (characters).\n","        idx_to_char (dict): A dictionary mapping index values to their corresponding characters.\n","\n","    Returns:\n","        list of str: A list of decoded text strings, one for each sequence in the batch. \n","        If a sequence is empty after decoding, it is represented as '<empty>'.\n","\n","    The function prints the raw predictions and the dynamic threshold used for filtering, \n","    providing insights into the decoding process.\n","    \"\"\"\n","    probs = output.softmax(2)\n","    max_probs, preds = probs.max(dim=2)\n","    preds = preds.cpu().numpy()\n","    max_probs = max_probs.cpu().numpy()\n","    texts = []\n","    for i, (pred, prob) in enumerate(zip(preds.T, max_probs.T)):\n","        #print(f\"Raw prediction {i} (pre-filter): {pred}, Max probs: {prob}\")\n","        function_logger.debug(f\"Raw prediction {i} (pre-filter): {pred}, Max probs: {prob}\")\n","        # Dynamic threshold: 75th percentile of max probs in this sequence\n","        threshold = np.percentile(prob, 75)\n","        #print(f\"Dynamic threshold for prediction {i}: {threshold:.4f}\")\n","        function_logger.debug(f\"Dynamic threshold for prediction {i}: {threshold:.4f}\")\n","        pred_text = []\n","        prev = -1\n","        for idx, p in zip(pred, prob):\n","            if idx != 0 and idx != prev and p > threshold:\n","                pred_text.append(idx_to_char.get(idx, ''))\n","            prev = idx\n","        decoded = ''.join(pred_text)\n","        texts.append(decoded if decoded else '<empty>')\n","    return texts"]},{"cell_type":"markdown","id":"4ef6573f","metadata":{"papermill":{"duration":0.017,"end_time":"2025-05-20T09:34:24.134103","exception":false,"start_time":"2025-05-20T09:34:24.117103","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Objective function for Optuna with full TensorBoard logging</font>**\n","-------------------"]},{"cell_type":"code","execution_count":49,"id":"b55a918c","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:24.169959Z","iopub.status.busy":"2025-05-20T09:34:24.169513Z","iopub.status.idle":"2025-05-20T09:34:24.218212Z","shell.execute_reply":"2025-05-20T09:34:24.217386Z"},"papermill":{"duration":0.068645,"end_time":"2025-05-20T09:34:24.219616","exception":false,"start_time":"2025-05-20T09:34:24.150971","status":"completed"},"tags":[]},"outputs":[],"source":["def objective(trial: optuna.trial.Trial):\n","    # Global constants\n","    global LEARNING_RATE, WEIGHT_DECAY, WARMUP_STEPS, TEMPERATURE\n","    global CTC_ENTROPY_WEIGHT, CTC_LABEL_SMOOTHING, CTC_BLANK_PENALTY_WEIGHT\n","    global BSD_BEAM_WIDTH, BSD_BLANK_PENALTY, BSD_LENGTH_PENALTY, GRADIENT_NORM_TRESHOLD\n","\n","    # Suggest hyperparameters to optimize\n","    LEARNING_RATE = trial.suggest_float('learning_rate', 1e-8, 1e-7, log=True)\n","    WEIGHT_DECAY = trial.suggest_float('weight_decay', 0.1, 0.14, log=True)\n","    WARMUP_STEPS = trial.suggest_int('warmup_steps', 1200, 1800)\n","    TEMPERATURE = trial.suggest_float('temperature', 1.0, 1.3)\n","    CTC_ENTROPY_WEIGHT = trial.suggest_float('ctc_entropy_weight', 0.6, 0.8)\n","    CTC_LABEL_SMOOTHING = trial.suggest_float('ctc_label_smoothing', 0.16, 0.18)\n","    CTC_BLANK_PENALTY_WEIGHT = trial.suggest_float('ctc_blank_penalty_weight', 0.2, 0.4)\n","    BSD_BEAM_WIDTH = trial.suggest_int('bsd_beam_width', 10, 12)\n","    BSD_BLANK_PENALTY = trial.suggest_float('bsd_blank_penalty', -0.135, -0.115)\n","    BSD_LENGTH_PENALTY = trial.suggest_float('bsd_length_penalty', -0.2, -0.15)\n","    GRADIENT_CLIPPING_VALUE = trial.suggest_float('gradient_clipping_value', 2.0, 6.0)\n","    GRADIENT_NORM_TRESHOLD = trial.suggest_int('gradient_norm_treshold', 200, 300)\n","\n","    optuna_logger.info('Optimalization hyperparameters was set.')\n","\n","    # Suggest model architecture parameters\n","    config_model = {\n","        'cnn_layers': [\n","            {'type': 'conv', 'out_channels': trial.suggest_int('cnn_out_channels_1', 30, 50), 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu', 'dropout': trial.suggest_float('cnn_dropout_1', 0.1, 0.2)},\n","            {'type': 'pool', 'kernel_size': 2, 'stride': 2},\n","            {'type': 'conv', 'out_channels': trial.suggest_int('cnn_out_channels_2', 60, 90), 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu', 'dropout': trial.suggest_float('cnn_dropout_2', 0.1, 0.18)},\n","            {'type': 'pool', 'kernel_size': 2, 'stride': 2},\n","            {'type': 'conv', 'out_channels': trial.suggest_int('cnn_out_channels_3', 150, 220), 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu'},\n","            {'type': 'pool', 'kernel_size': (2, 2), 'stride': (2, 1), 'padding': (0, 1)},  # CRNN pooling\n","            {'type': 'conv', 'out_channels': trial.suggest_int('cnn_out_channels_4', 250, 350), 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu'},\n","            {'type': 'pool', 'kernel_size': (2, 2), 'stride': (2, 1), 'padding': (0, 1)},  # CRNN pooling\n","        ],\n","        'rnn_type': 'lstm',\n","        'rnn_layers': trial.suggest_int('rnn_layers', 2, 3),\n","        'hidden_size': trial.suggest_int('hidden_size', 120, 200),\n","        'bidirectional': True,\n","        'dropout': trial.suggest_float('rnn_dropout', 0.1, 0.2),\n","        'fc_layers': [num_chars],  # One layer for OCR\n","    }\n","\n","    optuna_logger.info('Optimalization parameters of neural net model was set.')\n","\n","    # Clean the labels file\n","    valid_chars = set(CHARSET)\n","    clean_labels_file(LABELS_FILE, valid_chars)\n","    optuna_logger.info('Validation of LABELS_FILE was done.')\n","\n","    # Initialize the TensorBoard writer for this trial\n","    log_dir = os.path.join(TENSORBOARD_DIR, f\"ocr_experiment_trial_{trial.number}\")\n","    optuna_logger.info(f\"Start train of trial number: {trial.number}\")\n","\n","    global writer  # We use a global writer to make it available in train_model and elsewhere\n","\n","    if not os.path.exists(log_dir):\n","        os.makedirs(log_dir)\n","    writer = SummaryWriter(log_dir)\n","\n","    # Log the config_model settings to TensorBoard\n","    config_text = \"\\n\".join([f\"{k}: {v}\" for k, v in config_model.items()])\n","    writer.add_text('Config/model', config_text, 0)\n","\n","    print(f\"Model configuration:\\n {config_model} \\n\")\n","    optuna_logger.debug(f\"Model configuration:\\n {config_model} \\n\")\n","\n","    # Device setup\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Dataset setup (we assume that synthetic data is already generated)\n","    full_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n","    optuna_logger.info(\"Was load synthetic data of dataset.\")\n","\n","    for i in range(5):\n","        img, label, length = full_dataset[i]\n","        plt.imshow(img.squeeze(), cmap='gray')\n","        plt.title(''.join([idx_to_char.get(idx.item(), '') for idx in label[:length]]))\n","        plt.show()\n","\n","    if len(full_dataset) == 0:\n","        print(\"Dataset is empty! Check labels.txt or image directory.\")\n","        optuna_logger.error(\"Dataset is empty! Check labels.txt or image directory.\")\n","\n","        if not font_files:\n","            print(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n","            optuna_logger.error(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n","        else:\n","            # Clean the labels file\n","            valid_chars = set(CHARSET)\n","            clean_labels_file(LABELS_FILE, valid_chars)\n","            optuna_logger.info('Validation of LABELS_FILE was done.')\n","            \n","            create_synthetic_dataset(NUM_SAMPLES)\n","            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","            full_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n","    else:\n","        for i in range(5):\n","            img, label, length = full_dataset[i]\n","            plt.imshow(img.squeeze(), cmap='gray')\n","            plt.title(''.join([idx_to_char.get(idx.item(), '') for idx in label[:length]]))\n","            plt.show()\n","\n","        optuna_logger.info(\"Samples of data was shown.\")\n","        \n","        # Curriculum phases with pre-filtering\n","        model = OCRModel(config=config_model).to(device)\n","\n","        # Log the model graph to TensorBoard\n","        try:\n","            # Create a sample input tensor with the same shape as your dataset images\n","            sample_input = torch.randn(1, 1, IMG_HEIGHT, IMG_WIDTH).to(device)  # Shape: (batch_size, channels, height, width)\n","            writer.add_graph(model, sample_input)\n","            #print(f\"Logged model graph to TensorBoard for trial {trial.number}.\")\n","            optuna_logger.info(f\"Logged model graph to TensorBoard for trial {trial.number}.\")\n","        except Exception as e:\n","            #print(f\"Failed to log model graph to TensorBoard for trial {trial.number}: {str(e)}\")\n","            optuna_logger.warning(f\"Failed to log model graph to TensorBoard for trial {trial.number}: {str(e)}\")\n","\n","        \n","        criterion = CTCLossWithBlankPenalty(\n","            blank=0, zero_infinity=True, blank_penalty_weight=CTC_BLANK_PENALTY_WEIGHT,\n","            entropy_weight=CTC_ENTROPY_WEIGHT, label_smoothing=CTC_LABEL_SMOOTHING\n","        )\n","\n","        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n","\n","        optuna_logger.info(\"Model, Criterion, Optimizer, Scheduler was set.\")\n","        \n","        best_val_loss = float('inf')\n","        avg_grad_norm = 0\n","        avg_blank_probs = 0\n","        avg_loss = 0  # Initialize avg_loss\n","\n","        for epoch in range(EPOCHS):\n","            optuna_logger.info(f\"Start epoch number: {epoch}\")\n","            label_lengths = [lbl_len for _, _, lbl_len in full_dataset.data]\n","            #print(f\"Label lengths: {label_lengths}\")\n","            optuna_logger.debug(f\"Label lengths: {label_lengths}\")\n","            # Filter full dataset based on curriculum phase\n","            if epoch < 5:\n","                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 10]\n","                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]  # lbl is a string\n","                #print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n","                optuna_logger.debug(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n","            elif epoch < 10:\n","                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 15]\n","                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]\n","                #print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n","                optuna_logger.debug(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n","            else:\n","                filtered_data = full_dataset.data\n","                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]\n","                #print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n","                optuna_logger.debug(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n","\n","            # Create a new dataset with filtered data\n","            curr_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n","            curr_dataset.data = filtered_data  # Overwrite with filtered data\n","\n","            # Split into train and validation\n","            train_size = int(0.8 * len(curr_dataset))\n","            val_size = len(curr_dataset) - train_size\n","            train_dataset, val_dataset = torch.utils.data.random_split(curr_dataset, [train_size, val_size])\n","            #print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n","            optuna_logger.debug(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n","\n","            # Create data loaders\n","            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n","            val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n","\n","            skipped_batches = 0\n","\n","            # Training with TensorBoard logging\n","            model.train()\n","            optuna_logger.info('Start Train process.')\n","            total_loss = 0\n","            total_grad_norm = 0\n","            total_blank_probs = 0\n","            total_cer = 0  # Initialize total_cer\n","            total_wer = 0  # Initialize total_wer\n","            total_cer_prob = 0  # Initialize total_cer_prob\n","            total_wer_prob = 0  # Initialize total_wer_prob\n","            max_skipped_batches = max(1, int(0.1 * len(train_loader)))  # Allow up to 10% of batches to be skipped\n","            avg_loss = 0  # Track average loss for dynamic threshold\n","            num_valid_batches = 0\n","            \n","            global_step = epoch * len(train_loader)\n","            \n","            for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n","                imgs, labels = imgs.to(device), labels.to(device)\n","                label_lengths = label_lengths.to(device)\n","\n","                if global_step < WARMUP_STEPS:\n","                    lr_scale = min(1.0, float(global_step + 1) / WARMUP_STEPS)\n","                    for param_group in optimizer.param_groups:\n","                        param_group['lr'] = LEARNING_RATE * lr_scale\n","                        optuna_logger.debug(f\"Learning rate set at value: {param_group['lr']}\")\n","\n","                optimizer.zero_grad()\n","                max_label_length = label_lengths.max().item()\n","                outputs = model(imgs, max_length=max_label_length * 2)\n","                outputs = outputs / TEMPERATURE\n","                outputs = torch.clamp(outputs, min=-10, max=10)  # Clipping for stability\n","                outputs = outputs.log_softmax(2)\n","\n","                batch_size = imgs.size(0)\n","                seq_length = min(outputs.size(0), max_label_length * 2)\n","                input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n","\n","                # Dynamic penalty for blank tokens\n","                blank_probs = outputs[:, :, 0].exp().mean().item()\n","                dynamic_blank_penalty = CTC_BLANK_PENALTY_WEIGHT * (1 + blank_probs)\n","                criterion = CTCLossWithBlankPenalty(\n","                    blank=0, zero_infinity=True, blank_penalty_weight=dynamic_blank_penalty,\n","                    entropy_weight=CTC_ENTROPY_WEIGHT, label_smoothing=CTC_LABEL_SMOOTHING\n","                )\n","\n","                loss = criterion(outputs, labels, input_lengths, label_lengths)\n","\n","                # Calculating the gradient norm before clipping\n","                grad_norm_before = compute_gradient_norm(model.parameters())\n","\n","                # Dynamic threshold based on average loss of previous batches\n","                dynamic_threshold = max(40, avg_loss * 2) if num_valid_batches > 0 else 40  # Dynamic threshold\n","                \n","                if torch.isnan(loss) or torch.isinf(loss):\n","                    #print(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n","                    optuna_logger.warning(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n","                    writer.add_scalar('Skipped_Batches/NaN_Inf', 1, global_step)\n","                    skipped_batches += 1\n","                elif grad_norm_before > GRADIENT_NORM_TRESHOLD:  # Gradient norm threshold\n","                    #print(f\"Warning: High gradient norm {grad_norm_before:.4f} at batch {batch_idx}. Skipping...\")\n","                    optuna_logger.warning(f\"Warning: High gradient norm {grad_norm_before:.4f} at batch {batch_idx}. Skipping...\")\n","                    writer.add_scalar('Skipped_Batches/High_Gradient', 1, global_step)\n","                    skipped_batches += 1\n","                elif loss.item() > dynamic_threshold:\n","                    #print(f\"Warning: High loss {loss.item():.4f} at batch {batch_idx}. Adjusting learning rate...\")\n","                    optuna_logger.warning(f\"Warning: High loss {loss.item():.4f} at batch {batch_idx}. Adjusting learning rate...\")\n","                    # Gradually reduce the learning rate\n","                    for param_group in optimizer.param_groups:\n","                        param_group['lr'] *= 0.9  # Reduce learning rate by 10%\n","                        optuna_logger.debug(f\"Learning rate set at value: {param_group['lr']}\")\n","                    writer.add_scalar('Skipped_Batches/High_Loss', 1, global_step)\n","                    skipped_batches += 1\n","                else:\n","                    loss.backward()\n","\n","                    # Gradient clipping with a reasonable max_norm value\n","                    grad_norm_after = nn_utils.clip_grad_norm_(model.parameters(), max_norm=GRADIENT_CLIPPING_VALUE)\n","\n","                    # Logging gradient norms\n","                    #print(f\"Epoch {epoch+1}, Batch {batch_idx}, Gradient Norm Before: {grad_norm_before:.4f}, After: {grad_norm_after:.4f}\")\n","                    optuna_logger.debug(f\"Epoch {epoch+1}, Batch {batch_idx}, Gradient Norm Before: {grad_norm_before:.4f}, After: {grad_norm_after:.4f}\")\n","                    writer.add_scalar('Gradient_Norm/train_batch', grad_norm_after.item(), global_step)\n","                \n","                    optimizer.step()\n","                    total_loss += loss.item()\n","                    total_grad_norm += grad_norm_after.item()\n","                    total_blank_probs += blank_probs\n","                    num_valid_batches += 1\n","                    avg_loss = total_loss / num_valid_batches if num_valid_batches > 0 else 0\n","\n","                    # Compute CER, WER, and CER/WER probability\n","                    with torch.no_grad():\n","                        pred_texts = beam_search_decode(\n","                            output=outputs,\n","                            idx_to_char=idx_to_char,\n","                            target_lengths=label_lengths,\n","                            beam_width=BSD_BEAM_WIDTH,\n","                            blank_penalty=BSD_BLANK_PENALTY,\n","                            length_penalty=BSD_LENGTH_PENALTY,\n","                            global_step=global_step\n","                        )\n","                        label_sequences = split_labels(labels, label_lengths)\n","                        ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n","                                        for label_seq in label_sequences]\n","\n","                        cer = compute_cer(pred_texts, ground_truth)\n","                        wer = compute_wer(pred_texts, ground_truth)\n","                        cer_prob, wer_prob = compute_cer_wer_probability(outputs, pred_texts, ground_truth, idx_to_char)\n","\n","                        total_cer += cer\n","                        total_wer += wer\n","                        total_cer_prob += cer_prob\n","                        total_wer_prob += wer_prob\n","\n","                # Prune trial if too many batches are skipped\n","                if skipped_batches > max_skipped_batches:\n","                    #print(f\"Too many skipped batches ({skipped_batches}/{max_skipped_batches}) in epoch {epoch+1}. Pruning trial.\")\n","                    optuna_logger.warning(f\"Too many skipped batches ({skipped_batches}/{max_skipped_batches}) in epoch {epoch+1}. Pruning trial.\")\n","                    writer.add_text(\n","                        'Pruning/Details',\n","                        f\"Pruned at epoch {epoch+1}, batch {batch_idx}. Skipped batches: {skipped_batches}, \"\n","                        f\"Input lengths: {input_lengths.tolist()}, Label lengths: {label_lengths.tolist()}\",\n","                        global_step\n","                    )\n","                    optuna_logger.debug(f'Trial {trial.number} break in epoch {epoch+1}')\n","                    raise optuna.TrialPruned()\n","                \n","                global_step += 1\n","\n","                \n","                # Log additional metrics\n","                if batch_idx % NUMBER_OF_BATCH_REPORT == 0:\n","                    with torch.no_grad():\n","                        pred_texts = beam_search_decode(\n","                                        output=outputs,\n","                                        idx_to_char=idx_to_char,\n","                                        target_lengths=label_lengths,\n","                                        beam_width=BSD_BEAM_WIDTH,\n","                                        blank_penalty=BSD_BLANK_PENALTY,\n","                                        length_penalty=BSD_LENGTH_PENALTY\n","                                    )\n","                        raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n","                        blank_probs = outputs[:, :, 0].exp().mean().item()\n","                        label_sequences = split_labels(labels, label_lengths)\n","                        ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n","                                        for label_seq in label_sequences[:3]]\n","                        \n","                        probs = outputs.exp().flatten()\n","                        #print(f\"Probs min: {probs.min().item()}, max: {probs.max().item()}, mean: {probs.mean().item()}\")\n","                        optuna_logger.debug(f\"Probs min: {probs.min().item()}, max: {probs.max().item()}, mean: {probs.mean().item()}\")\n","                        #print(f\"Probs unique values: {torch.unique(probs).numel()}\")\n","                        optuna_logger.debug(f\"Probs unique values: {torch.unique(probs).numel()}\")\n","                        if torch.isnan(probs).any() or torch.isinf(probs).any():\n","                            #print(\"Warning: NaN or Inf values in probs\")\n","                            optuna_logger.warning(\"Warning: NaN or Inf values in probs\")\n","\n","                        # Logging into TensorBoard\n","                        writer.add_scalar('Loss/train_batch', loss.item(), global_step)\n","                        writer.add_scalar('Blank_Probability/train_batch', blank_probs, global_step)\n","                        writer.add_scalar('Gradient_Norm/train_batch', grad_norm_after.item(), global_step)\n","                        writer.add_scalar('CER/train_batch', cer, global_step)\n","                        writer.add_scalar('WER/train_batch', wer, global_step)\n","                        writer.add_scalar('CER_Probability/train_batch', cer_prob, global_step)\n","                        writer.add_scalar('WER_Probability/train_batch', wer_prob, global_step)\n","                        \n","                        if torch.isnan(probs).any() or torch.isinf(probs).any() or torch.unique(probs).numel() <= 1:\n","                            #print(\"Skipping histogram logging due to invalid or degenerate data\")\n","                            optuna_logger.warning(\"Skipping histogram logging due to invalid or degenerate data\")\n","                        else:\n","                            writer.add_histogram('Logits/train_probs', probs, global_step)\n","\n","                        # Adding raw outputs\n","                        writer.add_histogram('Raw_Outputs/train_argmax', raw_outputs.flatten(), global_step)\n","                        writer.add_text('Raw_Outputs/train_text', f\"Raw train outputs (argmax):\\n{str(raw_outputs)}\", global_step)\n","\n","                        # Token frequency calculation and logging\n","                        token_counts = Counter(raw_outputs.flatten())\n","                        writer.add_text(\n","                            'Raw_Outputs/train_token_counts',\n","                            f\"Token counts: {token_counts}\",\n","                            global_step\n","                        )\n","\n","                        #print(f\"Batch {batch_idx}, Gradient norm: {grad_norm_after.item():.4f}\")\n","                        optuna_logger.debug(f\"Batch {batch_idx}, Gradient norm: {grad_norm_after.item():.4f}\")\n","                        #print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n","                        optuna_logger.debug(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n","                        #print(f\"Avg Blank Probability: {blank_probs:.4f}\")\n","                        optuna_logger.debug(f\"Avg Blank Probability: {blank_probs:.4f}\")\n","                        #print(f\"CER: {cer:.4f}, WER: {wer:.4f}\")\n","                        optuna_logger.debug(f\"CER: {cer:.4f}, WER: {wer:.4f}\")\n","                        #print(f\"CER Probability: {cer_prob:.4f}, WER Probability: {wer_prob:.4f}\")\n","                        optuna_logger.debug(f\"CER Probability: {cer_prob:.4f}, WER Probability: {wer_prob:.4f}\")\n","                        #print(f\"Sample predictions: {pred_texts[:3]}\")\n","                        optuna_logger.debug(f\"Sample predictions: {pred_texts[:3]}\")\n","                        #print(f\"Ground Truth (first 3): {ground_truth}\")\n","                        optuna_logger.debug(f\"Ground Truth (first 3): {ground_truth}\")\n","                        #print(f\"Raw outputs (first 3): {raw_outputs}\")\n","                        optuna_logger.debug(f\"Raw outputs (first 3): {raw_outputs}\")\n","                        #print(f\"Input length: {seq_length}, Label lengths: {label_lengths[:3].tolist()}\")\n","                        optuna_logger.debug(f\"Input length: {seq_length}, Label lengths: {label_lengths[:3].tolist()}\")\n","                        #print(f\"Number of skipped batches: {skipped_batches}\")\n","                        optuna_logger.debug(f\"Number of skipped batches: {skipped_batches}\")\n","\n","            # Compute epoch averages\n","            if num_valid_batches == 0:\n","                #print(\"All batches skipped in this epoch. Pruning trial.\")\n","                optuna_logger.warning(\"All batches skipped in this epoch. Pruning trial.\")\n","                raise optuna.TrialPruned()\n","\n","            avg_loss = total_loss / len(train_loader)\n","            avg_grad_norm = total_grad_norm / len(train_loader)\n","            avg_blank_probs = total_blank_probs / len(train_loader)\n","            avg_cer = total_cer / num_valid_batches\n","            avg_wer = total_wer / num_valid_batches\n","            avg_cer_prob = total_cer_prob / num_valid_batches\n","            avg_wer_prob = total_wer_prob / num_valid_batches\n","\n","                    \n","            writer.add_scalar('Loss/train_epoch', avg_loss, epoch)\n","            writer.add_scalar('Gradient_Norm/train_epoch', avg_grad_norm, epoch)\n","            writer.add_scalar('Blank_Probability/train_epoch', avg_blank_probs, epoch)\n","            writer.add_scalar('CER/train_epoch', avg_cer, epoch)\n","            writer.add_scalar('WER/train_epoch', avg_wer, epoch)\n","            writer.add_scalar('CER_Probability/train_epoch', avg_cer_prob, epoch)\n","            writer.add_scalar('WER_Probability/train_epoch', avg_wer_prob, epoch)\n","            print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.4f}\")\n","            print(f\"Avg CER: {avg_cer:.4f}, Avg WER: {avg_wer:.4f}\")\n","            print(f\"Avg CER Probability: {avg_cer_prob:.4f}, Avg WER Probability: {avg_wer_prob:.4f}\")\n","            optuna_logger.info(f\"Train process finished: Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.4f}\")\n","            optuna_logger.info(f\"Avg CER: {avg_cer:.4f}, Avg WER: {avg_wer:.4f}\")\n","            optuna_logger.info(f\"Avg CER Probability: {avg_cer_prob:.4f}, Avg WER Probability: {avg_wer_prob:.4f}\")\n","\n","            # Validation with TensorBoard logging\n","            model.eval()\n","            optuna_logger.info('Start Evaluation process.')\n","            val_loss = 0\n","            val_blank_probs = 0\n","            val_cer = 0\n","            val_wer = 0\n","            val_cer_prob = 0\n","            val_wer_prob = 0\n","            val_num_batches = 0\n","            with torch.no_grad():\n","                for batch_idx, (imgs, labels, label_lengths) in enumerate(val_loader):\n","                    imgs, labels = imgs.to(device), labels.to(device)\n","                    label_lengths = label_lengths.to(device)\n","                    outputs = model(imgs)\n","                    outputs = outputs.log_softmax(2)\n","                    seq_length = outputs.size(0)\n","                    input_lengths = torch.full((imgs.size(0),), seq_length, dtype=torch.long).to(device)\n","                    val_loss += criterion(outputs, labels, input_lengths, label_lengths).item()\n","                    val_blank_probs += outputs[:, :, 0].exp().mean().item()\n","\n","                    # Compute CER, WER, and CER/WER probability\n","                    pred_texts = beam_search_decode(\n","                        output=outputs,\n","                        idx_to_char=idx_to_char,\n","                        target_lengths=label_lengths,\n","                        beam_width=BSD_BEAM_WIDTH,\n","                        blank_penalty=BSD_BLANK_PENALTY,\n","                        length_penalty=BSD_LENGTH_PENALTY,\n","                        global_step=epoch\n","                    )\n","                    label_sequences = split_labels(labels, label_lengths)\n","                    ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n","                                    for label_seq in label_sequences]\n","\n","                    cer = compute_cer(pred_texts, ground_truth)\n","                    wer = compute_wer(pred_texts, ground_truth)\n","                    cer_prob, wer_prob = compute_cer_wer_probability(outputs, pred_texts, ground_truth, idx_to_char)\n","\n","                    val_cer += cer\n","                    val_wer += wer\n","                    val_cer_prob += cer_prob\n","                    val_wer_prob += wer_prob\n","                    val_num_batches += 1\n","       \n","                    # Logging raw outputs for the first batch\n","                    if batch_idx == 0:  # We only log the first batch to save space\n","\n","                        # Control of the form and content of outputs\n","                        #print(f\"Outputs shape: {outputs.shape}, Outputs[0] shape: {outputs[0].shape}\")\n","                        optuna_logger.debug(f\"Outputs shape: {outputs.shape}, Outputs[0] shape: {outputs[0].shape}\")\n","                        if outputs.numel() == 0 or torch.isnan(outputs).any() or torch.isinf(outputs).any():\n","                            #print(\"Warning: Outputs contains invalid values (empty, NaN, or Inf). Skipping histogram logging.\")\n","                            optuna_logger.warning(\"Warning: Outputs contains invalid values (empty, NaN, or Inf). Skipping histogram logging.\")\n","                            continue\n","\n","                        # 1. Histogram of the distribution of predicted tokens (argmax)\n","                        raw_outputs = outputs.argmax(2).cpu().numpy()  # [seq_length, batch_size]\n","                        writer.add_histogram(\n","                            'Raw_Outputs/val_argmax',\n","                            raw_outputs.flatten(),  # We convert to a 1D array for the histogram\n","                            global_step=epoch\n","                        )\n","\n","                        # 2. Text listing of raw outputs (first 5 sequences)\n","                        raw_outputs_text = str(raw_outputs[:5])  # First 5 sequences as text\n","                        writer.add_text(\n","                            'Raw_Outputs/val_text',\n","                            f\"Raw validation outputs (argmax) for first batch:\\n{raw_outputs_text}\",\n","                            global_step=epoch\n","                        )\n","\n","                        # 3. Calculating token frequency and logging to TensorBoard\n","                        token_counts = Counter(raw_outputs.flatten())\n","                        writer.add_text(\n","                            'Raw_Outputs/val_token_counts',\n","                            f\"Token counts: {token_counts}\",\n","                            global_step=epoch\n","                        )\n","\n","                        # 4. (Optional) Logit histogram for specific tokens (e.g. first time step)\n","                        logits_first_step = outputs[0].cpu().numpy()  # [batch_size, num_chars]\n","                        writer.add_histogram(\n","                            'Raw_Outputs/val_logits_first_step',\n","                            logits_first_step.flatten(),\n","                            global_step=epoch\n","                        )\n","\n","                        logits_first_step = outputs[0].cpu().numpy()\n","                        writer.add_histogram('Logits/val_probs', torch.softmax(outputs[0], dim=-1).flatten(), global_step)\n","\n","                val_loss /= len(val_loader)\n","                val_blank_probs /= len(val_loader)\n","                val_cer /= val_num_batches\n","                val_wer /= val_num_batches\n","                val_cer_prob /= val_num_batches\n","                val_wer_prob /= val_num_batches\n","\n","                harmonic_mean = compute_harmonic_mean(val_cer, val_wer)\n","\n","                #if val_cer + val_wer == 0:\n","                #    harmonic_mean = 0.0\n","                #else:\n","                #    harmonic_mean = 2 / (1 / (val_cer + 1e-9) + 1 / (val_wer + 1e-9))\n","                \n","                pred_texts = beam_search_decode(\n","                                output=outputs,\n","                                idx_to_char=idx_to_char,\n","                                target_lengths=label_lengths,\n","                                beam_width=BSD_BEAM_WIDTH,\n","                                blank_penalty=BSD_BLANK_PENALTY,\n","                                length_penalty=BSD_LENGTH_PENALTY\n","                            )\n","                label_sequences = split_labels(labels, label_lengths)\n","                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n","                                for label_seq in label_sequences[:5]]\n","\n","                # Calculating edit distance\n","                edit_distances = []\n","                for pred, gt in zip(pred_texts, ground_truth):\n","                    edit_distances.append(levenshtein_distance(pred, gt))\n","                avg_edit_distance = sum(edit_distances) / len(edit_distances) if edit_distances else 0\n","\n","                \n","                # Validation logging to TensorBoard\n","                writer.add_scalar('Loss/val_epoch', val_loss, epoch)\n","                writer.add_scalar('Blank_Probability/val_epoch', val_blank_probs, epoch)\n","                writer.add_scalar('CER/val_epoch', val_cer, epoch)\n","                writer.add_scalar('WER/val_epoch', val_wer, epoch)\n","                writer.add_scalar('CER_Probability/val_epoch', val_cer_prob, epoch)\n","                writer.add_scalar('WER_Probability/val_epoch', val_wer_prob, epoch)\n","                writer.add_scalar('Harmonic_mean/val_epoch', harmonic_mean, epoch)\n","                writer.add_text('Predictions/val', f\"Validation Predictions: {pred_texts[:5]}\", epoch)\n","                writer.add_text('Ground_Truth/val', f\"Ground Truth: {ground_truth}\", epoch)\n","                print(f\"Validation Loss: {val_loss:.4f}\")\n","                optuna_logger.debug(f\"Validation Loss: {val_loss:.4f}\")\n","                print(f\"Validation CER: {val_cer:.4f}, Validation WER: {val_wer:.4f}\")\n","                optuna_logger.debug(f\"Validation CER: {val_cer:.4f}, Validation WER: {val_wer:.4f}\")\n","                print(f\"Validation CER Probability: {val_cer_prob:.4f}, Validation WER Probability: {val_wer_prob:.4f}\")\n","                optuna_logger.debug(f\"Validation CER Probability: {val_cer_prob:.4f}, Validation WER Probability: {val_wer_prob:.4f}\")\n","                #print(\"Validation Predictions:\", pred_texts[:5])\n","                optuna_logger.debug(f\"Validation Predictions: {pred_texts[:5]}\")\n","                #print(\"Ground Truth:\", ground_truth)\n","                optuna_logger.debug(f\"Ground Truth: {ground_truth}\")\n","                print(\"Harmonic mean:\", harmonic_mean)\n","                optuna_logger.debug(f\"Harmonic mean: {harmonic_mean}\")\n","\n","            scheduler.step(val_loss)\n","\n","            current_lr = scheduler.get_last_lr()[0]  # get_last_lr() returns a list.\n","            #print(f\"Current Learning Rate: {current_lr}\")\n","            optuna_logger.debug(f\"Current Learning Rate: {current_lr}\")\n","\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                torch.save(model.state_dict(), os.path.join(MODEL_DIR, f'best_ocr_model_{trial.number}.pth'))\n","                optuna_logger.info(f\"Best model was saved: best_ocr_model_{trial.number}.pth\")\n","\n","            optuna_logger.info(f\"Validation process finished: Epoch {epoch+1}/{EPOCHS}, Loss: {val_loss:.4f}\")\n","            \n","        torch.save(model.state_dict(), os.path.join(MODEL_DIR, f'final_ocr_model_{trial.number}.pth'))\n","        optuna_logger.info(f\"Final model was saved: final_ocr_model_{trial.number}.pth\")\n","\n","    avg_grad_norm /= EPOCHS\n","    avg_blank_probs /= EPOCHS\n","\n","    trial.set_user_attr(\"best_val_cer\", best_val_loss)\n","    trial.set_user_attr(\"avg_grad_norm\", avg_grad_norm)\n","    trial.set_user_attr(\"val_cer_prob\", val_cer_prob)\n","    trial.set_user_attr(\"val_wer_prob\", val_wer_prob)\n","    trial.set_user_attr(\"avg_blank_probs\", val_blank_probs)\n","    trial.set_user_attr(\"harmonic_mean\", harmonic_mean)\n","\n","    # Closing the TensorBoard writer\n","    writer.close()\n","\n","    return val_cer_prob, val_wer_prob, avg_blank_probs, harmonic_mean  # Metric to minimize"]},{"cell_type":"markdown","id":"fa5cb253","metadata":{"papermill":{"duration":0.017393,"end_time":"2025-05-20T09:34:24.253809","exception":false,"start_time":"2025-05-20T09:34:24.236416","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Function to run Optuna Dashboard in the background</font>**"]},{"cell_type":"code","execution_count":50,"id":"cd97045c","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:24.28884Z","iopub.status.busy":"2025-05-20T09:34:24.28862Z","iopub.status.idle":"2025-05-20T09:34:24.291616Z","shell.execute_reply":"2025-05-20T09:34:24.291007Z"},"papermill":{"duration":0.021881,"end_time":"2025-05-20T09:34:24.292786","exception":false,"start_time":"2025-05-20T09:34:24.270905","status":"completed"},"tags":[]},"outputs":[],"source":["def run_optuna_dashboard(storage_path):\n","    print(f\"Starting Optuna Dashboard with storage: {storage_path}\")\n","    os.system(f\"optuna-dashboard sqlite:///{storage_path} --host 0.0.0.0 --port 8080 &\")"]},{"cell_type":"markdown","id":"b5b115f3","metadata":{"papermill":{"duration":0.016747,"end_time":"2025-05-20T09:34:24.326762","exception":false,"start_time":"2025-05-20T09:34:24.310015","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Function create model from optuna optimizations trial parameters</font>**"]},{"cell_type":"code","execution_count":51,"id":"77d301e8","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:24.361612Z","iopub.status.busy":"2025-05-20T09:34:24.361384Z","iopub.status.idle":"2025-05-20T09:34:24.366547Z","shell.execute_reply":"2025-05-20T09:34:24.366024Z"},"papermill":{"duration":0.024195,"end_time":"2025-05-20T09:34:24.367838","exception":false,"start_time":"2025-05-20T09:34:24.343643","status":"completed"},"tags":[]},"outputs":[],"source":["def construct_config_model(trial_params):\n","    \"\"\"Construct config_model from Optuna trial parameters.\"\"\"\n","    return {\n","        'cnn_layers': [\n","            {'type': 'conv', 'out_channels': trial_params['cnn_out_channels_1'], 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu', 'dropout': trial_params['cnn_dropout_1']},\n","            {'type': 'pool', 'kernel_size': 2, 'stride': 2},\n","            {'type': 'conv', 'out_channels': trial_params['cnn_out_channels_2'], 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu', 'dropout': trial_params['cnn_dropout_2']},\n","            {'type': 'pool', 'kernel_size': 2, 'stride': 2},\n","            {'type': 'conv', 'out_channels': trial_params['cnn_out_channels_3'], 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu'},\n","            {'type': 'pool', 'kernel_size': (2, 2), 'stride': (2, 1), 'padding': (0, 1)},\n","            {'type': 'conv', 'out_channels': trial_params['cnn_out_channels_4'], 'kernel_size': 3, 'stride': 1, 'padding': 1, 'batchnorm': True, 'activation': 'relu'},\n","            {'type': 'pool', 'kernel_size': (2, 2), 'stride': (2, 1), 'padding': (0, 1)},\n","        ],\n","        'rnn_type': 'lstm',\n","        'rnn_layers': trial_params['rnn_layers'],\n","        'hidden_size': trial_params['hidden_size'],\n","        'bidirectional': True,\n","        'dropout': trial_params['rnn_dropout'],\n","        'fc_layers': [len(CHARSET)],  # Adjust based on your num_chars\n","    }"]},{"cell_type":"markdown","id":"fb2aa9e3","metadata":{"papermill":{"duration":0.016512,"end_time":"2025-05-20T09:34:24.400827","exception":false,"start_time":"2025-05-20T09:34:24.384315","status":"completed"},"tags":[]},"source":["### **<font style=\"color:green\">Function for calculation of balance metric</font>**"]},{"cell_type":"code","execution_count":52,"id":"2c806172","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:24.435079Z","iopub.status.busy":"2025-05-20T09:34:24.434811Z","iopub.status.idle":"2025-05-20T09:34:24.43819Z","shell.execute_reply":"2025-05-20T09:34:24.43761Z"},"papermill":{"duration":0.022182,"end_time":"2025-05-20T09:34:24.439471","exception":false,"start_time":"2025-05-20T09:34:24.417289","status":"completed"},"tags":[]},"outputs":[],"source":["# Select best trial (minimize |val_cer - val_wer| first, then best_val_loss)\n","def balance_metric(t):\n","    val_cer = t.user_attrs.get('val_cer', float('inf'))\n","    val_wer = t.user_attrs.get('val_wer', float('inf'))\n","    balance = abs(val_cer - val_wer)  # Absolute difference for CER-WER balance\n","    return (balance, t.values[0])  # Balance first, then val_loss"]},{"cell_type":"markdown","id":"b2e34a72","metadata":{"papermill":{"duration":0.01686,"end_time":"2025-05-20T09:34:24.473996","exception":false,"start_time":"2025-05-20T09:34:24.457136","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Main function</font>**\n","-------------------"]},{"cell_type":"code","execution_count":53,"id":"813f9aa8","metadata":{"execution":{"iopub.execute_input":"2025-05-20T09:34:24.509281Z","iopub.status.busy":"2025-05-20T09:34:24.509082Z","iopub.status.idle":"2025-05-20T17:26:04.625286Z","shell.execute_reply":"2025-05-20T17:26:04.624337Z"},"papermill":{"duration":28300.135712,"end_time":"2025-05-20T17:26:04.626852","exception":false,"start_time":"2025-05-20T09:34:24.49114","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated 0/10240 images (Country: Belgium, Text: CPUPC5)\n","Generated 100/10240 images (Country: Brazil, Text: HENYQ1)\n","Generated 200/10240 images (Country: Italy, Text: RVDZZ6)\n","Generated 300/10240 images (Country: Australia, Text: UOEJY1)\n","Generated 400/10240 images (Country: Belgium, Text: 4-DHX-503)\n","Generated 500/10240 images (Country: USA_v1, Text: FZJBH1)\n","Generated 600/10240 images (Country: Austria, Text: 5GHAA98)\n","Generated 700/10240 images (Country: Austria, Text: ZZOSB7)\n","Generated 800/10240 images (Country: USA_v1, Text: HRTAR3)\n","Generated 900/10240 images (Country: USA_v1, Text: ARLWN9)\n","Generated 1000/10240 images (Country: France, Text: TXQRN3)\n","Generated 1100/10240 images (Country: Serbia, Text: HPXFT6)\n","Generated 1200/10240 images (Country: Hungary, Text: NCOK2)\n","Generated 1300/10240 images (Country: USA_v2, Text: VCVTT1)\n","Generated 1400/10240 images (Country: Hungary, Text: FYFX2)\n","Generated 1500/10240 images (Country: Australia, Text: BYGEI8)\n","Generated 1600/10240 images (Country: France, Text: FA-325-BY)\n","Generated 1700/10240 images (Country: Norway, Text: PL 55 WQO)\n","Generated 1800/10240 images (Country: Germany, Text: PUDDU4)\n","Generated 1900/10240 images (Country: Spain, Text: ITBPV3)\n","Generated 2000/10240 images (Country: Belgium, Text: OGDU50)\n","Generated 2100/10240 images (Country: USA_v2, Text: AUXLM7)\n","Generated 2200/10240 images (Country: Netherlands, Text: NP 95 LF)\n","Generated 2300/10240 images (Country: Belgium, Text: F 614 FFA)\n","Generated 2400/10240 images (Country: Serbia, Text: HT 800-BO)\n","Generated 2500/10240 images (Country: Hungary, Text: YOCK2)\n","Generated 2600/10240 images (Country: Ukraine, Text: DNUTB3)\n","Generated 2700/10240 images (Country: Ukraine, Text: WFKFZ3)\n","Generated 2800/10240 images (Country: Spain, Text: FSJZ-17-R)\n","Generated 2900/10240 images (Country: Sweden, Text: YPCUL8)\n","Generated 3000/10240 images (Country: France, Text: TR949BF)\n","Generated 3100/10240 images (Country: USA_v1, Text: BDALD8)\n","Generated 3200/10240 images (Country: Spain, Text: LMPPP6)\n","Generated 3300/10240 images (Country: Serbia, Text: OTRVH6)\n","Generated 3400/10240 images (Country: Spain, Text: NCXHU4)\n","Generated 3500/10240 images (Country: Netherlands, Text: JTQX5)\n","Generated 3600/10240 images (Country: USA_v2, Text: HUHKF8)\n","Generated 3700/10240 images (Country: France, Text: EWKIC4)\n","Generated 3800/10240 images (Country: Belgium, Text: QUZDD4)\n","Generated 3900/10240 images (Country: Germany, Text: PHVU96)\n","Generated 4000/10240 images (Country: Czech Republic, Text: M8RFSQE)\n","Generated 4100/10240 images (Country: USA_v1, Text: ZWRQJ9)\n","Generated 4200/10240 images (Country: Norway, Text: HWLSI4)\n","Generated 4300/10240 images (Country: Ukraine, Text: IUIRG8)\n","Generated 4400/10240 images (Country: Italy, Text: QO 658SU)\n","Generated 4500/10240 images (Country: Belgium, Text: PODQS6)\n","Generated 4600/10240 images (Country: Belgium, Text: WPPT26)\n","Generated 4700/10240 images (Country: Brazil, Text: FTLQK3)\n","Generated 4800/10240 images (Country: Belgium, Text: 1-CZP-281)\n","Generated 4900/10240 images (Country: Netherlands, Text: EDHE9)\n","Generated 5000/10240 images (Country: Serbia, Text: QF 351-EM)\n","Generated 5100/10240 images (Country: USA_v1, Text: CWEMN4)\n","Generated 5200/10240 images (Country: Norway, Text: OSWDN7)\n","Generated 5300/10240 images (Country: United Kingdom, Text: VS92GDJ)\n","Generated 5400/10240 images (Country: Italy, Text: ZRYJ65)\n","Generated 5500/10240 images (Country: United Kingdom, Text: RMKP1)\n","Generated 5600/10240 images (Country: Hungary, Text: KHAT9)\n","Generated 5700/10240 images (Country: France, Text: IY 759 MZ)\n","Generated 5800/10240 images (Country: USA_v1, Text: DOTGT2)\n","Generated 5900/10240 images (Country: Czech Republic, Text: F5-ARIKC)\n","Generated 6000/10240 images (Country: Italy, Text: ISKCT6)\n","Generated 6100/10240 images (Country: USA_v2, Text: BQBYH6)\n","Generated 6200/10240 images (Country: Italy, Text: DY576XG)\n","Generated 6300/10240 images (Country: USA_v1, Text: AGETU7)\n","Generated 6400/10240 images (Country: Austria, Text: ZATWB4)\n","Generated 6500/10240 images (Country: Italy, Text: ND307IP)\n","Generated 6600/10240 images (Country: Austria, Text: JOYII6)\n","Generated 6700/10240 images (Country: Spain, Text: PDCXC3)\n","Generated 6800/10240 images (Country: United Kingdom, Text: RI56 ECM)\n","Generated 6900/10240 images (Country: USA_v2, Text: URRZM5)\n","Generated 7000/10240 images (Country: Belgium, Text: Y 905 BDS)\n","Generated 7100/10240 images (Country: Czech Republic, Text: P1VSUYB)\n","Generated 7200/10240 images (Country: USA_v2, Text: 073 EZN)\n","Generated 7300/10240 images (Country: Austria, Text: RMPAP6)\n","Generated 7400/10240 images (Country: United Kingdom, Text: CUJS3)\n","Generated 7500/10240 images (Country: Norway, Text: WGGXD3)\n","Generated 7600/10240 images (Country: France, Text: UFNIA3)\n","Generated 7700/10240 images (Country: Austria, Text: NQBZO6)\n","Generated 7800/10240 images (Country: Brazil, Text: MPNWU7)\n","Generated 7900/10240 images (Country: Netherlands, Text: NP 80 SC)\n","Generated 8000/10240 images (Country: Germany, Text: FTHRO4)\n","Generated 8100/10240 images (Country: Belgium, Text: EUNGL2)\n","Generated 8200/10240 images (Country: Australia, Text: TPJNO8)\n","Generated 8300/10240 images (Country: USA_v2, Text: TJCFN5)\n","Generated 8400/10240 images (Country: Austria, Text: 2FHHE81)\n","Generated 8500/10240 images (Country: Czech Republic, Text: L6OAKFP)\n","Generated 8600/10240 images (Country: Australia, Text: LHAPB6)\n","Generated 8700/10240 images (Country: Belgium, Text: GHKIW5)\n","Generated 8800/10240 images (Country: Ukraine, Text: 86AABL63)\n","Generated 8900/10240 images (Country: France, Text: UA-328-NC)\n","Generated 9000/10240 images (Country: USA_v1, Text: ANHDW7)\n","Generated 9100/10240 images (Country: USA_v1, Text: APHZS9)\n","Generated 9200/10240 images (Country: Sweden, Text: EXN 121)\n","Generated 9300/10240 images (Country: Austria, Text: ZEHHB3)\n","Generated 9400/10240 images (Country: USA_v2, Text: KHDNE4)\n","Generated 9500/10240 images (Country: Hungary, Text: GQJT8)\n","Generated 9600/10240 images (Country: Norway, Text: 10GUJUZ)\n","Generated 9700/10240 images (Country: Austria, Text: 0FXRZ91)\n","Generated 9800/10240 images (Country: Germany, Text: LKLH02)\n","Generated 9900/10240 images (Country: Czech Republic, Text: X0GGWGE)\n","Generated 10000/10240 images (Country: USA_v1, Text: LPEXI5)\n","Generated 10100/10240 images (Country: France, Text: UMVJ72)\n","Generated 10200/10240 images (Country: Australia, Text: GYG 932)\n","Labels written to '/kaggle/working/synthetic_data/labels.txt' (before cleaning).\n","Cleaned /kaggle/working/synthetic_data/labels.txt: 0 labels modified, 0 labels removed.\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 1200x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Total characters analyzed: 67172\n","Character frequencies: {'C': 1778, 'P': 1793, 'U': 1839, '5': 1811, 'D': 1848, 'T': 1764, 'R': 1790, 'B': 1852, '3': 1568, '6': 1678, '4': 1619, 'X': 1810, 'W': 1821, 'H': 1856, 'J': 1822, '0': 1652, 'L': 1829, 'I': 1756, 'O': 1832, '9': 1738, 'V': 1739, 'N': 1767, '1': 1682, 'K': 1764, 'S': 1792, 'E': 1744, '8': 1644, 'Y': 1822, ' ': 1781, 'Q': 1864, 'M': 1726, '-': 1705, '7': 1682, 'F': 1760, '2': 1752, 'G': 1848, 'Z': 1815, 'A': 1829}\n","Dataset generated! Images saved in '/kaggle/working/synthetic_data/images', labels in '/kaggle/working/synthetic_data/labels.txt'\n"]},{"name":"stderr","output_type":"stream","text":["Epochs: 100%|██████████| 20/20 [7:49:58<00:00, 1409.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/onnx/symbolic_opset9.py:4279: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\n","Training completed!\n","Final metrics:\n","  Best Validation Loss: 13.2713\n","  Final Validation CER: 1.0429\n","  Final Validation WER: 1.0000\n","  Final Harmonic Mean: 1.0210\n","\n"]}],"source":["if __name__ == \"__main__\":\n","    # Synthetic data generation (same as originally)\n","    if not font_files:\n","        print(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n","        main_logger.error(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n","    else:\n","        create_synthetic_dataset(NUM_SAMPLES)\n","        main_logger.info(\"Synthetic dataset generated.\")\n","\n","    # Path to Optuna database\n","    storage_path = os.path.join(OPTUNA_DIR, 'optuna_study.db')\n","    storage = f\"sqlite:///{storage_path}\"\n","    main_logger.info(f\"Optuna database set at {storage_path}\")\n","\n","    # Device setup\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    if not FINAL_TRAINING:\n","        # Multi-objective study\n","        study = optuna.create_study(\n","            directions=[\"minimize\", \"minimize\", \"minimize\", \"maximize\"],  # Validation loss, grad_norm, blank_probs\n","            storage=storage,\n","            study_name=\"ocr_multiobjective\",\n","            load_if_exists=True\n","        )\n","        main_logger.info(\"Set & Run Optuna optimalization.\")\n","        study.optimize(objective, n_trials=NUMBER_OF_OPTUNA_TRIALS) # You can adjust the number of trials\n","\n","        # Log best trials (Pareto front)\n","        #print(\"Best trials (Pareto front):\")\n","        main_logger.info(\"Best trials (Pareto front):\")\n","        for trial in study.best_trials:\n","            #print(f\"  Trial {trial.number}:\")\n","            main_logger.debug(f\"Trial {trial.number}:\")\n","            #print(f\"    Values: val_loss={trial.values[0]}, grad_norm={trial.values[1]}, blank_probs={trial.values[2]}\")\n","            main_logger.debug(f\"Values: val_loss={trial.values[0]}, grad_norm={trial.values[1]}, blank_probs={trial.values[2]}\")\n","            #print(f\"    Params: {trial.params}\")\n","            main_logger.debug(f\"Params: {trial.params}\")\n","\n","        # Running Optuna Dashboard in the background\n","        dashboard_thread = threading.Thread(target=run_optuna_dashboard, args=(storage_path,))\n","        dashboard_thread.start()\n","    else:\n","        # Load study for final training\n","        main_logger.info(\"Starting final training with predefined hyperparameters and model configuration.\")\n","        pretrained_model_path = PRETRAINED_MODEL_PATH\n","        \n","        # Construct config_model from best trial parameters\n","        config_model_train = config_model\n","\n","        # Load dataset\n","        full_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n","        main_logger.info(\"Loaded dataset for final training.\")\n","\n","        # Run final training\n","        best_val_loss, final_val_cer, final_val_wer, final_harmonic_mean = train(\n","            full_dataset=full_dataset,\n","            device=device,\n","            config_model=config_model_train,\n","            pretrained_model_path=PRETRAINED_MODEL_PATH,\n","            num_epochs=FINAL_EPOCHS,\n","            learning_rate=LEARNING_RATE,\n","            weight_decay=WEIGHT_DECAY,\n","            warmup_steps=WARMUP_STEPS,\n","            temperature=TEMPERATURE,\n","            ctc_entropy_weight=CTC_ENTROPY_WEIGHT,\n","            ctc_label_smoothing=CTC_LABEL_SMOOTHING,\n","            ctc_blank_penalty_weight=CTC_BLANK_PENALTY_WEIGHT,\n","            bsd_beam_width=BSD_BEAM_WIDTH,\n","            bsd_blank_penalty=BSD_BLANK_PENALTY,\n","            bsd_length_penalty=BSD_LENGTH_PENALTY,\n","            gradient_clipping_value=GRADIENT_CLIPPING_VALUE,\n","            gradient_norm_threshold=GRADIENT_NORM_TRESHOLD\n","        )\n","        \n","        main_logger.info(\n","            f\"Final training completed: \"\n","            f\"Best Validation Loss: {best_val_loss:.4f}, \"\n","            f\"Final Validation CER: {final_val_cer:.4f}, \"\n","            f\"Final Validation WER: {final_val_wer:.4f}, \"\n","            f\"Final Harmonic Mean: {final_harmonic_mean:.4f}\"\n","        )\n","\n","    # Close the file after logging is complete\n","    rotating_json_file_handler.close()"]},{"cell_type":"markdown","id":"4cfd7686","metadata":{"papermill":{"duration":0.022284,"end_time":"2025-05-20T17:26:04.672642","exception":false,"start_time":"2025-05-20T17:26:04.650358","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Check final ONNX model</font>**\n","-------------------"]},{"cell_type":"code","execution_count":54,"id":"f33e59c9","metadata":{"execution":{"iopub.execute_input":"2025-05-20T17:26:04.718741Z","iopub.status.busy":"2025-05-20T17:26:04.718472Z","iopub.status.idle":"2025-05-20T17:26:04.804632Z","shell.execute_reply":"2025-05-20T17:26:04.803568Z"},"papermill":{"duration":0.110869,"end_time":"2025-05-20T17:26:04.806037","exception":false,"start_time":"2025-05-20T17:26:04.695168","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["ONNX model is valid\n"]}],"source":["# Load ONNX model\n","if FINAL_TRAINING:\n","    onnx_model = onnx.load(os.path.join(MODEL_DIR, 'final_ocr_model_final.onnx'))\n","    onnx.checker.check_model(onnx_model)\n","    print(\"ONNX model is valid\")"]},{"cell_type":"code","execution_count":55,"id":"def177a0","metadata":{"execution":{"iopub.execute_input":"2025-05-20T17:26:04.858439Z","iopub.status.busy":"2025-05-20T17:26:04.858177Z","iopub.status.idle":"2025-05-20T17:26:04.895092Z","shell.execute_reply":"2025-05-20T17:26:04.894292Z"},"papermill":{"duration":0.065246,"end_time":"2025-05-20T17:26:04.896391","exception":false,"start_time":"2025-05-20T17:26:04.831145","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["ONNX inference successful, output shape: (34, 1, 39)\n"]}],"source":["# Run inference\n","if FINAL_TRAINING:\n","    ort_session = ort.InferenceSession(os.path.join(MODEL_DIR, 'final_ocr_model_final.onnx'))\n","    sample_input = np.random.randn(1, 1, IMG_HEIGHT, IMG_WIDTH).astype(np.float32)\n","    outputs = ort_session.run(None, {'input': sample_input})\n","    print(\"ONNX inference successful, output shape:\", outputs[0].shape)"]},{"cell_type":"markdown","id":"53eac0c8","metadata":{"papermill":{"duration":0.022627,"end_time":"2025-05-20T17:26:04.942369","exception":false,"start_time":"2025-05-20T17:26:04.919742","status":"completed"},"tags":[]},"source":["## **<font style=\"color:blue\">Download results</font>**\n","-------------------"]},{"cell_type":"code","execution_count":56,"id":"026cf7dd","metadata":{"execution":{"iopub.execute_input":"2025-05-20T17:26:04.98943Z","iopub.status.busy":"2025-05-20T17:26:04.989177Z","iopub.status.idle":"2025-05-20T17:26:04.992705Z","shell.execute_reply":"2025-05-20T17:26:04.99205Z"},"papermill":{"duration":0.028025,"end_time":"2025-05-20T17:26:04.993817","exception":false,"start_time":"2025-05-20T17:26:04.965792","status":"completed"},"tags":[]},"outputs":[],"source":["def zip_folder_with_shutil(source_folder, output_path):\n","    '''Function for zip dir data'''\n","    shutil.make_archive(output_path, 'zip', source_folder)"]},{"cell_type":"code","execution_count":57,"id":"d0d80a41","metadata":{"execution":{"iopub.execute_input":"2025-05-20T17:26:05.041339Z","iopub.status.busy":"2025-05-20T17:26:05.041104Z","iopub.status.idle":"2025-05-20T17:26:10.564326Z","shell.execute_reply":"2025-05-20T17:26:10.563656Z"},"papermill":{"duration":5.548824,"end_time":"2025-05-20T17:26:10.565861","exception":false,"start_time":"2025-05-20T17:26:05.017037","status":"completed"},"tags":[]},"outputs":[],"source":["zip_folder_with_shutil('/kaggle/working/backgrounds', '/kaggle/working/backgrounds')\n","zip_folder_with_shutil('/kaggle/working/synthetic_data', '/kaggle/working/synthetic_data')\n","zip_folder_with_shutil('/kaggle/working/model_dir', '/kaggle/working/model_dir')\n","zip_folder_with_shutil('/kaggle/working/runs', '/kaggle/working/runs')\n","zip_folder_with_shutil('/kaggle/working/optuna', '/kaggle/working/optuna')\n","zip_folder_with_shutil('/kaggle/working/logs', '/kaggle/working/logs')"]},{"cell_type":"code","execution_count":58,"id":"e4494ec6","metadata":{"execution":{"iopub.execute_input":"2025-05-20T17:26:10.613376Z","iopub.status.busy":"2025-05-20T17:26:10.613144Z","iopub.status.idle":"2025-05-20T17:26:10.615824Z","shell.execute_reply":"2025-05-20T17:26:10.615225Z"},"papermill":{"duration":0.027774,"end_time":"2025-05-20T17:26:10.617019","exception":false,"start_time":"2025-05-20T17:26:10.589245","status":"completed"},"tags":[]},"outputs":[],"source":["#!tensorboard --logdir=/kaggle/working/runs --port 6006\n","#!optuna-dashboard sqlite:///kaggle/working/optuna/optuna_study.db"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":6783030,"sourceId":10951507,"sourceType":"datasetVersion"}],"dockerImageVersionId":30918,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":28389.617927,"end_time":"2025-05-20T17:26:13.614314","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-20T09:33:03.996387","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}