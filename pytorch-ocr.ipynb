{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10911708,"sourceType":"datasetVersion","datasetId":6783030}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---------------\n\n# **<font style=\"color:Black\">Create OCR by PyTorch</font>**\n-------------------\n-----------------","metadata":{}},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Installation and import libraries</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"!pip install  pillow \n!pip install opencv-python\n!pip install matplotlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:26.019255Z","iopub.execute_input":"2025-03-06T23:15:26.019602Z","iopub.status.idle":"2025-03-06T23:15:40.689940Z","shell.execute_reply.started":"2025-03-06T23:15:26.019569Z","shell.execute_reply":"2025-03-06T23:15:40.688643Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.20->matplotlib) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport random\nfrom PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter\nimport numpy as np\nimport cv2\n\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F  # Add this import\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:40.691133Z","iopub.execute_input":"2025-03-06T23:15:40.691492Z","iopub.status.idle":"2025-03-06T23:15:48.955161Z","shell.execute_reply.started":"2025-03-06T23:15:40.691432Z","shell.execute_reply":"2025-03-06T23:15:48.954216Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Hyperparameters</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"OUTPUT_DIR = os.path.join('/kaggle','working','synthetic_data','images')\nMODEL_DIR = os.path.join('/kaggle','working','model_dir')\nLABELS_FILE = os.path.join('/kaggle','working','synthetic_data','labels.txt')\nNUM_SAMPLES = 5120  # Number of images generated\nIMG_WIDTH = 128\nIMG_HEIGHT = 32\nBATCH_SIZE = 32\nEPOCHS = 20\nLEARNING_RATE = 2e-5  \nWEIGHT_DECAY = 1e-4  \nWARMUP_STEPS = 1000  \nENTROPY_WEIGHT = 0.5\nTEMPERATURE = 0.3   \nBEAM_WIDTH = 10\nLABEL_SMOOTHING = 0.2\nBLANK_PENALTY_WEIGHT = 0.5\nCHARSET = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-*\"  # Group characters\nMAX_TEXT_LENGTH = 10  # Maximum length of text in an image\nFONT_DIR = os.path.join('/kaggle','input','google-fonts','GoogleFontScripts') # Folder with TrueType fonts (.ttf)\nBACKGROUND_DIR = os.path.join('/kaggle','working','backgrounds')  # New folder for background (optional)\nNUMBER_BACKGROUND_IMAGE = 50","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:48.956255Z","iopub.execute_input":"2025-03-06T23:15:48.956703Z","iopub.status.idle":"2025-03-06T23:15:48.963887Z","shell.execute_reply.started":"2025-03-06T23:15:48.956675Z","shell.execute_reply":"2025-03-06T23:15:48.962651Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Utils support functions</font>**\n-------------------","metadata":{}},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Create output folders</font>**","metadata":{}},{"cell_type":"code","source":"os.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(BACKGROUND_DIR, exist_ok=True)\n\n# Creates a new file\nwith open(LABELS_FILE, 'w') as fp:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:48.966258Z","iopub.execute_input":"2025-03-06T23:15:48.966766Z","iopub.status.idle":"2025-03-06T23:15:48.991577Z","shell.execute_reply.started":"2025-03-06T23:15:48.966714Z","shell.execute_reply":"2025-03-06T23:15:48.990587Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load the font list (add the paths to the .ttf files to the \"fonts\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"font_files = [\n    os.path.join(FONT_DIR, f) for f in os.listdir(FONT_DIR) \n    if f.endswith('.ttf') and os.path.isfile(os.path.join(FONT_DIR, f))\n]\nif not font_files:\n    raise FileNotFoundError(\"No fonts found in 'fonts' folder. Add .ttf files!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:48.993070Z","iopub.execute_input":"2025-03-06T23:15:48.993593Z","iopub.status.idle":"2025-03-06T23:15:49.418731Z","shell.execute_reply.started":"2025-03-06T23:15:48.993561Z","shell.execute_reply":"2025-03-06T23:15:49.417465Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generating a simple gradient background</font>**","metadata":{}},{"cell_type":"code","source":"def generate_gradient_background(filename, size=(128, 32)):\n    img = Image.new('L', size, color=230)  # Lighter gray as a base\n    draw = ImageDraw.Draw(img)\n    for y in range(size[1]):\n        # Soft gradient with low contrast\n        color = int(230 - 20 * (y / size[1]))  # From light gray to slightly darker\n        draw.line([(0, y), (size[0], y)], fill=color)\n    # Background blur\n    img = img.filter(ImageFilter.GaussianBlur(radius=2))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.419749Z","iopub.execute_input":"2025-03-06T23:15:49.420024Z","iopub.status.idle":"2025-03-06T23:15:49.426497Z","shell.execute_reply.started":"2025-03-06T23:15:49.420003Z","shell.execute_reply":"2025-03-06T23:15:49.425110Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generate a background with noise (paper texture)</font>**","metadata":{}},{"cell_type":"code","source":"def generate_paper_texture(filename, size=(128, 32)):\n    img = Image.new('L', size, color=220)  # Lighter gray\n    noise = np.random.normal(0, 5, size).astype(np.uint8)  # Less noise\n    noise_img = Image.fromarray(noise)\n    img.paste(noise_img, (0, 0), noise_img)\n    # Blur for a softer effect\n    img = img.filter(ImageFilter.GaussianBlur(radius=1.5))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.427925Z","iopub.execute_input":"2025-03-06T23:15:49.428393Z","iopub.status.idle":"2025-03-06T23:15:49.458603Z","shell.execute_reply.started":"2025-03-06T23:15:49.428351Z","shell.execute_reply":"2025-03-06T23:15:49.457326Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Creating multiple backgrounds</font>**","metadata":{}},{"cell_type":"code","source":"for i in range(NUMBER_BACKGROUND_IMAGE):\n    generate_gradient_background(f\"gradient_{i}.png\")\n    generate_paper_texture(f\"paper_{i}.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.460274Z","iopub.execute_input":"2025-03-06T23:15:49.460984Z","iopub.status.idle":"2025-03-06T23:15:49.583321Z","shell.execute_reply.started":"2025-03-06T23:15:49.460937Z","shell.execute_reply":"2025-03-06T23:15:49.582162Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load backgrounds (optional, add images to the \"backgrounds\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"background_files = (\n    [os.path.join(BACKGROUND_DIR, f) for f in os.listdir(BACKGROUND_DIR) \n     if f.endswith(('.png', '.jpg', '.jpeg'))] if os.path.exists(BACKGROUND_DIR) else []\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.584787Z","iopub.execute_input":"2025-03-06T23:15:49.585134Z","iopub.status.idle":"2025-03-06T23:15:49.591017Z","shell.execute_reply.started":"2025-03-06T23:15:49.585106Z","shell.execute_reply":"2025-03-06T23:15:49.589816Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Random text generation function</font>**","metadata":{}},{"cell_type":"code","source":"def generate_random_text(max_length):\n    length = random.randint(1, max_length)\n    return ''.join(random.choice(CHARSET) for _ in range(length))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.592266Z","iopub.execute_input":"2025-03-06T23:15:49.592757Z","iopub.status.idle":"2025-03-06T23:15:49.611431Z","shell.execute_reply.started":"2025-03-06T23:15:49.592718Z","shell.execute_reply":"2025-03-06T23:15:49.610218Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Functions for adding noise and distortions</font>**","metadata":{}},{"cell_type":"code","source":"def add_noise_and_distortion(img):\n    img_array = np.array(img)\n    # Mild Gaussian noise with lower intensity\n    if random.random() > 0.5:  # 50% šance\n        noise = np.random.normal(0, random.randint(5, 15), img_array.shape).astype(np.uint8)\n        img_array = cv2.add(img_array, noise)\n    # Subtle perspective distortion\n    rows, cols = img_array.shape\n    src_points = np.float32([[0, 0], [cols-1, 0], [0, rows-1], [cols-1, rows-1]])\n    dst_points = np.float32([\n        [random.uniform(0, 3), random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), random.uniform(0, 3)],\n        [random.uniform(0, 3), rows-1-random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), rows-1-random.uniform(0, 3)]\n    ])\n    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n    img_array = cv2.warpPerspective(img_array, matrix, (cols, rows))\n    return Image.fromarray(img_array)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.612606Z","iopub.execute_input":"2025-03-06T23:15:49.613002Z","iopub.status.idle":"2025-03-06T23:15:49.635578Z","shell.execute_reply.started":"2025-03-06T23:15:49.612964Z","shell.execute_reply":"2025-03-06T23:15:49.634503Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Improved image generation feature</font>**","metadata":{}},{"cell_type":"code","source":"def generate_synthetic_image(text, font_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n    # Pozadí\n    if background_files:\n        bg_path = random.choice(background_files)\n        img = Image.open(bg_path).convert('L').resize(img_size)\n    else:\n        img = Image.new('L', img_size, color=230)\n        draw = ImageDraw.Draw(img)\n        for y in range(img_size[1]):\n            color = int(230 - 20 * (y / img_size[1]))\n            draw.line([(0, y), (img_size[0], y)], fill=color)\n        img = img.filter(ImageFilter.GaussianBlur(radius=2))\n\n    draw = ImageDraw.Draw(img)\n\n    # Iterativní úprava fontu a textu\n    font_size = random.randint(20, min(IMG_HEIGHT-2, 28))\n    max_attempts = 5  # Omezení počtu pokusů\n    for attempt in range(max_attempts):\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n        if text_width <= IMG_WIDTH - 10:  # Text vejde\n            break\n        elif len(text) > 1:  # Zkrať text, pokud je příliš dlouhý\n            text = text[:len(text)//2]\n        else:  # Sniž velikost fontu\n            font_size = max(10, font_size - 5)  # Minimální velikost 10\n\n    # Pokud se nepodaří, použij minimální font a jednopísmený text\n    if text_width > IMG_WIDTH - 10:\n        text = text[0]  # Použij první písmeno\n        font_size = 10\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n    # Pozice textu\n    x = random.randint(5, max(5, IMG_WIDTH - text_width - 5))\n    y = random.randint(5, max(5, IMG_HEIGHT - text_height - 5))\n\n    # Zvýraznění textu\n    text_color = random.randint(0, 50)\n    outline_color = 200\n    for offset_x in [-1, 0, 1]:\n        for offset_y in [-1, 0, 1]:\n            if offset_x != 0 or offset_y != 0:\n                draw.text((x + offset_x, y + offset_y), text, font=font, fill=outline_color)\n    draw.text((x, y), text, font=font, fill=text_color)\n\n    # Šum a deformace\n    img = add_noise_and_distortion(img)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.636726Z","iopub.execute_input":"2025-03-06T23:15:49.637032Z","iopub.status.idle":"2025-03-06T23:15:49.661195Z","shell.execute_reply.started":"2025-03-06T23:15:49.637009Z","shell.execute_reply":"2025-03-06T23:15:49.660103Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function for splitting labels</font>**","metadata":{}},{"cell_type":"code","source":"def split_labels(labels, label_lengths):\n    \"\"\"Split a flat tensor of labels into a list of label sequences based on lengths.\"\"\"\n    split_labels = []\n    start = 0\n    for length in label_lengths:\n        split_labels.append(labels[start:start + length])\n        start += length\n    return split_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.665136Z","iopub.execute_input":"2025-03-06T23:15:49.665481Z","iopub.status.idle":"2025-03-06T23:15:49.690129Z","shell.execute_reply.started":"2025-03-06T23:15:49.665427Z","shell.execute_reply":"2025-03-06T23:15:49.689074Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function of Beam search decoding</font>**","metadata":{}},{"cell_type":"code","source":"def beam_search_decode(output, idx_to_char, beam_width=BEAM_WIDTH, blank_penalty=-0.1):\n    probs = output.softmax(2).cpu().numpy()  # [T, B, C]\n    T, B, C = probs.shape\n    predictions = []\n    \n    for b in range(B):\n        sequence_probs = [(0.0, [], 1.0)]  # (log_prob, sequence, prob)\n        for t in range(T):\n            new_sequences = []\n            for log_prob, seq, prob in sequence_probs:\n                top_k_probs, top_k_idx = torch.topk(torch.tensor(probs[t, b]), beam_width)\n                for k_prob, k_idx in zip(top_k_probs, top_k_idx):\n                    new_seq = seq + [k_idx.item()]\n                    new_prob = prob * k_prob.item()\n                    new_log_prob = log_prob + np.log(k_prob.item())\n                    if k_idx.item() == 0:  # Penalize blank\n                        new_log_prob += blank_penalty\n                    new_sequences.append((new_log_prob, new_seq, new_prob))\n            sequence_probs = sorted(new_sequences, key=lambda x: x[0], reverse=True)[:beam_width]\n        \n        # Collapse CTC repeats and remove blanks\n        best_seq = sequence_probs[0][1]\n        decoded = []\n        prev = -1\n        for idx in best_seq:\n            if idx != 0 and idx != prev:  # Skip blanks and repeats\n                decoded.append(idx_to_char.get(idx, ''))\n            prev = idx\n        predictions.append(''.join(decoded) if decoded else '<empty>')\n    \n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.691923Z","iopub.execute_input":"2025-03-06T23:15:49.692395Z","iopub.status.idle":"2025-03-06T23:15:49.752557Z","shell.execute_reply.started":"2025-03-06T23:15:49.692349Z","shell.execute_reply":"2025-03-06T23:15:49.751352Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Custom collate function</font>**","metadata":{}},{"cell_type":"code","source":"def custom_collate_fn(batch):\n    images, labels, label_lengths = zip(*batch)\n    # Stack images (all same size)\n    images = torch.stack(images, dim=0)\n    # Concatenate labels into a flat tensor\n    labels = torch.cat(labels, dim=0)\n    # Convert label_lengths to tensor\n    label_lengths = torch.tensor(label_lengths, dtype=torch.long)\n    return images, labels, label_lengths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.753753Z","iopub.execute_input":"2025-03-06T23:15:49.754028Z","iopub.status.idle":"2025-03-06T23:15:49.780487Z","shell.execute_reply.started":"2025-03-06T23:15:49.754005Z","shell.execute_reply":"2025-03-06T23:15:49.779265Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generování datasetu</font>**","metadata":{}},{"cell_type":"code","source":"def create_synthetic_dataset(num_samples):\n    labels = []\n    for i in range(num_samples):\n        text = generate_random_text(MAX_TEXT_LENGTH)\n        if not text:\n            continue\n        font_path = random.choice(font_files)\n        img = generate_synthetic_image(text, font_path)\n        img_name = f\"img_{i:05d}.png\"\n        img_path = os.path.join(OUTPUT_DIR, img_name)\n        img.save(img_path)\n        labels.append(f\"{img_name}\\t{text}\")  # Use tab (\\t) instead of space\n        if i % 100 == 0:\n            print(f\"Generated {i}/{num_samples} images\")\n\n    if labels:\n        with open(LABELS_FILE, 'w') as f:\n            f.write(\"\\n\".join(labels))\n        print(f\"Dataset generated! Images saved in '{OUTPUT_DIR}', labels in '{LABELS_FILE}'\")\n    else:\n        print(\"No labels generated!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.781874Z","iopub.execute_input":"2025-03-06T23:15:49.782313Z","iopub.status.idle":"2025-03-06T23:15:49.807941Z","shell.execute_reply.started":"2025-03-06T23:15:49.782274Z","shell.execute_reply":"2025-03-06T23:15:49.806805Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Mapping characters to indices and back</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"char_to_idx = {char: idx + 1 for idx, char in enumerate(CHARSET)}  # 0 is reserved for blank (CTC)\nidx_to_char = {idx: char for char, idx in char_to_idx.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.809129Z","iopub.execute_input":"2025-03-06T23:15:49.809463Z","iopub.status.idle":"2025-03-06T23:15:49.837895Z","shell.execute_reply.started":"2025-03-06T23:15:49.809414Z","shell.execute_reply":"2025-03-06T23:15:49.836901Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom dataset</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRDataset(Dataset):\n    def __init__(self, image_dir, labels_file):\n        self.image_dir = image_dir\n        self.labels_file = labels_file\n        self.data = []\n        with open(labels_file, 'r') as f:\n            for line in f:\n                if not line.strip():  # Skip empty lines\n                    continue\n                image_path, label = line.strip().split('\\t')\n                label_length = len(label)\n                self.data.append((image_path, label, label_length))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_path, label, label_length = self.data[idx]\n        image = Image.open(os.path.join(self.image_dir, image_path)).convert('L')\n        image = transforms.ToTensor()(image)\n        label_encoded = torch.tensor([char_to_idx[c] for c in label], dtype=torch.long)\n        return image, label_encoded, label_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.839124Z","iopub.execute_input":"2025-03-06T23:15:49.839411Z","iopub.status.idle":"2025-03-06T23:15:49.855917Z","shell.execute_reply.started":"2025-03-06T23:15:49.839388Z","shell.execute_reply":"2025-03-06T23:15:49.854857Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom CTC Loss with Blank Penalty</font>**\n-------------------\n> CTC Loss with Entropy Regularization","metadata":{}},{"cell_type":"code","source":"class CTCLossWithBlankPenalty(nn.Module):\n    def __init__(self, blank=0, zero_infinity=True, blank_penalty_weight=0.5, entropy_weight=0.5, label_smoothing=0.1):\n        super(CTCLossWithBlankPenalty, self).__init__()\n        self.blank = blank\n        self.zero_infinity = zero_infinity\n        self.blank_penalty_weight = blank_penalty_weight\n        self.entropy_weight = entropy_weight\n        self.label_smoothing = label_smoothing\n\n    def forward(self, log_probs, targets, input_lengths, target_lengths):\n        ctc_loss = F.ctc_loss(\n            log_probs,\n            targets,\n            input_lengths,\n            target_lengths,\n            blank=self.blank,\n            reduction='mean',\n            zero_infinity=self.zero_infinity\n        )\n        blank_probs = log_probs[:, :, self.blank].exp()\n        avg_blank_prob = blank_probs.mean(dim=0).mean()\n        probs = log_probs.exp()\n        entropy = -torch.sum(probs * log_probs, dim=2).mean()\n        total_loss = ctc_loss + self.blank_penalty_weight * avg_blank_prob - self.entropy_weight * entropy\n        return total_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.856967Z","iopub.execute_input":"2025-03-06T23:15:49.857300Z","iopub.status.idle":"2025-03-06T23:15:49.878956Z","shell.execute_reply.started":"2025-03-06T23:15:49.857266Z","shell.execute_reply":"2025-03-06T23:15:49.877934Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Model definition (CNN + RNN + CTC)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRModel(nn.Module):\n    def __init__(self, num_chars):\n        super(OCRModel, self).__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # 32x128 -> 16x64\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # 16x64 -> 8x32\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.Dropout(0.5)\n        )\n        self.linear = nn.Linear(256 * (IMG_HEIGHT // 4), 512)\n        self.rnn = nn.LSTM(\n            input_size=512,\n            hidden_size=256,  # Increased capacity\n            num_layers=3,     # Deeper RNN\n            bidirectional=True,\n            batch_first=True,\n            dropout=0.5\n        )\n        self.fc = nn.Linear(256 * 2, num_chars + 1)\n\n    def forward(self, x):\n        x = self.cnn(x)\n        x = x.permute(0, 3, 1, 2)\n        x = x.reshape(x.size(0), x.size(1), -1)\n        x = self.linear(x)\n        x = self.rnn(x)[0]\n        x = self.fc(x)\n        x = x[:, :MAX_TEXT_LENGTH, :]\n        x = x / TEMPERATURE  # Apply temperature scaling\n        x = x.permute(1, 0, 2)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.880070Z","iopub.execute_input":"2025-03-06T23:15:49.880495Z","iopub.status.idle":"2025-03-06T23:15:49.908763Z","shell.execute_reply.started":"2025-03-06T23:15:49.880432Z","shell.execute_reply":"2025-03-06T23:15:49.907578Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Training</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, device, epoch, warmup_steps=WARMUP_STEPS):\n    model.train()\n    total_loss = 0\n    global_step = epoch * len(train_loader)\n    for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n        imgs, labels = imgs.to(device), labels.to(device)\n        label_lengths = label_lengths.to(device)\n\n        if global_step < warmup_steps:\n            lr_scale = min(1.0, float(global_step + 1) / warmup_steps)\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = LEARNING_RATE * lr_scale\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        outputs = outputs / TEMPERATURE  # Apply temperature before log_softmax\n        outputs = outputs.log_softmax(2)\n\n        batch_size = imgs.size(0)\n        seq_length = outputs.size(0)\n        input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n\n        loss = criterion(outputs, labels, input_lengths, label_lengths)\n        if torch.isnan(loss) or torch.isinf(loss):\n            print(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n            continue\n\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n        optimizer.step()\n        total_loss += loss.item()\n        global_step += 1\n\n        if batch_idx % 10 == 0:\n            with torch.no_grad():\n                pred_texts = beam_search_decode(outputs, idx_to_char)\n                raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n                blank_probs = outputs[:, :, 0].exp().mean().item()\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:3]]\n                print(f\"Batch {batch_idx}, Gradient norm: {grad_norm.item():.4f}\")\n                print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n                print(f\"Avg Blank Probability: {blank_probs:.4f}\")\n                print(f\"Sample predictions: {pred_texts[:3]}\")\n                print(f\"Ground Truth (first 3): {ground_truth}\")\n                print(f\"Raw outputs (first 3): {raw_outputs}\")\n\n    return total_loss / len(train_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.909879Z","iopub.execute_input":"2025-03-06T23:15:49.910316Z","iopub.status.idle":"2025-03-06T23:15:49.934963Z","shell.execute_reply.started":"2025-03-06T23:15:49.910277Z","shell.execute_reply":"2025-03-06T23:15:49.933760Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Inference (prediction)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def decode_prediction(output, idx_to_char):\n    probs = output.softmax(2)\n    max_probs, preds = probs.max(dim=2)\n    preds = preds.cpu().numpy()\n    max_probs = max_probs.cpu().numpy()\n    texts = []\n    for i, (pred, prob) in enumerate(zip(preds.T, max_probs.T)):\n        print(f\"Raw prediction {i} (pre-filter): {pred}, Max probs: {prob}\")\n        # Dynamic threshold: 75th percentile of max probs in this sequence\n        threshold = np.percentile(prob, 75)\n        print(f\"Dynamic threshold for prediction {i}: {threshold:.4f}\")\n        pred_text = []\n        prev = -1\n        for idx, p in zip(pred, prob):\n            if idx != 0 and idx != prev and p > threshold:\n                pred_text.append(idx_to_char.get(idx, ''))\n            prev = idx\n        decoded = ''.join(pred_text)\n        texts.append(decoded if decoded else '<empty>')\n    return texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.936078Z","iopub.execute_input":"2025-03-06T23:15:49.936388Z","iopub.status.idle":"2025-03-06T23:15:49.959742Z","shell.execute_reply.started":"2025-03-06T23:15:49.936363Z","shell.execute_reply":"2025-03-06T23:15:49.958602Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Main launch</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    if not font_files:\n        print(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n    else:\n        create_synthetic_dataset(NUM_SAMPLES)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    full_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n    if len(full_dataset) == 0:\n        print(\"Dataset is empty! Check labels.txt or image directory.\")\n    else:\n        # Curriculum phases with pre-filtering\n        model = OCRModel(num_chars=len(CHARSET)).to(device)\n        criterion = CTCLossWithBlankPenalty(blank=0, zero_infinity=True, blank_penalty_weight=BLANK_PENALTY_WEIGHT, entropy_weight=ENTROPY_WEIGHT, label_smoothing=LABEL_SMOOTHING)\n        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n\n        best_loss = float('inf')\n        for epoch in range(EPOCHS):\n            # Filter full dataset based on curriculum phase\n            if epoch < 10:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 5]\n                print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {[lbl for _, lbl, _ in filtered_data[:3]]}\")\n            elif epoch < 15:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 7]\n            else:\n                filtered_data = full_dataset.data\n\n            # Create a new dataset with filtered data\n            curr_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n            curr_dataset.data = filtered_data  # Overwrite with filtered data\n\n            # Split into train and validation\n            train_size = int(0.8 * len(curr_dataset))\n            val_size = len(curr_dataset) - train_size\n            train_dataset, val_dataset = torch.utils.data.random_split(curr_dataset, [train_size, val_size])\n            print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n            \n            # Create data loaders\n            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n            val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n            \n            loss = train_model(model, train_loader, criterion, optimizer, device, epoch)\n            print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss:.4f}\")\n\n            # Validation\n            model.eval()\n            val_loss = 0\n            with torch.no_grad():\n                for imgs, labels, label_lengths in val_loader:\n                    imgs, labels = imgs.to(device), labels.to(device)\n                    label_lengths = label_lengths.to(device)\n                    outputs = model(imgs)\n                    outputs = outputs.log_softmax(2)\n                    seq_length = outputs.size(0)\n                    input_lengths = torch.full((imgs.size(0),), seq_length, dtype=torch.long).to(device)\n                    val_loss += criterion(outputs, labels, input_lengths, label_lengths).item()\n                \n                val_loss /= len(val_loader)\n                pred_texts = beam_search_decode(outputs, idx_to_char)\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:5]]\n                print(f\"Validation Loss: {val_loss:.4f}\")\n                print(\"Validation Predictions:\", pred_texts[:5])\n                print(\"Ground Truth:\", ground_truth)\n\n            model.train()\n            scheduler.step()\n            print(f\"Current Learning Rate: {optimizer.param_groups[0]['lr']}\")\n\n            if val_loss < best_loss:\n                best_loss = val_loss\n                torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'best_ocr_model.pth'))\n\n        torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'final_ocr_model.pth'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:15:49.960832Z","iopub.execute_input":"2025-03-06T23:15:49.961217Z","iopub.status.idle":"2025-03-06T23:46:38.301999Z","shell.execute_reply.started":"2025-03-06T23:15:49.961184Z","shell.execute_reply":"2025-03-06T23:46:38.300793Z"}},"outputs":[{"name":"stdout","text":"Generated 0/5120 images\nGenerated 100/5120 images\nGenerated 200/5120 images\nGenerated 300/5120 images\nGenerated 400/5120 images\nGenerated 500/5120 images\nGenerated 600/5120 images\nGenerated 700/5120 images\nGenerated 800/5120 images\nGenerated 900/5120 images\nGenerated 1000/5120 images\nGenerated 1100/5120 images\nGenerated 1200/5120 images\nGenerated 1300/5120 images\nGenerated 1400/5120 images\nGenerated 1500/5120 images\nGenerated 1600/5120 images\nGenerated 1700/5120 images\nGenerated 1800/5120 images\nGenerated 1900/5120 images\nGenerated 2000/5120 images\nGenerated 2100/5120 images\nGenerated 2200/5120 images\nGenerated 2300/5120 images\nGenerated 2400/5120 images\nGenerated 2500/5120 images\nGenerated 2600/5120 images\nGenerated 2700/5120 images\nGenerated 2800/5120 images\nGenerated 2900/5120 images\nGenerated 3000/5120 images\nGenerated 3100/5120 images\nGenerated 3200/5120 images\nGenerated 3300/5120 images\nGenerated 3400/5120 images\nGenerated 3500/5120 images\nGenerated 3600/5120 images\nGenerated 3700/5120 images\nGenerated 3800/5120 images\nGenerated 3900/5120 images\nGenerated 4000/5120 images\nGenerated 4100/5120 images\nGenerated 4200/5120 images\nGenerated 4300/5120 images\nGenerated 4400/5120 images\nGenerated 4500/5120 images\nGenerated 4600/5120 images\nGenerated 4700/5120 images\nGenerated 4800/5120 images\nGenerated 4900/5120 images\nGenerated 5000/5120 images\nGenerated 5100/5120 images\nDataset generated! Images saved in '/kaggle/working/synthetic_data/images', labels in '/kaggle/working/synthetic_data/labels.txt'\nEpoch 1, Filtered data size: 2551, Sample labels: ['Nc8V', '0d-', 'isLm']\nTrain size: 2040, Val size: 511\nBatch 0, Gradient norm: 27.0557\nEpoch 1, Batch 0/64, Loss: 14.8788\nAvg Blank Probability: 0.0103\nSample predictions: ['GeEe', 'fG', 'fGjG']\nGround Truth (first 3): ['2tJ', '5', '-']\nRaw outputs (first 3): [[33  6  6  6 31 33  8  6 33  6 33 33 31 33  6 33  6  6  6  6  6  6  6  6\n   6 33  8  6 33  6 33 10]\n [33  6  6 33 31 33  6  6 33  6 33 33 31 33 33 33  6  6  6 33 48  6  6 33\n   6  6  6 33 33  6 33 10]\n [33 33  6 33 31 31  6 33 33  6 33 33 10 33 33 33 33  6 31  6 48 33  6 33\n  33 33 33 33 33 33 33 33]]\nBatch 10, Gradient norm: 25.3750\nEpoch 1, Batch 10/64, Loss: 13.2105\nAvg Blank Probability: 0.0106\nSample predictions: ['EfEG', 'fG', 'fGf']\nGround Truth (first 3): ['3txfJ', 'mtr', 'h']\nRaw outputs (first 3): [[31  6  6 33  6 33  6 33  6  6  6  6 33  6 33 33  6  6 33 33 33 33  6 33\n   6  5  6 33  6 33  6  6]\n [31  6 33 33 33 33  6  6  6  6  5  6 33 33 33 33  6  6 33 33 33 33  6 33\n   6  8  6 33  6 31  6  6]\n [ 6  6 33 33 33 33  6  6  6  5 33 33  6 33 33 33 33 33 33 10 33 33 33 33\n  33 33  6 33  6  6  6 33]]\nBatch 20, Gradient norm: 22.3483\nEpoch 1, Batch 20/64, Loss: 12.0599\nAvg Blank Probability: 0.0109\nSample predictions: ['fG', 'GfEL', 'GeG']\nGround Truth (first 3): ['x2', 'XfEJ', '32']\nRaw outputs (first 3): [[ 6 33 33  6 33 33 33  6  6 10 33 33 48 33  6  6  6  6  6  6  6  6  6  6\n   6  6 33  6  6  6  6 33]\n [33 33 33  6 33 33 33 33 33 10 33 33 48 33 33  6  6  6 33  6  6 33 48 33\n  33 33  6 33  6  6  8 33]\n [33 33 33  5 33 33 33 33 33 33 33 33 48 33 33  6  6  6 33  6  6 10 33 33\n  33 31  6 33  6 33  6 33]]\nBatch 30, Gradient norm: 23.5881\nEpoch 1, Batch 30/64, Loss: 11.9127\nAvg Blank Probability: 0.0116\nSample predictions: ['fGVG', 'Gf', 'EfGE']\nGround Truth (first 3): ['t', 'bufZ', 'IsazR']\nRaw outputs (first 3): [[ 6 33 31 33 33  6  6 33  6  6 33 33  6  6  6  6 33 33  6  6  6  6  6  6\n   6  6 33  6  6  6 33 31]\n [33 33 31 33 33  6  6 33 10 33 33  6  6 33 49 10  6 33  6  6 33 33 33  6\n   6  6 33 31  6  6 33  6]\n [33 33  6 33 33 58  6 33 10  5 33 33  6 31 33 33 48 33 10  6  6 33 33 33\n   6 33 33 48  6  6 33 31]]\nBatch 40, Gradient norm: 30.5286\nEpoch 1, Batch 40/64, Loss: 13.6814\nAvg Blank Probability: 0.0121\nSample predictions: ['fGeG', 'GVGhG', 'fGfG']\nGround Truth (first 3): ['*lI', 'Fk', '-te']\nRaw outputs (first 3): [[ 6 33  6  6  6  6  6  5 33  6 33 33 33  6 33  6  6 33  6  6 33  6  6  6\n   6 33  6  6  6  6 33  6]\n [33 33  6  6  6  6  6  6 33  6 33 33 33  6 33 49  6 33  6 48 10  3  6 10\n   6  6  6 31 33 33 33  6]\n [33 33  6  6  6  6  6 48 33  6 33 33  5  6 33 33  6 33 33 48  6 33  6 48\n   6 33  6 31 33  6  6  6]]\nBatch 50, Gradient norm: 37.9018\nEpoch 1, Batch 50/64, Loss: 14.7589\nAvg Blank Probability: 0.0130\nSample predictions: ['fEG', 'fGfG', 'GfG']\nGround Truth (first 3): ['K-zDJ', 'JEjZ', 'r']\nRaw outputs (first 3): [[ 6  6 33  6  6  6  6  6  6  6 33  6 33  6 38  6  6 33  6  6  6  6  6  6\n   6 33  6  6 33  6  6  6]\n [ 6 33 33  6  6  6  6  6  6  6 33  6  6  6 33  6  6 33  6 31 31 33  6 33\n   6 33  6 33 33 33  6  6]\n [31  6 33 33  6  6  6 33  6  6  5 33 33 33 33  6  6 33  6 20 33 33  6  6\n   6 33  6 10 33 33  6  6]]\nBatch 60, Gradient norm: 39.4043\nEpoch 1, Batch 60/64, Loss: 13.1164\nAvg Blank Probability: 0.0151\nSample predictions: ['fGfGVGf', 'fGfG', 'fGeEe']\nGround Truth (first 3): ['LUdt', 'MqYVj', 'M']\nRaw outputs (first 3): [[ 6  6  6  6  6  6  6  6  6 33 33  6  6 33 33  6  6  6 33  5  6  6  6  6\n   6  6  6 33 33 33  6  6]\n [33  6  6 33  6  6  6  6 33 33 31 31 10 33 33 31  6 31 33  5  6 31 33 33\n   6  6  6 33  8 33  6 33]\n [ 6  6  6 33  6  6  6 33 33 10 33 10  6 33 33 33  6 33 33 31 33 31 33 33\n  33  6  6 33 33 33  6 33]]\nEpoch 1/20, Loss: 14.5701\nValidation Loss: 14.2799\nValidation Predictions: ['G', 'fG', 'fG', 'fG', 'fG']\nGround Truth: ['mbs', 'NP9', 'pv', 'j', '8']\nCurrent Learning Rate: 1.2782763676833193e-06\nEpoch 2, Filtered data size: 2551, Sample labels: ['Nc8V', '0d-', 'isLm']\nTrain size: 2040, Val size: 511\nBatch 0, Gradient norm: 25.9740\nEpoch 2, Batch 0/64, Loss: 10.7990\nAvg Blank Probability: 0.0154\nSample predictions: ['fGE', 'GfG', 'GfGtG']\nGround Truth (first 3): ['loQ3h', '*I', '7lMbe']\nRaw outputs (first 3): [[ 6 33 33  6  6  6  6 33  6  6  6  6  6 33  6  6  6  6  6  6  6  6  6 48\n  33  6  6  6  6  6 33 33]\n [ 6 33  6  6  6 31  6 33  6  6  6 33  6 33  6  6  6  6  6  6  6  6  6  6\n   6  6  6  6 33 38 33  6]\n [33 33 33 31  6  6 31 33  6  6 31 33  6 33 33  6  6 33  6  6  6  6  6  5\n   6  6  6  6 33 31 33 33]]\nBatch 10, Gradient norm: 29.6932\nEpoch 2, Batch 10/64, Loss: 11.0733\nAvg Blank Probability: 0.0174\nSample predictions: ['fGtGetGfG', 'GtGfG', 'GVWG']\nGround Truth (first 3): ['K', 'G', 'BrLTI']\nRaw outputs (first 3): [[ 6 33 33 33 33 33 33 33  6  6  6  6  6 33  6  6  6  6 33  6  6  6  6  6\n  33  6 33  6 33  6  6  6]\n [33 33 33 31 33  6  6 33 33  6 33  6 33 33 31  6  6 33  6  6 31 33 31  6\n  33 33  6  6  6  6  6 33]\n [20 33 33 31 33 33  6 33  6  6 33 48 33 33 31 33  6 33  6  6  6 33  6 33\n  33 33 33 33  6 33 31 33]]\nBatch 20, Gradient norm: 51.8067\nEpoch 2, Batch 20/64, Loss: 14.1453\nAvg Blank Probability: 0.0213\nSample predictions: ['G', 'GEGj', 'fEG']\nGround Truth (first 3): ['U', 'h2i', 'o1FZS']\nRaw outputs (first 3): [[33 33  6 33  6  6 33  6 33 33  6  6  6 33 33 33 48  6  6  6  6 33  6  6\n   6 31  6 33 33  6 33  6]\n [33 31 31 33 33  6 33  6 33 33  6 10  6 33 33 33 48  6 33 33 33 33 33  6\n  33 33 33 33 33 33  8  6]\n [33 33 33 33 33 33 33  6 33 33 33 10 33 33 33 33 48 33 33 10 33 33 33  6\n   6 33 33 33 33 33 33 33]]\nBatch 30, Gradient norm: 50.1085\nEpoch 2, Batch 30/64, Loss: 13.1023\nAvg Blank Probability: 0.0249\nSample predictions: ['VG', 'GWG', 'fG']\nGround Truth (first 3): ['YI3', 'V*', 'wnct']\nRaw outputs (first 3): [[48 33  6  6 10 33  6  6 33  6  6 33  6 33  6  6 33 33  6  6  6  6 33  6\n   6  6  6  6  6  6  6 33]\n [33 33  6  6  6 33 10 33 49 33  6 33  6 33  6  6 33  6 31  6  6  6 33 33\n  33 49  6  6 33  6  6  8]\n [33 49  6  6 33  6  6 33  5 33  6 33  6 33 33 31  3 33 31 33 33 33 33 33\n  33  0  6 33 33  6  6 33]]\nBatch 40, Gradient norm: 49.6889\nEpoch 2, Batch 40/64, Loss: 11.2270\nAvg Blank Probability: 0.0319\nSample predictions: ['fGfG', 'fG', 'GfGj']\nGround Truth (first 3): ['sxV-r', 'fNo', 'llsou']\nRaw outputs (first 3): [[ 6  6 33  6  6 33  6  6  6 10  6 33  6  6 33  6  6 33  6  6 33 33  6 33\n  33  6  6  6 33 33 33 33]\n [ 6  6 33  6  6  6 33  6  6  6  6 33 33  6 33 31 31 33 31  6 33  6 33 33\n  33 48  6 33 31 33  6 33]\n [33  6 33  6  6 33 33  0  6  6  6  0 33  6 33 33 31 33  0  6 33 20 33  5\n  33  6  0 33 31  5  6  0]]\nBatch 50, Gradient norm: 55.9426\nEpoch 2, Batch 50/64, Loss: 11.6162\nAvg Blank Probability: 0.0397\nSample predictions: ['fVEfGVWG', 'f', 'fG']\nGround Truth (first 3): ['7h4', 'SaJ', '5yW']\nRaw outputs (first 3): [[ 6  6  6  6 33  6  6 33  6 33  8  6  6 33 33 33  6  6  6 33 33  6  6  6\n   6  6 33  6  6 49  6  6]\n [48  6  0 33 33 33  6 33  6 31 33  6  6  0 33  0  0  0 33  6 49  6  6 33\n   6  6  6  6 33  6  6  6]\n [ 0  6  0 33  0 33  0 33  6 31  0 33  5  0 33 33 33  0  0  0 49  6  0 33\n   6  0  6  6  0  0  6  6]]\nBatch 60, Gradient norm: 64.7113\nEpoch 2, Batch 60/64, Loss: 11.7138\nAvg Blank Probability: 0.0544\nSample predictions: ['GG', 'G', 'f']\nGround Truth (first 3): ['zaf3', 'Z', 'i0']\nRaw outputs (first 3): [[33 33  6  0  6  6  0  6  6  6  6  0 33  6  6  6  0  6  6  6  6 33 10  5\n  31 49  0  6  6  6 33  6]\n [ 0  0  0  0  6  0  0  0  0  0  6  0  0  6  0  6  0  0  0  0  0 33  0  0\n   0  0  0  0  0  0  0  0]\n [ 0 33  0  0  0  0  0  0  0  0 33  0  0  0  0 33  0  0  0  0  0 33  0  0\n   0  0  0  0  0  0  0  0]]\nEpoch 2/20, Loss: 12.6491\nValidation Loss: 13.1021\nValidation Predictions: ['f', 'f', 'f', 'f', 'f']\nGround Truth: ['Pi', 'W', '2Ci', 'OR4', 'Zd']\nCurrent Learning Rate: 2.5312501981619186e-06\nEpoch 3, Filtered data size: 2551, Sample labels: ['Nc8V', '0d-', 'isLm']\nTrain size: 2040, Val size: 511\nBatch 0, Gradient norm: 60.0417\nEpoch 3, Batch 0/64, Loss: 9.8023\nAvg Blank Probability: 0.0660\nSample predictions: ['G', 'G', '<empty>']\nGround Truth (first 3): ['ZZQiP', '5whUy', 'n*f']\nRaw outputs (first 3): [[ 0 33  0  0  0  0  6  0 33 33  6  0  6  0  0 33  0  0  6 33  0  0  6 48\n  33  0  0  6  6 33  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 33  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nBatch 10, Gradient norm: 48.9131\nEpoch 3, Batch 10/64, Loss: 8.1573\nAvg Blank Probability: 0.0875\nSample predictions: ['<empty>', 'f', 'f']\nGround Truth (first 3): ['Pqg', 'e', 'h8cRN']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0 33  0  0  0 33 33  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nBatch 20, Gradient norm: 54.8648\nEpoch 3, Batch 20/64, Loss: 7.6542\nAvg Blank Probability: 0.1392\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['GVvTZ', 'g', 'r']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 42.4307\nEpoch 3, Batch 30/64, Loss: 5.9680\nAvg Blank Probability: 0.2263\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['yH', 'XlD7', 'PRlv']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 21.0222\nEpoch 3, Batch 40/64, Loss: 4.6131\nAvg Blank Probability: 0.3340\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['hybXv', 'Vw3P', 'M']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 12.1018\nEpoch 3, Batch 50/64, Loss: 4.6344\nAvg Blank Probability: 0.5048\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['iTcv', 'dv9', '3EH9']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 7.6827\nEpoch 3, Batch 60/64, Loss: 4.3581\nAvg Blank Probability: 0.6488\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['ibcib', 'yvmu', 'DB']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 3/20, Loss: 6.7332\nValidation Loss: 9.7280\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['UQieF', '0', '-', 'X', 'ZG8']\nCurrent Learning Rate: 3.7525899346539115e-06\nEpoch 4, Filtered data size: 2551, Sample labels: ['Nc8V', '0d-', 'isLm']\nTrain size: 2040, Val size: 511\nBatch 0, Gradient norm: 8.3828\nEpoch 4, Batch 0/64, Loss: 4.5074\nAvg Blank Probability: 0.6716\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['DqAh', 'QOvYg', 'yU']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 4.8853\nEpoch 4, Batch 10/64, Loss: 4.5782\nAvg Blank Probability: 0.6616\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Tq', 'Dz54c', 'RwWqE']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 8.5737\nEpoch 4, Batch 20/64, Loss: 4.5551\nAvg Blank Probability: 0.5961\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['*e9t', 'w', 'N']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 4.4497\nEpoch 4, Batch 30/64, Loss: 4.3715\nAvg Blank Probability: 0.6158\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['wRC', '9', 'kBp']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 6.5237\nEpoch 4, Batch 40/64, Loss: 4.2410\nAvg Blank Probability: 0.6456\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['sG', '4', 'ypKm']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 4.5969\nEpoch 4, Batch 50/64, Loss: 4.5050\nAvg Blank Probability: 0.6425\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['2', 'q3Mp', 'iI']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 5.3310\nEpoch 4, Batch 60/64, Loss: 4.2904\nAvg Blank Probability: 0.6136\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['3', 'As2e4', '3ZR']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 4/20, Loss: 4.4470\nValidation Loss: 9.6702\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['OeGwb', 'mwww3', 'e', 'KuBk7', '9LYJA']\nCurrent Learning Rate: 4.9413666327902935e-06\nEpoch 5, Filtered data size: 2551, Sample labels: ['Nc8V', '0d-', 'isLm']\nTrain size: 2040, Val size: 511\nBatch 0, Gradient norm: 6.7435\nEpoch 5, Batch 0/64, Loss: 4.5801\nAvg Blank Probability: 0.6168\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['n6L', '7V', 'Jpz8x']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 6.4504\nEpoch 5, Batch 10/64, Loss: 4.4498\nAvg Blank Probability: 0.6022\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['VO', 'qn', 'TQ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 7.0522\nEpoch 5, Batch 20/64, Loss: 4.0766\nAvg Blank Probability: 0.6056\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['1bb0R', '9', 'iYtQY']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 10.6769\nEpoch 5, Batch 30/64, Loss: 4.7240\nAvg Blank Probability: 0.6268\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['4I', 'Ma', 'O']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 4.0338\nEpoch 5, Batch 40/64, Loss: 4.3113\nAvg Blank Probability: 0.6318\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['iyoL', 'kD', 'h']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 5.5134\nEpoch 5, Batch 50/64, Loss: 4.4079\nAvg Blank Probability: 0.6007\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['9LYJA', 'lMU', 'Xxg']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 4.4587\nEpoch 5, Batch 60/64, Loss: 4.2573\nAvg Blank Probability: 0.6074\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['U', 'SA', 'DFua']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 5/20, Loss: 4.3507\nValidation Loss: 8.7667\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['yvmu', 'hdAo', '-hBxb', 't', 'nJ7pZ']\nCurrent Learning Rate: 6.095793266216659e-06\nEpoch 6, Filtered data size: 2551, Sample labels: ['Nc8V', '0d-', 'isLm']\nTrain size: 2040, Val size: 511\nBatch 0, Gradient norm: 3.8418\nEpoch 6, Batch 0/64, Loss: 4.3752\nAvg Blank Probability: 0.6529\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['-TLC', '0XBIE', 'JomN']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 4.5148\nEpoch 6, Batch 10/64, Loss: 4.1863\nAvg Blank Probability: 0.5995\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['oW2', 'fdoUR', 'EFy5']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 4.1875\nEpoch 6, Batch 20/64, Loss: 4.1915\nAvg Blank Probability: 0.6038\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['sjY', 'h8cRN', 'Mncn6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 4.6662\nEpoch 6, Batch 30/64, Loss: 4.3447\nAvg Blank Probability: 0.6149\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Z6', 'NUQ', '2']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 7.1313\nEpoch 6, Batch 40/64, Loss: 4.1352\nAvg Blank Probability: 0.6254\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['BDJ', 'K5n', 'S']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 9.9927\nEpoch 6, Batch 50/64, Loss: 4.2093\nAvg Blank Probability: 0.5327\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Zwla', 'OuYvn', 'BbC']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 4.8054\nEpoch 6, Batch 60/64, Loss: 4.3409\nAvg Blank Probability: 0.6494\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['MdpRw', 'dN1Y', '-fx']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 6/20, Loss: 4.2639\nValidation Loss: 9.4736\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['8FQi', 'A', 'F', 'swT', 'mI-0']\nCurrent Learning Rate: 7.213088485268389e-06\nEpoch 7, Filtered data size: 2551, Sample labels: ['Nc8V', '0d-', 'isLm']\nTrain size: 2040, Val size: 511\nBatch 0, Gradient norm: 4.2099\nEpoch 7, Batch 0/64, Loss: 4.0727\nAvg Blank Probability: 0.5726\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['kgA1J', 'Hs6Rf', 'zmG']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 6.1815\nEpoch 7, Batch 10/64, Loss: 4.2466\nAvg Blank Probability: 0.5892\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['2', 'iU', 'J']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 5.0407\nEpoch 7, Batch 20/64, Loss: 4.0607\nAvg Blank Probability: 0.5735\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Tk', 'Hs', 'X']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 8.2626\nEpoch 7, Batch 30/64, Loss: 4.3899\nAvg Blank Probability: 0.5945\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['z', 'B', 'g']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 6.8132\nEpoch 7, Batch 40/64, Loss: 4.0020\nAvg Blank Probability: 0.5842\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['WfT', 'ZvH', 'Qwu']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 8.5935\nEpoch 7, Batch 50/64, Loss: 4.2006\nAvg Blank Probability: 0.5511\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Wy', 'Pqg', 's']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 6.0684\nEpoch 7, Batch 60/64, Loss: 3.9488\nAvg Blank Probability: 0.5654\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['1bb0R', '1', 'hv']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 7/20, Loss: 4.1794\nValidation Loss: 9.3295\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['L-', 'c', '3E', 'b7s', 'cxfFb']\nCurrent Learning Rate: 8.289250458282304e-06\nEpoch 8, Filtered data size: 2551, Sample labels: ['Nc8V', '0d-', 'isLm']\nTrain size: 2040, Val size: 511\nBatch 0, Gradient norm: 4.3405\nEpoch 8, Batch 0/64, Loss: 3.9976\nAvg Blank Probability: 0.5729\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['x9dEv', 'c', 'BS']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 4.7200\nEpoch 8, Batch 10/64, Loss: 4.1549\nAvg Blank Probability: 0.5941\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['5w3', 'XlD7', 'lqI']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 10.4677\nEpoch 8, Batch 20/64, Loss: 4.2921\nAvg Blank Probability: 0.5481\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['6eI0l', 'Rfn', 'Klq2']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 5.9425\nEpoch 8, Batch 30/64, Loss: 4.1696\nAvg Blank Probability: 0.6202\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['EdhH5', 'Pme', 'WML']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 4.4114\nEpoch 8, Batch 40/64, Loss: 3.8429\nAvg Blank Probability: 0.5071\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['GVvTZ', 'B8Gd', 'X']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 8.0027\nEpoch 8, Batch 50/64, Loss: 4.1843\nAvg Blank Probability: 0.6185\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['zNg', 'td', '5zZVR']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 8.6529\nEpoch 8, Batch 60/64, Loss: 4.1038\nAvg Blank Probability: 0.5450\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Uqzc', 'Ea', '-']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 8/20, Loss: 4.1039\nValidation Loss: 9.2019\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['jM', 'nXLYQ', 'geote', 'h2i', '09Li']\nCurrent Learning Rate: 9.318704303907865e-06\nEpoch 9, Filtered data size: 2551, Sample labels: ['Nc8V', '0d-', 'isLm']\nTrain size: 2040, Val size: 511\nBatch 0, Gradient norm: 12.0624\nEpoch 9, Batch 0/64, Loss: 3.8636\nAvg Blank Probability: 0.5647\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Gh4', 'nkTG', 'xl*v']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 5.5539\nEpoch 9, Batch 10/64, Loss: 3.9599\nAvg Blank Probability: 0.5373\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['cO', 'Tk', 'xwfXx']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 6.5948\nEpoch 9, Batch 20/64, Loss: 4.0644\nAvg Blank Probability: 0.5546\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['B4p', '3', 'HJK0X']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 13.8165\nEpoch 9, Batch 30/64, Loss: 4.0024\nAvg Blank Probability: 0.6182\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['MiLY', 'zwHly', '7d8ka']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 6.8590\nEpoch 9, Batch 40/64, Loss: 3.9627\nAvg Blank Probability: 0.5045\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['yaE*', 'qSTUD', 'Fp']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 8.9629\nEpoch 9, Batch 50/64, Loss: 4.1687\nAvg Blank Probability: 0.5756\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['3', 'uJ*D', '7']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 5.6072\nEpoch 9, Batch 60/64, Loss: 3.9968\nAvg Blank Probability: 0.5647\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['nXiN', '-TLC', '8bx']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 9/20, Loss: 4.0607\nValidation Loss: 9.4127\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['6A*J', '7LY4N', 'OXka', 'QHb', 'Vx0']\nCurrent Learning Rate: 1.0293760603950233e-05\nEpoch 10, Filtered data size: 2551, Sample labels: ['Nc8V', '0d-', 'isLm']\nTrain size: 2040, Val size: 511\nBatch 0, Gradient norm: 9.6020\nEpoch 10, Batch 0/64, Loss: 3.9964\nAvg Blank Probability: 0.5742\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['rF', 't', 'cCIqc']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 5.0612\nEpoch 10, Batch 10/64, Loss: 4.0439\nAvg Blank Probability: 0.5806\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['1Ex', 'G', 'mn']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 8.2876\nEpoch 10, Batch 20/64, Loss: 4.2963\nAvg Blank Probability: 0.6076\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['DT*o8', 'RwWqE', 'AX']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 8.0501\nEpoch 10, Batch 30/64, Loss: 3.9735\nAvg Blank Probability: 0.5177\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['qJq0E', 'jyZ8M', 'U']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 7.4918\nEpoch 10, Batch 40/64, Loss: 4.1922\nAvg Blank Probability: 0.6234\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['PVK', '5d', 'hNMip']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 11.9932\nEpoch 10, Batch 50/64, Loss: 3.9641\nAvg Blank Probability: 0.4956\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['wzy', 'see9', 'v2af']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 13.2482\nEpoch 10, Batch 60/64, Loss: 3.7854\nAvg Blank Probability: 0.5457\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['E6S-1', '-fx', 'E4D3f']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 10/20, Loss: 4.0486\nValidation Loss: 9.2791\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['Is', 'U1C', 'Kf', 'Z5F', 'rOJl']\nCurrent Learning Rate: 1.1203777521962295e-05\nTrain size: 2887, Val size: 722\nBatch 0, Gradient norm: 7.2877\nEpoch 11, Batch 0/91, Loss: 3.7721\nAvg Blank Probability: 0.5097\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['jyZ8M', 'I0ZQ2Qr', 'bKjK']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 9.7719\nEpoch 11, Batch 10/91, Loss: 3.6345\nAvg Blank Probability: 0.4242\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['oTA7', 'WPxF39', '-n0vsSr']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 8.5870\nEpoch 11, Batch 20/91, Loss: 3.6195\nAvg Blank Probability: 0.4020\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['WC', 'EhI', 'uFKHH']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 11.9159\nEpoch 11, Batch 30/91, Loss: 3.6133\nAvg Blank Probability: 0.4127\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['o1FZS', 'K', 'VhJ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 6.8025\nEpoch 11, Batch 40/91, Loss: 3.4342\nAvg Blank Probability: 0.4147\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['vGVnNV2', 'q', 'ZC97']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 13.1131\nEpoch 11, Batch 50/91, Loss: 3.4953\nAvg Blank Probability: 0.4706\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['hn5PEOs', '6Pzb5', 'boqMDo']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 7.1268\nEpoch 11, Batch 60/91, Loss: 3.6013\nAvg Blank Probability: 0.4603\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['P', 'ccw0Ce5', 'SpFx']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 70, Gradient norm: 13.8030\nEpoch 11, Batch 70/91, Loss: 3.5562\nAvg Blank Probability: 0.4608\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['q', 'j*4v', 'Lm9eAhI']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 80, Gradient norm: 5.1682\nEpoch 11, Batch 80/91, Loss: 3.5209\nAvg Blank Probability: 0.4320\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['gn0-rF', 'nMTWO', 't']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 90, Gradient norm: 7.5798\nEpoch 11, Batch 90/91, Loss: 3.4563\nAvg Blank Probability: 0.4323\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['h7LKMlh', 'Xvt0av', 'AkpP']\nRaw outputs (first 3): [[0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]]\nEpoch 11/20, Loss: 3.6630\nValidation Loss: 7.6263\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['Nh', 'qOYxYe', 'GB', 'tRk1', 'P']\nCurrent Learning Rate: 1.702774516423562e-05\nTrain size: 2887, Val size: 722\nBatch 0, Gradient norm: 6.7655\nEpoch 12, Batch 0/91, Loss: 3.4865\nAvg Blank Probability: 0.4160\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['0', 'tn', 'qBpi']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 5.5654\nEpoch 12, Batch 10/91, Loss: 3.6648\nAvg Blank Probability: 0.4803\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['92', 'O*6S9PP', 'r']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 4.9209\nEpoch 12, Batch 20/91, Loss: 3.5738\nAvg Blank Probability: 0.4557\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['x9dEv', 'RYhB', 'm']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 4.3217\nEpoch 12, Batch 30/91, Loss: 3.6421\nAvg Blank Probability: 0.4532\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['mXK8N', 'nTl', 'dN1Y']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 5.0459\nEpoch 12, Batch 40/91, Loss: 3.5053\nAvg Blank Probability: 0.3963\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['jVc', 'mb', 'Tn']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 5.6531\nEpoch 12, Batch 50/91, Loss: 3.4240\nAvg Blank Probability: 0.4012\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['UyTcV', 'vf8x5aU', 'FHXMNU*']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 7.6945\nEpoch 12, Batch 60/91, Loss: 3.5358\nAvg Blank Probability: 0.4458\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['6GWwGA', 'O7DCZ', 'ez']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 70, Gradient norm: 9.0875\nEpoch 12, Batch 70/91, Loss: 3.7879\nAvg Blank Probability: 0.4262\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['5q0fuy', 't', 'nNGMeD2']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 80, Gradient norm: 5.5956\nEpoch 12, Batch 80/91, Loss: 3.7434\nAvg Blank Probability: 0.4804\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['cY88u', 'C-HD0F', 'KThC']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 90, Gradient norm: 9.3197\nEpoch 12, Batch 90/91, Loss: 3.5229\nAvg Blank Probability: 0.4282\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['5Bo', 'Sny', 'tNOnidS']\nRaw outputs (first 3): [[0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]]\nEpoch 12/20, Loss: 3.6287\nValidation Loss: 7.5965\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['5Aihb', 'W2PDWFQ', 'J', 'zEZtOwE', '84o']\nCurrent Learning Rate: 1.4128677106876001e-05\nTrain size: 2887, Val size: 722\nBatch 0, Gradient norm: 4.9857\nEpoch 13, Batch 0/91, Loss: 3.7187\nAvg Blank Probability: 0.4819\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['nrv', '9', 'MdLg']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 4.0313\nEpoch 13, Batch 10/91, Loss: 3.6755\nAvg Blank Probability: 0.4671\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['7nfttA', 'rU6qYC', '9']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 6.8760\nEpoch 13, Batch 20/91, Loss: 3.4854\nAvg Blank Probability: 0.4313\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Agh3', 'vZolv-', 'aN7']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 5.5542\nEpoch 13, Batch 30/91, Loss: 3.4582\nAvg Blank Probability: 0.4295\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['WIHV', 'YL', 'OV1Y4ye']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 9.9902\nEpoch 13, Batch 40/91, Loss: 3.6472\nAvg Blank Probability: 0.4960\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['2zYnXyz', 'b', 'IqJS']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 4.7477\nEpoch 13, Batch 50/91, Loss: 3.5532\nAvg Blank Probability: 0.4235\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['wgbr', 'bOXs', 'KCw1I']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 4.8434\nEpoch 13, Batch 60/91, Loss: 3.7292\nAvg Blank Probability: 0.4939\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['UG7CVM', 'XStMt', 'TnO']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 70, Gradient norm: 5.7876\nEpoch 13, Batch 70/91, Loss: 3.5685\nAvg Blank Probability: 0.4211\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['LQP', 'd6qE3', 'vHFUX']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 80, Gradient norm: 8.4628\nEpoch 13, Batch 80/91, Loss: 3.5125\nAvg Blank Probability: 0.3667\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['td', 'UpfW8e', 'c-oja']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 90, Gradient norm: 10.9848\nEpoch 13, Batch 90/91, Loss: 3.7450\nAvg Blank Probability: 0.4521\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['d', 'r4U', 'um*']\nRaw outputs (first 3): [[0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]]\nEpoch 13/20, Loss: 3.6245\nValidation Loss: 7.2915\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['IYeNr', 'eudfdD', 'FR6Ir', '3', 'JT4']\nCurrent Learning Rate: 1.1374180504948612e-05\nTrain size: 2887, Val size: 722\nBatch 0, Gradient norm: 5.5269\nEpoch 14, Batch 0/91, Loss: 3.6391\nAvg Blank Probability: 0.4724\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['sd49U', '*bwy', 'r7']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 5.3939\nEpoch 14, Batch 10/91, Loss: 3.1606\nAvg Blank Probability: 0.3355\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['W8I', 'edqSUo', 'AWp']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 6.5191\nEpoch 14, Batch 20/91, Loss: 3.6243\nAvg Blank Probability: 0.4660\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['3f', 'eLVBHE', 'XlH']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 5.8702\nEpoch 14, Batch 30/91, Loss: 3.4677\nAvg Blank Probability: 0.4317\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['MhPEr6', '9TcSK', '7D2uL*']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 5.5631\nEpoch 14, Batch 40/91, Loss: 3.5211\nAvg Blank Probability: 0.4241\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['OPE', 'BG', 'wCV']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 4.0752\nEpoch 14, Batch 50/91, Loss: 3.5463\nAvg Blank Probability: 0.4181\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['*-4Z', '-jwcAH-', 'Iov3X']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 6.6076\nEpoch 14, Batch 60/91, Loss: 3.6515\nAvg Blank Probability: 0.4860\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['mI-0', 'cjS', 'z3R']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 70, Gradient norm: 3.3526\nEpoch 14, Batch 70/91, Loss: 3.4371\nAvg Blank Probability: 0.3868\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['a', 'Hii', 'A1z5']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 80, Gradient norm: 14.0173\nEpoch 14, Batch 80/91, Loss: 4.0517\nAvg Blank Probability: 0.5053\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['DPqRLb', 'Ev', '6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 90, Gradient norm: 22.6877\nEpoch 14, Batch 90/91, Loss: 3.9690\nAvg Blank Probability: 0.4566\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['LbRGYpf', 'G', 'anT2an']\nRaw outputs (first 3): [[0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]]\nEpoch 14/20, Loss: 3.6101\nValidation Loss: 7.4385\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['d-a', '88DO', 'TURdQe5', 'sh1', '5*lj8hD']\nCurrent Learning Rate: 8.832080206443014e-06\nTrain size: 2887, Val size: 722\nBatch 0, Gradient norm: 4.3273\nEpoch 15, Batch 0/91, Loss: 3.4983\nAvg Blank Probability: 0.4084\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['-7QBgF', 'OeGwb', 'Iov3X']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 9.8530\nEpoch 15, Batch 10/91, Loss: 3.9126\nAvg Blank Probability: 0.4771\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['joo', 'biM74', '9W']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 3.8803\nEpoch 15, Batch 20/91, Loss: 3.6194\nAvg Blank Probability: 0.4513\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['6u', '3P8RvgN', 'PVK']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 5.0945\nEpoch 15, Batch 30/91, Loss: 3.5283\nAvg Blank Probability: 0.4349\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['lDu4uhw', 'BB7', 'dX-ggM']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 3.6642\nEpoch 15, Batch 40/91, Loss: 3.3538\nAvg Blank Probability: 0.3713\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['pM5ZwwG', 'i8', 'O8w9-V']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 6.7787\nEpoch 15, Batch 50/91, Loss: 3.5001\nAvg Blank Probability: 0.4325\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['pEItr8', '2nrdV', 'RrdPQ5']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 3.8701\nEpoch 15, Batch 60/91, Loss: 3.5227\nAvg Blank Probability: 0.4190\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['PHP', 'cTgX8m', 'zQY4Slr']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 70, Gradient norm: 7.9821\nEpoch 15, Batch 70/91, Loss: 3.6525\nAvg Blank Probability: 0.4219\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['ielsDeg', 'xgO', 'b']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 80, Gradient norm: 4.8296\nEpoch 15, Batch 80/91, Loss: 3.5564\nAvg Blank Probability: 0.4522\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['b', 'I', 'rE']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 90, Gradient norm: 6.6126\nEpoch 15, Batch 90/91, Loss: 3.3290\nAvg Blank Probability: 0.3916\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['1rozc', 'bsT', 'NA']\nRaw outputs (first 3): [[0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]]\nEpoch 15/20, Loss: 3.6037\nValidation Loss: 7.3196\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['q', 'E6S-1', 'rL', 'Uu1', 'nJ7pZ']\nCurrent Learning Rate: 6.564971157455598e-06\nTrain size: 4096, Val size: 1024\nBatch 0, Gradient norm: 6.2358\nEpoch 16, Batch 0/128, Loss: 3.2852\nAvg Blank Probability: 0.3814\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['yb1e*xF4sf', '25Y', 'y9IF3KDKB']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 3.1765\nEpoch 16, Batch 10/128, Loss: 3.0242\nAvg Blank Probability: 0.2916\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['b', '4x2*HF1', 'LwjkVOQ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 4.9226\nEpoch 16, Batch 20/128, Loss: 3.3725\nAvg Blank Probability: 0.3422\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['4I', 'Br9Y5R1', 'N']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 4.3704\nEpoch 16, Batch 30/128, Loss: 3.3058\nAvg Blank Probability: 0.3464\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['PU1V9M', 'IFphdA0', '66BdZY']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 7.3640\nEpoch 16, Batch 40/128, Loss: 2.9215\nAvg Blank Probability: 0.3071\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['zcnTr', 'M229', 'IIFQZCzg6q']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 3.7765\nEpoch 16, Batch 50/128, Loss: 3.1652\nAvg Blank Probability: 0.2959\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['HJNMIEMlN', '8xbkfB87k', 'kfaj']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 9.5664\nEpoch 16, Batch 60/128, Loss: 3.1551\nAvg Blank Probability: 0.3786\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['TuQv', 'g5IBD6ck', '3L9vrmJj']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 70, Gradient norm: 7.1139\nEpoch 16, Batch 70/128, Loss: 3.1762\nAvg Blank Probability: 0.3576\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['-Mm2IN', 'eo', '6slOgQ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 80, Gradient norm: 5.0359\nEpoch 16, Batch 80/128, Loss: 3.2824\nAvg Blank Probability: 0.3623\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['VnsPJH6*', '9xEHKn', 'K5MYL3Q']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 90, Gradient norm: 4.9233\nEpoch 16, Batch 90/128, Loss: 3.2858\nAvg Blank Probability: 0.3333\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['lnQYpu', 'LHc7txR', 'y']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 100, Gradient norm: 4.2889\nEpoch 16, Batch 100/128, Loss: 3.0566\nAvg Blank Probability: 0.3409\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['DWWnk52JCs', 'L0Mp', 'PU']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 110, Gradient norm: 3.5029\nEpoch 16, Batch 110/128, Loss: 3.2563\nAvg Blank Probability: 0.3265\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['S', 'JEjZ', 'w6JvM']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 120, Gradient norm: 6.6116\nEpoch 16, Batch 120/128, Loss: 3.2117\nAvg Blank Probability: 0.3575\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['tNZZz', 'X', 'fzmv4hf8lV']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 16/20, Loss: 3.2289\nValidation Loss: 5.4912\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['5JP81', 'Op', 'rNTPcpsCIw', 'u22jHCnT', 'jecYo']\nCurrent Learning Rate: 4.628677106876001e-06\nTrain size: 4096, Val size: 1024\nBatch 0, Gradient norm: 5.6408\nEpoch 17, Batch 0/128, Loss: 3.3642\nAvg Blank Probability: 0.3291\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['xWpp0xmW2', 'U', 'tfYl']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 5.7505\nEpoch 17, Batch 10/128, Loss: 3.4427\nAvg Blank Probability: 0.4090\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['sRMFByYjHR', 'I', 'SpDx5p']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 14.3006\nEpoch 17, Batch 20/128, Loss: 3.4338\nAvg Blank Probability: 0.3265\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['o4', 'daEO8Gd', 'N']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 4.1970\nEpoch 17, Batch 30/128, Loss: 3.0702\nAvg Blank Probability: 0.3285\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['OKPp', 'URk', '1']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 4.9698\nEpoch 17, Batch 40/128, Loss: 3.3788\nAvg Blank Probability: 0.3856\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['dijgr', 'BOWiyt-sG1', '8iYe0st']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 3.5356\nEpoch 17, Batch 50/128, Loss: 2.9413\nAvg Blank Probability: 0.2977\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['ojEa', 'UfXYFL4', 'H329q']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 6.9050\nEpoch 17, Batch 60/128, Loss: 3.3122\nAvg Blank Probability: 0.3480\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Q', 'Jx*ncr', 'q2GPFw']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 70, Gradient norm: 4.0956\nEpoch 17, Batch 70/128, Loss: 3.2269\nAvg Blank Probability: 0.3078\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['gVyRX', 'yH', 'OXka']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 80, Gradient norm: 3.3368\nEpoch 17, Batch 80/128, Loss: 3.2196\nAvg Blank Probability: 0.3158\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['loQ3h', 'kqhEiWDwz', '7prX3Ih']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 90, Gradient norm: 12.6091\nEpoch 17, Batch 90/128, Loss: 2.8881\nAvg Blank Probability: 0.3239\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['1uduMnwy', 've', 'vnswEqcr']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 100, Gradient norm: 4.1453\nEpoch 17, Batch 100/128, Loss: 3.2275\nAvg Blank Probability: 0.3620\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['KQSwuM9', 'z', 'QdxT2']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 110, Gradient norm: 4.9509\nEpoch 17, Batch 110/128, Loss: 3.3563\nAvg Blank Probability: 0.3671\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Q', '61', 'meQ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 120, Gradient norm: 5.1463\nEpoch 17, Batch 120/128, Loss: 3.0000\nAvg Blank Probability: 0.2727\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Y6YnL5q5cO', 'W1oiFu', 'tGuc7h']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 17/20, Loss: 3.2083\nValidation Loss: 5.7820\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['oPPPak6LX', 'nqf', 'aqMnUs', 'MT4jli', 'J9DnQmB9d']\nCurrent Learning Rate: 3.070876040421012e-06\nTrain size: 4096, Val size: 1024\nBatch 0, Gradient norm: 6.0885\nEpoch 18, Batch 0/128, Loss: 3.1904\nAvg Blank Probability: 0.3342\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['x', 'vN', 'ph5']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 5.0284\nEpoch 18, Batch 10/128, Loss: 3.4462\nAvg Blank Probability: 0.3740\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['nqrdJwuGM', 'PPdJxp', 'B4p']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 12.6348\nEpoch 18, Batch 20/128, Loss: 3.7784\nAvg Blank Probability: 0.4012\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['O', 'R', 'H0l']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 5.4058\nEpoch 18, Batch 30/128, Loss: 3.1998\nAvg Blank Probability: 0.3361\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['S5IdiM', 'oHxWYNHt', '1']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 3.6647\nEpoch 18, Batch 40/128, Loss: 3.0884\nAvg Blank Probability: 0.3094\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['biM74', '2Uu', 'QHb']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 7.9747\nEpoch 18, Batch 50/128, Loss: 3.0827\nAvg Blank Probability: 0.3349\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['DB3', 'prCPyZi', 'Wwco-SHR']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 4.8887\nEpoch 18, Batch 60/128, Loss: 3.1231\nAvg Blank Probability: 0.3035\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['*XFqNkG', 'Ij5', 'fzmv4hf8lV']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 70, Gradient norm: 5.8003\nEpoch 18, Batch 70/128, Loss: 3.1840\nAvg Blank Probability: 0.3470\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['sW4paX', 'w0d26PrI', 'gQpxRCq7']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 80, Gradient norm: 5.9544\nEpoch 18, Batch 80/128, Loss: 3.3896\nAvg Blank Probability: 0.4038\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['U', 'kHm4kXQl1', 'UaXngyf']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 90, Gradient norm: 4.1206\nEpoch 18, Batch 90/128, Loss: 3.2392\nAvg Blank Probability: 0.3369\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['yJgO6x', 'E23l', 'vWV65ZXHf']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 100, Gradient norm: 4.6594\nEpoch 18, Batch 100/128, Loss: 2.9848\nAvg Blank Probability: 0.3077\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['b8L8', 'zOkcJ', 'HW-M']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 110, Gradient norm: 3.6091\nEpoch 18, Batch 110/128, Loss: 2.9652\nAvg Blank Probability: 0.2663\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['gyKj0pIWm-', 'Li0iCR18', '7K0v98N']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 120, Gradient norm: 7.5808\nEpoch 18, Batch 120/128, Loss: 2.8306\nAvg Blank Probability: 0.2909\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['WUqDEMqJl', '1BrG0O8', 'r6IbvkZh']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 18/20, Loss: 3.1999\nValidation Loss: 5.8382\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['W1oiFu', 'c4Ay2KlP5O', 'xhb6MyUCDH', 'T4ROxWzyPl', 'G']\nCurrent Learning Rate: 1.929926190392083e-06\nTrain size: 4096, Val size: 1024\nBatch 0, Gradient norm: 4.4750\nEpoch 19, Batch 0/128, Loss: 3.1747\nAvg Blank Probability: 0.3216\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['kQQibJ', 'w0rtkwjyQ', '5']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 3.3577\nEpoch 19, Batch 10/128, Loss: 3.0781\nAvg Blank Probability: 0.3260\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['MoEeBGH8', 'aVD', '2oh6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 7.3985\nEpoch 19, Batch 20/128, Loss: 3.3081\nAvg Blank Probability: 0.3218\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['A', 'R12*h3*', 'qRpBNDIr']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 3.7011\nEpoch 19, Batch 30/128, Loss: 2.9278\nAvg Blank Probability: 0.3311\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['L', 'e', 'Tj-z8Y5m']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 4.3193\nEpoch 19, Batch 40/128, Loss: 3.3447\nAvg Blank Probability: 0.3492\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['dmumWj6G', 'nOo', 'VTpwq']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 3.8228\nEpoch 19, Batch 50/128, Loss: 3.2852\nAvg Blank Probability: 0.3348\nSample predictions: ['<empty>', '<empty>', 'w7u']\nGround Truth (first 3): ['ps', 'TnO', 'Y8lvRtZvqT']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 7.8454\nEpoch 19, Batch 60/128, Loss: 3.2806\nAvg Blank Probability: 0.3332\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['vjj', 'UgK*6cVW', 'smobHF']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 70, Gradient norm: 3.7696\nEpoch 19, Batch 70/128, Loss: 3.0365\nAvg Blank Probability: 0.3031\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['NIJW6U', 'L5', 'Zq*iYP']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 80, Gradient norm: 3.8062\nEpoch 19, Batch 80/128, Loss: 3.1073\nAvg Blank Probability: 0.2966\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['UG7CVM', 'ihFTNP', '0sXkJi4k']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 90, Gradient norm: 5.1296\nEpoch 19, Batch 90/128, Loss: 3.2667\nAvg Blank Probability: 0.3117\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['bKjK', 'cxfFb', 'bm']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 100, Gradient norm: 5.9498\nEpoch 19, Batch 100/128, Loss: 3.3155\nAvg Blank Probability: 0.3762\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['hEBK5Je', 'pnmmpzaEz', 'r']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 110, Gradient norm: 3.5886\nEpoch 19, Batch 110/128, Loss: 3.0049\nAvg Blank Probability: 0.2744\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['n', 'a6Fw', 'Sny']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 120, Gradient norm: 3.3816\nEpoch 19, Batch 120/128, Loss: 3.1776\nAvg Blank Probability: 0.2982\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['IQN', 'ZJQFW', 'O*AQKia']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 19/20, Loss: 3.1877\nValidation Loss: 5.8508\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['g2Lo6b', 'WhBUk', 'KLuyXpTzw', '33U', 'g']\nCurrent Learning Rate: 1.2339215286923845e-06\nTrain size: 4096, Val size: 1024\nBatch 0, Gradient norm: 3.4406\nEpoch 20, Batch 0/128, Loss: 3.2942\nAvg Blank Probability: 0.3442\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['HF*vZfvgn', '4', 'gLrY']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 10, Gradient norm: 5.1125\nEpoch 20, Batch 10/128, Loss: 2.8720\nAvg Blank Probability: 0.2527\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['zK-2lT', 'hNKPAIJE70', 'fECs']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 20, Gradient norm: 4.4027\nEpoch 20, Batch 20/128, Loss: 3.1786\nAvg Blank Probability: 0.3144\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['XHJW', 'gt', 'DT*o8']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 30, Gradient norm: 4.4938\nEpoch 20, Batch 30/128, Loss: 3.2113\nAvg Blank Probability: 0.3149\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['2', 'BBV5c', '*UYKOzocC3']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 40, Gradient norm: 3.5481\nEpoch 20, Batch 40/128, Loss: 3.2630\nAvg Blank Probability: 0.3882\nSample predictions: ['<empty>', 'a', '<empty>']\nGround Truth (first 3): ['HJK0X', 'ePk3ybw8*D', '1tH5']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 50, Gradient norm: 6.1549\nEpoch 20, Batch 50/128, Loss: 3.3735\nAvg Blank Probability: 0.3715\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['RUgfs', 'BSnOJd', 'WvxS']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 60, Gradient norm: 5.7500\nEpoch 20, Batch 60/128, Loss: 3.1807\nAvg Blank Probability: 0.3410\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['7OwwT', 'KJBuX', 'ESo']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 70, Gradient norm: 4.7673\nEpoch 20, Batch 70/128, Loss: 3.3726\nAvg Blank Probability: 0.3489\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['sMe', 'Rt2M', 'oO2od5i']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 80, Gradient norm: 9.7737\nEpoch 20, Batch 80/128, Loss: 3.5006\nAvg Blank Probability: 0.3558\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['m', 'qOYxYe', 'D14']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 90, Gradient norm: 4.1207\nEpoch 20, Batch 90/128, Loss: 3.1581\nAvg Blank Probability: 0.3497\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['ATPT81', 'g6aUw', 'E4D3f']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 100, Gradient norm: 4.2796\nEpoch 20, Batch 100/128, Loss: 3.3172\nAvg Blank Probability: 0.3463\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['FNJa', 'Mwc', '3s-t07y']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 110, Gradient norm: 4.5427\nEpoch 20, Batch 110/128, Loss: 3.5061\nAvg Blank Probability: 0.3926\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['w1yLYQoNa', 'tIB', 'zb']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nBatch 120, Gradient norm: 3.7362\nEpoch 20, Batch 120/128, Loss: 3.2468\nAvg Blank Probability: 0.3261\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Q', '5', 'OV3zT3Kqv']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nEpoch 20/20, Loss: 3.2050\nValidation Loss: 5.5923\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['e6', 'Ejr1hYub', 'g', 'RoKKrzZdR', 'PU1V9M']\nCurrent Learning Rate: 1e-06\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"def zip_folder_with_shutil(source_folder, output_path):\n    '''Function for zip dir data'''\n    shutil.make_archive(output_path, 'zip', source_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:46:38.303336Z","iopub.execute_input":"2025-03-06T23:46:38.303673Z","iopub.status.idle":"2025-03-06T23:46:38.308508Z","shell.execute_reply.started":"2025-03-06T23:46:38.303630Z","shell.execute_reply":"2025-03-06T23:46:38.307435Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/backgrounds', '/kaggle/working/backgrounds')\nzip_folder_with_shutil('/kaggle/working/synthetic_data', '/kaggle/working/synthetic_data')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:46:38.309578Z","iopub.execute_input":"2025-03-06T23:46:38.309913Z","iopub.status.idle":"2025-03-06T23:46:39.350213Z","shell.execute_reply.started":"2025-03-06T23:46:38.309877Z","shell.execute_reply":"2025-03-06T23:46:39.349056Z"}},"outputs":[],"execution_count":25}]}