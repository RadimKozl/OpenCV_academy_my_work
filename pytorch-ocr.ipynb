{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10911708,"sourceType":"datasetVersion","datasetId":6783030}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---------------\n\n# **<font style=\"color:Black\">Create OCR by PyTorch</font>**\n-------------------\n-----------------","metadata":{}},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Installation and import libraries</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"!pip install  pillow \n!pip install opencv-python\n!pip install matplotlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:44:58.163044Z","iopub.execute_input":"2025-03-06T18:44:58.163385Z","iopub.status.idle":"2025-03-06T18:45:11.928597Z","shell.execute_reply.started":"2025-03-06T18:44:58.163357Z","shell.execute_reply":"2025-03-06T18:45:11.927570Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.20->matplotlib) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport random\nfrom PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter\nimport numpy as np\nimport cv2\n\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:11.929626Z","iopub.execute_input":"2025-03-06T18:45:11.929908Z","iopub.status.idle":"2025-03-06T18:45:19.357811Z","shell.execute_reply.started":"2025-03-06T18:45:11.929884Z","shell.execute_reply":"2025-03-06T18:45:19.356836Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Hyperparameters</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"OUTPUT_DIR = os.path.join('/kaggle','working','synthetic_data','images')\nMODEL_DIR = os.path.join('/kaggle','working','model_dir')\nLABELS_FILE = os.path.join('/kaggle','working','synthetic_data','labels.txt')\nNUM_SAMPLES = 5120  # Number of images generated\nIMG_WIDTH = 128\nIMG_HEIGHT = 32\nBATCH_SIZE = 32\nEPOCHS = 50\nLEARNING_RATE = 5e-5  # Lowered from 1e-4\nWEIGHT_DECAY = 5e-4  # Increased from 1e-4\nWARMUP_STEPS = 200  # Reduced to ~1 epoch (160 batches)\nCHARSET = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-*\"  # Group characters\nMAX_TEXT_LENGTH = 10  # Maximum length of text in an image\nFONT_DIR = os.path.join('/kaggle','input','google-fonts','GoogleFontScripts') # Folder with TrueType fonts (.ttf)\nBACKGROUND_DIR = os.path.join('/kaggle','working','backgrounds')  # New folder for background (optional)\nNUMBER_BACKGROUND_IMAGE = 50","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.359340Z","iopub.execute_input":"2025-03-06T18:45:19.359847Z","iopub.status.idle":"2025-03-06T18:45:19.365920Z","shell.execute_reply.started":"2025-03-06T18:45:19.359807Z","shell.execute_reply":"2025-03-06T18:45:19.364719Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Utils support functions</font>**\n-------------------","metadata":{}},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Create output folders</font>**","metadata":{}},{"cell_type":"code","source":"os.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(BACKGROUND_DIR, exist_ok=True)\n\n# Creates a new file\nwith open(LABELS_FILE, 'w') as fp:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.367602Z","iopub.execute_input":"2025-03-06T18:45:19.367952Z","iopub.status.idle":"2025-03-06T18:45:19.389635Z","shell.execute_reply.started":"2025-03-06T18:45:19.367926Z","shell.execute_reply":"2025-03-06T18:45:19.388886Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load the font list (add the paths to the .ttf files to the \"fonts\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"font_files = [\n    os.path.join(FONT_DIR, f) for f in os.listdir(FONT_DIR) \n    if f.endswith('.ttf') and os.path.isfile(os.path.join(FONT_DIR, f))\n]\nif not font_files:\n    raise FileNotFoundError(\"No fonts found in 'fonts' folder. Add .ttf files!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.390814Z","iopub.execute_input":"2025-03-06T18:45:19.391198Z","iopub.status.idle":"2025-03-06T18:45:19.639637Z","shell.execute_reply.started":"2025-03-06T18:45:19.391133Z","shell.execute_reply":"2025-03-06T18:45:19.638586Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generating a simple gradient background</font>**","metadata":{}},{"cell_type":"code","source":"def generate_gradient_background(filename, size=(128, 32)):\n    img = Image.new('L', size, color=230)  # Lighter gray as a base\n    draw = ImageDraw.Draw(img)\n    for y in range(size[1]):\n        # Soft gradient with low contrast\n        color = int(230 - 20 * (y / size[1]))  # From light gray to slightly darker\n        draw.line([(0, y), (size[0], y)], fill=color)\n    # Background blur\n    img = img.filter(ImageFilter.GaussianBlur(radius=2))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.640884Z","iopub.execute_input":"2025-03-06T18:45:19.641239Z","iopub.status.idle":"2025-03-06T18:45:19.647871Z","shell.execute_reply.started":"2025-03-06T18:45:19.641197Z","shell.execute_reply":"2025-03-06T18:45:19.646611Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generate a background with noise (paper texture)</font>**","metadata":{}},{"cell_type":"code","source":"def generate_paper_texture(filename, size=(128, 32)):\n    img = Image.new('L', size, color=220)  # Lighter gray\n    noise = np.random.normal(0, 5, size).astype(np.uint8)  # Less noise\n    noise_img = Image.fromarray(noise)\n    img.paste(noise_img, (0, 0), noise_img)\n    # Blur for a softer effect\n    img = img.filter(ImageFilter.GaussianBlur(radius=1.5))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.649051Z","iopub.execute_input":"2025-03-06T18:45:19.649477Z","iopub.status.idle":"2025-03-06T18:45:19.674559Z","shell.execute_reply.started":"2025-03-06T18:45:19.649429Z","shell.execute_reply":"2025-03-06T18:45:19.673356Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Creating multiple backgrounds</font>**","metadata":{}},{"cell_type":"code","source":"for i in range(NUMBER_BACKGROUND_IMAGE):\n    generate_gradient_background(f\"gradient_{i}.png\")\n    generate_paper_texture(f\"paper_{i}.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.678082Z","iopub.execute_input":"2025-03-06T18:45:19.678443Z","iopub.status.idle":"2025-03-06T18:45:19.790435Z","shell.execute_reply.started":"2025-03-06T18:45:19.678418Z","shell.execute_reply":"2025-03-06T18:45:19.789548Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load backgrounds (optional, add images to the \"backgrounds\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"background_files = (\n    [os.path.join(BACKGROUND_DIR, f) for f in os.listdir(BACKGROUND_DIR) \n     if f.endswith(('.png', '.jpg', '.jpeg'))] if os.path.exists(BACKGROUND_DIR) else []\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.792097Z","iopub.execute_input":"2025-03-06T18:45:19.792502Z","iopub.status.idle":"2025-03-06T18:45:19.797590Z","shell.execute_reply.started":"2025-03-06T18:45:19.792476Z","shell.execute_reply":"2025-03-06T18:45:19.796756Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Random text generation function</font>**","metadata":{}},{"cell_type":"code","source":"def generate_random_text(max_length):\n    length = random.randint(1, max_length)\n    return ''.join(random.choice(CHARSET) for _ in range(length))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.798717Z","iopub.execute_input":"2025-03-06T18:45:19.799009Z","iopub.status.idle":"2025-03-06T18:45:19.817943Z","shell.execute_reply.started":"2025-03-06T18:45:19.798986Z","shell.execute_reply":"2025-03-06T18:45:19.816622Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Functions for adding noise and distortions</font>**","metadata":{}},{"cell_type":"code","source":"def add_noise_and_distortion(img):\n    img_array = np.array(img)\n    # Mild Gaussian noise with lower intensity\n    if random.random() > 0.5:  # 50% šance\n        noise = np.random.normal(0, random.randint(5, 15), img_array.shape).astype(np.uint8)\n        img_array = cv2.add(img_array, noise)\n    # Subtle perspective distortion\n    rows, cols = img_array.shape\n    src_points = np.float32([[0, 0], [cols-1, 0], [0, rows-1], [cols-1, rows-1]])\n    dst_points = np.float32([\n        [random.uniform(0, 3), random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), random.uniform(0, 3)],\n        [random.uniform(0, 3), rows-1-random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), rows-1-random.uniform(0, 3)]\n    ])\n    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n    img_array = cv2.warpPerspective(img_array, matrix, (cols, rows))\n    return Image.fromarray(img_array)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.819430Z","iopub.execute_input":"2025-03-06T18:45:19.819829Z","iopub.status.idle":"2025-03-06T18:45:19.842643Z","shell.execute_reply.started":"2025-03-06T18:45:19.819796Z","shell.execute_reply":"2025-03-06T18:45:19.841483Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Improved image generation feature</font>**","metadata":{}},{"cell_type":"code","source":"def generate_synthetic_image(text, font_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n    # Pozadí\n    if background_files:\n        bg_path = random.choice(background_files)\n        img = Image.open(bg_path).convert('L').resize(img_size)\n    else:\n        img = Image.new('L', img_size, color=230)\n        draw = ImageDraw.Draw(img)\n        for y in range(img_size[1]):\n            color = int(230 - 20 * (y / img_size[1]))\n            draw.line([(0, y), (img_size[0], y)], fill=color)\n        img = img.filter(ImageFilter.GaussianBlur(radius=2))\n\n    draw = ImageDraw.Draw(img)\n\n    # Iterativní úprava fontu a textu\n    font_size = random.randint(20, min(IMG_HEIGHT-2, 28))\n    max_attempts = 5  # Omezení počtu pokusů\n    for attempt in range(max_attempts):\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n        if text_width <= IMG_WIDTH - 10:  # Text vejde\n            break\n        elif len(text) > 1:  # Zkrať text, pokud je příliš dlouhý\n            text = text[:len(text)//2]\n        else:  # Sniž velikost fontu\n            font_size = max(10, font_size - 5)  # Minimální velikost 10\n\n    # Pokud se nepodaří, použij minimální font a jednopísmený text\n    if text_width > IMG_WIDTH - 10:\n        text = text[0]  # Použij první písmeno\n        font_size = 10\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n    # Pozice textu\n    x = random.randint(5, max(5, IMG_WIDTH - text_width - 5))\n    y = random.randint(5, max(5, IMG_HEIGHT - text_height - 5))\n\n    # Zvýraznění textu\n    text_color = random.randint(0, 50)\n    outline_color = 200\n    for offset_x in [-1, 0, 1]:\n        for offset_y in [-1, 0, 1]:\n            if offset_x != 0 or offset_y != 0:\n                draw.text((x + offset_x, y + offset_y), text, font=font, fill=outline_color)\n    draw.text((x, y), text, font=font, fill=text_color)\n\n    # Šum a deformace\n    img = add_noise_and_distortion(img)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.843826Z","iopub.execute_input":"2025-03-06T18:45:19.844239Z","iopub.status.idle":"2025-03-06T18:45:19.868152Z","shell.execute_reply.started":"2025-03-06T18:45:19.844200Z","shell.execute_reply":"2025-03-06T18:45:19.867091Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generování datasetu</font>**","metadata":{}},{"cell_type":"code","source":"def create_synthetic_dataset(num_samples):\n    labels = []\n    for i in range(num_samples):\n        text = generate_random_text(MAX_TEXT_LENGTH)\n        if not text:\n            continue\n        font_path = random.choice(font_files)\n        img = generate_synthetic_image(text, font_path)\n        img_name = f\"img_{i:05d}.png\"\n        img_path = os.path.join(OUTPUT_DIR, img_name)\n        img.save(img_path)\n        labels.append(f\"{img_name} {text}\")\n        if i % 100 == 0:\n            print(f\"Generated {i}/{num_samples} images\")\n\n    if labels:\n        with open(LABELS_FILE, 'w') as f:\n            f.write(\"\\n\".join(labels))\n        print(f\"Dataset generated! Images saved in '{OUTPUT_DIR}', labels in '{LABELS_FILE}'\")\n    else:\n        print(\"No labels generated!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.869133Z","iopub.execute_input":"2025-03-06T18:45:19.869540Z","iopub.status.idle":"2025-03-06T18:45:19.886406Z","shell.execute_reply.started":"2025-03-06T18:45:19.869503Z","shell.execute_reply":"2025-03-06T18:45:19.885009Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Mapping characters to indices and back</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"char_to_idx = {char: idx + 1 for idx, char in enumerate(CHARSET)}  # 0 is reserved for blank (CTC)\nidx_to_char = {idx: char for char, idx in char_to_idx.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.887503Z","iopub.execute_input":"2025-03-06T18:45:19.887895Z","iopub.status.idle":"2025-03-06T18:45:19.907158Z","shell.execute_reply.started":"2025-03-06T18:45:19.887852Z","shell.execute_reply":"2025-03-06T18:45:19.905909Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom dataset</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRDataset(Dataset):\n    def __init__(self, image_dir, labels_file, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform or transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.5], std=[0.5])\n        ])\n        self.data = []\n        with open(labels_file, 'r') as f:\n            for line in f:\n                img_name, text = line.strip().split(' ', 1)\n                self.data.append((img_name, text))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name, text = self.data[idx]\n        img_path = os.path.join(self.image_dir, img_name)\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n        img = Image.fromarray(img)\n        if self.transform:\n            img = self.transform(img)\n        label = [char_to_idx[c] for c in text if c in char_to_idx]\n        label_length = len(label)\n        label = torch.tensor(label + [0] * (MAX_TEXT_LENGTH - label_length), dtype=torch.long)\n        return img, label, label_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.908545Z","iopub.execute_input":"2025-03-06T18:45:19.908992Z","iopub.status.idle":"2025-03-06T18:45:19.934050Z","shell.execute_reply.started":"2025-03-06T18:45:19.908954Z","shell.execute_reply":"2025-03-06T18:45:19.932674Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Model definition (CNN + RNN + CTC)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRModel(nn.Module):\n    def __init__(self, num_chars):\n        super(OCRModel, self).__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # 32x128 -> 16x64\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # 16x64 -> 8x32\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # 8x32 -> 4x16\n            nn.Dropout(0.5)  # Increased from 0.4\n        )\n        self.linear = nn.Linear(512 * (IMG_HEIGHT // 8), 1024)  # Adjusted for fewer channels\n        self.rnn = nn.LSTM(\n            input_size=1024,\n            hidden_size=256,  # Reduced from 512\n            num_layers=2,\n            bidirectional=True,\n            batch_first=True,\n            dropout=0.5  # Increased from 0.4\n        )\n        self.fc = nn.Linear(256 * 2, num_chars + 1)\n\n    def forward(self, x):\n        x = self.cnn(x)  # (N, 512, 4, 16)\n        x = x.permute(0, 3, 1, 2)  # (N, 16, 512, 4)\n        x = x.reshape(x.size(0), x.size(1), -1)  # (N, 16, 2048)\n        x = self.linear(x)  # (N, 16, 1024)\n        x, _ = self.rnn(x)  # (N, 16, 512)\n        x = self.fc(x)  # (N, 16, num_chars + 1)\n        x = x.permute(1, 0, 2)  # (16, N, num_chars + 1)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.935405Z","iopub.execute_input":"2025-03-06T18:45:19.935822Z","iopub.status.idle":"2025-03-06T18:45:19.959602Z","shell.execute_reply.started":"2025-03-06T18:45:19.935785Z","shell.execute_reply":"2025-03-06T18:45:19.958425Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Training</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, device, epoch, warmup_steps=WARMUP_STEPS):\n    model.train()\n    total_loss = 0\n    global_step = epoch * len(train_loader)\n    for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n        imgs, labels = imgs.to(device), labels.to(device)\n        label_lengths = label_lengths.to(device)\n\n        # Warm-up learning rate\n        if global_step < warmup_steps:\n            lr_scale = min(1.0, float(global_step + 1) / warmup_steps)\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = LEARNING_RATE * lr_scale\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        outputs = outputs.log_softmax(2)\n\n        batch_size = imgs.size(0)\n        seq_length = outputs.size(0)\n        input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n\n        assert outputs.size(1) == batch_size, f\"Batch size mismatch: outputs {outputs.size(1)} vs imgs {batch_size}\"\n        assert label_lengths.size(0) == batch_size, f\"Label lengths size {label_lengths.size(0)} != batch size {batch_size}\"\n\n        loss = criterion(outputs, labels, input_lengths, label_lengths)\n        if torch.isnan(loss) or torch.isinf(loss):\n            print(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n            continue\n\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n        optimizer.step()\n        total_loss += loss.item()\n        global_step += 1\n\n        if batch_idx % 10 == 0:\n            with torch.no_grad():\n                pred_texts = decode_prediction(outputs, idx_to_char)\n                raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n                print(f\"Batch {batch_idx}, Gradient norm: {grad_norm.item():.4f}\")\n                print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n                print(f\"Sample predictions: {pred_texts[:3]}\")\n                print(f\"Raw outputs (first 3): {raw_outputs}\")\n\n    avg_loss = total_loss / len(train_loader)\n    return avg_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.960909Z","iopub.execute_input":"2025-03-06T18:45:19.961374Z","iopub.status.idle":"2025-03-06T18:45:19.984822Z","shell.execute_reply.started":"2025-03-06T18:45:19.961336Z","shell.execute_reply":"2025-03-06T18:45:19.983680Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Inference (prediction)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def decode_prediction(output, idx_to_char):\n    output = output.argmax(2).cpu().numpy()  # (T, N)\n    texts = []\n    for i, pred in enumerate(output.T):\n        print(f\"Raw prediction {i}: {pred}\")\n        pred_text = []\n        prev = -1\n        for idx in pred:\n            if idx != 0 and idx != prev:\n                pred_text.append(idx_to_char.get(idx, ''))\n            prev = idx\n        decoded = ''.join(pred_text)\n        texts.append(decoded if decoded else '<empty>')\n    return texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:19.985996Z","iopub.execute_input":"2025-03-06T18:45:19.986422Z","iopub.status.idle":"2025-03-06T18:45:20.012345Z","shell.execute_reply.started":"2025-03-06T18:45:19.986382Z","shell.execute_reply":"2025-03-06T18:45:20.011019Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Main launch</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    if not font_files:\n        print(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n    else:\n        create_synthetic_dataset(NUM_SAMPLES)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n    if len(dataset) == 0:\n        print(\"Dataset is empty! Check labels.txt or image directory.\")\n    else:\n        train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n        model = OCRModel(num_chars=len(CHARSET)).to(device)\n        criterion = nn.CTCLoss(blank=0, zero_infinity=True)\n        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n\n        best_loss = float('inf')\n        for epoch in range(EPOCHS):\n            loss = train_model(model, train_loader, criterion, optimizer, device, epoch)\n            print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss:.4f}\")\n\n            model.eval()\n            with torch.no_grad():\n                for i, (imgs, labels, label_lengths) in enumerate(train_loader):\n                    if i >= 1:\n                        break\n                    imgs, labels = imgs.to(device), labels.to(device)\n                    outputs = model(imgs)\n                    pred_texts = decode_prediction(outputs, idx_to_char)\n                    ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label[:length.item()]]) \n                                    for label, length in zip(labels, label_lengths)]\n                    print(\"Validation Predictions:\", pred_texts[:5])\n                    print(\"Ground Truth:\", ground_truth[:5])\n            model.train()\n\n            scheduler.step()  # Cosine annealing after warm-up\n            print(f\"Current Learning Rate: {optimizer.param_groups[0]['lr']}\")\n\n            if loss < best_loss:\n                best_loss = loss\n                torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'best_ocr_model.pth'))\n\n        torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'final_ocr_model.pth'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:45:20.013517Z","iopub.execute_input":"2025-03-06T18:45:20.013853Z","execution_failed":"2025-03-06T18:47:07.656Z"}},"outputs":[{"name":"stdout","text":"Generated 0/5120 images\nGenerated 100/5120 images\nGenerated 200/5120 images\nGenerated 300/5120 images\nGenerated 400/5120 images\nGenerated 500/5120 images\nGenerated 600/5120 images\nGenerated 700/5120 images\nGenerated 800/5120 images\nGenerated 900/5120 images\nGenerated 1000/5120 images\nGenerated 1100/5120 images\nGenerated 1200/5120 images\nGenerated 1300/5120 images\nGenerated 1400/5120 images\nGenerated 1500/5120 images\nGenerated 1600/5120 images\nGenerated 1700/5120 images\nGenerated 1800/5120 images\nGenerated 1900/5120 images\nGenerated 2000/5120 images\nGenerated 2100/5120 images\nGenerated 2200/5120 images\nGenerated 2300/5120 images\nGenerated 2400/5120 images\nGenerated 2500/5120 images\nGenerated 2600/5120 images\nGenerated 2700/5120 images\nGenerated 2800/5120 images\nGenerated 2900/5120 images\nGenerated 3000/5120 images\nGenerated 3100/5120 images\nGenerated 3200/5120 images\nGenerated 3300/5120 images\nGenerated 3400/5120 images\nGenerated 3500/5120 images\nGenerated 3600/5120 images\nGenerated 3700/5120 images\nGenerated 3800/5120 images\nGenerated 3900/5120 images\nGenerated 4000/5120 images\nGenerated 4100/5120 images\nGenerated 4200/5120 images\nGenerated 4300/5120 images\nGenerated 4400/5120 images\nGenerated 4500/5120 images\nGenerated 4600/5120 images\nGenerated 4700/5120 images\nGenerated 4800/5120 images\nGenerated 4900/5120 images\nGenerated 5000/5120 images\nGenerated 5100/5120 images\nDataset generated! Images saved in '/kaggle/working/synthetic_data/images', labels in '/kaggle/working/synthetic_data/labels.txt'\nRaw prediction 0: [50 13 27 27 27 42  1 38  2 50 24 38 18 28 62 18]\nRaw prediction 1: [27 18 18 50 50  4 42 42 18 18 50 54 50 50 50 18]\nRaw prediction 2: [42 12 12 12 42 42  2 26 42  7 26 18  3  3  3 50]\nRaw prediction 3: [50 50 50 50 50 56 56  2  2  1  1 18 50 18 50 18]\nRaw prediction 4: [24 24 27 27 27 27 50 50 27 27 50 50 50 50 50 48]\nRaw prediction 5: [ 1  1  1  2  2 13  1  1  2 50 50  4  1  1 54 42]\nRaw prediction 6: [50 13 50 13 36 50 27 27  3 27  7 38  2 38  2  4]\nRaw prediction 7: [27  1  1 18  1  2  3 16 27  3 62 42  3 62  3 12]\nRaw prediction 8: [27 50 50 50 50 50 50 50 42 50 54 54 54 54  3  3]\nRaw prediction 9: [50 50 12 27 18 38 38 50 18 18 18 18 18 18 18  2]\nRaw prediction 10: [27 27 42 50 54 42 42 42  2  3  3  7  3 50 50 50]\nRaw prediction 11: [27 18 18  3 50  3 27 27 27  1  3 27  1 27  3 24]\nRaw prediction 12: [ 1  1  1 50 50 50 42 50 25 50 50 38 50 42 27 18]\nRaw prediction 13: [26 27 27 26  2  2  2 27  2 27  2  2 27  2  2  3]\nRaw prediction 14: [50 50 42 50 48  2  4 27  2  2  1 38  1  3 36 60]\nRaw prediction 15: [27  1  1  1  1  1 27 27 27 25 26  1 26  3 38 50]\nRaw prediction 16: [42 42 42 18 18  1 27 27 27 42 50  7 18 42 50  7]\nRaw prediction 17: [18 50 29 50 56 12 12 42 42 42  7  2 18 28 28 18]\nRaw prediction 18: [27 27 56 56  6 18 42 18 18 50 50  2 50  2  7 50]\nRaw prediction 19: [ 7  7  1 18 26 56 26  2  2 18 18 18 18  2 18  2]\nRaw prediction 20: [42 27 27 27 27  3  3 18 18  6  6 50 42 42 28 12]\nRaw prediction 21: [ 1  1  3  2 27  1 50 27  2  2 13  7  3 24 56 56]\nRaw prediction 22: [42  2  2  2  2 38 25 25 42 12 12 12 50 50 12 50]\nRaw prediction 23: [27 37  1 41 27  2  2  2  2 59  2 18 42 50 50 50]\nRaw prediction 24: [27 50  3  1  3  3  3  3  3 42 27  1 42 42 18 18]\nRaw prediction 25: [27 27 12 50 12 27 27 27 27 27 27 27 12 27 27 27]\nRaw prediction 26: [24 36  1  1  1  3  3 27  1 27 24 62 24 18  3 25]\nRaw prediction 27: [ 1 27 42 42 42  2  2  2  2 18 18 18 18 18 18  2]\nRaw prediction 28: [27 42 50  2  2  2  2  2 27  7 50 12 12  2 50  3]\nRaw prediction 29: [27  2  2  2  1  1  4 38  1 50  3  3 18 18 18  3]\nRaw prediction 30: [27 27 27 27 62 27 62  2  1  1  1  2  2  2  1 42]\nRaw prediction 31: [ 2 27 27 50 42  3 59 59 27 27 27 27 27  1 12 25]\nBatch 0, Gradient norm: 7.8751\nEpoch 1, Batch 0/160, Loss: 17.5141\nSample predictions: ['XmAPaLbXxLrB9r', 'ArXdPrX1Xr', 'PlPbzPgzrcX']\nRaw outputs (first 3): [[50 27 42 50 24  1 50 27 27 50 27 27  1 26 50 27 42 18 27  7 42  1 42 27\n  27 27 24  1 27 27 27  2]\n [13 18 12 50 24  1 13  1 50 50 27 18  1 27 50  1 42 50 27  7 27  1  2 37\n  50 27 36 27 42  2 27 27]\n [27 18 12 50 27  1 50  1 50 12 42 18  1 27 42  1 42 29 56  1 27  3  2  1\n   3 12  1 42 50  2 27 27]]\nRaw prediction 0: [27  3  3  3  3  3  3  3 24  2  2  2 50 50 18  3]\nRaw prediction 1: [26 50 50 50  2 50  1 38 50 38 18  2 50 50 50 50]\nRaw prediction 2: [27 27  1  1 27 27 50 50 50 27 50 50 50 27 42 35]\nRaw prediction 3: [ 1  1  1  1  1  1 27  1 27 27  1  7 12 50  3 58]\nRaw prediction 4: [ 2  2 50 50 24 27 27 13 38 35  3  7 42 12 42 62]\nRaw prediction 5: [27 27  3 38 38 38  2  2 27  3 27 42 27 25  3  3]\nRaw prediction 6: [27 27 61 60 42 42  2 27 27  2 50 50 50 42 42 50]\nRaw prediction 7: [56  7 38 54 50 50  0 50 50 50  1 18 18 13  1  2]\nRaw prediction 8: [27 27  1  1  1  7 42 42  3  3 62 62 62  3 62  7]\nRaw prediction 9: [26  1  1  7  1  1  3  3  3  3  3  3 18  0 36  2]\nRaw prediction 10: [ 1  1 27 27 27  3  1  1 50 54  3  1 26 26  1  1]\nRaw prediction 11: [26 26 50  2 50 50 42  4 50  4 50 50  2  7 12 50]\nRaw prediction 12: [25 41 41 41 18  7 42 16 13 26 14  6 42 18 18 60]\nRaw prediction 13: [42 54  2  2 26 50  2  1 50  0  3 27 27 48 42 12]\nRaw prediction 14: [ 1 29 29 27 27 42 42  1  1 51 42 35 27 42  3  1]\nRaw prediction 15: [50 50  1 55  1 50 50 50 13 13 13  1  1 27 34 34]\nRaw prediction 16: [ 2  2  2  2  2  2 41  2  2  2  2  1  2  2 42  2]\nRaw prediction 17: [26 18 42 18 18  1 62 12 62  3  3 55 12 50 50 50]\nRaw prediction 18: [18  1  1  1 18 18  2  2  2  2  2  2  2 17 27 59]\nRaw prediction 19: [26  2  2 42 42 50 50  1 18  2 62 50 50 50 50 50]\nRaw prediction 20: [27  2  2  2  7 13  3  3  3 50  1  2  2  2 42 42]\nRaw prediction 21: [61 27 56  2 56 42 42 42 42 56 42  7  6 62 18 60]\nRaw prediction 22: [27 27 27  4 61 27 26  1 12 12 12 12 12  3  3  3]\nRaw prediction 23: [50 50 54 54 54 42 14  6 58 58 50 56 50 50 50  4]\nRaw prediction 24: [ 1 62 27 27 38 27 38 41 27 41 27  2 54  3  3  6]\nRaw prediction 25: [50 50 42 42  2 12  2  2  2  4 50 50  1  3  3 18]\nRaw prediction 26: [49 28  3  3  3 50 18 42 42 42 38 35 50 50 50 50]\nRaw prediction 27: [18  1 50 50 50 50 50 50 50 42 50  3 50  2 50 50]\nRaw prediction 28: [49  2  2  2 24 50 24  3  1 42 42 42 50 50 12 34]\nRaw prediction 29: [24 50  2  2 27 62 50  2  7  2  1  1 50 50 14 14]\nRaw prediction 30: [26 26 26 42 42 26  6 18 50 50 50 50 50 50 50 60]\nRaw prediction 31: [42 42 62  1  2  1  7 54 26 42 26  3  3  3  3 18]\nBatch 10, Gradient norm: 6.6887\nEpoch 1, Batch 10/160, Loss: 14.3081\nSample predictions: ['AcxbXrc', 'zXbXaLXLrbX', 'AaAXAXAPI']\nRaw outputs (first 3): [[27 26 27  1  2 27 27 56 27 26  1 26 25 42  1 50  2 26 18 26 27 61 27 50\n   1 50 49 18 49 24 26 42]\n [ 3 50 27  1  2 27 27  7 27  1  1 26 41 54 29 50  2 18  1  2  2 27 27 50\n  62 50 28  1  2 50 26 42]\n [ 3 50  1  1 50  3 61 38  1  1 27 50 41  2 29  1  2 42  1  2  2 56 27 54\n  27 42  3 50  2  2 26 62]]\nRaw prediction 0: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 1: [0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 4]\nRaw prediction 2: [ 1 27  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\nRaw prediction 3: [27 27 27  0  0  0  0  0  0  0  0  0  0  0  0 42]\nRaw prediction 4: [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60]\nRaw prediction 5: [ 1  1  0  0  0  0 42 42  0  0 27  0  0 40 50  0]\nRaw prediction 6: [12  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0]\nRaw prediction 7: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 8: [ 0  0 50 50  0  0  0 27 27  0  0  0  0  0  0  0]\nRaw prediction 9: [1 1 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\nRaw prediction 10: [ 0  0 60  0  0  0  0  0  0  0  0  0  0  0  0  0]\nRaw prediction 11: [27  0  0  0  0  0  0  3  0  0  0  0  0  0 27  0]\nRaw prediction 12: [0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0]\nRaw prediction 13: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0]\nRaw prediction 14: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 15: [ 1 26 24 24  0  0  0  0  3  0  0  2 27 48  0 18]\nRaw prediction 16: [42 42  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\nRaw prediction 17: [ 0  0  0  0  0 48  0  0  0  0  0  0  0  0  0  0]\nRaw prediction 18: [ 0  0  1  0  0  0  0  2  0  0  0  0  0  0 59  0]\nRaw prediction 19: [61 50  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\nRaw prediction 20: [61 61  0  0  0  0  0  2  0  0  0  0  0  0  0  3]\nRaw prediction 21: [ 2  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60]\nRaw prediction 22: [61  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\nRaw prediction 23: [ 0  0  0  0  0  0  0  0  0  0  0  0  0 62  0  3]\nRaw prediction 24: [ 0  0  0  0  0  0  0  0  0  0  0  0  0 27 27 50]\nRaw prediction 25: [61  0  0  0  0  0  0  0  0  0  0  0  0  0 60 60]\nRaw prediction 26: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 27: [ 0  0  0  0  0  0  2  0  0  0  0  0  0  0  0 27]\nRaw prediction 28: [42  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60]\nRaw prediction 29: [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60]\nRaw prediction 30: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 31: [ 0  0  0  0  0  0  0  0  0  0 25 27 60  1  0 14]\nBatch 20, Gradient norm: 10.4769\nEpoch 1, Batch 20/160, Loss: 17.2123\nSample predictions: ['<empty>', 'acd', 'aAb']\nRaw outputs (first 3): [[ 0  0  1 27  0  1 12  0  0  1  0 27  0  0  0  1 42  0  0 61 61  2 61  0\n   0 61  0  0 42  0  0  0]\n [ 0  0 27 27  0  1  0  0  0  1  0  0  0  0  0 26 42  0  0 50 61  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  2 27  0  0  0  0 50  0 60  0  0  0  0 24  0  0  1  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nRaw prediction 0: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 1: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 2: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 3: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 4: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 5: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 6: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 7: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 8: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 9: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 10: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 11: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 12: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 13: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 14: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 15: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 16: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 17: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 18: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 19: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 20: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 21: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 22: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 23: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 24: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 25: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 26: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 27: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 28: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 29: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 30: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 31: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nBatch 30, Gradient norm: 7.2116\nEpoch 1, Batch 30/160, Loss: 11.7830\nSample predictions: ['<empty>', '<empty>', '<empty>']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nRaw prediction 0: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 1: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 2: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 3: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 4: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 5: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 6: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 7: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 8: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 9: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 10: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 11: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 12: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 13: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 14: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 15: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 16: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 17: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 18: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 19: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 20: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 21: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 22: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 23: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 24: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 25: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 26: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 27: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 28: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 29: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 30: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nRaw prediction 31: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nBatch 40, Gradient norm: 14.5831\nEpoch 1, Batch 40/160, Loss: 16.5500\nSample predictions: ['<empty>', '<empty>', '<empty>']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"def zip_folder_with_shutil(source_folder, output_path):\n    '''Function for zip dir data'''\n    shutil.make_archive(output_path, 'zip', source_folder)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-06T18:47:07.659Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/backgrounds', '/kaggle/working/backgrounds')\nzip_folder_with_shutil('/kaggle/working/synthetic_data', '/kaggle/working/synthetic_data')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-06T18:47:07.659Z"}},"outputs":[],"execution_count":null}]}