{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10911708,"sourceType":"datasetVersion","datasetId":6783030}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---------------\n\n# **<font style=\"color:Black\">Create OCR by PyTorch</font>**\n-------------------\n-----------------","metadata":{}},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Installation and import libraries</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"!pip install  pillow \n!pip install opencv-python\n!pip install matplotlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:26.358579Z","iopub.execute_input":"2025-03-07T11:21:26.358941Z","iopub.status.idle":"2025-03-07T11:21:40.295107Z","shell.execute_reply.started":"2025-03-07T11:21:26.358904Z","shell.execute_reply":"2025-03-07T11:21:40.293346Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.20->matplotlib) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport random\nfrom PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter\nimport numpy as np\nimport cv2\n\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F  # Add this import\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:40.296951Z","iopub.execute_input":"2025-03-07T11:21:40.297256Z","iopub.status.idle":"2025-03-07T11:21:49.774050Z","shell.execute_reply.started":"2025-03-07T11:21:40.297227Z","shell.execute_reply":"2025-03-07T11:21:49.771419Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Hyperparameters</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"seed = 3\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:49.775720Z","iopub.execute_input":"2025-03-07T11:21:49.776194Z","iopub.status.idle":"2025-03-07T11:21:49.795560Z","shell.execute_reply.started":"2025-03-07T11:21:49.776166Z","shell.execute_reply":"2025-03-07T11:21:49.793116Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7cb8fde66e70>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"OUTPUT_DIR = os.path.join('/kaggle','working','synthetic_data','images')\nMODEL_DIR = os.path.join('/kaggle','working','model_dir')\nLABELS_FILE = os.path.join('/kaggle','working','synthetic_data','labels.txt')\nNUM_SAMPLES = 5120  # Number of images generated\nIMG_WIDTH = 128\nIMG_HEIGHT = 32\nBATCH_SIZE = 32\nEPOCHS = 20\nLEARNING_RATE = 1e-6 \nWEIGHT_DECAY = 1e-4  \nWARMUP_STEPS = 1000  \nENTROPY_WEIGHT = 2.0\nTEMPERATURE = 0.3\nDROPOUT = 0.7\nBEAM_WIDTH = 10\nLABEL_SMOOTHING = 0.2\nBLANK_PENALTY_WEIGHT = 2.0\nMAX_SEQ_LENGTH = 15\nCHARSET = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-*\"  # Group characters\nMAX_TEXT_LENGTH = 10  # Maximum length of text in an image\nFONT_DIR = os.path.join('/kaggle','input','google-fonts','GoogleFontScripts') # Folder with TrueType fonts (.ttf)\nBACKGROUND_DIR = os.path.join('/kaggle','working','backgrounds')  # New folder for background (optional)\nNUMBER_BACKGROUND_IMAGE = 1000","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:49.797304Z","iopub.execute_input":"2025-03-07T11:21:49.797757Z","iopub.status.idle":"2025-03-07T11:21:49.831127Z","shell.execute_reply.started":"2025-03-07T11:21:49.797717Z","shell.execute_reply":"2025-03-07T11:21:49.828768Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Utils support functions</font>**\n-------------------","metadata":{}},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Create output folders</font>**","metadata":{}},{"cell_type":"code","source":"os.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(BACKGROUND_DIR, exist_ok=True)\n\n# Creates a new file\nwith open(LABELS_FILE, 'w') as fp:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:49.834178Z","iopub.execute_input":"2025-03-07T11:21:49.834952Z","iopub.status.idle":"2025-03-07T11:21:49.865813Z","shell.execute_reply.started":"2025-03-07T11:21:49.834887Z","shell.execute_reply":"2025-03-07T11:21:49.864514Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load the font list (add the paths to the .ttf files to the \"fonts\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"font_files = [\n    os.path.join(FONT_DIR, f) for f in os.listdir(FONT_DIR) \n    if f.endswith('.ttf') and os.path.isfile(os.path.join(FONT_DIR, f))\n]\nif not font_files:\n    raise FileNotFoundError(\"No fonts found in 'fonts' folder. Add .ttf files!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:49.868743Z","iopub.execute_input":"2025-03-07T11:21:49.869134Z","iopub.status.idle":"2025-03-07T11:21:52.016203Z","shell.execute_reply.started":"2025-03-07T11:21:49.869102Z","shell.execute_reply":"2025-03-07T11:21:52.014541Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generating a simple gradient background</font>**","metadata":{}},{"cell_type":"code","source":"def generate_gradient_background(filename, size=(128, 32)):\n    img = Image.new('L', size, color=230)  # Lighter gray as a base\n    draw = ImageDraw.Draw(img)\n    for y in range(size[1]):\n        # Soft gradient with low contrast\n        color = int(230 - 20 * (y / size[1]))  # From light gray to slightly darker\n        draw.line([(0, y), (size[0], y)], fill=color)\n    # Background blur\n    img = img.filter(ImageFilter.GaussianBlur(radius=2))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:52.017984Z","iopub.execute_input":"2025-03-07T11:21:52.018393Z","iopub.status.idle":"2025-03-07T11:21:52.025477Z","shell.execute_reply.started":"2025-03-07T11:21:52.018355Z","shell.execute_reply":"2025-03-07T11:21:52.023313Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generate a background with noise (paper texture)</font>**","metadata":{}},{"cell_type":"code","source":"def generate_paper_texture(filename, size=(128, 32)):\n    img = Image.new('L', size, color=220)  # Lighter gray\n    noise = np.random.normal(0, 5, size).astype(np.uint8)  # Less noise\n    noise_img = Image.fromarray(noise)\n    img.paste(noise_img, (0, 0), noise_img)\n    # Blur for a softer effect\n    img = img.filter(ImageFilter.GaussianBlur(radius=1.5))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:52.026831Z","iopub.execute_input":"2025-03-07T11:21:52.027225Z","iopub.status.idle":"2025-03-07T11:21:52.065348Z","shell.execute_reply.started":"2025-03-07T11:21:52.027178Z","shell.execute_reply":"2025-03-07T11:21:52.063530Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Creating multiple backgrounds</font>**","metadata":{}},{"cell_type":"code","source":"for i in range(NUMBER_BACKGROUND_IMAGE):\n    generate_gradient_background(f\"gradient_{i}.png\")\n    generate_paper_texture(f\"paper_{i}.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:52.066337Z","iopub.execute_input":"2025-03-07T11:21:52.066672Z","iopub.status.idle":"2025-03-07T11:21:52.967173Z","shell.execute_reply.started":"2025-03-07T11:21:52.066639Z","shell.execute_reply":"2025-03-07T11:21:52.965432Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load backgrounds (optional, add images to the \"backgrounds\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"background_files = (\n    [os.path.join(BACKGROUND_DIR, f) for f in os.listdir(BACKGROUND_DIR) \n     if f.endswith(('.png', '.jpg', '.jpeg'))] if os.path.exists(BACKGROUND_DIR) else []\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:52.968240Z","iopub.execute_input":"2025-03-07T11:21:52.968663Z","iopub.status.idle":"2025-03-07T11:21:52.978635Z","shell.execute_reply.started":"2025-03-07T11:21:52.968519Z","shell.execute_reply":"2025-03-07T11:21:52.976986Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Random text generation function</font>**","metadata":{}},{"cell_type":"code","source":"def generate_random_text(max_length):\n    length = random.randint(1, max_length)\n    return ''.join(random.choice(CHARSET) for _ in range(length))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:52.980266Z","iopub.execute_input":"2025-03-07T11:21:52.980850Z","iopub.status.idle":"2025-03-07T11:21:52.999261Z","shell.execute_reply.started":"2025-03-07T11:21:52.980810Z","shell.execute_reply":"2025-03-07T11:21:52.997689Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Functions for adding noise and distortions</font>**","metadata":{}},{"cell_type":"code","source":"def add_noise_and_distortion(img):\n    img_array = np.array(img)\n    # Mild Gaussian noise with lower intensity\n    if random.random() > 0.5:  # 50% šance\n        noise = np.random.normal(0, random.randint(5, 15), img_array.shape).astype(np.uint8)\n        img_array = cv2.add(img_array, noise)\n    # Subtle perspective distortion\n    rows, cols = img_array.shape\n    src_points = np.float32([[0, 0], [cols-1, 0], [0, rows-1], [cols-1, rows-1]])\n    dst_points = np.float32([\n        [random.uniform(0, 3), random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), random.uniform(0, 3)],\n        [random.uniform(0, 3), rows-1-random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), rows-1-random.uniform(0, 3)]\n    ])\n    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n    img_array = cv2.warpPerspective(img_array, matrix, (cols, rows))\n    return Image.fromarray(img_array)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:53.001087Z","iopub.execute_input":"2025-03-07T11:21:53.001489Z","iopub.status.idle":"2025-03-07T11:21:53.028756Z","shell.execute_reply.started":"2025-03-07T11:21:53.001452Z","shell.execute_reply":"2025-03-07T11:21:53.026994Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Improved image generation feature</font>**","metadata":{}},{"cell_type":"code","source":"def generate_synthetic_image(text, font_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n    # Pozadí\n    if background_files:\n        bg_path = random.choice(background_files)\n        img = Image.open(bg_path).convert('L').resize(img_size)\n    else:\n        img = Image.new('L', img_size, color=230)\n        draw = ImageDraw.Draw(img)\n        for y in range(img_size[1]):\n            color = int(230 - 20 * (y / img_size[1]))\n            draw.line([(0, y), (img_size[0], y)], fill=color)\n        img = img.filter(ImageFilter.GaussianBlur(radius=2))\n\n    draw = ImageDraw.Draw(img)\n\n    # Iterativní úprava fontu a textu\n    font_size = random.randint(20, min(IMG_HEIGHT-2, 28))\n    max_attempts = 5  # Omezení počtu pokusů\n    for attempt in range(max_attempts):\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n        if text_width <= IMG_WIDTH - 10:  # Text vejde\n            break\n        elif len(text) > 1:  # Zkrať text, pokud je příliš dlouhý\n            text = text[:len(text)//2]\n        else:  # Sniž velikost fontu\n            font_size = max(10, font_size - 5)  # Minimální velikost 10\n\n    # Pokud se nepodaří, použij minimální font a jednopísmený text\n    if text_width > IMG_WIDTH - 10:\n        text = text[0]  # Použij první písmeno\n        font_size = 10\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n    # Pozice textu\n    x = random.randint(5, max(5, IMG_WIDTH - text_width - 5))\n    y = random.randint(5, max(5, IMG_HEIGHT - text_height - 5))\n\n    # Zvýraznění textu\n    text_color = random.randint(0, 50)\n    outline_color = 200\n    for offset_x in [-1, 0, 1]:\n        for offset_y in [-1, 0, 1]:\n            if offset_x != 0 or offset_y != 0:\n                draw.text((x + offset_x, y + offset_y), text, font=font, fill=outline_color)\n    draw.text((x, y), text, font=font, fill=text_color)\n\n    # Šum a deformace\n    img = add_noise_and_distortion(img)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:53.030299Z","iopub.execute_input":"2025-03-07T11:21:53.030685Z","iopub.status.idle":"2025-03-07T11:21:53.067396Z","shell.execute_reply.started":"2025-03-07T11:21:53.030643Z","shell.execute_reply":"2025-03-07T11:21:53.065636Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function for splitting labels</font>**","metadata":{}},{"cell_type":"code","source":"def split_labels(labels, label_lengths):\n    \"\"\"Split a flat tensor of labels into a list of label sequences based on lengths.\"\"\"\n    split_labels = []\n    start = 0\n    for length in label_lengths:\n        split_labels.append(labels[start:start + length])\n        start += length\n    return split_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:53.068562Z","iopub.execute_input":"2025-03-07T11:21:53.069004Z","iopub.status.idle":"2025-03-07T11:21:53.096691Z","shell.execute_reply.started":"2025-03-07T11:21:53.068969Z","shell.execute_reply":"2025-03-07T11:21:53.095678Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function of Beam search decoding</font>**","metadata":{}},{"cell_type":"code","source":"def beam_search_decode(output, idx_to_char, target_lengths=None, beam_width=10, blank_penalty=-0.5, length_penalty=-0.5):\n    probs = output.softmax(2).cpu().numpy()\n    T, B, C = probs.shape\n    predictions = []\n    \n    for b in range(B):\n        sequence_probs = [(0.0, [], 1.0)]\n        max_length = target_lengths[b].item() * 2 if target_lengths is not None else T  # Cap at 2x target length\n        for t in range(T):\n            new_sequences = []\n            for log_prob, seq, prob in sequence_probs:\n                if len(seq) >= max_length:\n                    new_sequences.append((log_prob, seq, prob))\n                    continue\n                top_k_probs, top_k_idx = torch.topk(torch.tensor(probs[t, b]), beam_width)\n                for k_prob, k_idx in zip(top_k_probs, top_k_idx):\n                    new_seq = seq + [k_idx.item()]\n                    new_prob = prob * k_prob.item()\n                    new_log_prob = log_prob + np.log(k_prob.item())\n                    if k_idx.item() == 0:\n                        new_log_prob += blank_penalty\n                    new_log_prob += length_penalty * len(new_seq)\n                    new_sequences.append((new_log_prob, new_seq, new_prob))\n            sequence_probs = sorted(new_sequences, key=lambda x: x[0], reverse=True)[:beam_width]\n        \n        best_seq = sequence_probs[0][1]\n        decoded = []\n        prev = -1\n        for idx in best_seq:\n            if idx != 0 and idx != prev:\n                decoded.append(idx_to_char.get(idx, ''))\n            prev = idx\n        predictions.append(''.join(decoded) if decoded else '<empty>')\n    \n    token_counts = Counter(best_seq)\n    print(f\"Token distribution (Batch {b}): {dict(token_counts)}\")\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:53.097626Z","iopub.execute_input":"2025-03-07T11:21:53.097989Z","iopub.status.idle":"2025-03-07T11:21:53.116604Z","shell.execute_reply.started":"2025-03-07T11:21:53.097954Z","shell.execute_reply":"2025-03-07T11:21:53.115175Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Custom collate function</font>**","metadata":{}},{"cell_type":"code","source":"def custom_collate_fn(batch):\n    images, labels, label_lengths = zip(*batch)\n    # Stack images (all same size)\n    images = torch.stack(images, dim=0)\n    # Concatenate labels into a flat tensor\n    labels = torch.cat(labels, dim=0)\n    # Convert label_lengths to tensor\n    label_lengths = torch.tensor(label_lengths, dtype=torch.long)\n    return images, labels, label_lengths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:53.117630Z","iopub.execute_input":"2025-03-07T11:21:53.118013Z","iopub.status.idle":"2025-03-07T11:21:53.151123Z","shell.execute_reply.started":"2025-03-07T11:21:53.117983Z","shell.execute_reply":"2025-03-07T11:21:53.149087Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generování datasetu</font>**","metadata":{}},{"cell_type":"code","source":"def create_synthetic_dataset(num_samples):\n    labels = []\n    for i in range(num_samples):\n        text = generate_random_text(MAX_TEXT_LENGTH)\n        if not text:\n            continue\n        font_path = random.choice(font_files)\n        img = generate_synthetic_image(text, font_path)\n        img_name = f\"img_{i:05d}.png\"\n        img_path = os.path.join(OUTPUT_DIR, img_name)\n        img.save(img_path)\n        labels.append(f\"{img_name}\\t{text}\")  # Use tab (\\t) instead of space\n        if i % 100 == 0:\n            print(f\"Generated {i}/{num_samples} images\")\n\n    if labels:\n        with open(LABELS_FILE, 'w') as f:\n            f.write(\"\\n\".join(labels))\n        print(f\"Dataset generated! Images saved in '{OUTPUT_DIR}', labels in '{LABELS_FILE}'\")\n    else:\n        print(\"No labels generated!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:53.152470Z","iopub.execute_input":"2025-03-07T11:21:53.153169Z","iopub.status.idle":"2025-03-07T11:21:53.181392Z","shell.execute_reply.started":"2025-03-07T11:21:53.153112Z","shell.execute_reply":"2025-03-07T11:21:53.179924Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Mapping characters to indices and back</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"char_to_idx = {char: idx + 1 for idx, char in enumerate(CHARSET)}  # 0 is reserved for blank (CTC)\nidx_to_char = {idx: char for char, idx in char_to_idx.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:53.185075Z","iopub.execute_input":"2025-03-07T11:21:53.185468Z","iopub.status.idle":"2025-03-07T11:21:53.207636Z","shell.execute_reply.started":"2025-03-07T11:21:53.185426Z","shell.execute_reply":"2025-03-07T11:21:53.205915Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom dataset</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRDataset(Dataset):\n    def __init__(self, image_dir, labels_file):\n        self.image_dir = image_dir\n        self.labels_file = labels_file\n        self.data = []\n        with open(labels_file, 'r') as f:\n            for line in f:\n                if not line.strip():  # Skip empty lines\n                    continue\n                image_path, label = line.strip().split('\\t')\n                label_length = len(label)\n                self.data.append((image_path, label, label_length))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_path, label, label_length = self.data[idx]\n        image = Image.open(os.path.join(self.image_dir, image_path)).convert('L')\n        image = transforms.ToTensor()(image)\n        label_encoded = torch.tensor([char_to_idx[c] for c in label], dtype=torch.long)\n        return image, label_encoded, label_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:53.209583Z","iopub.execute_input":"2025-03-07T11:21:53.210031Z","iopub.status.idle":"2025-03-07T11:21:53.235269Z","shell.execute_reply.started":"2025-03-07T11:21:53.209995Z","shell.execute_reply":"2025-03-07T11:21:53.233823Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom CTC Loss with Blank Penalty</font>**\n-------------------\n> CTC Loss with Entropy Regularization","metadata":{}},{"cell_type":"code","source":"class CTCLossWithBlankPenalty(nn.Module):\n    def __init__(self, blank=0, zero_infinity=True, blank_penalty_weight=1.0, entropy_weight=1.0, label_smoothing=0.2):\n        super().__init__()\n        self.ctc_loss = nn.CTCLoss(blank=blank, zero_infinity=zero_infinity)\n        self.blank_penalty_weight = blank_penalty_weight\n        self.entropy_weight = entropy_weight\n        self.label_smoothing = label_smoothing\n\n    def forward(self, log_probs, targets, input_lengths, target_lengths):\n        ctc_loss = self.ctc_loss(log_probs, targets, input_lengths, target_lengths)\n        blank_probs = log_probs[:, :, 0].exp().mean()\n        blank_penalty = -torch.log(1 - blank_probs + 1e-6) * self.blank_penalty_weight\n        entropy = -(log_probs.exp() * log_probs).sum(dim=-1).mean()  # Negative entropy\n        total_loss = ctc_loss + blank_penalty + self.entropy_weight * entropy\n        return total_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:53.236230Z","iopub.execute_input":"2025-03-07T11:21:53.236533Z","iopub.status.idle":"2025-03-07T11:21:53.273322Z","shell.execute_reply.started":"2025-03-07T11:21:53.236482Z","shell.execute_reply":"2025-03-07T11:21:53.272299Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Model definition (CNN + RNN + CTC)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRModel(nn.Module):\n    def __init__(self, num_chars):\n        super(OCRModel, self).__init__()\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.rnn = nn.LSTM(128 * (IMG_HEIGHT // 4), 256, num_layers=2, bidirectional=True, dropout=DROPOUT)\n        self.fc = nn.Linear(256 * 2, num_chars)\n        self.dropout = nn.Dropout(DROPOUT)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        batch, channels, height, width = x.size()\n        x = x.view(batch, channels * height, width).permute(2, 0, 1)\n        x = x[:MAX_SEQ_LENGTH]  # Truncate to MAX_SEQ_LENGTH\n        x, _ = self.rnn(x)\n        x = self.dropout(x)\n        x = self.fc(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:53.274175Z","iopub.execute_input":"2025-03-07T11:21:53.274433Z","iopub.status.idle":"2025-03-07T11:21:53.302797Z","shell.execute_reply.started":"2025-03-07T11:21:53.274410Z","shell.execute_reply":"2025-03-07T11:21:53.301903Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Training</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, device, epoch, warmup_steps=WARMUP_STEPS):\n    model.train()\n    total_loss = 0\n    global_step = epoch * len(train_loader)\n    for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n        imgs, labels = imgs.to(device), labels.to(device)\n        label_lengths = label_lengths.to(device)\n\n        if global_step < warmup_steps:\n            lr_scale = min(1.0, float(global_step + 1) / warmup_steps)\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = LEARNING_RATE * lr_scale\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        outputs = outputs / TEMPERATURE\n        outputs = outputs.log_softmax(2)\n\n        batch_size = imgs.size(0)\n        seq_length = outputs.size(0)\n        input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n\n        loss = criterion(outputs, labels, input_lengths, label_lengths)\n        if torch.isnan(loss) or torch.isinf(loss):\n            print(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n            continue\n\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)  # Tightened\n        optimizer.step()\n        total_loss += loss.item()\n        global_step += 1\n\n        if batch_idx % 10 == 0:\n            with torch.no_grad():\n                pred_texts = beam_search_decode(outputs, idx_to_char, label_lengths)\n                raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n                blank_probs = outputs[:, :, 0].exp().mean().item()\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:3]]\n                print(f\"Batch {batch_idx}, Gradient norm: {grad_norm.item():.4f}\")\n                print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n                print(f\"Avg Blank Probability: {blank_probs:.4f}\")\n                print(f\"Sample predictions: {pred_texts[:3]}\")\n                print(f\"Ground Truth (first 3): {ground_truth}\")\n                print(f\"Raw outputs (first 3): {raw_outputs}\")\n                print(f\"Input length: {seq_length}, Label lengths: {label_lengths[:3].tolist()}\")\n\n    return total_loss / len(train_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:53.304385Z","iopub.execute_input":"2025-03-07T11:21:53.304851Z","iopub.status.idle":"2025-03-07T11:21:53.338900Z","shell.execute_reply.started":"2025-03-07T11:21:53.304809Z","shell.execute_reply":"2025-03-07T11:21:53.337318Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Inference (prediction)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def decode_prediction(output, idx_to_char):\n    probs = output.softmax(2)\n    max_probs, preds = probs.max(dim=2)\n    preds = preds.cpu().numpy()\n    max_probs = max_probs.cpu().numpy()\n    texts = []\n    for i, (pred, prob) in enumerate(zip(preds.T, max_probs.T)):\n        print(f\"Raw prediction {i} (pre-filter): {pred}, Max probs: {prob}\")\n        # Dynamic threshold: 75th percentile of max probs in this sequence\n        threshold = np.percentile(prob, 75)\n        print(f\"Dynamic threshold for prediction {i}: {threshold:.4f}\")\n        pred_text = []\n        prev = -1\n        for idx, p in zip(pred, prob):\n            if idx != 0 and idx != prev and p > threshold:\n                pred_text.append(idx_to_char.get(idx, ''))\n            prev = idx\n        decoded = ''.join(pred_text)\n        texts.append(decoded if decoded else '<empty>')\n    return texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:53.340110Z","iopub.execute_input":"2025-03-07T11:21:53.340546Z","iopub.status.idle":"2025-03-07T11:21:53.368441Z","shell.execute_reply.started":"2025-03-07T11:21:53.340508Z","shell.execute_reply":"2025-03-07T11:21:53.367031Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Main launch</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    if not font_files:\n        print(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n    else:\n        create_synthetic_dataset(NUM_SAMPLES)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    full_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n\n    for i in range(5):\n        img, label, length = full_dataset[i]\n        plt.imshow(img.squeeze(), cmap='gray')\n        plt.title(''.join([idx_to_char.get(idx.item(), '') for idx in label[:length]]))\n        plt.show()\n    \n    if len(full_dataset) == 0:\n        print(\"Dataset is empty! Check labels.txt or image directory.\")\n    else:\n        # Curriculum phases with pre-filtering\n        model = OCRModel(num_chars=len(CHARSET)).to(device)\n        criterion = CTCLossWithBlankPenalty(blank=0, zero_infinity=True, blank_penalty_weight=BLANK_PENALTY_WEIGHT, entropy_weight=ENTROPY_WEIGHT, label_smoothing=LABEL_SMOOTHING)\n        \n        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n\n        best_loss = float('inf')\n        for epoch in range(EPOCHS):\n            # Filter full dataset based on curriculum phase\n            if epoch < 10:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 5]\n                print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {[lbl for _, lbl, _ in filtered_data[:3]]}\")\n            elif epoch < 15:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 7]\n            else:\n                filtered_data = full_dataset.data\n\n            # Create a new dataset with filtered data\n            curr_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n            curr_dataset.data = filtered_data  # Overwrite with filtered data\n\n            # Split into train and validation\n            train_size = int(0.8 * len(curr_dataset))\n            val_size = len(curr_dataset) - train_size\n            train_dataset, val_dataset = torch.utils.data.random_split(curr_dataset, [train_size, val_size])\n            print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n            \n            # Create data loaders\n            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n            val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n            \n            loss = train_model(model, train_loader, criterion, optimizer, device, epoch)\n            print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss:.4f}\")\n\n            # Validation\n            model.eval()\n            val_loss = 0\n            with torch.no_grad():\n                for imgs, labels, label_lengths in val_loader:\n                    imgs, labels = imgs.to(device), labels.to(device)\n                    label_lengths = label_lengths.to(device)\n                    outputs = model(imgs)\n                    outputs = outputs.log_softmax(2)\n                    seq_length = outputs.size(0)\n                    input_lengths = torch.full((imgs.size(0),), seq_length, dtype=torch.long).to(device)\n                    val_loss += criterion(outputs, labels, input_lengths, label_lengths).item()\n                \n                val_loss /= len(val_loader)\n                pred_texts = beam_search_decode(outputs, idx_to_char)\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:5]]\n                print(f\"Validation Loss: {val_loss:.4f}\")\n                print(\"Validation Predictions:\", pred_texts[:5])\n                print(\"Ground Truth:\", ground_truth)\n\n            model.train()\n            scheduler.step()\n            print(f\"Current Learning Rate: {optimizer.param_groups[0]['lr']}\")\n\n            if val_loss < best_loss:\n                best_loss = val_loss\n                torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'best_ocr_model.pth'))\n\n        torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'final_ocr_model.pth'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:21:53.369348Z","iopub.execute_input":"2025-03-07T11:21:53.369651Z","iopub.status.idle":"2025-03-07T11:35:39.099933Z","shell.execute_reply.started":"2025-03-07T11:21:53.369624Z","shell.execute_reply":"2025-03-07T11:35:39.098869Z"}},"outputs":[{"name":"stdout","text":"Generated 0/5120 images\nGenerated 100/5120 images\nGenerated 200/5120 images\nGenerated 300/5120 images\nGenerated 400/5120 images\nGenerated 500/5120 images\nGenerated 600/5120 images\nGenerated 700/5120 images\nGenerated 800/5120 images\nGenerated 900/5120 images\nGenerated 1000/5120 images\nGenerated 1100/5120 images\nGenerated 1200/5120 images\nGenerated 1300/5120 images\nGenerated 1400/5120 images\nGenerated 1500/5120 images\nGenerated 1600/5120 images\nGenerated 1700/5120 images\nGenerated 1800/5120 images\nGenerated 1900/5120 images\nGenerated 2000/5120 images\nGenerated 2100/5120 images\nGenerated 2200/5120 images\nGenerated 2300/5120 images\nGenerated 2400/5120 images\nGenerated 2500/5120 images\nGenerated 2600/5120 images\nGenerated 2700/5120 images\nGenerated 2800/5120 images\nGenerated 2900/5120 images\nGenerated 3000/5120 images\nGenerated 3100/5120 images\nGenerated 3200/5120 images\nGenerated 3300/5120 images\nGenerated 3400/5120 images\nGenerated 3500/5120 images\nGenerated 3600/5120 images\nGenerated 3700/5120 images\nGenerated 3800/5120 images\nGenerated 3900/5120 images\nGenerated 4000/5120 images\nGenerated 4100/5120 images\nGenerated 4200/5120 images\nGenerated 4300/5120 images\nGenerated 4400/5120 images\nGenerated 4500/5120 images\nGenerated 4600/5120 images\nGenerated 4700/5120 images\nGenerated 4800/5120 images\nGenerated 4900/5120 images\nGenerated 5000/5120 images\nGenerated 5100/5120 images\nDataset generated! Images saved in '/kaggle/working/synthetic_data/images', labels in '/kaggle/working/synthetic_data/labels.txt'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {32: 2, 34: 1, 11: 1, 42: 1, 1: 2, 19: 1}\nBatch 0, Gradient norm: 15.2698\nEpoch 1, Batch 0/66, Loss: 30.6459\nAvg Blank Probability: 0.0148\nSample predictions: ['lv2a', 'elj3faja', 'kv-jaG']\nGround Truth (first 3): ['Up', '4Kv4', 'OFf']\nRaw outputs (first 3): [[12  5 11 11 19 12  6 47  1 27  1  1  1 50  1 19 56 10 10 56 10 34 27  1\n  32 33 32 10 43 42 34 32]\n [22 12 22  5 27 32  1 10 56  1 24 56  8  1  1 32 11  1 42 62  4 47 44 19\n  57 50  1  6  1 27 23 34]\n [55 10 63 34 19 56 47 11 48  1  1 42 24  1  1 43 12 32  1 10 34 56  1  1\n  48  1 22 12  1  1  1 11]]\nInput length: 15, Label lengths: [2, 4, 3]\nToken distribution (Batch 31): {56: 1, 17: 1}\nBatch 10, Gradient norm: 18.0795\nEpoch 1, Batch 10/66, Loss: 32.5870\nAvg Blank Probability: 0.0147\nSample predictions: ['Qj', '3a', 'asvlPj']\nGround Truth (first 3): ['X', 'K', '6eE']\nRaw outputs (first 3): [[43 56  1 12  6  1 36 43 29  6 13 30 12  4 25 12 10 63 14  1 29  6  4 56\n  34 11 42  6  1 43  1 56]\n [10  1 19  1  1 60 61  6  1 16  1  1 48 34 10  5 63 22 42 43 24 24  1  1\n  47 30 47  1 19  1 56 17]\n [ 1 34 22 10  1 32 12 10 43 56 42  1 10 32  2 50 22  6 12 62 47  1 43 34\n  22 30  6 43  1 47  1 10]]\nInput length: 15, Label lengths: [1, 1, 3]\nToken distribution (Batch 31): {4: 2, 1: 1, 5: 1}\nBatch 20, Gradient norm: 243.1549\nEpoch 1, Batch 20/66, Loss: 27.3454\nAvg Blank Probability: 0.0145\nSample predictions: ['UfADyQUlAj', 'HIFsFyml', 'sflVd2asa']\nGround Truth (first 3): ['u6XUi', 'qUYe', '*afWc']\nRaw outputs (first 3): [[47 34 19 14 24 42 12  6 47  1 10  6  1  1  1 12 22  8 63  6 63  6  1  6\n  56  1 56 45  1 32  1  4]\n [ 6 35 19 34 19 17 57 47  5 19 10 56 47  1 24 24  1 43  1 63 10 47 27 10\n   5 27 24 43  7 10 32  4]\n [27  0  6 32 22 34 32  1 16 19 12 11 56 11 47 50 35 47  5  1 25 47 22 10\n  13  1 16 10 13  6  1  1]]\nInput length: 15, Label lengths: [5, 4, 5]\nToken distribution (Batch 31): {4: 1, 47: 1, 33: 1, 35: 1}\nBatch 30, Gradient norm: 18.0939\nEpoch 1, Batch 30/66, Loss: 32.7700\nAvg Blank Probability: 0.0146\nSample predictions: ['HjyU', 'ayFLv8FrFH', 'HQaUHaFgda']\nGround Truth (first 3): ['9K', 'jEXUx', '8aW40']\nRaw outputs (first 3): [[34  1 34 10  1  6 50 20 56  5 35 32  1 27  4  1  1 48 63 21 19  1 10  1\n  34 10 34  6 11 10  1  4]\n [10 25 43 47  1 30 11  1 32  7  4 22 32  6 12 11  1 30 11 56 32 56 25  6\n  32 10 63 10 47 55 11 47]\n [25 32  1 34  7  1 63 50 60 14  1 47  1  1 30 19 11 63 11 61 63 34  4  6\n  32 36 41 34  1 10 47 33]]\nInput length: 15, Label lengths: [2, 5, 5]\nToken distribution (Batch 31): {10: 2, 11: 2, 12: 1, 1: 1, 50: 1, 5: 1, 35: 1, 19: 1}\nBatch 40, Gradient norm: 26.5551\nEpoch 1, Batch 40/66, Loss: 32.2890\nAvg Blank Probability: 0.0148\nSample predictions: ['Aj', 'kd', 'HaXyaI2']\nGround Truth (first 3): ['K', 'z', '5*m2']\nRaw outputs (first 3): [[27 11 34 19 34 34 11 19 34  1 34 48 10 12  1 43 22  1 11  2 11 11  1 56\n  10 55 10 10  1 10 32 10]\n [10  4  1 47 48 47 47  1 25 22 35  4  6  8 35  1 12 32  5  6  1  6 47 50\n  43  1 29 19 16 11 10 11]\n [29 55  1 20  1  1 47 56 63 34  1 59 10 32  1  1 27 32 10 43 35 12 32  6\n   5 10  1 10  1 19  1 11]]\nInput length: 15, Label lengths: [1, 1, 4]\nToken distribution (Batch 31): {1: 3, 10: 1}\nBatch 50, Gradient norm: 20.7488\nEpoch 1, Batch 50/66, Loss: 35.5255\nAvg Blank Probability: 0.0150\nSample predictions: ['a3', 'kl', 'HUkHd3FU']\nGround Truth (first 3): ['0', '3', 'Ox9Z']\nRaw outputs (first 3): [[ 1 11 34  1 10 24  1 10 42 22  1 63 24 12  1 19 16 50 10 47 63  1 24 32\n  10 10 25 10  1 19 56  1]\n [56 12 47  6  1 42 22  6 32 24 22 47 10  5 22 33  1 19  4 23  1 48  1  1\n   5 27 12  2  6 12 12  1]\n [10  7 11  1  1 32 10  1 10  1 11  4  1 10 34 19 35 56 11  5  1  6 32 32\n   1 56  4 46  4  1 48  1]]\nInput length: 15, Label lengths: [1, 1, 4]\nToken distribution (Batch 31): {11: 1, 50: 1, 19: 1, 1: 1}\nBatch 60, Gradient norm: 1423.7924\nEpoch 1, Batch 60/66, Loss: 31.4721\nAvg Blank Probability: 0.0148\nSample predictions: ['jdP-XFv-sa', 'fsakeaVAPA', 'k8Fa']\nGround Truth (first 3): ['p46O6', 'oChe-', 'Jf']\nRaw outputs (first 3): [[10  6 11  6  1 34  4 46 56 12 35 24 43 43  1  1 10 22  1 11 22 47 33 34\n   4 34 25 63 42  1 11 11]\n [ 4 19 61 63  1 10  1 35 12 10 11 19 42  4  4  1  4 47 10 43  1 32 19 27\n   1  1 10 34 27  1 10 50]\n [42  1 32  4 34 25 56 32  1  4  1 12 42  1 50 10  9 22 19 34 27  1  1  1\n   1  1  1 12 19  4 12 19]]\nInput length: 15, Label lengths: [5, 5, 2]\nEpoch 1/20, Loss: 33.5684\nToken distribution (Batch 8): {1: 15}\nValidation Loss: 32.5908\nValidation Predictions: ['aj', 'aj', 'aj', 'a', 'aj']\nGround Truth: ['Ems', 'Dt', '4z', 'OdrNd', '8QWWA']\nCurrent Learning Rate: 7.17495449420706e-08\nEpoch 2, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {1: 2, 43: 1, 34: 1}\nBatch 0, Gradient norm: 14.3615\nEpoch 2, Batch 0/66, Loss: 27.3951\nAvg Blank Probability: 0.0150\nSample predictions: ['pyjaQJea', 'UeFeaw', 'fPj3']\nGround Truth (first 3): ['VNbV', 'pn9', 'K3']\nRaw outputs (first 3): [[16 47  6  1 11  6  5  1 12 11  1 34 34 16  1 12 33 47 56 11 56 11 11 22\n  22 22 56 32 57 34 12  1]\n [25  5 42 37 12  1 10 11 56 22  1 12 33  1 50 10 12 10 10  1 10 57  1 10\n  12 42  1 16  5  4 50 43]\n [10 32 10  1  5 47 11 19 16 10 42 11 50  6 11 56 56 20 35  1 27 11  1  5\n   5 11  4 20  1  1 34  1]]\nInput length: 15, Label lengths: [4, 3, 2]\nToken distribution (Batch 31): {63: 1, 43: 1, 35: 1, 42: 1}\nBatch 10, Gradient norm: 18.9960\nEpoch 2, Batch 10/66, Loss: 34.5906\nAvg Blank Probability: 0.0150\nSample predictions: ['jI4vsf', 'eskjkaUk', 'a']\nGround Truth (first 3): ['CVN', '76rX', 'w']\nRaw outputs (first 3): [[10  5  1  4  1  1 34 42  1  1 11 12 10 11 12 34 11  4  1  5  6  1 10 47\n  12 10  1 63 14  4 10 63]\n [35 19  1 22 12 25 14 22  1 19  1  1 43  6 10 10 47 56  1 16 48 32  1 35\n   1 43  1 10  4 34 10 43]\n [57 11 19 12  1 11 10 10  9 34  1 22 11 32 35 10 47 11 10 34 35 34  4 11\n  22 25 48 27 32 43  1 35]]\nInput length: 15, Label lengths: [3, 4, 1]\nToken distribution (Batch 31): {34: 2, 6: 1, 1: 3, 32: 1, 19: 1, 10: 1, 7: 1}\nBatch 20, Gradient norm: 13.3206\nEpoch 2, Batch 20/66, Loss: 26.7473\nAvg Blank Probability: 0.0149\nSample predictions: ['ksajXHyVaC', 'aVdjaVDj', 'yUajsjsH']\nGround Truth (first 3): ['4hA6-', 'qLqg', 'LE5c']\nRaw outputs (first 3): [[11  1 25  1 47 56  1 10  1  1 47 42 10 16 22 43 10 50 24 43 10 63 10 63\n  16 63 34 12 24 56  1 34]\n [19 48 47 34 22 56 50 22 47  1 12 10 42 10  1 10  1 21 11 38  4 56 11 10\n  16 32 30 46 55 43  1  6]\n [ 1  4  1 10 60  1 22  4  1 10  1 32  1 10 32 24  1 56  1 24  4 25 50 10\n  22  4 11 12  1 32  1  1]]\nInput length: 15, Label lengths: [5, 4, 4]\nToken distribution (Batch 31): {63: 1, 47: 1, 12: 1, 42: 1, 51: 1, 34: 1}\nBatch 30, Gradient norm: 20.5362\nEpoch 2, Batch 30/66, Loss: 35.9618\nAvg Blank Probability: 0.0149\nSample predictions: ['jaFsvUad', 'AasP', 'da']\nGround Truth (first 3): ['3CFh', 'TK', 'B']\nRaw outputs (first 3): [[10 27  4 10 11 35 42  6 47 42 11 11 10 14  1 34 63 63 10 63 47 19  1  1\n   4 11 63 34 34  1 35 63]\n [ 1  1  1 12 35 20 34 19  1 47 42 35 57 63  4 32 56 25 10 42  1 47  1 34\n  28  1 35 25 32 32 13 47]\n [32 19  1 57  1 19 34 32  1 28 42 32 11  1 56 32 10 16 38 56 32 11 27 47\n  11 11 10  1 34 22  1 12]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {25: 1, 43: 1, 4: 2, 30: 1, 10: 1, 1: 1, 12: 1, 19: 1, 55: 1}\nBatch 40, Gradient norm: 28.0817\nEpoch 2, Batch 40/66, Loss: 43.1877\nAvg Blank Probability: 0.0149\nSample predictions: ['g642Udxde', 'kPFp', 'aRk']\nGround Truth (first 3): ['-Bk62', 'Ad', '7-']\nRaw outputs (first 3): [[ 7 11  1  1 11 35 10  4 11 60 30  5 11 10  1  1 19  1 22 10  1 34  1  1\n  56 34 34 11 25 35 43 25]\n [ 7 42 44  1 12 56 10 34 32 10 47 11  1 63  6 42 34  4 10 34 19 27 16 27\n  19  1 33 33 42 34  5 43]\n [59 32 11 47 43 33  1  1  1 61 42  6 12  1 24  6 12 19  1 42  1  1 42 27\n  30 10  1 22 56 35 11  4]]\nInput length: 15, Label lengths: [5, 2, 2]\nToken distribution (Batch 31): {1: 2, 4: 1, 11: 1, 34: 1, 22: 1}\nBatch 50, Gradient norm: 14.2276\nEpoch 2, Batch 50/66, Loss: 28.5656\nAvg Blank Probability: 0.0149\nSample predictions: ['kakfjav', 'aiXsaVU', 'Da']\nGround Truth (first 3): ['3uam', 'A6TT', 'E']\nRaw outputs (first 3): [[11  1 30 63 25  1 56  6 63 43 12  1  1  6  1 63  1 11  1 11  1 11 10 22\n  32  1 24  1 19 11  6  1]\n [ 1  9  1  6 47 56 47  1 34 19 10 61 19  1  1 50  0  9  4 34  4 43 10 12\n  32  2  5 11  4 35 10  1]\n [11 50 48 56 42  1  4 18  1 34  1 34  1  5  1 16 16  1 34 42  1 56  1 22\n  11 46 25 19 33 47 47  4]]\nInput length: 15, Label lengths: [4, 4, 1]\nToken distribution (Batch 31): {10: 1, 11: 1}\nBatch 60, Gradient norm: 244.9769\nEpoch 2, Batch 60/66, Loss: 39.0594\nAvg Blank Probability: 0.0150\nSample predictions: ['3ajn', 'FAPsjAkH', 'ajeFey8U']\nGround Truth (first 3): ['tP', 'orH2', 'jxG9']\nRaw outputs (first 3): [[56 32  1 28 14 10 19 19 34 11 10 16  6 56 10 56  1 34  1  1  6 34 19 12\n  56 43 12 42 56  1  4  0]\n [ 1 27 10 10  5  1  1  1  1 43 47  1  1 42  1 60 59  1  1  5  1 34  1 32\n  43 32  6 35 55 50  1 11]\n [10 42  5 55 57 32 25 28 43 34 48  1 50  1  6 32  5 47 50 10 43 47 33  1\n   1  6  1 47 47 48 48 10]]\nInput length: 15, Label lengths: [2, 4, 4]\nEpoch 2/20, Loss: 33.1154\nToken distribution (Batch 8): {1: 13, 10: 2}\nValidation Loss: 33.0377\nValidation Predictions: ['a', 'aj', 'a', 'a', 'aj']\nGround Truth: ['nxOD', 'DYK', 'kXK', 'Bw', '*4VnO']\nCurrent Learning Rate: 1.4799668461247093e-07\nEpoch 3, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {11: 1, 47: 1, 1: 2}\nBatch 0, Gradient norm: 20.0118\nEpoch 3, Batch 0/66, Loss: 34.5269\nAvg Blank Probability: 0.0148\nSample predictions: ['fIDaEa', '3ajk', 'aj']\nGround Truth (first 3): ['NXr', 'Ii', 'Z']\nRaw outputs (first 3): [[ 6 56  1 34 34  1  4 63 12 10  4 24 47 32 57 56  4  5  1 43 34 63  1 35\n  35  6 22 22 10  4 12 11]\n [35  1 10 11  1 35 13 11 42 34  1  1 16 48  1  1 63  1 56 22 47 43 12 22\n  57  1  1 34  4 32 24 47]\n [30 10 34 11 34 56  1 35 47  1  5 19  1 11 19 46 43 28  1 42  1 56  1 55\n  47 56 35  1  4  1 57  1]]\nInput length: 15, Label lengths: [3, 2, 1]\nToken distribution (Batch 31): {56: 1, 35: 1, 24: 1, 4: 1, 18: 1, 6: 1, 27: 1, 1: 3}\nBatch 10, Gradient norm: 236.4342\nEpoch 3, Batch 10/66, Loss: 40.3717\nAvg Blank Probability: 0.0151\nSample predictions: ['yjs2jsja', 'aX', 'HekladQjA']\nGround Truth (first 3): ['2b6t', 'z', 'UM8yk']\nRaw outputs (first 3): [[25  1 34 12  5 35 10 24  5 63 34  1 22 11 19 61  1 25  6 10 35  1 43 11\n  63  6 11  1  6 10  4 56]\n [10 50 34 10 35 56 32 34  1 47 56 32 10 10 32 25  1 61  6  4  1 10 30 10\n   6  1 40  0 32 10 56 35]\n [19  1  5 10  1 22 30 10  1  9 34 32 11  1 32 12 34  1 24 56  4 11 63 32\n   1  6 32 24 47 25 10 24]]\nInput length: 15, Label lengths: [4, 1, 5]\nToken distribution (Batch 31): {1: 2, 42: 2, 34: 1, 22: 1}\nBatch 20, Gradient norm: 919.6471\nEpoch 3, Batch 20/66, Loss: 31.4911\nAvg Blank Probability: 0.0150\nSample predictions: ['fA-s3ja8', 'jnaIxa', 'VFtaQ']\nGround Truth (first 3): ['AaGy', 'JnBX', 'QVW']\nRaw outputs (first 3): [[ 6 10 48 12  1  4  1  1  1 10  6 56 11 30 43  4 47 63 11 47 42 56 35 30\n  63 11 63 16  6 16  1  1]\n [27 14 32  7 34  4 35  1  6  1 22 57 11  6 56 35 19 28 11 30  4 55  1 12\n  30  1  4 32 16  1 10 42]\n [63  1 20 10 45 47 43  5 32 27 10  4 11 35 56  1  6  1 50 56 11 30  4 56\n   1 11 56 32 11  1  6 42]]\nInput length: 15, Label lengths: [4, 4, 3]\nToken distribution (Batch 31): {4: 1, 12: 1}\nBatch 30, Gradient norm: 14.6620\nEpoch 3, Batch 30/66, Loss: 29.2894\nAvg Blank Probability: 0.0149\nSample predictions: ['dF2ageU', '4Qva', 'kA']\nGround Truth (first 3): ['yz2K', 'Pn', 'd']\nRaw outputs (first 3): [[ 4 57 11  4 12 27 14 16 12  4 11 12 34  5 56 42 24  1  1  1 25  1 25 30\n   1  1  1  1 44 10 34  4]\n [32 43 27 24 42  1 24 32  1 32 22 30 10 35 34  1 22 12 47  6 10 12 10 19\n   1 19  4  5  1  5 47 12]\n [32 22  7 19 11  9 10 32 61 51 61 32 22 10 56 32 46 59 28 63 10  1  1 24\n  22 35 33  1 10  1 63  1]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {47: 1, 22: 1}\nBatch 40, Gradient norm: 20.1998\nEpoch 3, Batch 40/66, Loss: 35.4440\nAvg Blank Probability: 0.0152\nSample predictions: ['Pjl3', 'vald3tUl-', 'F2']\nGround Truth (first 3): ['HJ', 'lCXSq', 's']\nRaw outputs (first 3): [[42 22 32  1 34  1  4 48 14  4 34 56 32  1  1  4 10  6 34 26 10 47 63 12\n  12 61  1  1 63 56  1 47]\n [10  1 55  1 10 17 10  5 63  1  1 22 24 12  4 48  1  1 11 12 42  1 19  1\n   1 12 25 13 42 22  1 22]\n [12  1  1 22  6 34 33  4 35 36 32 17 10 51  1 19 35 43 11 32 43  1  1 32\n  10 32  1 14  1  6  1 47]]\nInput length: 15, Label lengths: [2, 5, 1]\nToken distribution (Batch 31): {1: 2, 50: 1, 10: 1, 11: 2, 27: 2, 34: 1, 19: 1}\nBatch 50, Gradient norm: 20.9832\nEpoch 3, Batch 50/66, Loss: 36.5857\nAvg Blank Probability: 0.0152\nSample predictions: ['qs', 'QjyE2Pwka', 'jI']\nGround Truth (first 3): ['h', 'HzLVh', 'P']\nRaw outputs (first 3): [[17 43 10 42 19  4  1  4  1  6  4  1 32  6 56 16 11  1 42 60 34 19 10  6\n   1 16 22 63 48 32 63  1]\n [19 10 35  1 47 50 10  1  1  1 25 47 11 10 10 35 47 43 50 11 27 22 56  1\n  63 47 22 11 35  1 34 50]\n [ 6 25 27  4 30 10 25 48  1  1  1 30 27  1 12 10 47 27  1 47  4  1 42  1\n  42 12 10 63  1  1 11 10]]\nInput length: 15, Label lengths: [1, 5, 1]\nToken distribution (Batch 31): {56: 1, 1: 3, 6: 1, 21: 1, 29: 1, 22: 1, 14: 1, 32: 1}\nBatch 60, Gradient norm: 22.0793\nEpoch 3, Batch 60/66, Loss: 33.1768\nAvg Blank Probability: 0.0152\nSample predictions: ['-fxU', 'a3OsaftV', 'j3ekagAs']\nGround Truth (first 3): ['x*', 'z2xI', 'ddhf']\nRaw outputs (first 3): [[63  1 10 47 34  1  4  1  4 22 35 56 10  1 24 57  1 11  1 30  0  1 34 48\n  10 22 12 12  6 63  1 56]\n [ 6 56 56 12  1  1 12 63  5 16  1  1 56 18 12 22 34  1 19 24 46 31  6 50\n  56  1  1 10  1 11  4  1]\n [24 41  5 48 22 30  4  1 10  1 19 22  4 11 10 11 10 22  1 13 35  1 35 47\n  32  4 47 34 35 34  1  1]]\nInput length: 15, Label lengths: [2, 4, 4]\nEpoch 3/20, Loss: 33.0644\nToken distribution (Batch 8): {1: 15}\nValidation Loss: 32.5882\nValidation Predictions: ['a', 'aj', 'a', 'a', 'aj']\nGround Truth: ['XgM1X', 'UVE', 'oChe-', 'NjDj6', 'i9ud8']\nCurrent Learning Rate: 2.2268411000266314e-07\nEpoch 4, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {5: 1, 18: 1, 19: 1, 10: 1, 27: 1, 55: 2, 35: 1, 9: 1, 47: 1}\nBatch 0, Gradient norm: 21.3629\nEpoch 4, Batch 0/66, Loss: 36.5697\nAvg Blank Probability: 0.0150\nSample predictions: ['IafvFAX', 'e-df', 'fV']\nGround Truth (first 3): ['r8lu', 'Xf', '-']\nRaw outputs (first 3): [[35  5  6 56 10 16 47  1  1  1  1 61  4  4 27 35  1 56 10 10 20  1 11 30\n  19  1 22  1  1 63 32  5]\n [ 1 63 48 35 34  7 10 47 34 56 22 27 12 47 32 34  4 10 35 32 25 32 10 47\n  11 47 11 25 30 12 63 18]\n [ 6  4  1 19  4 48 50 22 61 43 40  1 11  1 19 12 11  1 55 35  1 10 63 61\n  19  5  1 14 34 35 10 19]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {6: 2}\nBatch 10, Gradient norm: 23.5976\nEpoch 4, Batch 10/66, Loss: 37.9451\nAvg Blank Probability: 0.0152\nSample predictions: ['HFrUaU3a', 'vfa', 'fadja32a']\nGround Truth (first 3): ['zypb', 'P0', 'hrNK']\nRaw outputs (first 3): [[34 22  6 32  1 30 42  4  6 10 32 12 42 12  1 10 63  6 63 63 22 32 12 34\n   1 35  1 13 63  1 10  6]\n [32  6  1  1 22  1 47 32 32  4 43 34 19 47 10  1 11 10  6 30 24  1 12  1\n  12 56 30 12 34 34 42  6]\n [18  1  4 24 32 22  1  5  1  4 10 34 20 10  1  2  1 10  6 10  1  1  7  1\n  10 10 10 24 42 11 16  1]]\nInput length: 15, Label lengths: [4, 2, 4]\nToken distribution (Batch 31): {1: 2, 10: 1, 22: 1}\nBatch 20, Gradient norm: 19.0534\nEpoch 4, Batch 20/66, Loss: 32.5811\nAvg Blank Probability: 0.0152\nSample predictions: ['-UjI', 'tHQauBaPFa', 'avdQ']\nGround Truth (first 3): ['WJ', 'tgEPL', '-k']\nRaw outputs (first 3): [[63 20  1 56 10 34 27 19 13 10 47 33 34 47 10 12 63  1 24  6  1 12 11 27\n  28  1  6 22 43 10  1  1]\n [47 34 22  6 52 63 35 24 43  1 16  4  1  5  1  1 56 47 10 33  1  1  1 42\n   1 24 42 32 61 34  4 10]\n [10 43  4 55 35  4  6 20 56 32  8  4 34 10 47 38 10  1  1 19 16  1 11 47\n  34  1 11  6 32 30  1  1]]\nInput length: 15, Label lengths: [2, 5, 2]\nToken distribution (Batch 31): {1: 1, 55: 1, 42: 1, 34: 2, 9: 1}\nBatch 30, Gradient norm: 19.5906\nEpoch 4, Batch 30/66, Loss: 33.6296\nAvg Blank Probability: 0.0153\nSample predictions: ['Asa3aj', 'ajy', '2HFaFHaX']\nGround Truth (first 3): ['DwBi', 'G5', 'SqlG']\nRaw outputs (first 3): [[27  1 55  1 23 30 32  1 10 34 47 12 50  4  6 25 22 56 47  1 47 24 42 48\n  10 35  1 43 63 12 11  1]\n [19 10 34  6 19 43 16 10 47 56  1 33 35 22 12 10 47 22  1 63 42 12 19 13\n   5  1 12 10  1  6 19 55]\n [ 1 10 32  1 19 27 50 60 10  5 33  1 10 33 56 22  1 27 10 48 19 42  4 19\n  55 12 18 41 34 11 27 42]]\nInput length: 15, Label lengths: [4, 2, 4]\nToken distribution (Batch 31): {14: 1, 1: 1}\nBatch 40, Gradient norm: 100.6588\nEpoch 4, Batch 40/66, Loss: 33.3635\nAvg Blank Probability: 0.0154\nSample predictions: ['Vl', 'fF', 'aHsI']\nGround Truth (first 3): ['o', 'D', 'ce']\nRaw outputs (first 3): [[48  6  1 10 32 22 33  1 30 43 32 10 32 24  4  1  6 32 47  1 29 63 42 43\n   1 51 12 63  1 11  4 14]\n [12 32 34  5 35  1 35 10 24 35 32  4 10 16 63 34 48 30 24  1 34  1 22  1\n  10 56 34 10 10 32  1  1]\n [ 1 56 19  5 57  1  1 42 30 56  1 24  1 55  6  1  1 34  1 36  1 42 27 46\n  11 22  1  1 43 47  1  1]]\nInput length: 15, Label lengths: [1, 1, 2]\nToken distribution (Batch 31): {10: 1, 1: 2, 32: 1, 22: 1, 47: 1, 6: 1, 26: 1}\nBatch 50, Gradient norm: 51.6066\nEpoch 4, Batch 50/66, Loss: 36.9319\nAvg Blank Probability: 0.0155\nSample predictions: ['kax7faE3', 'jaFa', 'jp']\nGround Truth (first 3): ['V6lI', '55', '3']\nRaw outputs (first 3): [[11 10 10 30  6 10  1 47 25  1 34  5 25 19  6 27 30 63 56 16 22 32  1 56\n  63  4 27 10 24  6 32 10]\n [ 1  1 16  9 42 55 56 12 34 19 12  1 12  4 32 34 10  6  1  1  1  1  1  1\n   1  1 10 20 22 10 43  1]\n [24 32  1 16 34  1 10 20 10 63 56 12 32 42 47 19 32 10 12 10 47 11 13 56\n  12 11 27 19 22  1  1  1]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {35: 1, 1: 1, 22: 2}\nBatch 60, Gradient norm: 15.6516\nEpoch 4, Batch 60/66, Loss: 29.3711\nAvg Blank Probability: 0.0156\nSample predictions: ['a2HAvUj', 'QaXUjtaIjX', '3HirFHav']\nGround Truth (first 3): ['TDXV', 'jfCBl', 'vOUX']\nRaw outputs (first 3): [[ 1 43 56 12 34 61 56 34 25 11  6 24 33 10 48 61  1 10 34 10  6 10  5 10\n   6 33 57 22 47 56 63 35]\n [ 1  1 34  1 32 10 43  1 11  6 63 32 47  1 43 32  1  5  1  1 10 22 42 34\n  30 25 12  1 10  1 63  1]\n [55 50  9 12  1 48  1  1 38 21  1 50  1  1 50 42 24  7 11 11 27 34 19 47\n  11 34 32  1 32  1 63 22]]\nInput length: 15, Label lengths: [4, 5, 4]\nEpoch 4/20, Loss: 33.1666\nToken distribution (Batch 8): {1: 15}\nValidation Loss: 33.0255\nValidation Predictions: ['aj', 'aj', 'aj', 'aj', 'a']\nGround Truth: ['sIU', 'Dt', 'w19', 'h44Q', 'VjYzO']\nCurrent Learning Rate: 2.9591120346270475e-07\nEpoch 5, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {35: 1, 1: 1}\nBatch 0, Gradient norm: 22.4862\nEpoch 5, Batch 0/66, Loss: 35.0008\nAvg Blank Probability: 0.0157\nSample predictions: ['kHiFjsk', 'kAj3kQ', 'akafjH3ega']\nGround Truth (first 3): ['*m4W', 'FZD', '*glGz']\nRaw outputs (first 3): [[11 11  1 63 12 11 10 10  1 12 61 11 56 14  6 22 61 47 19 63 43 10 63  1\n  22  1 48  4 32 57 34 35]\n [34 27 11 12 10  1 10 42  1 34 34 19 32  1 50  4 10  1  1 11  1 63 16 11\n  34 32 34 24 56 20 11  1]\n [ 9 10  1 25  1 10 35 48  6 47  6 14  1 35 56 47 25 47 20  4  1 47 34 19\n  50 32 32  4 12 34  1 19]]\nInput length: 15, Label lengths: [4, 3, 5]\nToken distribution (Batch 31): {23: 1, 32: 1}\nBatch 10, Gradient norm: 15.4980\nEpoch 5, Batch 10/66, Loss: 28.5485\nAvg Blank Probability: 0.0158\nSample predictions: ['kjUsPVLilI', 'aUjljQaflr', 'kCpIkj']\nGround Truth (first 3): ['4ylL0', 'xDoww', 'Azb']\nRaw outputs (first 3): [[11  1 11  5 50 24 42  1  1 63 42  1 12  1  6 10  4  1 34 11 34  1  1  1\n   1  1 32  1 24 35 36 23]\n [10 47 29  1 25 48  1  7 22 47  1 10 35  0  1 55 23  1 24 34  4  4  1  1\n  56 11 46  6  1 34 56 32]\n [47 10 16 61 32 34 34 32 43  6 10 30  1 42 42  1 11  1  6  1 42 30 34 32\n  27 22 43 38 22  1 11  1]]\nInput length: 15, Label lengths: [5, 5, 3]\nToken distribution (Batch 31): {19: 1, 1: 1}\nBatch 20, Gradient norm: 19.7104\nEpoch 5, Batch 20/66, Loss: 32.7256\nAvg Blank Probability: 0.0155\nSample predictions: ['aUyHPa', 'fvaP', 'D3a28ia2k']\nGround Truth (first 3): ['FqIm', 'by', '-RY61']\nRaw outputs (first 3): [[ 1  6 30 63 56 13 24 22  1 11 35  1 43  1 14  1 47  1 24 10  4 43 10 42\n   4 16  5 19 56  1 19 19]\n [47 22 56 19 56  1 35 10 56 30 10 48 19  1 43  1  1 34  1 30 47 56  1 43\n  32 42 43 34 12  1  6  1]\n [25  1  1 22 56 10 35 10 48  6 11 11 22 56  6  4 32  1  1 34  1  1 27 34\n  10 22 12  1 10 32 22 50]]\nInput length: 15, Label lengths: [4, 2, 5]\nToken distribution (Batch 31): {4: 1, 43: 2, 63: 1, 6: 1, 5: 2, 32: 1, 10: 1, 28: 1}\nBatch 30, Gradient norm: 22.2194\nEpoch 5, Batch 30/66, Loss: 34.9320\nAvg Blank Probability: 0.0160\nSample predictions: ['kHavlHU', 'jaj', 'HkjarfsFxH']\nGround Truth (first 3): ['uJJX-', 'Pv', 'xM7tm']\nRaw outputs (first 3): [[11 10 34  1 10 11 12 50  4 50 47  1  4 22  1  1 34 12 24  1  4 61  6 10\n  11 12 19  1  6  1  0  4]\n [34 10 11 34 11  4 32  6 34 42 29 42  6 11  1 14  4  1 63 10  6 19  1 33\n  14 11  1 47 10 24 42 43]\n [34  1 10 32  1 27  1 27 34 19 28  1 22 25 32  1 30  1 19 32 34  4 11 42\n  11  1 10 44 12 27 19 63]]\nInput length: 15, Label lengths: [5, 2, 5]\nToken distribution (Batch 31): {63: 1, 34: 1, 24: 1, 50: 1}\nBatch 40, Gradient norm: 338.5422\nEpoch 5, Batch 40/66, Loss: 31.1703\nAvg Blank Probability: 0.0158\nSample predictions: ['aHFgsIla', 'aVf3VjH', 'kftDsH']\nGround Truth (first 3): ['ZXrt', '7SGL', 'Q5C']\nRaw outputs (first 3): [[ 1  1 11 42 34 56  1 34 10 43 10 12 25 44  1 11  1 24 25  1  1  6  1 10\n  34 56 10 42 11 33 42 63]\n [34 48  6 43 43 32 34  1 47  4 24 18 43 30 32 43 16 34 35  0 56 47 51 34\n   1 43  1 10 48 32  1 34]\n [32  6 20 22  6 19 47 10 22  5 56 22 34  1 35 34 22  1 22  1 19 42  1 35\n   1 35 10 30  1 48 47 24]]\nInput length: 15, Label lengths: [4, 4, 3]\nToken distribution (Batch 31): {22: 1, 1: 3, 35: 1, 12: 1, 5: 1, 11: 1}\nBatch 50, Gradient norm: 17.8858\nEpoch 5, Batch 50/66, Loss: 29.2315\nAvg Blank Probability: 0.0160\nSample predictions: ['JIUh', '4j', 'jHa2P']\nGround Truth (first 3): ['36', 'p', 'L2B']\nRaw outputs (first 3): [[36 57 10 43  1 18  1  1 10 63 18 32 10 12 42  1  1  1 48  4 24 56 47 10\n  48 13 42  1 34 11 56 22]\n [35 10 10 10 12 47  6  1 35  1  1 11 10 63 32  7 11  5 12 63  4  1 56 47\n  11  4 22 47 35 27  6  1]\n [47 32 34  1 11 48  1  1 10 14 10  1 19 20 35 32 19 11  5 56  1  5  5 43\n  55 46 10 57  1  1 10 35]]\nInput length: 15, Label lengths: [2, 1, 3]\nToken distribution (Batch 31): {61: 1, 1: 2, 34: 1, 25: 1, 47: 2, 7: 1}\nBatch 60, Gradient norm: 20.0727\nEpoch 5, Batch 60/66, Loss: 31.1433\nAvg Blank Probability: 0.0162\nSample predictions: ['pa', 'PjDijrA-l', 'spHjUpjHjv']\nGround Truth (first 3): ['4z', 'b4YLU', 'VjYzO']\nRaw outputs (first 3): [[16 42 19 34  5 43  4 12 12 43 56  1  6 50 61  1 10  1 10 16  1 42 48 10\n  32 10 11 13  6  1  6 61]\n [ 1 10 16 63 47 32 19 32  1 19  1  4 25 22 10  1  1  1 50  1 47  4 10 11\n   1  1  6 32  6  1 34  1]\n [ 1 10 34  1 19  1  1 19 13 34 16 32  4 35 27 10 57 42 23 10  1  1 11  1\n  10 19  6  1 45 47  4 34]]\nInput length: 15, Label lengths: [2, 5, 5]\nEpoch 5/20, Loss: 32.6889\nToken distribution (Batch 8): {1: 15}\nValidation Loss: 34.8575\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['rFyEG', '8', 'A5', 'F*y3i', 'K']\nCurrent Learning Rate: 3.6774416882126643e-07\nEpoch 6, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {56: 1, 11: 1, 1: 3, 47: 1}\nBatch 0, Gradient norm: 1279.6031\nEpoch 6, Batch 0/66, Loss: 34.8619\nAvg Blank Probability: 0.0160\nSample predictions: ['fa', 'jwValgaH', 'aVU2']\nGround Truth (first 3): ['4F', 'tKd4F', 'IC']\nRaw outputs (first 3): [[ 6 10  1  1 16  4 63 33 34 10  4 32 11  1  1 19  1 11 50 11 12 10 22 56\n   4 24 42 34 10 63 32 56]\n [ 1 10 48 22  1 10 12 10 11  6 27 48  1 32  1 22  5 11  7  1 57  1 56 10\n  10 61  4 12 35  1 11 11]\n [ 1 23 47 32 12  1  1 19  0  1 32  4 22 25 32  1 22 63 10 43 32 27  1 56\n   8  6 31 50 19  1 16  1]]\nInput length: 15, Label lengths: [2, 5, 2]\nToken distribution (Batch 31): {1: 1, 4: 1, 56: 1, 32: 1}\nBatch 10, Gradient norm: 29.9816\nEpoch 6, Batch 10/66, Loss: 30.9813\nAvg Blank Probability: 0.0160\nSample predictions: ['auU', 'xHF2VFap', 'vFmj']\nGround Truth (first 3): ['p9', '7SGL', 'yN']\nRaw outputs (first 3): [[ 1 24 22 10 42  4 35 25  1 57  6 57 10 63 47 63  6 35 34  1  6 56 32  1\n   1 35 16 47 10 35 14  1]\n [ 1 34 32 16 48 56 22 24 55  6  1  1 34 56  1  4  1 34 35 55 10 10 56 12\n  11 13 34  1  1 11 47  4]\n [21 32 13 10 11  6 34 35  1 25  1 19 47 61 22 32 23 10 10 12  1 25 47  1\n  35  1 22  6  1 12 22 56]]\nInput length: 15, Label lengths: [2, 4, 2]\nToken distribution (Batch 31): {34: 2, 55: 1, 35: 1, 42: 2, 19: 1, 43: 1, 1: 2}\nBatch 20, Gradient norm: 52.1339\nEpoch 6, Batch 20/66, Loss: 32.4854\nAvg Blank Probability: 0.0160\nSample predictions: ['-aAlPk', 'dfUl', 'ajAaIH']\nGround Truth (first 3): ['Os7', 'RS', '7lDV']\nRaw outputs (first 3): [[63  4  1 12 56 50  1 12  1 35 35 31 34  1 42  1 11 20 10 22  4 55 63 25\n   1 11 35 22 34  6  5 34]\n [ 1  6  0 22 22 10 27 42  1 35  9 10  1 59 10 19 35 11  6 50  1 34 32 55\n  47 36 12 42 14 10 55 55]\n [27 47 10 12 11  1  7 35  1 43  1 25  1 35  1 63 35 34 10 34 12  1 32  1\n  25 48  1 10  1 56  1 35]]\nInput length: 15, Label lengths: [3, 2, 4]\nToken distribution (Batch 31): {34: 2, 24: 1, 27: 1, 21: 1, 4: 1, 47: 1, 55: 1}\nBatch 30, Gradient norm: 21.5839\nEpoch 6, Batch 30/66, Loss: 33.3642\nAvg Blank Probability: 0.0163\nSample predictions: ['ca', 'HAa2H', 'jpayaydk']\nGround Truth (first 3): ['kX', 'uHJ', 'AaGy']\nRaw outputs (first 3): [[ 3 34 10 16 56 18 63 34  1  4 14 11 50 42 34 34  1 32 12 12  1 12 10 34\n   1 56 10 10 56 12 34 34]\n [ 1 27 16 34  1 12 34  1 50  1 10 34  1  5 56  1 47 56  1 22 10  1 11 10\n   6 34  9 43 12 47 48 34]\n [ 1  1  1 12 19 32  6 12  1 32 36  1  1 56  1 50 34 55 56  1  4  1 12  5\n  32  6 22  1 19 40 43 24]]\nInput length: 15, Label lengths: [2, 3, 4]\nToken distribution (Batch 31): {63: 1, 16: 1, 23: 1, 5: 1}\nBatch 40, Gradient norm: 16.0591\nEpoch 6, Batch 40/66, Loss: 28.0690\nAvg Blank Probability: 0.0165\nSample predictions: ['aAsPsa', 'aIdak-', 'j3v2elxjd4']\nGround Truth (first 3): ['S65', '8NA', 'dX*TW']\nRaw outputs (first 3): [[ 1  1 10  1 24 47 19  1 32  1 12 35 27 42 56 12  1 11  6 20 63 32 10 32\n  11 34  4 42 19 11 20 63]\n [27 35 56 35 19 34 12 47  1 50 12 61 47 42 11 22 50 48 12 56 11 19 56  1\n  32 50 32 42 25 42 23 16]\n [19  4 22  1 10  1 34  1 32 24 43  1 42  0  1  1  1  0 32 48 11 43 47 43\n   1  1  1 19 12 56  4 23]]\nInput length: 15, Label lengths: [3, 3, 5]\nToken distribution (Batch 31): {32: 3, 4: 1, 24: 1, 19: 1}\nBatch 50, Gradient norm: 25.8749\nEpoch 6, Batch 50/66, Loss: 37.4313\nAvg Blank Probability: 0.0165\nSample predictions: ['a3PHdj', 'xHvIdpjHmU', 'ak']\nGround Truth (first 3): ['sLL', 'c6jM0', 'I']\nRaw outputs (first 3): [[ 1 24  1 14  1 32 22 48 12 34 34 11 10 42 22 50 34 29 11 11 13  4 32 30\n   0  1  1 48  1 22 12 32]\n [56 34 11  1 48 29 32  1 42 10  1  4 10 50 56 42 10 56 56  1 21  1  9  4\n  12 42 32  1 42 34 32  4]\n [42 22  1 19 63 63 46  1  1 19 19 23 43 50 57  4  4  1 35 12 34 56 42 10\n  50  1  1 19 11 11 10 24]]\nInput length: 15, Label lengths: [3, 5, 1]\nToken distribution (Batch 31): {1: 2, 43: 1, 34: 1, 19: 1, 23: 1}\nBatch 60, Gradient norm: 22.5107\nEpoch 6, Batch 60/66, Loss: 33.7063\nAvg Blank Probability: 0.0168\nSample predictions: ['-t', '-aFjAP', 'FIsd']\nGround Truth (first 3): ['R', 'GHo', 'YT']\nRaw outputs (first 3): [[63 63 32  1 19  1  1 32 32 63  6 63 34 35 10  1 24 29  1 22 10 34 10  1\n  32 10 50 42 10  1  1  1]\n [20  1 35 11 43 10  1 12  6 25 32  1 19 55 34 11  4 36  6 27  1 10 25 56\n   1 34  1 42  1 12 42  1]\n [63 32 19 35 43 11  0 25  1 56  5 32  6  6 19 27 10 27  1 12 27 34 19 47\n  47 32  1 48 12 27 34 43]]\nInput length: 15, Label lengths: [1, 3, 2]\nEpoch 6/20, Loss: 32.8246\nToken distribution (Batch 8): {1: 15}\nValidation Loss: 32.6808\nValidation Predictions: ['a', 'a', 'a', 'aj', 'a']\nGround Truth: ['CFS', 'efa8', 'Z*', 'JkOF3', '55Gq']\nCurrent Learning Rate: 4.3821774773920554e-07\nEpoch 7, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {1: 1, 13: 1}\nBatch 0, Gradient norm: 24.8461\nEpoch 7, Batch 0/66, Loss: 35.6852\nAvg Blank Probability: 0.0168\nSample predictions: ['aF4jas', 'aV-alXys', 'HfX']\nGround Truth (first 3): ['jNX', '68hng', 'Pv']\nRaw outputs (first 3): [[ 1  1 34 22  1  1 43 43 34  6  1  1 10  1 10 46 43 11 10 47 32 14 34 10\n   1  1  9  6  1  1 25  1]\n [32 48  6 30 48 43 19 47  6  4  1 42 11 11  1  1  1  7  1 35  4 56 34 56\n  27 25 10 34 34  1 19 13]\n [57 63 50 22  6 63 50  1 30 16  4 34  6 10 12 19 19 50  1  9 48  1  1 34\n   4 61 35  1 56 47 32  4]]\nInput length: 15, Label lengths: [3, 5, 2]\nToken distribution (Batch 31): {1: 2, 13: 1, 27: 1, 22: 2, 10: 2, 32: 1, 25: 1}\nBatch 10, Gradient norm: 25.2957\nEpoch 7, Batch 10/66, Loss: 36.4058\nAvg Blank Probability: 0.0169\nSample predictions: ['jpsjajyVf', 'aylpsa3', '-Pfl']\nGround Truth (first 3): ['E0V2k', 'VudB', 'Q*']\nRaw outputs (first 3): [[10  1 63 34 20 19 20 19  1  0 47 34 50 32  1  1 10 12 19 35 11 19 11 48\n   1 56 11  1 10 34 10  1]\n [16  1 42 22 32  1 50 47 34 34  5  4 46 27 12 11 34  4  1  1  1  1 36 34\n   5 24 18  1 12  1 10  1]\n [19 25  6  1  1  6 42  1  1  1 12 10  1  4 30 47  1 34  4  1  1 43 47 42\n   4  5  1 47  1 32  1 13]]\nInput length: 15, Label lengths: [5, 4, 2]\nToken distribution (Batch 31): {19: 1, 22: 1, 10: 1, 17: 1, 34: 2, 1: 1, 6: 1}\nBatch 20, Gradient norm: 20.4679\nEpoch 7, Batch 20/66, Loss: 27.1240\nAvg Blank Probability: 0.0170\nSample predictions: ['UvPFs', 'as', 'mylHIH']\nGround Truth (first 3): ['Ufo', 'a', 'KV2']\nRaw outputs (first 3): [[47  1 13 32 42 34 32  6  1  1 43 16  1  1 50 61 23  1 10 56  1 10  4 22\n  56 25  4 23 34  1 34 19]\n [47 19 25  1  1 34 47 10  1 22 22 32 22  1  1  0 50 20 22  0 22 21  1 34\n  22  1 35 55  1 56 21 22]\n [22 24 12  0  1  4 32 10 11  1  1  1  1 50 33 47 12 27 35 55 42 19 22  6\n  63 22 32 34  1  1  1 10]]\nInput length: 15, Label lengths: [3, 1, 3]\nToken distribution (Batch 31): {19: 1, 34: 1, 33: 1, 32: 1, 1: 1, 50: 1}\nBatch 30, Gradient norm: 21.3184\nEpoch 7, Batch 30/66, Loss: 31.4043\nAvg Blank Probability: 0.0169\nSample predictions: ['lasFaeUFdw', 'ajaIas', '-adF2vU']\nGround Truth (first 3): ['U7Dtf', 'ZxKU', 'dWi3']\nRaw outputs (first 3): [[12  1 63 27  1 10 34 11 47 27  6 12 25 50 12  1 56 10 10 12  1 10 13 12\n   1 10  1 12  6 56 22 19]\n [ 1 10  1 36  1  1 23 22 34 19 42 24 19  1 12 56 10 11 30  1 56 63 13 43\n  11  1 16  1 34 16  6 34]\n [19  1  1  1 22 42 10 34  1  1  1 11 47 10 34 48 35 43 22 42  4 43 47 10\n  34 10  4 35  1 12 56 33]]\nInput length: 15, Label lengths: [5, 4, 4]\nToken distribution (Batch 31): {22: 1, 18: 1}\nBatch 40, Gradient norm: 24.6171\nEpoch 7, Batch 40/66, Loss: 29.3539\nAvg Blank Probability: 0.0173\nSample predictions: ['aUaFs4-Q', 'HIsUa3v3vd', 'paIskVQAU']\nGround Truth (first 3): ['uJJX-', 'wSqWA', 'xl1Yx']\nRaw outputs (first 3): [[ 1 34 16 11 34 35 34  1 34  1  1 43  4 10 47 10  6 56 10 47 10 47  1 11\n  16  1 42  1  4 34  1 22]\n [ 1 35  1 56  1 25 35 24  5  4  1 30  1 56 46  4 34 10 33 47  1 55 36  4\n  43 10  6 20 35 28  1  0]\n [47 19 35 51  4  1 10 34  1 27 50 47  1  1 10 32  1  1 10  1 35 25  4 34\n   1 63  1 16 47 10 56 22]]\nInput length: 15, Label lengths: [5, 5, 5]\nToken distribution (Batch 31): {56: 2}\nBatch 50, Gradient norm: 22.8273\nEpoch 7, Batch 50/66, Loss: 33.1313\nAvg Blank Probability: 0.0174\nSample predictions: ['HaHgiate', 'HlDaFa', 's-HysIFE']\nGround Truth (first 3): ['nQD9O', 'L2B', 'bFM5']\nRaw outputs (first 3): [[34 34  0 47 32 10 25  1  1  9  1 11 11 11 63  0 59 10 10 56 56 34 11 63\n  19  5 56  1  1  1  1 56]\n [ 1 12 63 22 12 12 46 60 32 11 34 18  1 35 10 56 10 43  1 27 56 47 24  4\n  55 43  1  1  6 34 56 56]\n [34 30 34 32 50  5 60  4  1 27 27 19 27  1 56 55  5  1  0  6 48  1  5  1\n  24  1 56  4 34  1 19 56]]\nInput length: 15, Label lengths: [5, 3, 4]\nToken distribution (Batch 31): {43: 1, 47: 1, 6: 1, 35: 1, 50: 1, 19: 1, 1: 1, 42: 1}\nBatch 60, Gradient norm: 22.5408\nEpoch 7, Batch 60/66, Loss: 32.6335\nAvg Blank Probability: 0.0176\nSample predictions: ['ICeav', 'kFlI', 'peAsATdyAs']\nGround Truth (first 3): ['RD6', 'iF', 'n3jVe']\nRaw outputs (first 3): [[35 11 16 12  1  1 47  1 22 10 42 10 24 20  1 62  1 11 11 11 32 10 32 56\n   1 27 32  5 22  1 18 43]\n [29 32  5 47 10 47 22 22 57  4  1 35 56  1 43 56 10 10  1  1 47 56  6  1\n  10 57 34 34  1 28  0 47]\n [ 5 12 27 50  1 10  1 32 12 50  1 30 27 47 30 27 11 30 27 24  1 10 35 27\n   1  1  1 34 32 50 21  6]]\nInput length: 15, Label lengths: [3, 2, 5]\nEpoch 7/20, Loss: 32.3644\nToken distribution (Batch 8): {1: 15}\nValidation Loss: 33.8782\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['Yvw', 'j4CGh', 'L', 'PuL', 'Ocf0']\nCurrent Learning Rate: 5.073345795784071e-07\nEpoch 8, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {22: 1, 6: 1, 56: 1, 42: 1}\nBatch 0, Gradient norm: 18.1137\nEpoch 8, Batch 0/66, Loss: 29.0623\nAvg Blank Probability: 0.0176\nSample predictions: ['fAIadPyvr', '3mPV', 'daAj']\nGround Truth (first 3): ['MJOdz', '05', '5I8']\nRaw outputs (first 3): [[ 6 56  4  1 34 35 25 56  1 48 56 22 10 32 11 34 34  1  1  1  1  1 35 34\n  32 22 56 43 42 19  4 22]\n [27 13  1 22 24 47 34 10  1 34  1  4 36 10 56 12 35  1 34 47  1 50 11 11\n  22 43 34 12  1 13  1  6]\n [35 42 27 43  5 22 12 56  7  4 19 55 47  1 11 12 50  1  7 50  1  5  1  6\n  22  6  1 27 32 32  1 56]]\nInput length: 15, Label lengths: [5, 2, 3]\nToken distribution (Batch 31): {32: 1, 1: 1}\nBatch 10, Gradient norm: 25.2322\nEpoch 8, Batch 10/66, Loss: 31.1299\nAvg Blank Probability: 0.0177\nSample predictions: ['dFPzh3dpX', 'FHy', '-kjsU23']\nGround Truth (first 3): ['t0K4D', 'TK', 'ALMJ']\nRaw outputs (first 3): [[ 4 32 63  1 43 46 10  4 10 12 50 16 50  1 24 35 11 12  1  6 12  1 10 32\n  34  1 47 12  6 11  6 32]\n [32 34 11  9 19 12 12  6 12 34 11 22 63 11 35 11 38 32 47 19 27  1 32 43\n  19  1 63 47 42  1 11  1]\n [42 25 10 42 34 19 47  5 10  6 22  1 10 11  1 32 11 35 10  6 12 56  1 50\n  19 11  1 10  4 43 11  0]]\nInput length: 15, Label lengths: [5, 2, 4]\nToken distribution (Batch 31): {11: 2, 6: 1, 56: 2, 12: 1, 4: 1, 7: 1}\nBatch 20, Gradient norm: 21.4355\nEpoch 8, Batch 20/66, Loss: 31.2446\nAvg Blank Probability: 0.0175\nSample predictions: ['dvaUf', 'UQk2', 'deUa']\nGround Truth (first 3): ['T-F', '9W', 'IG']\nRaw outputs (first 3): [[ 4 47  4  1 12 19 34 31  1 63 27 56 12 10  1 25 19 10  4  6 11 32 16  1\n  10  4  5 10 47 25 10 11]\n [22 43  5 34 28 20 10 34  1  1 11 32  4 19  6 42 10 27  1 12 27 12  1 32\n   1  1  0 50 32  5 19  6]\n [ 1 11 47 35 19 10 10 34  1 32 50 43 32 47  5 43 61 27  1  1 34  1 10 32\n  11 19 16 43  0 19  1  0]]\nInput length: 15, Label lengths: [3, 2, 2]\nToken distribution (Batch 31): {34: 1, 48: 1, 47: 1, 1: 2, 18: 1, 25: 1, 12: 1}\nBatch 30, Gradient norm: 69.4452\nEpoch 8, Batch 30/66, Loss: 30.7937\nAvg Blank Probability: 0.0179\nSample predictions: ['vajvas', 'jajIV-', '8jadfj']\nGround Truth (first 3): ['KqsU', 'F6Y', '8MW']\nRaw outputs (first 3): [[22 10 61 10 11  1 10  1 19 25 47 22 32 42 22 35 10  6 19 11 32 56 12  4\n  56 56  1 34 16  1  6 34]\n [ 1  1 10 34  1 22 12  4  1 32  1 11 10 47 56 30 42 10 56 63 12 12  1 20\n  10 19 10  1 12 19 10 48]\n [10  0  1  6  6  5 12 61 26 18 50 10 13 32 19 47  4  1  1 32  1 56  1 22\n  36 22  1  1  0  1 48 47]]\nInput length: 15, Label lengths: [4, 3, 3]\nToken distribution (Batch 31): {1: 1, 32: 1}\nBatch 40, Gradient norm: 24.6049\nEpoch 8, Batch 40/66, Loss: 34.5066\nAvg Blank Probability: 0.0180\nSample predictions: ['jQjsHg', '-j2dj', 'ksHdsyjy3j']\nGround Truth (first 3): ['lAV', '5Lpu', 'L-eej']\nRaw outputs (first 3): [[10 63 11  1  0  1 47  1 63 50 34  5  6  6 10  4 22  1  0 61  1 12  4 19\n   0 50 30  5 32 42  4  1]\n [43 10 19 34 34 10  1  6  1  5 56  1  1  1 47 34  6 32 29 47 42 11 22  1\n   1 56 22 27  1  1 32 32]\n [10 55 34  6  0 35 20 32 11 19 42  4  4 42 34  6 48 20 55 63 32 24  4 48\n   5  5  1 35  1 34  1 10]]\nInput length: 15, Label lengths: [3, 4, 5]\nToken distribution (Batch 31): {35: 1, 34: 2, 1: 2, 32: 2, 9: 1, 10: 1, 11: 1}\nBatch 50, Gradient norm: 79.6403\nEpoch 8, Batch 50/66, Loss: 32.2580\nAvg Blank Probability: 0.0181\nSample predictions: ['Qv', 'ykga', 'FX']\nGround Truth (first 3): ['G', 'Q*', 'K']\nRaw outputs (first 3): [[43 25 32 12 11 35 34  1 11 11 10 11  4  1 11 32 34  1  9 12 45  1 19  1\n  10 19  1 12 34 25 42 35]\n [22 11 50 33 35  4 11 47 11 61  1 34 10  1 10  1 19 11 32  1 42 34  1 11\n  34  6 10 34  1  7 22 34]\n [48  7 10  1  0 33 35 32 12 34 21 56 34  1 43  1 60 12 56  6 12 34 47 32\n  19 11 43 34 61 32 20 34]]\nInput length: 15, Label lengths: [1, 2, 1]\nToken distribution (Batch 31): {34: 1, 63: 1, 19: 1, 35: 1, 12: 1, 32: 1, 42: 1, 7: 1, 5: 1, 25: 1}\nBatch 60, Gradient norm: 31.9841\nEpoch 8, Batch 60/66, Loss: 39.2124\nAvg Blank Probability: 0.0183\nSample predictions: ['ja', 'ayFQfeiaU', 'aj']\nGround Truth (first 3): ['l', 'ZrSBq', 'c']\nRaw outputs (first 3): [[10  1  1 32  0  4 61 32 50 10  1  6  1 35  9 11  1 27  1 63  1 10  1 27\n  27  1 50 27 22 19 10 34]\n [ 1 25 10 11 56  1 11 43 16  1  1 12 19 10 22 63 33  1  5  0 42 29 10 32\n   1 10 22  1 19 13 19 63]\n [24 32 27 34 27  1 22 19 56 32  1 32 50 11 12 34 19  1 14  0 56 43  0  1\n  10  6  1 22 18  4 19 19]]\nInput length: 15, Label lengths: [1, 5, 1]\nEpoch 8/20, Loss: 32.8448\nToken distribution (Batch 8): {1: 15}\nValidation Loss: 33.7883\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['r*dU-', 'On', '2hT', 'iE3z5', 'q']\nCurrent Learning Rate: 5.750618580687756e-07\nEpoch 9, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {47: 2, 42: 1, 10: 1, 50: 1, 1: 1}\nBatch 0, Gradient norm: 111.0676\nEpoch 9, Batch 0/66, Loss: 33.2293\nAvg Blank Probability: 0.0183\nSample predictions: ['Uj4V', 'daFIjg', 'HFXjajia']\nGround Truth (first 3): ['HT', 'Hlb', 'L7Vk']\nRaw outputs (first 3): [[47  4 34 32 19 10 11 33 19  0  1 24 22 34 10 48  9 10 47 16  1 22  1 50\n  11  1  1 10  1 56  1 47]\n [10  1 32  5  1  1 25 10  0 30  1 11 12  5 10 12  6 42  1 11 56  4 10 11\n   1 42  5  1 56 32 42 42]\n [57 32 50 56  4 10 22 56  1 11  1 29  1 63 10  1 11  1 19 43 43 50  1  1\n   6  1 12  6  1 10 32 47]]\nInput length: 15, Label lengths: [2, 3, 4]\nToken distribution (Batch 31): {1: 5, 7: 1, 27: 2, 50: 1, 56: 1}\nBatch 10, Gradient norm: 1039.7926\nEpoch 9, Batch 10/66, Loss: 33.6124\nAvg Blank Probability: 0.0189\nSample predictions: ['ada', 'klkazVa', '-HeaFea']\nGround Truth (first 3): ['ad', 'mQxk', 'YhVSr']\nRaw outputs (first 3): [[ 1 11 63 27 43  0 63 56 63 27  1 57 19 11  1 50 20  4  1  0 12 11  1 43\n  11  0 10  1  0  4 19  1]\n [ 4 12 34 19  1 33 35  1  7  0 22  4 34 11  1  1 56 19  6 17 35  1 50 36\n  11  1 19 63 34 11  1  1]\n [ 1  0  5  5 34 47 13 13  1 33  4 43 56 14 56  1 19  4 32 22 11  5 28 43\n  42  1  1 43 10 32 40  7]]\nInput length: 15, Label lengths: [2, 4, 5]\nToken distribution (Batch 31): {1: 1, 34: 1}\nBatch 20, Gradient norm: 357.5270\nEpoch 9, Batch 20/66, Loss: 29.8372\nAvg Blank Probability: 0.0192\nSample predictions: ['HaHF', 'jUFA2IHa', 'HsaIdkDQ']\nGround Truth (first 3): ['0*T', '-zp9', 'DwBi']\nRaw outputs (first 3): [[34 10 34  1  1 50  4  6  1 30  1 25 56 42 56 16  1 17 10 35  6  1 42 43\n  19 47 22 11 63 56 50  1]\n [ 1 47 19  1  1  6 35 34 10 12  1  1  0 11 22  1  1 22 10  1  0  9  6  0\n  19 12 32  1  1 42  0 34]\n [ 1 32  1  4 11 55  0 56 32  1  1  4 10 34 47  0  1 11 10  1  0 22  1  4\n   1 34 34  1  1  6 48 32]]\nInput length: 15, Label lengths: [3, 4, 4]\nToken distribution (Batch 31): {32: 1, 52: 1, 56: 1, 22: 1, 34: 1, 42: 2, 26: 1}\nBatch 30, Gradient norm: 53.7476\nEpoch 9, Batch 30/66, Loss: 29.0059\nAvg Blank Probability: 0.0189\nSample predictions: ['Fxke', '3Qa', '4j3aU']\nGround Truth (first 3): ['dm', 's0', 'K2s']\nRaw outputs (first 3): [[32 56 57  1  1 11  4  4 12 10 43 34 12  1 16 24  1 30 24 11 63  1 11  4\n  47 47  0  1 10 61 43 32]\n [24 43 10  1 34 27  6  0 22  9 47  5  1  1 10  9 24 34  6 12  4  6 11  1\n  10 12 12  1 12 35 32 52]\n [11  1 10  1 32  4 10 61 47  0  1 10 25  5 60 12 47 32  6  0 11  0  5  6\n  57 63  1 50 11 47 22 56]]\nInput length: 15, Label lengths: [2, 2, 3]\nToken distribution (Batch 31): {32: 1, 19: 1}\nBatch 40, Gradient norm: 24.6753\nEpoch 9, Batch 40/66, Loss: 32.4724\nAvg Blank Probability: 0.0190\nSample predictions: ['Pa', 'lnasfA', 'sU']\nGround Truth (first 3): ['z', 'g8X', 'Z']\nRaw outputs (first 3): [[42 12 19 16 24  1 34 13  6 34  1  0 42 27 47 10 48 47 10  4  1 10 12 34\n   4 11 34 24 48  1 23 32]\n [ 1 14 47 11 13 25 25  1 42 10 11 56 27  6 30 32  1 47 56 11  0 35 63  4\n   1  0 19  1 19 32 19 19]\n [10  1 10  1 34  1 30  4 32 27  1  1 32 47 56  1  1 34  7 19  4  1 11 55\n  34 19  1  5 32 34 10 48]]\nInput length: 15, Label lengths: [1, 3, 1]\nToken distribution (Batch 31): {22: 1, 44: 1}\nBatch 50, Gradient norm: 40.0440\nEpoch 9, Batch 50/66, Loss: 34.2365\nAvg Blank Probability: 0.0191\nSample predictions: ['aXa4PAld', '-UsAava', 'dDjFde']\nGround Truth (first 3): ['KbANC', 'xj3G', 'T5Y']\nRaw outputs (first 3): [[ 1 63  4 43  1 10  1 56  1 11 22  1 12  1 19  1  5 32 11 10 10 46 34 22\n  34  4 22 47  1 10  1 22]\n [50 47  0  6 10  1 47 34  1  9 56 19 11  1 34 34  1 34 27 42  1  4 11 63\n  43 19  4 32 63  0 14 44]\n [ 1 19 10 50 19  9 19 10 22 44  1  0  1 32 35 32 34 34 19 30 61 27 12 11\n   5 47 30 32  1 19 28 10]]\nInput length: 15, Label lengths: [5, 4, 3]\nToken distribution (Batch 31): {34: 1, 1: 2, 5: 1, 11: 1, 27: 1, 56: 1, 10: 1}\nBatch 60, Gradient norm: 23.7264\nEpoch 9, Batch 60/66, Loss: 29.2943\nAvg Blank Probability: 0.0195\nSample predictions: ['HU', 'aX', 'alAy']\nGround Truth (first 3): ['8', 'w1', 'Mk']\nRaw outputs (first 3): [[34  1  1 34 42 63  1  6 63 19  1 34 12 48 47 25 19 10 34 43 34 10 34  1\n   4 14 10 11 42 32  6 34]\n [47  1 12 11  1 47 42  0 24  6 34  1  1  6  1 11  0 10 32  1  1  6 35 19\n  10 12 21  1  1  6 48  1]\n [33  1 27 10 16  0  0 22  1  1 34  5  0 35 10  1 22  0  0 56  1  4 32 12\n  19 42 10  1  1 19 34  1]]\nInput length: 15, Label lengths: [1, 2, 2]\nEpoch 9/20, Loss: 32.3413\nToken distribution (Batch 8): {1: 15}\nValidation Loss: 32.8643\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['*B', 'EG', 'L2B', 'XSpH', 'DK']\nCurrent Learning Rate: 6.413244481745442e-07\nEpoch 10, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {24: 1, 20: 1, 5: 1, 12: 1, 1: 1, 56: 1, 9: 1, 4: 1}\nBatch 0, Gradient norm: 17.3208\nEpoch 10, Batch 0/66, Loss: 26.2888\nAvg Blank Probability: 0.0196\nSample predictions: ['dUaDFa', 'fIXjaJ3a', 'aA']\nGround Truth (first 3): ['3U6', 'Nsc6', 'p']\nRaw outputs (first 3): [[ 4  6  0 10 12 34 34 12 56 10  1  6  1 27 42 63 42 30 22  6 56 20  1 32\n   1 19 48 42  4 34  1 24]\n [47 35 27  4 22 33  4 34  0  1 19 10  1  0  0  0  0 12  1 42 10  0 47  0\n  43  1 48 11  0 34 47  0]\n [ 1  0 12 32 47 19 45 47  0  1 43  1  1  1  5 11  1 11 22  6 50 42 11  1\n  48 10 30 35 55  7  0  5]]\nInput length: 15, Label lengths: [3, 4, 1]\nToken distribution (Batch 31): {11: 1, 32: 1, 34: 1, 63: 1}\nBatch 10, Gradient norm: 22.8188\nEpoch 10, Batch 10/66, Loss: 30.3868\nAvg Blank Probability: 0.0200\nSample predictions: ['x3j3xIkdP', 'AU', '3a']\nGround Truth (first 3): ['ahDQZ', 'A', 'f']\nRaw outputs (first 3): [[ 0 27  0 11 12 34  1 12 50  1  1 34  1 34  1 47  4  1  0 34 19 42 30  0\n   0 11  4 12 12 10  3 11]\n [56  0  0  0 19  0 12 63 42  4 47 27  1 22 11 34 47 25 47 11 34  0 47  4\n  12 43 21 47 27 27 12 32]\n [ 0 47  0 13 47  0 34 32 10  6 34  4  5  1 12 32  1 10  4 35  1  0 27  5\n  47 55 24 55 25 42  1 34]]\nInput length: 15, Label lengths: [5, 1, 1]\nToken distribution (Batch 31): {4: 1, 14: 1, 32: 1, 13: 1, 1: 1, 12: 1}\nBatch 20, Gradient norm: 584.0659\nEpoch 10, Batch 20/66, Loss: 30.1424\nAvg Blank Probability: 0.0200\nSample predictions: ['aFA4UdAH', '3yeHFld', 'aI4aAl2k']\nGround Truth (first 3): ['o68L', 'bneT', 'O5al']\nRaw outputs (first 3): [[ 1 56  1  1 32  1 11 56  1 10 10 33  1  4 55 12 23 56 27 47 42  1 22 56\n   1 12 22 20 10  6  1  4]\n [32 25 35 25  6 12 11 19 19 63  1 10  1  1  4 42  0 12  5  1 42  1  0 55\n  27  4 43 27  1 57  1  0]\n [27  5 57  6 10  6 47 10  1 22  1 47 63 32  4 32 10  1  1 55  5 25 19 32\n  22  1 25 47  1 10 12 32]]\nInput length: 15, Label lengths: [4, 4, 4]\nToken distribution (Batch 31): {48: 1, 51: 1, 1: 1, 10: 1}\nBatch 30, Gradient norm: 27.3876\nEpoch 10, Batch 30/66, Loss: 33.4915\nAvg Blank Probability: 0.0203\nSample predictions: ['kFfkU2tjaX', 'vHaXH3sH3s', 'ak2kv2']\nGround Truth (first 3): ['j-D*x', 'c8sos', 'FLP']\nRaw outputs (first 3): [[11 22  1 32 11 32  4  0  6  6 20 10  1 10  6 47 63 63  0 32 12 34  1  1\n  10 11 32 56 36 22 47 48]\n [32 34 11 19 50 11 34  0  0  6 10 34 48  4 56  5 25 10  1  5 12 10  0  6\n   1  1  1 43 43  1 63 51]\n [ 6  1 55  0  1 10 48 42 33  5  1 35 25 32  0 47  0  1 28 35 11 34  0 34\n   6  1 22 36 43 61 50  1]]\nInput length: 15, Label lengths: [5, 5, 3]\nToken distribution (Batch 31): {47: 1, 1: 1, 10: 1, 50: 1, 30: 1, 32: 1}\nBatch 40, Gradient norm: 30.2762\nEpoch 10, Batch 40/66, Loss: 32.1727\nAvg Blank Probability: 0.0204\nSample predictions: ['HaHlHdQ', '-TadHy', 'HaFIFaF']\nGround Truth (first 3): ['hACa', '5Za', 'oiUh']\nRaw outputs (first 3): [[ 0 63 34 30 10 35  1  1  1  1 30 12 56 43 10 42 12 56 10 34 10  1 56  6\n  25 63  1  6 34 12 10 47]\n [ 1 46  1  0 32  0  1 22 16 19 42 27  0 19 32 34 63 56 10 19 56 47  0  0\n  56 47 10 47  0  1 56  1]\n [ 1  1  0  1  0 55  1 22 43 11 48 48  0  0 14 11  0  1 24 34 20 47  0 48\n  43 43 47 34  1 28 38 10]]\nInput length: 15, Label lengths: [4, 3, 4]\nToken distribution (Batch 31): {14: 1, 1: 1}\nBatch 50, Gradient norm: 189.2840\nEpoch 10, Batch 50/66, Loss: 34.5007\nAvg Blank Probability: 0.0206\nSample predictions: ['fQl3paFaF', 'ja', 'jyIy']\nGround Truth (first 3): ['jY*7c', '5', 's0']\nRaw outputs (first 3): [[ 0 10 10  1 56 10  1  6  6 34 10 12 22  1 16 10 22 11  4 50  1  1 12 34\n  32 42  6  1  0 56 35 14]\n [43  0 25  0  6  5  5 50 10 34 19  0  0  1 47 42 24  1  4 11 34 32  1 22\n  24  1  6  1  4 34 35  1]\n [12  1 35 38 12 63 11 26  0 47  5 47 10 56 27 10  4  0  1  6 34  0 46 55\n   0 10  1 34 14  1  1  4]]\nInput length: 15, Label lengths: [5, 1, 2]\nToken distribution (Batch 31): {11: 1, 47: 1}\nBatch 60, Gradient norm: 25.4403\nEpoch 10, Batch 60/66, Loss: 31.3606\nAvg Blank Probability: 0.0206\nSample predictions: ['laHaFHaFeH', 'IaVaFjuIt', 'IlYaQaHa-a']\nGround Truth (first 3): ['pRXvu', 'oZROy', 'n4LAz']\nRaw outputs (first 3): [[12 35 35 30 24  0  5 63 10 35  1 27  6 34 12 43 43 10 20 19 19 12  1  1\n   1 56 32 19 34 48 11 11]\n [ 1  1  0 10 10 34  1  6  1 56 12  4 27 11 42  4 43 63 32 24 34  6 12 20\n  19 63  0 56 32  0 10 47]\n [34  1  0 32  0 35 19  1 11 27 56 35 35  1  1 22 43  1 30  0  0 59 11 34\n  43 50 27 22 16  4 34  0]]\nInput length: 15, Label lengths: [5, 5, 5]\nEpoch 10/20, Loss: 32.0056\nToken distribution (Batch 8): {1: 15}\nValidation Loss: 33.5582\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['Ck', 'R', 'En', 'jAh4', 'Du38J']\nCurrent Learning Rate: 7.059928510621034e-07\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {35: 1, 47: 3, 43: 1, 1: 2, 13: 1}\nBatch 0, Gradient norm: 17.8159\nEpoch 11, Batch 0/91, Loss: 25.9461\nAvg Blank Probability: 0.0209\nSample predictions: ['3akzj', 'yd', '3lkIF3sHk']\nGround Truth (first 3): ['uCYo', 'P', 'wx-je']\nRaw outputs (first 3): [[56  0 56 34 19 10 63 56 19  1  4 10 10 43  4 22  1  1  1  4 35  1  1 25\n   1  6 11  1 35 10 10 35]\n [ 1  4 12 20 35 63  1  1 19  1 47 50 35 19  1  1  0 48 17 10  1 34  4 43\n   1  0 19 19 32  1  4 47]\n [ 1  0 11 34 34 47 62 35  4 16  6  0 47  1  0 34 34 47 35 42  0 34  1 42\n  32  6  1 19  1  6 50 43]]\nInput length: 15, Label lengths: [4, 1, 5]\nToken distribution (Batch 31): {10: 2, 27: 1, 50: 1}\nBatch 10, Gradient norm: 23.0401\nEpoch 11, Batch 10/91, Loss: 29.5298\nAvg Blank Probability: 0.0209\nSample predictions: ['ajkHkaHaQ3f', 'AkaHvHBvcj', 'yaH3']\nGround Truth (first 3): ['RqAgCd', 'biTha', '93']\nRaw outputs (first 3): [[ 1  0  0 11 32  0 63 32 34 11 19 56 16 35  0  1 22  6 34  1  1 56 22 34\n  32  1 42  1 11  1 47 10]\n [10  0  0  1 47  1 42 43 35  5  5  1 19 12  1 22 35 14 25 11  1 10  1  1\n   1  1  5  0  1 61 27 27]\n [10  0 34  1 10  1 32  0  0  6  4  1 50  0 48 35  1  1  4 32 27 12  1  1\n  24 19 27 34 59 63 32 50]]\nInput length: 15, Label lengths: [6, 5, 2]\nToken distribution (Batch 31): {11: 2, 1: 3, 55: 1, 30: 1, 32: 1}\nBatch 20, Gradient norm: 33.2764\nEpoch 11, Batch 20/91, Loss: 22.2268\nAvg Blank Probability: 0.0221\nSample predictions: ['3a3UfQsluDae', 'aJfQa3UiP', 'Hjaf3a-vyijkF']\nGround Truth (first 3): ['gSGYn-', 'T9vty', '4haKGSo']\nRaw outputs (first 3): [[56  1 34 10 43 12 47 17  4  4 42 40  0 47 48 10 34 10  0 50  4  6  4 12\n   0  4  1 56 11 10 11 11]\n [ 1  1 10 20  1  0  5  1 27 17 22 34  0  0  5  0 47  1  0  1  1 27 22 57\n   0  4 35  0 35 22  0 11]\n [56 36  1 10 10  0 26 11 11 34  0  4  1 50 34 34  6  4 24 30 24 12  1 12\n   0 22  0 12  0  5  0  1]]\nInput length: 15, Label lengths: [6, 5, 7]\nToken distribution (Batch 31): {1: 3, 6: 1, 47: 2, 34: 1, 43: 1, 10: 1, 19: 1}\nBatch 30, Gradient norm: 774.2866\nEpoch 11, Batch 30/91, Loss: 28.9953\nAvg Blank Probability: 0.0224\nSample predictions: ['akaHaHmasPvds', 'dk', 'kaX']\nGround Truth (first 3): ['Oqb511L', 'P', 'SF']\nRaw outputs (first 3): [[ 1  4  0 32  6 11  0 63  4  0  1  0 42 22 20 43  0  1 42  1  0 12  0 11\n   1  1  1 10  4 63  0  1]\n [ 1 11  1  1 35 27  0 17  1 50 19 47  0  4 35  0 34  4  0  1 27 32  0  6\n  34 10 12  1  0  0 22  1]\n [ 0 22  0 47  0  1  0 43  0 32  1  8 47  0  4 56  0 34 32  1 34  0 47  0\n  19 32  1 34 63 33  0  6]]\nInput length: 15, Label lengths: [7, 1, 2]\nToken distribution (Batch 31): {19: 1, 1: 3, 22: 1, 43: 1, 5: 1, 21: 1, 35: 1, 10: 1, 50: 1, 12: 1, 4: 1, 56: 1}\nBatch 40, Gradient norm: 36.1726\nEpoch 11, Batch 40/91, Loss: 23.1431\nAvg Blank Probability: 0.0226\nSample predictions: ['HFeAfBFfHsl', '-axsPKdHj', 'UsUaesSaItglY8']\nGround Truth (first 3): ['aIZk9O', '30Ez6', 'K8vUvMN']\nRaw outputs (first 3): [[34 63  0 47  1  0  0  0 10 10 19 50 42 19  1  1 17  9  1  1 22 12  4 27\n   1  0 32 32 16  1 10 19]\n [34  1  0 34 34 12 32  0 32  0 19  0 10 33 34 47 50 12 32  0 27  0  0 11\n   1  1 35  0  5 10  1  1]\n [32  1  0  6  0  1 34 35  1 12  1 43 32  4 27 20 35  0  6  0 25 47 56  0\n  34  1  0 43  0  1 31  1]]\nInput length: 15, Label lengths: [6, 5, 7]\nToken distribution (Batch 31): {10: 1, 41: 1, 34: 1, 6: 1, 32: 1, 50: 1, 4: 2}\nBatch 50, Gradient norm: 22.7721\nEpoch 11, Batch 50/91, Loss: 27.4972\nAvg Blank Probability: 0.0230\nSample predictions: ['jHvpaP', 'FjVaQl3aeaja', 'mjnFkd']\nGround Truth (first 3): ['7ZZ', 'uWA78n0', 'dNm']\nRaw outputs (first 3): [[10  0 13  0 34 12  0 56 56  6 22  1 32 29  1 32 22 56 32 56  0 35  4 10\n  47 19 32 22  4 63  1 10]\n [ 0  0 10 42  0 22 19 10 56  1  0  1  1  0  0 11 22  0  0  0 12  0 56 32\n   7  0  0 22  0  0  1 41]\n [ 0  0  0 34  0  6  1 10  1 32 47  1 11  0 11 27 22  1  0  0  0 27  0  0\n  11 56  0 20 34 30  0 34]]\nInput length: 15, Label lengths: [3, 7, 3]\nToken distribution (Batch 31): {11: 1, 6: 2, 10: 1, 4: 1, 22: 1}\nBatch 60, Gradient norm: 111.9723\nEpoch 11, Batch 60/91, Loss: 30.8480\nAvg Blank Probability: 0.0231\nSample predictions: ['anaHI', '3j', 'ljHEG3I']\nGround Truth (first 3): ['I*0', 'l', '3uam']\nRaw outputs (first 3): [[ 1 56 12  6  4  7  1  0 12  4 19 18  0  1  0 10  0 34  1 10  0  0 10  8\n   1 48  0 42 56 43 23 11]\n [14 10 10 11  1 25  1  0 10  3 16 22 61 27 34  0 25  0  0 34 47  0  7  0\n   5 34  0 11  0 10  5  6]\n [ 1 56  0 50  0 22  0  0 17  1 10  0  5  1  1  1 56  1  0  5  0 25 12 14\n   4  4  0 47  0  0 46  6]]\nInput length: 15, Label lengths: [3, 1, 4]\nToken distribution (Batch 31): {1: 1, 34: 1}\nBatch 70, Gradient norm: 23.3864\nEpoch 11, Batch 70/91, Loss: 27.4752\nAvg Blank Probability: 0.0239\nSample predictions: ['faH', 'xv3aRUlaXAaja', 'fiXjHa2sFHQaA']\nGround Truth (first 3): ['hQ', 'iikgJBB', 'ZyI9z8r']\nRaw outputs (first 3): [[ 6 24  0  0 56  1 11 50 43 22 11  0  0  0  1 10 43 10  4  0 43  1 34  1\n  56 47 10  1 56  0 24  1]\n [ 6 22  9  1  0  1 34  1 56 63  0  0  0 47 56  0 47  0 47 11  0 50  0  0\n   0  1 35  0 19  0  6  0]\n [ 1  0  0  0 34 27  5  0 27 47  0 11 43  0  0 19 47 12  1  0 53 23  0  5\n  13  4 34  1 12  0 27  1]]\nInput length: 15, Label lengths: [2, 7, 7]\nToken distribution (Batch 31): {19: 1, 34: 1, 1: 4, 6: 1, 12: 1, 11: 1, 42: 1}\nBatch 80, Gradient norm: 27.1586\nEpoch 11, Batch 80/91, Loss: 28.8747\nAvg Blank Probability: 0.0238\nSample predictions: ['Xf', 'IjFzfXk', 'atF2Izf5aPHI']\nGround Truth (first 3): ['3', 'd40XO', 'UeXm8Z']\nRaw outputs (first 3): [[50 35  1 34  1  0 56  0 10 32 22 10 22  1 20 28 10 42 10 43  4 57 32 25\n  63 32  1  0 42  4  1  0]\n [ 6  0 20  0 12 12 20 43 14  0 47  0  0  0 10 19 25  5  0 47 63 11  5  0\n  25 63 48  5  0 34 32  0]\n [ 6 10 32  0  9  0  0 50 11 32  1  6 33 11  0 22 11  0  4  0  0  0 22  0\n  12 51 32 48 34  0 32  1]]\nInput length: 15, Label lengths: [1, 5, 6]\nToken distribution (Batch 15): {1: 4, 22: 1, 19: 1, 6: 1, 12: 1, 9: 1, 63: 1}\nBatch 90, Gradient norm: 19.4946\nEpoch 11, Batch 90/91, Loss: 24.5900\nAvg Blank Probability: 0.0244\nSample predictions: ['Xvsa', 'lajHxifveSkH2s', 'la-aAasHdoe']\nGround Truth (first 3): ['HL', '9vQ54v5', 'TBnHM5*']\nRaw outputs (first 3): [[50 12 12 14 10 57 47  1 35  1 19 12 34  0  0  0]\n [ 0  1  1  0 27  0  0 50  1  0  0 22  0  0 22 22]\n [ 0 10  1 56  0  0  0 19  1 10  0  6  5  1  0 19]]\nInput length: 15, Label lengths: [2, 7, 7]\nEpoch 11/20, Loss: 27.2594\nToken distribution (Batch 19): {1: 15}\nValidation Loss: 27.2271\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['bLBIm9', 'h65z19', 'Noe', 'U-xr4', 'dh8hotR']\nCurrent Learning Rate: 1e-06\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {1: 1, 43: 1}\nBatch 0, Gradient norm: 350.1766\nEpoch 12, Batch 0/91, Loss: 29.0433\nAvg Blank Probability: 0.0246\nSample predictions: ['keaHPeIaFRwVa', 'DeVdQeda', 'F']\nGround Truth (first 3): ['h7epS8M', 'O-ir', 'c']\nRaw outputs (first 3): [[11 30 32  0 34  1 27 10  4 56 24  0 47 43  1 50  1 48  1  1 22 36  0  1\n  13  1  1 11  0  0  0  1]\n [ 5  0 32  0 12  0  6 10 24 56 19 19  0 38 32  0  1 32  0 47  6 63  1  0\n   0 48  0 34 12 34  0 43]\n [ 1  0  0  0 56  0  1  0  0  0 18 32  0 36 41 19  4  0  0  0  0 28  0 24\n   9  1 56  0  0 47  0 10]]\nInput length: 15, Label lengths: [7, 4, 1]\nToken distribution (Batch 31): {25: 1, 1: 3, 6: 1, 22: 1, 61: 1, 34: 1, 35: 1, 10: 1, 26: 1, 12: 1, 20: 1, 4: 1}\nBatch 10, Gradient norm: 26.4531\nEpoch 12, Batch 10/91, Loss: 28.9071\nAvg Blank Probability: 0.0252\nSample predictions: ['ljDFkvaUd', 'lad', 'djas']\nGround Truth (first 3): ['QGLe0', 'er', 'lm']\nRaw outputs (first 3): [[12  0  4 11 34 20 42 11  0 32  8  6 12  0 13  4  1 12  0 34 32 43  0 22\n   0 61 56 10  6 10  4 25]\n [10  1 10  4  0 32  0  0 11  5 27  0 56  0  0  6  0  0  0  0 50  0 22 47\n  10  1  0  6  0 11  0  1]\n [ 0  0  1  5  0  5  0 27  0  0  4 12  0 61 25  0  0 14  0  0  0  0 10  1\n   5  6 48 25  1 19  0  1]]\nInput length: 15, Label lengths: [5, 2, 2]\nToken distribution (Batch 31): {10: 1, 42: 1, 32: 3, 50: 1, 27: 3, 34: 2, 1: 2, 36: 1}\nBatch 20, Gradient norm: 21.9364\nEpoch 12, Batch 20/91, Loss: 25.4743\nAvg Blank Probability: 0.0258\nSample predictions: ['UzrkOFAa3', 'h-ajXjHvyFHdHf', 'HIc']\nGround Truth (first 3): ['kHfqx', 'wn4a7rf', '1N']\nRaw outputs (first 3): [[47  0 34  1  0  4  1  1 32  0  1  0  1  0  0  0 34 63 32  0  1 22  1  1\n  47  0  1 18 34 47 10  0]\n [ 0 63 34 10  1  0  6 11 42  1 36  0  0  0 10  1  0  4 32 12 34 34 56  0\n   0  0 11 34  6  0 32  0]\n [18  0 35 30  0  0 47 32  1 22 34  1  0  0  0  1 22  0 32  0  0  0  1  0\n   0  1  0 32  0  0 22 32]]\nInput length: 15, Label lengths: [5, 7, 2]\nToken distribution (Batch 31): {63: 2, 47: 1, 35: 1, 34: 1, 30: 1, 32: 1, 1: 1, 7: 1, 27: 1}\nBatch 30, Gradient norm: 19.2473\nEpoch 12, Batch 30/91, Loss: 23.7522\nAvg Blank Probability: 0.0263\nSample predictions: ['H2F34', 'jQUv', '6fafaI']\nGround Truth (first 3): ['Yvw', 'rT', 'yGW']\nRaw outputs (first 3): [[34  0 59  0 11  0  0 34  0 11 12 63 12 11 35  0 32 32 11  4 11  0 32  0\n   0  4 25  1 63 50 11  0]\n [34 43  6  0  0 12  0  0  0 32 11  0  5 24 22  0  1  0  0  4  0  1  0  0\n   1 12 32  0 47 47  1 47]\n [55 47  0 47  0 32  0  0  0  0  0 63  5  0  1  0  0  1  0  0 11  0 34  1\n   0  0  6  0 50  5 63  0]]\nInput length: 15, Label lengths: [3, 2, 3]\nToken distribution (Batch 31): {19: 1, 25: 1, 1: 2, 5: 1, 35: 1, 22: 2}\nBatch 40, Gradient norm: 22.7853\nEpoch 12, Batch 40/91, Loss: 25.8671\nAvg Blank Probability: 0.0267\nSample predictions: ['adva3Aa', 'sPHidaA', 'lksU']\nGround Truth (first 3): ['q6gTu', 'Ocf0', '02']\nRaw outputs (first 3): [[ 1  0 12  0  0 56 35  0  0 12  0  0  1 11  0  0  0 11  0 34  0  0  0  0\n  27 42  1 19  5 32 36 19]\n [ 4 42 11  0  0 47 25  0 34 21  1 12  1  0  6  4  0  6  4  0  0  6  0  4\n   0  0  1 48 56  0  0 25]\n [22 42  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  1 34\n   0 25  0  0  7  0 10  0]]\nInput length: 15, Label lengths: [5, 4, 2]\nToken distribution (Batch 31): {13: 1, 47: 1, 11: 1, 63: 1, 22: 1, 55: 1}\nBatch 50, Gradient norm: 21.6065\nEpoch 12, Batch 50/91, Loss: 24.6635\nAvg Blank Probability: 0.0274\nSample predictions: ['Jk4lUFAPsHVUg', '-IdxashUa', 'BsaUadD']\nGround Truth (first 3): ['yeZBt6x', 'WJ3im', 'rj2Y']\nRaw outputs (first 3): [[36 63 28  0  0 10 10  0  0 56  0  0  6  0 34  0  0 56 42  1 63 12 11  4\n   0 34  1  0  0  0 63  0]\n [11 35 19  0 11  1  0 10  0  0  5 11 19 11 10 12  0  0  0  0  0  0 10  0\n   0 34  0 56  0  0  0  0]\n [ 0  0  0  0 32  0  1 11  0  0 48  0 10 24 22  0  0  0  0 22 20  0  0 19\n  50  0 47  0 11 63 34  0]]\nInput length: 15, Label lengths: [7, 5, 4]\nToken distribution (Batch 31): {34: 1, 3: 1, 7: 1, 1: 1, 43: 1, 6: 1, 32: 1, 19: 1, 27: 1, 50: 1}\nBatch 60, Gradient norm: 509.3365\nEpoch 12, Batch 60/91, Loss: 25.5079\nAvg Blank Probability: 0.0278\nSample predictions: ['ePHgwa', 'FXsF4HUvjsRA', '-k']\nGround Truth (first 3): ['2JT', 'nQoAFh', 'q']\nRaw outputs (first 3): [[ 5 32 63  0  1 56  0 32 35 47  0  0 32 32  0  0  0 10  0  0  0  0  6  0\n  50  1  0 34 32  6  1 34]\n [ 0 50 11  1 34 43  0  1  1  0 27 25 50  0  0  0  4  0  0 12  0  0  0  0\n   5  0  0  0  1  0  0  3]\n [ 0 19 25  0  0 26  0  0  0  0  0  0  0 34 32  0  0  0  0  0 24  1  0  0\n  43  0 47  0  0  0  0  7]]\nInput length: 15, Label lengths: [3, 6, 1]\nToken distribution (Batch 31): {10: 1, 12: 1, 63: 1, 11: 1}\nBatch 70, Gradient norm: 34.3363\nEpoch 12, Batch 70/91, Loss: 24.7609\nAvg Blank Probability: 0.0283\nSample predictions: ['sH', 'VQIJ', 'fakejkehvjm']\nGround Truth (first 3): ['k', 'T1', 'XaGhKvP']\nRaw outputs (first 3): [[19 48  0  0 11 25  6  6  3 47  1  0 56 34 10  0 14  0 34  0  0  0 12  1\n   0  0 47  0 10  1 34 10]\n [ 0  0  0  0  0 12 34  0 32  0  0  0 42  0  0  0  0  0 10  0  0  0  0 10\n   0 21 47  0 19  6 35 12]\n [ 1  0  1  0  0  0  0 27  1  0  0 47  0  1  0  0 32 22  0 12  0  0 10  0\n   0  0  0  0  0  0  4  0]]\nInput length: 15, Label lengths: [1, 2, 7]\nToken distribution (Batch 31): {1: 2, 9: 1, 11: 1, 47: 1, 5: 1}\nBatch 80, Gradient norm: 21.0825\nEpoch 12, Batch 80/91, Loss: 23.9585\nAvg Blank Probability: 0.0292\nSample predictions: ['lsAaFaPmasi6', '2aFsHCvkFsFH', 'ksdIak']\nGround Truth (first 3): ['YWmFk6', 'AjNIAzj', 'xe5']\nRaw outputs (first 3): [[12 55 11 63 22  0  6 47 34  1 16  0 32  4  0 32  4  1  0  0  0  0 30 48\n   1  0  0 61 11  0  0  0]\n [ 0  0 19  0  0  4 32 32  0  0  1  0  0  0  0  0 11  0 32 32  0  0  0 34\n   0 34 43  0 35  0 25  9]\n [27 32  4  1  0  0  0  0  0  0  0 34  0  0 14  0  0  0  1  0  0  0  0  0\n   0  0  0  0  5 29  5 11]]\nInput length: 15, Label lengths: [6, 7, 3]\nToken distribution (Batch 15): {10: 1, 1: 3, 56: 1, 50: 2, 42: 1, 33: 1, 35: 1, 0: 1, 24: 1}\nBatch 90, Gradient norm: 21.8421\nEpoch 12, Batch 90/91, Loss: 23.3251\nAvg Blank Probability: 0.0297\nSample predictions: ['aH', '-FlH', 'stPFAsIHa2ydFH']\nGround Truth (first 3): ['3', 'BQ', 'j39MjIY']\nRaw outputs (first 3): [[ 0 63 19  0  0  0 22 63 10 32  0 34 47  0  0 10]\n [ 0 32  0  0  0  0  0 20  4 19  0  0  0  0 12  0]\n [ 0  0 42  0  0  0  1 14  0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [1, 2, 7]\nEpoch 12/20, Loss: 26.5774\nToken distribution (Batch 19): {1: 15}\nValidation Loss: 27.3006\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['uduag5', 'v', 'kXK', '4oAo', 'Xgg*r']\nCurrent Learning Rate: 1e-06\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {55: 1, 56: 1, 23: 1, 12: 1, 22: 1, 7: 1, 32: 2, 1: 1, 34: 3, 33: 1, 27: 1}\nBatch 0, Gradient norm: 58.1643\nEpoch 13, Batch 0/91, Loss: 26.9846\nAvg Blank Probability: 0.0299\nSample predictions: ['vialI2jld', 'jePHUdsUPkAaP', 'jUaIvZzvAjaHD']\nGround Truth (first 3): ['DMYT*', '2m09p04', 'rsJczXz']\nRaw outputs (first 3): [[22 10  0  6  0 43  0  0  0  0  0  0  0  0 44  0  6  4  6 47 10 12 35  0\n  11  1 10  0  1  0 63 55]\n [ 0  0  0  0  1  0  0  1  0  0 27  6 21  0  4  1  0  0  1  0  0 34 48 11\n  34  0 10  0  0 10  1 56]\n [ 1  0  1  0  0  0  0  0  6  0 61  0  0 27  0  0  0  1 56  0  0  0 34  0\n  34  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [5, 7, 7]\nToken distribution (Batch 31): {63: 1, 52: 1, 27: 2, 11: 1, 0: 1, 50: 1, 5: 1, 14: 1, 12: 1}\nBatch 10, Gradient norm: 25.1877\nEpoch 13, Batch 10/91, Loss: 25.8381\nAvg Blank Probability: 0.0302\nSample predictions: ['XVXkjF', 'jHkAjVfkA', 'QlFwaY3IiaPQ']\nGround Truth (first 3): ['Zax', 'GblpNE', 'AO5O8Xz']\nRaw outputs (first 3): [[50 10 43  0 27  0 34  0 34  1  0  0  0 61 34 10 22  0  0  0 47  0  0 30\n  32  0  0  0  0  1 20  0]\n [ 0  0  0  1  0  0 11  0  0  0  0 11  0  1  0  0  0  0  0  0  1  0  0 19\n   0  0  0  4 30  0 11  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 63  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  1  0]]\nInput length: 15, Label lengths: [3, 6, 7]\nToken distribution (Batch 31): {34: 1, 35: 1, 1: 2, 10: 1, 11: 1, 27: 1, 43: 1}\nBatch 20, Gradient norm: 166.3692\nEpoch 13, Batch 20/91, Loss: 28.7085\nAvg Blank Probability: 0.0310\nSample predictions: ['sa', 'UDPj', 'UFaz']\nGround Truth (first 3): ['c', 'DZ', 'yE']\nRaw outputs (first 3): [[ 0 47 47  0  0  0  0 34 47  0 12  0 22 32 47 19  0 11 63  4  0  4  0  0\n  34  0  0  0 34  0  1  0]\n [ 1  0 32  0  0  0  0  0  0  6 35 34  0  0  1  1  0  0  0  0  0  0  0  0\n   0  0  0  0 29  1  0 35]\n [ 0 42  0  0  0  0  0  0  0  0 11  0  0  0  1  0  0  0 63  0  0  1  0  0\n   0  0  0  0  0  0  1  1]]\nInput length: 15, Label lengths: [1, 2, 2]\nToken distribution (Batch 31): {25: 1, 4: 1, 17: 1, 5: 1, 1: 1, 9: 1, 21: 1, 43: 1}\nBatch 30, Gradient norm: 169.2322\nEpoch 13, Batch 30/91, Loss: 25.0001\nAvg Blank Probability: 0.0327\nSample predictions: ['fHajFUyA', 'jfUHkalaH', 'HUjla']\nGround Truth (first 3): ['Gpz4l', 'gHBHK', 'wL7']\nRaw outputs (first 3): [[ 6 10  0  0  0 34  0  0  0  8  0 32  0  0  6  0  4  0  0  0 11  0  1  0\n   0 34 46 11  0  0 47 25]\n [ 0  0 47  0  0 12  0  0  0  0  1  0  0  0  4  1  0 10  0  0  0  0  0  0\n   0  0  0 19  0  0  0  0]\n [34  0  0  0  0  0  0  0  0  0 53  0  0  0  0  0  1  0  0  0  0  0  0  1\n   0 47  1  0  0  0  0  0]]\nInput length: 15, Label lengths: [5, 5, 3]\nToken distribution (Batch 31): {32: 1, 11: 1, 10: 1, 20: 1, 1: 5, 6: 1, 24: 1, 34: 1}\nBatch 40, Gradient norm: 28.2899\nEpoch 13, Batch 40/91, Loss: 26.2464\nAvg Blank Probability: 0.0326\nSample predictions: ['XsEkHaFdU', 'XH', 'eFyvl']\nGround Truth (first 3): ['xM7tm', '-', '7BJ']\nRaw outputs (first 3): [[50  0  0  0  0  1  0 12 34  0  0  0 47  0 30  0 47  0 19  0  0 11 32  0\n   0  0  0  0  0 25  0 32]\n [19  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0 47 32  0 11 34  0\n   0  0  0 10  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0 34  0  0  0  0  0  0  0\n   0  0  0  0  0 35  0 10]]\nInput length: 15, Label lengths: [5, 1, 3]\nToken distribution (Batch 31): {20: 1, 0: 3, 27: 1, 1: 1, 56: 1, 32: 1, 34: 1, 10: 1}\nBatch 50, Gradient norm: 30.3803\nEpoch 13, Batch 50/91, Loss: 27.1080\nAvg Blank Probability: 0.0333\nSample predictions: ['DUjH3QaHKek', 'aC', 'jljdD']\nGround Truth (first 3): ['3cT-U7', 'R', '2XR']\nRaw outputs (first 3): [[ 0  1  0  1  0  0 19  0  1 56 35  0  0  0  0  4  0  0  0  0  1  0  0 22\n  24  0  0  0 29  4  6  0]\n [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0 34  0  0  0]\n [ 0  0  0  0  0  0  0  0  0 32  0  0  0  0  0  0  0  0  0  0  0  0  1  1\n   0  0  6  0  0 32  0  0]]\nInput length: 15, Label lengths: [6, 1, 3]\nToken distribution (Batch 31): {11: 2, 34: 1, 1: 2, 27: 1}\nBatch 60, Gradient norm: 26.3799\nEpoch 13, Batch 60/91, Loss: 24.6780\nAvg Blank Probability: 0.0345\nSample predictions: ['maevlCHXes', 'FHvkeARal', 'aUePA']\nGround Truth (first 3): ['vYIU0WD', 'v8Nha', 'G4R']\nRaw outputs (first 3): [[13  0  0 47  0  0  0  0  0  0  0  1 47  1 47  0  0  0 22  0  0  0  0  0\n  32  1  1  0  0  0  6  0]\n [ 0  0  0  5  0  0  0  0  0 12 47  0 10  0  0 12  1 11  1 11 47  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0 22  0  0  0  0  0  0  1  1 34  0  0  0  0  0  0  0  0  0  0  5  1  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [7, 5, 3]\nToken distribution (Batch 31): {19: 2, 11: 1, 26: 1, 32: 1, 22: 1, 9: 1, 5: 1, 35: 2, 53: 1, 0: 1, 1: 1, 10: 1}\nBatch 70, Gradient norm: 34.6752\nEpoch 13, Batch 70/91, Loss: 26.3773\nAvg Blank Probability: 0.0351\nSample predictions: ['IPIvaaI', 'eYkefxAa', 'kAakvksBFak']\nGround Truth (first 3): ['RdZ1x', 'WOr3O', 'BVzm05v']\nRaw outputs (first 3): [[35  5 11 20 11  0  0  0 10  0  0 10  6 10 61  0 63  0  0  0  0  0  0  0\n   0  4 47  0  0 63  0  0]\n [ 0  0  0  0  0  0  0 12  0 32  1  0  0  1  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0 47  0  0  0 47  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [5, 5, 7]\nToken distribution (Batch 31): {35: 1, 11: 1}\nBatch 80, Gradient norm: 30.6256\nEpoch 13, Batch 80/91, Loss: 25.4773\nAvg Blank Probability: 0.0357\nSample predictions: ['aUja', 'kHFlxovaklav', 'UaejFl']\nGround Truth (first 3): ['oe', 'eKSRDzi', 'bxDZ']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  1  0 63  0  4  0  0  4 11  6  0  0  0  0 10  0 63\n   0  0  1  0 47  0 34 35]\n [47  0  0  0  0  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0\n   0 12  0  0  0 27  0  0]\n [ 0  0  0  0  0  0 22  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [2, 7, 4]\nToken distribution (Batch 15): {22: 1, 35: 1}\nBatch 90, Gradient norm: 34.8781\nEpoch 13, Batch 90/91, Loss: 28.0771\nAvg Blank Probability: 0.0366\nSample predictions: ['kUPaFSG', 'HxabllUd', 'FaB3sU']\nGround Truth (first 3): ['FqXD', 't5ttxVy', 'LkN']\nRaw outputs (first 3): [[11  0  0  0  0  0 35  1  0  0  1  0  0  0 20  0]\n [ 0  0  1  0  0  0 10  0  0  0  0 32  0  0  0 35]\n [ 0  0  0  0 47  0  0  0  0  0  0 63  0 31  0  0]]\nInput length: 15, Label lengths: [4, 7, 3]\nEpoch 13/20, Loss: 25.8065\nToken distribution (Batch 19): {1: 15}\nValidation Loss: 27.2264\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['oiUh', 'PfCU3-m', 'n', 'o*N', 'C']\nCurrent Learning Rate: 1e-06\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {47: 1, 26: 1, 43: 1, 11: 1, 1: 3, 42: 1, 0: 3, 34: 2, 6: 1}\nBatch 0, Gradient norm: 31.7913\nEpoch 14, Batch 0/91, Loss: 26.3261\nAvg Blank Probability: 0.0370\nSample predictions: ['a', 'kUd3aaj', 'afajaHaadv']\nGround Truth (first 3): ['e', 'E6RxizT', 'QjW7gxl']\nRaw outputs (first 3): [[ 0  0  1  0 50 63  0  0  0  0 34  0  0  0  0  0  0  0  0  0  0  0  0 56\n   0  0  0  0 34  0  0 47]\n [ 0  0  6  0  0 51  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0 11  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  6\n  12  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [1, 7, 7]\nToken distribution (Batch 31): {4: 1, 0: 3, 34: 1, 1: 3, 6: 1, 36: 1}\nBatch 10, Gradient norm: 27.4307\nEpoch 14, Batch 10/91, Loss: 21.1001\nAvg Blank Probability: 0.0385\nSample predictions: ['vfAFAA', 'sydH', 'lqanaJUa']\nGround Truth (first 3): ['7N7d', '0D', 'ixDqn']\nRaw outputs (first 3): [[ 0  0  0 12  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0 22\n   0  0  0  0  5  4  6  0]\n [ 0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n   0 34  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [4, 2, 5]\nToken distribution (Batch 31): {6: 1, 56: 1}\nBatch 20, Gradient norm: 35.3802\nEpoch 14, Batch 20/91, Loss: 25.4844\nAvg Blank Probability: 0.0392\nSample predictions: ['mJXjJI', 'AkXFje', 'BQBtH']\nGround Truth (first 3): ['tKd4F', 'tkL', 'V*czz']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0 11  0  0  0  1  1  0  0  0  0  0  1  0  0 13  0 11\n   0  0 32  0  0 47  0  6]\n [ 0  0  0  0  0 16  0  0  0  0  0  0 32  0  0 10  0  0  0  0  0  0  0  0\n   0  1  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0 35  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   5  0  4  0  0  0  0  0]]\nInput length: 15, Label lengths: [5, 3, 5]\nToken distribution (Batch 31): {35: 1, 12: 2, 42: 1, 24: 1, 0: 1}\nBatch 30, Gradient norm: 28.4907\nEpoch 14, Batch 30/91, Loss: 23.4307\nAvg Blank Probability: 0.0418\nSample predictions: ['ZflaUJHfH', 'v', 'lAaHHvaj-k']\nGround Truth (first 3): ['XaGhKvP', 'VQ', 'PVS8nuq']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  7  0  4  0\n   0  0  0 34  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0 27  0  0  0  0]]\nInput length: 15, Label lengths: [7, 2, 7]\nToken distribution (Batch 31): {11: 2, 1: 3, 25: 1, 0: 2, 5: 1, 14: 1}\nBatch 40, Gradient norm: 20.0282\nEpoch 14, Batch 40/91, Loss: 20.4974\nAvg Blank Probability: 0.0402\nSample predictions: ['jHUHiskA', 'GwU4', 'HUHildU']\nGround Truth (first 3): ['DQsMZ9', 'TAi', 'Q8dF']\nRaw outputs (first 3): [[ 0  0  0 42 48  0  0  4  0  0  0  0  1  0  1  0  0 22  0 12 32  0  0 34\n   0 27  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 34  0  0  0  0  0  0\n   0  0  0 11  0  0  0  1]]\nInput length: 15, Label lengths: [6, 3, 4]\nToken distribution (Batch 31): {1: 1, 12: 2, 5: 1, 4: 1, 0: 4, 34: 1, 31: 1, 42: 1, 22: 1, 47: 1}\nBatch 50, Gradient norm: 22.1366\nEpoch 14, Batch 50/91, Loss: 20.0081\nAvg Blank Probability: 0.0432\nSample predictions: ['-s3UaF', 'lxfd2', 'laHUfe']\nGround Truth (first 3): ['*tIE', 'bVwNB', '19VXY']\nRaw outputs (first 3): [[ 0  0  0  0  0  0 12  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0 32  0  6  0 34  0]\n [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 34  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [4, 5, 5]\nToken distribution (Batch 31): {0: 5, 1: 3, 10: 1, 32: 1, 34: 2}\nBatch 60, Gradient norm: 58.7825\nEpoch 14, Batch 60/91, Loss: 27.2504\nAvg Blank Probability: 0.0440\nSample predictions: ['al', 'HI', 'ak']\nGround Truth (first 3): ['u', '37', '6']\nRaw outputs (first 3): [[ 0  0  0 43 34  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0  4 22  0 56\n   0  4  0  0 63  0  0  0]\n [ 0  0  0  0  0 32  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0 34  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [1, 2, 1]\nToken distribution (Batch 31): {35: 1, 32: 2, 0: 7, 22: 1, 56: 1}\nBatch 70, Gradient norm: 41.0492\nEpoch 14, Batch 70/91, Loss: 25.7566\nAvg Blank Probability: 0.0440\nSample predictions: ['43', 'fYaya', '2H']\nGround Truth (first 3): ['h', 'UVE', 'j']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12 56\n   0 32  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [1, 3, 1]\nToken distribution (Batch 31): {1: 3, 56: 1, 32: 1, 0: 2, 26: 1}\nBatch 80, Gradient norm: 43.7071\nEpoch 14, Batch 80/91, Loss: 26.1389\nAvg Blank Probability: 0.0464\nSample predictions: ['Vjf', 'lHaF', 'l']\nGround Truth (first 3): ['6JT6A', '*ukzOg', 'ks']\nRaw outputs (first 3): [[48  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0 22  0  0  1]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 56  0  0  0  0  0\n   0  0  0 42  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0 11  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [5, 6, 2]\nToken distribution (Batch 15): {33: 1, 1: 2, 35: 1, 9: 1, 0: 1}\nBatch 90, Gradient norm: 36.2124\nEpoch 14, Batch 90/91, Loss: 21.7121\nAvg Blank Probability: 0.0484\nSample predictions: ['FhaF-U', 'kUtDv', 'P']\nGround Truth (first 3): ['b3OhG', 'yn*', 'rOq']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 3, 3]\nEpoch 14/20, Loss: 24.8157\nToken distribution (Batch 19): {1: 15}\nValidation Loss: 26.9730\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['exRVivK', '1', 'zLD', 'ALMJ', '32']\nCurrent Learning Rate: 1e-06\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {6: 1, 12: 1, 9: 1, 47: 1, 0: 2, 1: 3, 25: 1}\nBatch 0, Gradient norm: 43.2413\nEpoch 15, Batch 0/91, Loss: 24.2383\nAvg Blank Probability: 0.0484\nSample predictions: ['vF', 'dlUsv8', 'fa3']\nGround Truth (first 3): ['Ub', '7VLzPb', '-k']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0 63  0  0  0  0  0  0  0  0  0  0 47  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  1  0  0  0  0 42  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [2, 6, 2]\nToken distribution (Batch 31): {47: 1, 35: 1, 34: 1, 22: 1, 1: 2, 0: 2}\nBatch 10, Gradient norm: 32.1141\nEpoch 15, Batch 10/91, Loss: 23.3253\nAvg Blank Probability: 0.0496\nSample predictions: ['kPa', 'la', '<empty>']\nGround Truth (first 3): ['HlfFN', '5hb', 'Hl']\nRaw outputs (first 3): [[ 0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0  9 20\n   0  0  0  0  0 50  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [5, 3, 2]\nToken distribution (Batch 31): {47: 1, 0: 11, 40: 1, 5: 1}\nBatch 20, Gradient norm: 57.9435\nEpoch 15, Batch 20/91, Loss: 23.3915\nAvg Blank Probability: 0.0504\nSample predictions: ['Qza', 'fYFHs', '-azRxay']\nGround Truth (first 3): ['7Ifh9Q', 'UuGt', 'W4WB']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0 22  0  0  0  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [6, 4, 4]\nToken distribution (Batch 31): {1: 1, 30: 1}\nBatch 30, Gradient norm: 58.4989\nEpoch 15, Batch 30/91, Loss: 26.4361\nAvg Blank Probability: 0.0521\nSample predictions: ['F2Ha', 'ad', '0a']\nGround Truth (first 3): ['TA9pm', 'EItm', 'C']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  1  0  0  0  0  0  0]\n [ 0  0  0  0  0  0 34  0  0  0  0  0  0  0 47  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [5, 4, 1]\nToken distribution (Batch 31): {19: 1, 0: 3}\nBatch 40, Gradient norm: 51.8706\nEpoch 15, Batch 40/91, Loss: 24.2322\nAvg Blank Probability: 0.0531\nSample predictions: ['VHaHd', 'F3F', 'fd']\nGround Truth (first 3): ['ViIigG', '9k0', 'PCa']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 3, 3]\nToken distribution (Batch 31): {1: 1, 0: 6, 4: 1, 27: 1, 11: 1}\nBatch 50, Gradient norm: 40.5300\nEpoch 15, Batch 50/91, Loss: 25.4207\nAvg Blank Probability: 0.0559\nSample predictions: ['3', '3', '0dkUF']\nGround Truth (first 3): ['v', 'u', 'cCNy0u1']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0 42  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [1, 1, 7]\nToken distribution (Batch 31): {12: 1, 0: 11, 1: 1, 26: 1}\nBatch 60, Gradient norm: 38.2454\nEpoch 15, Batch 60/91, Loss: 24.5934\nAvg Blank Probability: 0.0568\nSample predictions: ['aaH', 'CUz', 'kOA']\nGround Truth (first 3): ['n3jVe', 'Sbl', 'HEu9kyT']\nRaw outputs (first 3): [[ 0  0  0  0  0  0 56  0  0  0  0  0 35  0  0  0  0  0  0  0  0 11  0  0\n   0  0  0  0  0  0  0  0]\n [ 0 47  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [5, 3, 7]\nToken distribution (Batch 31): {0: 3, 22: 1}\nBatch 70, Gradient norm: 117.8162\nEpoch 15, Batch 70/91, Loss: 23.6641\nAvg Blank Probability: 0.0607\nSample predictions: ['Cla', 'ad', 'Ua']\nGround Truth (first 3): ['uwYu', 'ZEvd7', 'N94']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 5, 3]\nToken distribution (Batch 31): {42: 1, 0: 9}\nBatch 80, Gradient norm: 50.3668\nEpoch 15, Batch 80/91, Loss: 25.7721\nAvg Blank Probability: 0.0630\nSample predictions: ['v', 'Ha', 'A']\nGround Truth (first 3): ['Zg', 'Uw0', 'fA']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [2, 3, 2]\nToken distribution (Batch 15): {34: 1, 0: 1}\nBatch 90, Gradient norm: 38.0409\nEpoch 15, Batch 90/91, Loss: 23.7867\nAvg Blank Probability: 0.0626\nSample predictions: ['FI', 'vH', 'Xl']\nGround Truth (first 3): ['6Ki', 'uVaQJ', 'cqS']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 5, 3]\nEpoch 15/20, Loss: 23.4321\nToken distribution (Batch 19): {1: 15}\nValidation Loss: 28.0670\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['G', 'Wa131', 'q', 'SdH', 'mSQ']\nCurrent Learning Rate: 1e-06\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {6: 1, 0: 6, 32: 1}\nBatch 0, Gradient norm: 36.0862\nEpoch 16, Batch 0/128, Loss: 21.1038\nAvg Blank Probability: 0.0637\nSample predictions: ['X', 'd', '<empty>']\nGround Truth (first 3): ['v', 'xpYZA5', 'Ub']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [1, 6, 2]\nToken distribution (Batch 31): {0: 9, 47: 1}\nBatch 10, Gradient norm: 122.5993\nEpoch 16, Batch 10/128, Loss: 17.5842\nAvg Blank Probability: 0.0682\nSample predictions: ['<empty>', 'k', 'X']\nGround Truth (first 3): ['ubsoqa', 'blCQ', 'pX']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 4, 2]\nToken distribution (Batch 31): {51: 1, 0: 5}\nBatch 20, Gradient norm: 32.2713\nEpoch 16, Batch 20/128, Loss: 18.4019\nAvg Blank Probability: 0.0712\nSample predictions: ['1', 'jije', 'Xf']\nGround Truth (first 3): ['2JJ', 'ZGrO', 'xFfxJd']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 4, 6]\nToken distribution (Batch 31): {34: 1, 0: 6, 1: 1, 12: 1, 63: 1}\nBatch 30, Gradient norm: 12780.9893\nEpoch 16, Batch 30/128, Loss: 20.1028\nAvg Blank Probability: 0.0692\nSample predictions: ['ja', 'a', 'rFa']\nGround Truth (first 3): ['xXf5uZ', 'lw', 'I0kNxv']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [6, 2, 6]\nToken distribution (Batch 31): {0: 14, 6: 1}\nBatch 40, Gradient norm: 25.3397\nEpoch 16, Batch 40/128, Loss: 18.3948\nAvg Blank Probability: 0.0738\nSample predictions: ['Uaa', 'k', 'ri']\nGround Truth (first 3): ['Y1amuTnSp', 'w2kXVHIec', 'BahV']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [9, 9, 4]\nToken distribution (Batch 31): {10: 1, 0: 1}\nBatch 50, Gradient norm: 640.5679\nEpoch 16, Batch 50/128, Loss: 20.4662\nAvg Blank Probability: 0.0761\nSample predictions: ['P', 'a', 'Yya']\nGround Truth (first 3): ['V90V682C', 'L', 'QUXKSN']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 1, 6]\nToken distribution (Batch 31): {0: 13, 26: 1}\nBatch 60, Gradient norm: 107.4633\nEpoch 16, Batch 60/128, Loss: 19.5181\nAvg Blank Probability: 0.0791\nSample predictions: ['da', 'dUQ', '<empty>']\nGround Truth (first 3): ['oPE*cz', 'RlxA*QNSli', 'fWbbc6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 10, 6]\nToken distribution (Batch 31): {0: 12}\nBatch 70, Gradient norm: 3681.6001\nEpoch 16, Batch 70/128, Loss: 19.5020\nAvg Blank Probability: 0.0857\nSample predictions: ['<empty>', 'H', 'la']\nGround Truth (first 3): ['56', 'v*LHo0TY', 'lSPYJWf']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 8, 7]\nToken distribution (Batch 31): {0: 8}\nBatch 80, Gradient norm: 31.3621\nEpoch 16, Batch 80/128, Loss: 19.0167\nAvg Blank Probability: 0.0879\nSample predictions: ['<empty>', 'k', 'l']\nGround Truth (first 3): ['iA', 'Yp5', '5rxkXtyka']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0 32  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [2, 3, 9]\nToken distribution (Batch 31): {47: 1, 0: 11}\nBatch 90, Gradient norm: 31.8024\nEpoch 16, Batch 90/128, Loss: 18.7762\nAvg Blank Probability: 0.0901\nSample predictions: ['<empty>', '<empty>', 's']\nGround Truth (first 3): ['tkg', 'Ocf0', 'Qi']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 4, 2]\nToken distribution (Batch 31): {0: 8}\nBatch 100, Gradient norm: 1303.4816\nEpoch 16, Batch 100/128, Loss: 17.6098\nAvg Blank Probability: 0.0951\nSample predictions: ['<empty>', 'd', 'a']\nGround Truth (first 3): ['EqtUXBUD', 'RMii', 'rQVG7a8bAn']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 47  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [8, 4, 10]\nToken distribution (Batch 31): {0: 2}\nBatch 110, Gradient norm: 40.1693\nEpoch 16, Batch 110/128, Loss: 21.2585\nAvg Blank Probability: 0.0954\nSample predictions: ['<empty>', 'l', 'v']\nGround Truth (first 3): ['eMBEWR', 'xd', 'YiJn5tka6z']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 2, 10]\nToken distribution (Batch 31): {32: 1, 0: 9}\nBatch 120, Gradient norm: 58.0437\nEpoch 16, Batch 120/128, Loss: 20.1514\nAvg Blank Probability: 0.0984\nSample predictions: ['F', 'fu', '<empty>']\nGround Truth (first 3): ['UKi-iSUyo', 'Q', 'ooEkgjnB']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0 47  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [9, 1, 8]\nEpoch 16/20, Loss: 19.5057\nToken distribution (Batch 31): {12: 1, 1: 3, 0: 11}\nValidation Loss: 22.5526\nValidation Predictions: ['laa', 'laa', 'laa', 'la', 'laa']\nGround Truth: ['5N0ju', 'MDVk', 'PbuH2h-L38', 'rdC-', '0bL-p5o']\nCurrent Learning Rate: 1e-06\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {47: 1, 0: 13, 32: 1}\nBatch 0, Gradient norm: 34.7107\nEpoch 17, Batch 0/128, Loss: 19.1133\nAvg Blank Probability: 0.1039\nSample predictions: ['<empty>', 'y', '3']\nGround Truth (first 3): ['xc', 'RkYgh', 'b33h*xc-']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 5, 8]\nToken distribution (Batch 31): {22: 1, 0: 1}\nBatch 10, Gradient norm: 189730.9062\nEpoch 17, Batch 10/128, Loss: 19.1309\nAvg Blank Probability: 0.1110\nSample predictions: ['<empty>', 'iU', '<empty>']\nGround Truth (first 3): ['S', 'NJlcyoqK', 'nkX7OoRR9E']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 8, 10]\nToken distribution (Batch 31): {0: 15}\nBatch 20, Gradient norm: 33.9684\nEpoch 17, Batch 20/128, Loss: 16.8896\nAvg Blank Probability: 0.1120\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['-Bs', 'LJI8DCME', 'yuDw3']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 8, 5]\nToken distribution (Batch 31): {19: 1, 0: 5}\nBatch 30, Gradient norm: 37.1327\nEpoch 17, Batch 30/128, Loss: 18.8618\nAvg Blank Probability: 0.1122\nSample predictions: ['H', '<empty>', '<empty>']\nGround Truth (first 3): ['K7ebq', 'dP', '7FqjaQiPG']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 2, 9]\nToken distribution (Batch 31): {34: 1, 0: 9}\nBatch 40, Gradient norm: 19.7196\nEpoch 17, Batch 40/128, Loss: 15.3848\nAvg Blank Probability: 0.1194\nSample predictions: ['<empty>', 'j', '<empty>']\nGround Truth (first 3): ['gZ9rU', 'jAh4', 'kXK']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 4, 3]\nToken distribution (Batch 31): {0: 15}\nBatch 50, Gradient norm: 42.9263\nEpoch 17, Batch 50/128, Loss: 20.3066\nAvg Blank Probability: 0.1248\nSample predictions: ['<empty>', 'H', '<empty>']\nGround Truth (first 3): ['HkIUAN8CPh', '6', 'WOr3O']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [10, 1, 5]\nToken distribution (Batch 31): {0: 6}\nBatch 60, Gradient norm: 47.1476\nEpoch 17, Batch 60/128, Loss: 20.7278\nAvg Blank Probability: 0.1291\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['wCG6wX7fc', '76rX', 'w']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [9, 4, 1]\nToken distribution (Batch 31): {0: 14, 11: 1}\nBatch 70, Gradient norm: 139.4912\nEpoch 17, Batch 70/128, Loss: 16.3260\nAvg Blank Probability: 0.1354\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['p1TWXUAoWG', 'VNbV', '*dgl1']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [10, 4, 5]\nToken distribution (Batch 31): {1: 1, 0: 14}\nBatch 80, Gradient norm: 47.0943\nEpoch 17, Batch 80/128, Loss: 16.9099\nAvg Blank Probability: 0.1390\nSample predictions: ['y', '<empty>', 'v']\nGround Truth (first 3): ['9KxJ3uEnv4', '7ONq2*yVPG', 'LQY']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [10, 10, 3]\nToken distribution (Batch 31): {0: 12}\nBatch 90, Gradient norm: 347.4478\nEpoch 17, Batch 90/128, Loss: 17.8713\nAvg Blank Probability: 0.1430\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['p9', 'Aofdh5RsDS', 'q']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 10, 1]\nToken distribution (Batch 31): {6: 1, 0: 3}\nBatch 100, Gradient norm: 290.4939\nEpoch 17, Batch 100/128, Loss: 17.3936\nAvg Blank Probability: 0.1495\nSample predictions: ['F', '<empty>', '<empty>']\nGround Truth (first 3): ['NNv8U8', '60ko', '97Vu2R']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 4, 6]\nToken distribution (Batch 31): {63: 1, 0: 1}\nBatch 110, Gradient norm: 28.8181\nEpoch 17, Batch 110/128, Loss: 16.1668\nAvg Blank Probability: 0.1610\nSample predictions: ['<empty>', '<empty>', 'F']\nGround Truth (first 3): ['Z5bX87Rpgi', 'bVwNB', '607MvwXKzK']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [10, 5, 10]\nToken distribution (Batch 31): {0: 14}\nBatch 120, Gradient norm: 50789184.0000\nEpoch 17, Batch 120/128, Loss: 17.9248\nAvg Blank Probability: 0.1698\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Q', 'io', 'Y5jwp']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 2, 5]\nEpoch 17/20, Loss: 17.9412\nToken distribution (Batch 31): {12: 1, 0: 13, 1: 1}\nValidation Loss: 21.8742\nValidation Predictions: ['la', 'la', 'la', 'la', 'la']\nGround Truth: ['rn3tWG', 'Cg0k4r', 'Yp5', 'kPzmE48bf0', '8AIjG']\nCurrent Learning Rate: 1e-06\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {0: 2}\nBatch 0, Gradient norm: 9208.6406\nEpoch 18, Batch 0/128, Loss: 16.6124\nAvg Blank Probability: 0.1736\nSample predictions: ['<empty>', '<empty>', 'P']\nGround Truth (first 3): ['yzB', 'MFC1jnHEBt', '7FqjaQiPG']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 10, 9]\nToken distribution (Batch 31): {0: 10}\nBatch 10, Gradient norm: 71.1296\nEpoch 18, Batch 10/128, Loss: 18.6721\nAvg Blank Probability: 0.1771\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['8SCvKN0S', 'JwDvNN', '4oAo']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 6, 4]\nToken distribution (Batch 31): {0: 10}\nBatch 20, Gradient norm: 5971906.0000\nEpoch 18, Batch 20/128, Loss: 15.0071\nAvg Blank Probability: 0.1859\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['KtQhCC', 'k1Z', 'rf2o']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 3, 4]\nToken distribution (Batch 31): {0: 4}\nBatch 30, Gradient norm: 38594.8125\nEpoch 18, Batch 30/128, Loss: 16.6426\nAvg Blank Probability: 0.1888\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['PwC8ai3', 'zBv', 'K0b']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 3, 3]\nToken distribution (Batch 31): {0: 12}\nBatch 40, Gradient norm: 160715616.0000\nEpoch 18, Batch 40/128, Loss: 16.4219\nAvg Blank Probability: 0.1984\nSample predictions: ['<empty>', '<empty>', 'a']\nGround Truth (first 3): ['TOI', 'bVwNB', 'IsX3zLd']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 5, 7]\nToken distribution (Batch 31): {0: 14}\nBatch 50, Gradient norm: 144.8818\nEpoch 18, Batch 50/128, Loss: 15.6802\nAvg Blank Probability: 0.2091\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['WpNtD7cz', 'E6HnJZsVV', 'eQ8pMyQp']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 9, 8]\nToken distribution (Batch 31): {0: 6}\nBatch 60, Gradient norm: 600.3907\nEpoch 18, Batch 60/128, Loss: 15.3534\nAvg Blank Probability: 0.2132\nSample predictions: ['<empty>', '<empty>', 'l']\nGround Truth (first 3): ['5yccyJ', 'Bq', '0x']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 2, 2]\nToken distribution (Batch 31): {0: 14}\nBatch 70, Gradient norm: 54.0141\nEpoch 18, Batch 70/128, Loss: 18.4463\nAvg Blank Probability: 0.2217\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['JfCY', 'CZfOCe9FV', '4yILIwOF']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 9, 8]\nToken distribution (Batch 31): {0: 4}\nBatch 80, Gradient norm: 37.2519\nEpoch 18, Batch 80/128, Loss: 15.6292\nAvg Blank Probability: 0.2350\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['kAWIPaZw4', '7lDV', 'zninSN1y7G']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [9, 4, 10]\nToken distribution (Batch 31): {0: 10}\nBatch 90, Gradient norm: 6115.5938\nEpoch 18, Batch 90/128, Loss: 15.0525\nAvg Blank Probability: 0.2425\nSample predictions: ['X', '<empty>', '<empty>']\nGround Truth (first 3): ['3JuRA61mc', '2f', 'P7QbB']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [9, 2, 5]\nToken distribution (Batch 31): {0: 4}\nBatch 100, Gradient norm: 1227139072.0000\nEpoch 18, Batch 100/128, Loss: 15.3711\nAvg Blank Probability: 0.2453\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['2UiKEQ', '5JsDVGajf', '56']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 9, 2]\nToken distribution (Batch 31): {0: 8}\nBatch 110, Gradient norm: 5965.3877\nEpoch 18, Batch 110/128, Loss: 14.3618\nAvg Blank Probability: 0.2539\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['b005xtkb', 'X9rqrpSp', 'zOxS']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 8, 4]\nToken distribution (Batch 31): {0: 15}\nBatch 120, Gradient norm: 309820.0938\nEpoch 18, Batch 120/128, Loss: 14.1435\nAvg Blank Probability: 0.2649\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['r5y8', 'JHJlmh0i', 'NS7KJL6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 8, 7]\nEpoch 18/20, Loss: 16.0749\nToken distribution (Batch 31): {0: 15}\nValidation Loss: 21.3665\nValidation Predictions: ['<empty>', 'a', 'a', '<empty>', '<empty>']\nGround Truth: ['nq', 'fxHGS', '9IIwuwWAr', 'nwEPlz6V', '4rz']\nCurrent Learning Rate: 1e-06\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {0: 10}\nBatch 0, Gradient norm: 41.4120\nEpoch 19, Batch 0/128, Loss: 15.4655\nAvg Blank Probability: 0.2746\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Y', 'vpIY', 'AfNS6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 4, 5]\nToken distribution (Batch 31): {0: 2}\nBatch 10, Gradient norm: 83.3333\nEpoch 19, Batch 10/128, Loss: 16.3699\nAvg Blank Probability: 0.2862\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['rMdg2h0uii', 'M*li4jM', 'KFJJ7Egd']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [10, 7, 8]\nToken distribution (Batch 31): {0: 15}\nBatch 20, Gradient norm: 46.1306\nEpoch 19, Batch 20/128, Loss: 15.6213\nAvg Blank Probability: 0.2939\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['CYefHF', '1BaHucs7', '45t061hgf9']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 8, 10]\nToken distribution (Batch 31): {0: 14}\nBatch 30, Gradient norm: 116088.0000\nEpoch 19, Batch 30/128, Loss: 13.7754\nAvg Blank Probability: 0.3240\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['uduag5', 'fr1jAmXu', 'RMaR5*7p']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 8, 8]\nToken distribution (Batch 31): {0: 2}\nBatch 40, Gradient norm: 4483402170368.0000\nEpoch 19, Batch 40/128, Loss: 14.0469\nAvg Blank Probability: 0.3200\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['7zV', '-i6LwZrz47', 'lj1']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 10, 3]\nToken distribution (Batch 31): {0: 15}\nBatch 50, Gradient norm: 4379.8389\nEpoch 19, Batch 50/128, Loss: 16.1935\nAvg Blank Probability: 0.3392\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['1', '0pQUIWd', '4RpW']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 7, 4]\nToken distribution (Batch 31): {0: 14}\nBatch 60, Gradient norm: 78486.2188\nEpoch 19, Batch 60/128, Loss: 13.8941\nAvg Blank Probability: 0.3273\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['NkE9', 'GRgo5', 'MRrU']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 5, 4]\nToken distribution (Batch 31): {0: 14}\nBatch 70, Gradient norm: 3801663.7500\nEpoch 19, Batch 70/128, Loss: 13.5452\nAvg Blank Probability: 0.3696\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['waV', 'Mx', 'yn*']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 2, 3]\nToken distribution (Batch 31): {0: 12}\nBatch 80, Gradient norm: 80752.2422\nEpoch 19, Batch 80/128, Loss: 14.8816\nAvg Blank Probability: 0.3749\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['O', 'C5Wdy4c', 'WLe']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 7, 3]\nToken distribution (Batch 31): {0: 2}\nBatch 90, Gradient norm: 41.9384\nEpoch 19, Batch 90/128, Loss: 14.0594\nAvg Blank Probability: 0.3785\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['lZ2TUT', 'q9zklSaiuC', 'AXtKCJ05k']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 10, 9]\nToken distribution (Batch 31): {0: 15}\nBatch 100, Gradient norm: 47943.2461\nEpoch 19, Batch 100/128, Loss: 13.6816\nAvg Blank Probability: 0.3967\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['P5-Gz9K', 'zYARCOeb', '2j']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 8, 2]\nToken distribution (Batch 31): {0: 15}\nBatch 110, Gradient norm: 34.7849\nEpoch 19, Batch 110/128, Loss: 13.3302\nAvg Blank Probability: 0.4108\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['hACa', 'g', 'kOnkX']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 1, 5]\nToken distribution (Batch 31): {0: 8}\nBatch 120, Gradient norm: 32.1026\nEpoch 19, Batch 120/128, Loss: 12.7624\nAvg Blank Probability: 0.4178\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['**GKC5p', 'MI', 'Ql1pa--3']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 2, 8]\nEpoch 19/20, Loss: 14.1200\nToken distribution (Batch 31): {0: 15}\nValidation Loss: 20.3708\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['Tn', 'zypb', 'U6LgEHC8oW', 'c', 'NXr']\nCurrent Learning Rate: 1e-06\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {0: 14}\nBatch 0, Gradient norm: 45.8229\nEpoch 20, Batch 0/128, Loss: 14.0945\nAvg Blank Probability: 0.4182\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['PDeSdwlOT', 'kPAyIFQu', 'fForlf']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [9, 8, 6]\nToken distribution (Batch 31): {0: 15}\nBatch 10, Gradient norm: 5698202.5000\nEpoch 20, Batch 10/128, Loss: 12.4915\nAvg Blank Probability: 0.4476\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['pOTlc0P5pw', 'u6XUi', 'n']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [10, 5, 1]\nToken distribution (Batch 31): {0: 4}\nBatch 20, Gradient norm: 37.2680\nEpoch 20, Batch 20/128, Loss: 12.1852\nAvg Blank Probability: 0.4676\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['6', '7N7d', 'g']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 4, 1]\nToken distribution (Batch 31): {0: 15}\nBatch 30, Gradient norm: 249675.5312\nEpoch 20, Batch 30/128, Loss: 12.9643\nAvg Blank Probability: 0.4662\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['T6', 'AE', 'q']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 2, 1]\nToken distribution (Batch 31): {0: 8}\nBatch 40, Gradient norm: 28.0686\nEpoch 20, Batch 40/128, Loss: 12.0063\nAvg Blank Probability: 0.4989\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['MmvXqd05', '55kxoPw', 'K9']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 7, 2]\nToken distribution (Batch 31): {0: 8}\nBatch 50, Gradient norm: 851492480.0000\nEpoch 20, Batch 50/128, Loss: 12.2114\nAvg Blank Probability: 0.5046\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['9KaMuuhtgy', 'RQz0Sj', '8']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [10, 6, 1]\nToken distribution (Batch 31): {0: 15}\nBatch 60, Gradient norm: 12507314.0000\nEpoch 20, Batch 60/128, Loss: 12.5644\nAvg Blank Probability: 0.4981\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Q', '1qwdH4orZZ', 'b0sr']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 10, 4]\nToken distribution (Batch 31): {0: 15}\nBatch 70, Gradient norm: 31.3821\nEpoch 20, Batch 70/128, Loss: 12.0658\nAvg Blank Probability: 0.5300\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['zapD0Ga3q', 'hjpH', 'H9Ih-81']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [9, 4, 7]\nToken distribution (Batch 31): {0: 15}\nBatch 80, Gradient norm: 220034990080.0000\nEpoch 20, Batch 80/128, Loss: 11.9227\nAvg Blank Probability: 0.5373\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['bUNq', '*m4W', 'BGcfsHl0j6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 4, 10]\nToken distribution (Batch 31): {0: 2}\nBatch 90, Gradient norm: 25.6210\nEpoch 20, Batch 90/128, Loss: 11.7199\nAvg Blank Probability: 0.5762\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['1', 'OWs', '2UiKEQ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 3, 6]\nToken distribution (Batch 31): {0: 15}\nBatch 100, Gradient norm: 2410903808.0000\nEpoch 20, Batch 100/128, Loss: 11.9197\nAvg Blank Probability: 0.5646\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['09Vsfm3', 'k1Z', 'A8Be2f']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 3, 6]\nToken distribution (Batch 31): {0: 2}\nBatch 110, Gradient norm: 1042.3949\nEpoch 20, Batch 110/128, Loss: 12.2811\nAvg Blank Probability: 0.5701\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['uBJcLx', 'l', '*mfyDLwx']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 1, 8]\nToken distribution (Batch 31): {0: 4}\nBatch 120, Gradient norm: 29.9891\nEpoch 20, Batch 120/128, Loss: 11.9822\nAvg Blank Probability: 0.5934\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['UtXibJFR', 'GMTm', '65GcR']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 4, 5]\nEpoch 20/20, Loss: 12.1980\nToken distribution (Batch 31): {0: 15}\nValidation Loss: 20.1790\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['K7ebq', 'GXX3PhE', 'kuG', 'Bw', 'DV14']\nCurrent Learning Rate: 1e-06\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"def zip_folder_with_shutil(source_folder, output_path):\n    '''Function for zip dir data'''\n    shutil.make_archive(output_path, 'zip', source_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:35:39.101034Z","iopub.execute_input":"2025-03-07T11:35:39.101381Z","iopub.status.idle":"2025-03-07T11:35:39.108470Z","shell.execute_reply.started":"2025-03-07T11:35:39.101346Z","shell.execute_reply":"2025-03-07T11:35:39.106875Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/backgrounds', '/kaggle/working/backgrounds')\nzip_folder_with_shutil('/kaggle/working/synthetic_data', '/kaggle/working/synthetic_data')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:35:39.110127Z","iopub.execute_input":"2025-03-07T11:35:39.110664Z","iopub.status.idle":"2025-03-07T11:35:40.129183Z","shell.execute_reply.started":"2025-03-07T11:35:39.110612Z","shell.execute_reply":"2025-03-07T11:35:40.127144Z"}},"outputs":[],"execution_count":26}]}