{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10951507,"sourceType":"datasetVersion","datasetId":6783030}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---------------\n\n# **<font style=\"color:Black\">Create OCR by PyTorch</font>**\n-------------------\n-----------------","metadata":{}},{"cell_type":"code","source":"#!pip install tensorboard\n!tensorboard --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:52:27.652627Z","iopub.execute_input":"2025-03-10T04:52:27.652945Z","iopub.status.idle":"2025-03-10T04:52:47.343952Z","shell.execute_reply.started":"2025-03-10T04:52:27.652914Z","shell.execute_reply":"2025-03-10T04:52:47.342718Z"}},"outputs":[{"name":"stdout","text":"2025-03-10 04:52:32.013708: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-10 04:52:32.260993: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-10 04:52:32.330314: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2.17.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport random\nfrom PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter\nimport numpy as np\nimport cv2\n\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F  # Add this import\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:52:47.345168Z","iopub.execute_input":"2025-03-10T04:52:47.345590Z","iopub.status.idle":"2025-03-10T04:52:58.513022Z","shell.execute_reply.started":"2025-03-10T04:52:47.345552Z","shell.execute_reply":"2025-03-10T04:52:58.511811Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Hyperparameters</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"seed = 3\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:52:58.514503Z","iopub.execute_input":"2025-03-10T04:52:58.515150Z","iopub.status.idle":"2025-03-10T04:52:58.528580Z","shell.execute_reply.started":"2025-03-10T04:52:58.515113Z","shell.execute_reply":"2025-03-10T04:52:58.527362Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7870bc13edd0>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"OUTPUT_DIR = os.path.join('/kaggle','working','synthetic_data','images')\nTENSORBOARD_DIR = os.path.join('/kaggle','working','runs')\nMODEL_DIR = os.path.join('/kaggle','working','model_dir')\nLABELS_FILE = os.path.join('/kaggle','working','synthetic_data','labels.txt')\nNUM_SAMPLES = 5120  # Number of images generated\nIMG_WIDTH = 128\nIMG_HEIGHT = 32\nBATCH_SIZE = 32\nEPOCHS = 20\nLEARNING_RATE = 1e-5 \nWEIGHT_DECAY = 1e-4  \nWARMUP_STEPS = 1000  \nENTROPY_WEIGHT = 3.0\nTEMPERATURE = 0.3\nDROPOUT = 0.7\nBEAM_WIDTH = 10\nLABEL_SMOOTHING = 0.2\nBLANK_PENALTY_WEIGHT = 3.0\nMAX_SEQ_LENGTH = 15\nCHARSET = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-*\"  # Group characters\nMAX_TEXT_LENGTH = 10  # Maximum length of text in an image\nFONT_DIR = os.path.join('/kaggle','input','google-fonts','GoogleFontScripts') # Folder with TrueType fonts (.ttf)\nBACKGROUND_DIR = os.path.join('/kaggle','working','backgrounds')  # New folder for background (optional)\nNUMBER_BACKGROUND_IMAGE = 1000","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:52:58.529702Z","iopub.execute_input":"2025-03-10T04:52:58.530086Z","iopub.status.idle":"2025-03-10T04:52:58.541419Z","shell.execute_reply.started":"2025-03-10T04:52:58.530055Z","shell.execute_reply":"2025-03-10T04:52:58.540284Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Utils support functions</font>**\n-------------------","metadata":{}},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Create output folders</font>**","metadata":{}},{"cell_type":"code","source":"os.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(BACKGROUND_DIR, exist_ok=True)\nos.makedirs(TENSORBOARD_DIR, exist_ok=True)\n\n# Creates a new file\nwith open(LABELS_FILE, 'w') as fp:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:52:58.542712Z","iopub.execute_input":"2025-03-10T04:52:58.543101Z","iopub.status.idle":"2025-03-10T04:52:58.560883Z","shell.execute_reply.started":"2025-03-10T04:52:58.543071Z","shell.execute_reply":"2025-03-10T04:52:58.559862Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load the font list (add the paths to the .ttf files to the \"fonts\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"font_files = [\n    os.path.join(FONT_DIR, f) for f in os.listdir(FONT_DIR) \n    if f.endswith('.ttf') and os.path.isfile(os.path.join(FONT_DIR, f))\n]\nif not font_files:\n    raise FileNotFoundError(\"No fonts found in 'fonts' folder. Add .ttf files!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:52:58.563621Z","iopub.execute_input":"2025-03-10T04:52:58.563939Z","iopub.status.idle":"2025-03-10T04:53:00.054700Z","shell.execute_reply.started":"2025-03-10T04:52:58.563911Z","shell.execute_reply":"2025-03-10T04:53:00.053614Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generating a simple gradient background</font>**","metadata":{}},{"cell_type":"code","source":"def generate_gradient_background(filename, size=(128, 32)):\n    img = Image.new('L', size, color=230)  # Lighter gray as a base\n    draw = ImageDraw.Draw(img)\n    for y in range(size[1]):\n        # Soft gradient with low contrast\n        color = int(230 - 20 * (y / size[1]))  # From light gray to slightly darker\n        draw.line([(0, y), (size[0], y)], fill=color)\n    # Background blur\n    img = img.filter(ImageFilter.GaussianBlur(radius=2))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:00.056318Z","iopub.execute_input":"2025-03-10T04:53:00.056617Z","iopub.status.idle":"2025-03-10T04:53:00.062478Z","shell.execute_reply.started":"2025-03-10T04:53:00.056583Z","shell.execute_reply":"2025-03-10T04:53:00.061494Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generate a background with noise (paper texture)</font>**","metadata":{}},{"cell_type":"code","source":"def generate_paper_texture(filename, size=(128, 32)):\n    img = Image.new('L', size, color=220)  # Lighter gray\n    noise = np.random.normal(0, 5, size).astype(np.uint8)  # Less noise\n    noise_img = Image.fromarray(noise)\n    img.paste(noise_img, (0, 0), noise_img)\n    # Blur for a softer effect\n    img = img.filter(ImageFilter.GaussianBlur(radius=1.5))\n    img.save(os.path.join(BACKGROUND_DIR, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:00.063596Z","iopub.execute_input":"2025-03-10T04:53:00.063921Z","iopub.status.idle":"2025-03-10T04:53:00.081490Z","shell.execute_reply.started":"2025-03-10T04:53:00.063886Z","shell.execute_reply":"2025-03-10T04:53:00.080404Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Creating multiple backgrounds</font>**","metadata":{}},{"cell_type":"code","source":"for i in range(NUMBER_BACKGROUND_IMAGE):\n    generate_gradient_background(f\"gradient_{i}.png\")\n    generate_paper_texture(f\"paper_{i}.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:00.082629Z","iopub.execute_input":"2025-03-10T04:53:00.082955Z","iopub.status.idle":"2025-03-10T04:53:01.252408Z","shell.execute_reply.started":"2025-03-10T04:53:00.082923Z","shell.execute_reply":"2025-03-10T04:53:01.251294Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Load backgrounds (optional, add images to the \"backgrounds\" folder)</font>**","metadata":{}},{"cell_type":"code","source":"background_files = (\n    [os.path.join(BACKGROUND_DIR, f) for f in os.listdir(BACKGROUND_DIR) \n     if f.endswith(('.png', '.jpg', '.jpeg'))] if os.path.exists(BACKGROUND_DIR) else []\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.253301Z","iopub.execute_input":"2025-03-10T04:53:01.253665Z","iopub.status.idle":"2025-03-10T04:53:01.262972Z","shell.execute_reply.started":"2025-03-10T04:53:01.253630Z","shell.execute_reply":"2025-03-10T04:53:01.261667Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Random text generation function</font>**","metadata":{}},{"cell_type":"code","source":"def generate_random_text(max_length):\n    length = random.randint(1, max_length)\n    return ''.join(random.choice(CHARSET) for _ in range(length))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.264125Z","iopub.execute_input":"2025-03-10T04:53:01.264619Z","iopub.status.idle":"2025-03-10T04:53:01.275833Z","shell.execute_reply.started":"2025-03-10T04:53:01.264574Z","shell.execute_reply":"2025-03-10T04:53:01.274875Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Functions for adding noise and distortions</font>**","metadata":{}},{"cell_type":"code","source":"def add_noise_and_distortion(img):\n    img_array = np.array(img)\n    # Mild Gaussian noise with lower intensity\n    if random.random() > 0.5:  # 50% šance\n        noise = np.random.normal(0, random.randint(5, 15), img_array.shape).astype(np.uint8)\n        img_array = cv2.add(img_array, noise)\n    # Subtle perspective distortion\n    rows, cols = img_array.shape\n    src_points = np.float32([[0, 0], [cols-1, 0], [0, rows-1], [cols-1, rows-1]])\n    dst_points = np.float32([\n        [random.uniform(0, 3), random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), random.uniform(0, 3)],\n        [random.uniform(0, 3), rows-1-random.uniform(0, 3)],\n        [cols-1-random.uniform(0, 3), rows-1-random.uniform(0, 3)]\n    ])\n    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n    img_array = cv2.warpPerspective(img_array, matrix, (cols, rows))\n    return Image.fromarray(img_array)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.276903Z","iopub.execute_input":"2025-03-10T04:53:01.277240Z","iopub.status.idle":"2025-03-10T04:53:01.290024Z","shell.execute_reply.started":"2025-03-10T04:53:01.277208Z","shell.execute_reply":"2025-03-10T04:53:01.288876Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Improved image generation feature</font>**","metadata":{}},{"cell_type":"code","source":"def generate_synthetic_image(text, font_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n    # Pozadí\n    if background_files:\n        bg_path = random.choice(background_files)\n        img = Image.open(bg_path).convert('L').resize(img_size)\n    else:\n        img = Image.new('L', img_size, color=230)\n        draw = ImageDraw.Draw(img)\n        for y in range(img_size[1]):\n            color = int(230 - 20 * (y / img_size[1]))\n            draw.line([(0, y), (img_size[0], y)], fill=color)\n        img = img.filter(ImageFilter.GaussianBlur(radius=2))\n\n    draw = ImageDraw.Draw(img)\n\n    # Iterativní úprava fontu a textu\n    font_size = random.randint(20, min(IMG_HEIGHT-2, 28))\n    max_attempts = 5  # Omezení počtu pokusů\n    for attempt in range(max_attempts):\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n        if text_width <= IMG_WIDTH - 10:  # Text vejde\n            break\n        elif len(text) > 1:  # Zkrať text, pokud je příliš dlouhý\n            text = text[:len(text)//2]\n        else:  # Sniž velikost fontu\n            font_size = max(10, font_size - 5)  # Minimální velikost 10\n\n    # Pokud se nepodaří, použij minimální font a jednopísmený text\n    if text_width > IMG_WIDTH - 10:\n        text = text[0]  # Použij první písmeno\n        font_size = 10\n        font = ImageFont.truetype(font_path, font_size)\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n\n    # Pozice textu\n    x = random.randint(5, max(5, IMG_WIDTH - text_width - 5))\n    y = random.randint(5, max(5, IMG_HEIGHT - text_height - 5))\n\n    # Zvýraznění textu\n    text_color = random.randint(0, 50)\n    outline_color = 200\n    for offset_x in [-1, 0, 1]:\n        for offset_y in [-1, 0, 1]:\n            if offset_x != 0 or offset_y != 0:\n                draw.text((x + offset_x, y + offset_y), text, font=font, fill=outline_color)\n    draw.text((x, y), text, font=font, fill=text_color)\n\n    # Šum a deformace\n    img = add_noise_and_distortion(img)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.291048Z","iopub.execute_input":"2025-03-10T04:53:01.291416Z","iopub.status.idle":"2025-03-10T04:53:01.306985Z","shell.execute_reply.started":"2025-03-10T04:53:01.291377Z","shell.execute_reply":"2025-03-10T04:53:01.306031Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function for splitting labels</font>**","metadata":{}},{"cell_type":"code","source":"def split_labels(labels, label_lengths):\n    \"\"\"Split a flat tensor of labels into a list of label sequences based on lengths.\"\"\"\n    split_labels = []\n    start = 0\n    for length in label_lengths:\n        split_labels.append(labels[start:start + length])\n        start += length\n    return split_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.308234Z","iopub.execute_input":"2025-03-10T04:53:01.308685Z","iopub.status.idle":"2025-03-10T04:53:01.326349Z","shell.execute_reply.started":"2025-03-10T04:53:01.308643Z","shell.execute_reply":"2025-03-10T04:53:01.324918Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Function of Beam search decoding</font>**","metadata":{}},{"cell_type":"code","source":"def beam_search_decode(output, idx_to_char, target_lengths=None, beam_width=10, blank_penalty=-1.0, length_penalty=-0.5):\n    probs = output.softmax(2).cpu().numpy()\n    T, B, C = probs.shape\n    predictions = []\n    \n    for b in range(B):\n        sequence_probs = [(0.0, [], 1.0)]\n        max_length = target_lengths[b].item() * 2 if target_lengths is not None else T\n        for t in range(T):\n            new_sequences = []\n            for log_prob, seq, prob in sequence_probs:\n                if len(seq) >= max_length:\n                    new_sequences.append((log_prob, seq, prob))\n                    continue\n                top_k_probs, top_k_idx = torch.topk(torch.tensor(probs[t, b]), beam_width)\n                for k_prob, k_idx in zip(top_k_probs, top_k_idx):\n                    new_seq = seq + [k_idx.item()]\n                    new_prob = prob * k_prob.item()\n                    new_log_prob = log_prob + np.log(k_prob.item())\n                    if k_idx.item() == 0:\n                        new_log_prob += blank_penalty\n                    new_log_prob += length_penalty * len(new_seq)\n                    new_sequences.append((new_log_prob, new_seq, new_prob))\n            sequence_probs = sorted(new_sequences, key=lambda x: x[0], reverse=True)[:beam_width]\n        \n        best_seq = sequence_probs[0][1]\n        decoded = []\n        prev = -1\n        for idx in best_seq:\n            if idx != 0 and idx != prev:\n                decoded.append(idx_to_char.get(idx, ''))\n            prev = idx\n        predictions.append(''.join(decoded) if decoded else '<empty>')\n    \n    token_counts = Counter(best_seq)\n    print(f\"Token distribution (Batch {b}): {dict(token_counts)}\")\n    return predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.327722Z","iopub.execute_input":"2025-03-10T04:53:01.328149Z","iopub.status.idle":"2025-03-10T04:53:01.344919Z","shell.execute_reply.started":"2025-03-10T04:53:01.328110Z","shell.execute_reply":"2025-03-10T04:53:01.343891Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Custom collate function</font>**","metadata":{}},{"cell_type":"code","source":"def custom_collate_fn(batch):\n    images, labels, label_lengths = zip(*batch)\n    # Stack images (all same size)\n    images = torch.stack(images, dim=0)\n    # Concatenate labels into a flat tensor\n    labels = torch.cat(labels, dim=0)\n    # Convert label_lengths to tensor\n    label_lengths = torch.tensor(label_lengths, dtype=torch.long)\n    return images, labels, label_lengths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.346092Z","iopub.execute_input":"2025-03-10T04:53:01.346416Z","iopub.status.idle":"2025-03-10T04:53:01.363524Z","shell.execute_reply.started":"2025-03-10T04:53:01.346390Z","shell.execute_reply":"2025-03-10T04:53:01.362319Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"### **<font style=\"color:green\">Generování datasetu</font>**","metadata":{}},{"cell_type":"code","source":"def create_synthetic_dataset(num_samples):\n    labels = []\n    for i in range(num_samples):\n        text = generate_random_text(MAX_TEXT_LENGTH)\n        if not text:\n            continue\n        font_path = random.choice(font_files)\n        img = generate_synthetic_image(text, font_path)\n        img_name = f\"img_{i:05d}.png\"\n        img_path = os.path.join(OUTPUT_DIR, img_name)\n        img.save(img_path)\n        labels.append(f\"{img_name}\\t{text}\")  # Use tab (\\t) instead of space\n        if i % 100 == 0:\n            print(f\"Generated {i}/{num_samples} images\")\n\n    if labels:\n        with open(LABELS_FILE, 'w') as f:\n            f.write(\"\\n\".join(labels))\n        print(f\"Dataset generated! Images saved in '{OUTPUT_DIR}', labels in '{LABELS_FILE}'\")\n    else:\n        print(\"No labels generated!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.364547Z","iopub.execute_input":"2025-03-10T04:53:01.364878Z","iopub.status.idle":"2025-03-10T04:53:01.377799Z","shell.execute_reply.started":"2025-03-10T04:53:01.364847Z","shell.execute_reply":"2025-03-10T04:53:01.376619Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Mapping characters to indices and back</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"char_to_idx = {char: idx + 1 for idx, char in enumerate(CHARSET)}  # 0 is reserved for blank (CTC)\nidx_to_char = {idx: char for char, idx in char_to_idx.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.378895Z","iopub.execute_input":"2025-03-10T04:53:01.379262Z","iopub.status.idle":"2025-03-10T04:53:01.392026Z","shell.execute_reply.started":"2025-03-10T04:53:01.379214Z","shell.execute_reply":"2025-03-10T04:53:01.390707Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom dataset</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRDataset(Dataset):\n    def __init__(self, image_dir, labels_file):\n        self.image_dir = image_dir\n        self.labels_file = labels_file\n        self.data = []\n        with open(labels_file, 'r') as f:\n            for line in f:\n                if not line.strip():  # Skip empty lines\n                    continue\n                image_path, label = line.strip().split('\\t')\n                label_length = len(label)\n                self.data.append((image_path, label, label_length))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_path, label, label_length = self.data[idx]\n        image = Image.open(os.path.join(self.image_dir, image_path)).convert('L')\n        image = transforms.ToTensor()(image)\n        label_encoded = torch.tensor([char_to_idx[c] for c in label], dtype=torch.long)\n        return image, label_encoded, label_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.393025Z","iopub.execute_input":"2025-03-10T04:53:01.393410Z","iopub.status.idle":"2025-03-10T04:53:01.403821Z","shell.execute_reply.started":"2025-03-10T04:53:01.393368Z","shell.execute_reply":"2025-03-10T04:53:01.402693Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Custom CTC Loss with Blank Penalty</font>**\n-------------------\n> CTC Loss with Entropy Regularization","metadata":{}},{"cell_type":"code","source":"class CTCLossWithBlankPenalty(nn.Module):\n    def __init__(self, blank=0, zero_infinity=True, blank_penalty_weight=3.0, entropy_weight=3.0, label_smoothing=0.2):\n        super().__init__()\n        self.ctc_loss = nn.CTCLoss(blank=blank, zero_infinity=zero_infinity)\n        self.blank_penalty_weight = blank_penalty_weight\n        self.entropy_weight = entropy_weight\n        self.label_smoothing = label_smoothing\n\n    def forward(self, log_probs, targets, input_lengths, target_lengths):\n        ctc_loss = self.ctc_loss(log_probs, targets, input_lengths, target_lengths)\n        blank_probs = log_probs[:, :, 0].exp().mean()\n        blank_penalty = -torch.log(1 - blank_probs + 1e-6) * self.blank_penalty_weight\n        entropy = -(log_probs.exp() * log_probs).sum(dim=-1).mean()  # Negative entropy\n        total_loss = ctc_loss + blank_penalty + self.entropy_weight * entropy\n        return total_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.407459Z","iopub.execute_input":"2025-03-10T04:53:01.407823Z","iopub.status.idle":"2025-03-10T04:53:01.424426Z","shell.execute_reply.started":"2025-03-10T04:53:01.407786Z","shell.execute_reply":"2025-03-10T04:53:01.423330Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Model definition (CNN + RNN + CTC)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"class OCRModel(nn.Module):\n    def __init__(self, num_chars):\n        super(OCRModel, self).__init__()\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.rnn = nn.LSTM(128 * (IMG_HEIGHT // 4), 256, num_layers=2, bidirectional=True, dropout=DROPOUT)\n        self.fc = nn.Linear(256 * 2, num_chars)\n        self.dropout = nn.Dropout(DROPOUT)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        batch, channels, height, width = x.size()\n        x = x.view(batch, channels * height, width).permute(2, 0, 1)\n        x = x[:MAX_SEQ_LENGTH]  # Truncate to MAX_SEQ_LENGTH\n        x, _ = self.rnn(x)\n        x = self.dropout(x)\n        x = self.fc(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.425727Z","iopub.execute_input":"2025-03-10T04:53:01.426104Z","iopub.status.idle":"2025-03-10T04:53:01.442139Z","shell.execute_reply.started":"2025-03-10T04:53:01.426071Z","shell.execute_reply":"2025-03-10T04:53:01.440727Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Training</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, device, epoch, warmup_steps=WARMUP_STEPS):\n    model.train()\n    total_loss = 0\n    global_step = epoch * len(train_loader)\n    \n    for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n        imgs, labels = imgs.to(device), labels.to(device)\n        label_lengths = label_lengths.to(device)\n\n        if global_step < warmup_steps:\n            lr_scale = min(1.0, float(global_step + 1) / warmup_steps)\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = LEARNING_RATE * lr_scale\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        outputs = outputs / TEMPERATURE\n        outputs = outputs.log_softmax(2)\n\n        batch_size = imgs.size(0)\n        seq_length = outputs.size(0)\n        input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n\n        loss = criterion(outputs, labels, input_lengths, label_lengths)\n        if torch.isnan(loss) or torch.isinf(loss):\n            print(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n            continue\n\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.05)  # Sníženo\n        optimizer.step()\n        total_loss += loss.item()\n        global_step += 1\n\n        if batch_idx % 10 == 0:\n            with torch.no_grad():\n                pred_texts = beam_search_decode(outputs, idx_to_char, label_lengths)\n                raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n                blank_probs = outputs[:, :, 0].exp().mean().item()\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:3]]\n                \n                # Logování do TensorBoard\n                writer.add_scalar('Loss/train_batch', loss.item(), global_step)\n                writer.add_scalar('Blank_Probability/train_batch', blank_probs, global_step)\n                writer.add_scalar('Gradient_Norm/train_batch', grad_norm.item(), global_step)  # Přidáno logování\n                \n                print(f\"Batch {batch_idx}, Gradient norm: {grad_norm.item():.4f}\")\n                print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n                print(f\"Avg Blank Probability: {blank_probs:.4f}\")\n                print(f\"Sample predictions: {pred_texts[:3]}\")\n                print(f\"Ground Truth (first 3): {ground_truth}\")\n                print(f\"Raw outputs (first 3): {raw_outputs}\")\n                print(f\"Input length: {seq_length}, Label lengths: {label_lengths[:3].tolist()}\")\n\n    avg_loss = total_loss / len(train_loader)\n    writer.add_scalar('Loss/train_epoch', avg_loss, epoch)\n    return avg_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.443015Z","iopub.execute_input":"2025-03-10T04:53:01.443311Z","iopub.status.idle":"2025-03-10T04:53:01.458418Z","shell.execute_reply.started":"2025-03-10T04:53:01.443275Z","shell.execute_reply":"2025-03-10T04:53:01.457409Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Inference (prediction)</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"def decode_prediction(output, idx_to_char):\n    probs = output.softmax(2)\n    max_probs, preds = probs.max(dim=2)\n    preds = preds.cpu().numpy()\n    max_probs = max_probs.cpu().numpy()\n    texts = []\n    for i, (pred, prob) in enumerate(zip(preds.T, max_probs.T)):\n        print(f\"Raw prediction {i} (pre-filter): {pred}, Max probs: {prob}\")\n        # Dynamic threshold: 75th percentile of max probs in this sequence\n        threshold = np.percentile(prob, 75)\n        print(f\"Dynamic threshold for prediction {i}: {threshold:.4f}\")\n        pred_text = []\n        prev = -1\n        for idx, p in zip(pred, prob):\n            if idx != 0 and idx != prev and p > threshold:\n                pred_text.append(idx_to_char.get(idx, ''))\n            prev = idx\n        decoded = ''.join(pred_text)\n        texts.append(decoded if decoded else '<empty>')\n    return texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.459521Z","iopub.execute_input":"2025-03-10T04:53:01.459912Z","iopub.status.idle":"2025-03-10T04:53:01.477287Z","shell.execute_reply.started":"2025-03-10T04:53:01.459877Z","shell.execute_reply":"2025-03-10T04:53:01.476291Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## **<font style=\"color:blue\">Main launch</font>**\n-------------------","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Inicializace TensorBoard writeru\n    log_dir = \"runs/ocr_experiment\"\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    writer = SummaryWriter(log_dir)\n\n    if not font_files:\n        print(\"Download some TrueType fonts (.ttf) and place them in the 'fonts' folder!\")\n    else:\n        create_synthetic_dataset(NUM_SAMPLES)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    full_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n\n    for i in range(5):\n        img, label, length = full_dataset[i]\n        plt.imshow(img.squeeze(), cmap='gray')\n        plt.title(''.join([idx_to_char.get(idx.item(), '') for idx in label[:length]]))\n        plt.show()\n    \n    if len(full_dataset) == 0:\n        print(\"Dataset is empty! Check labels.txt or image directory.\")\n    else:\n        # Curriculum phases with pre-filtering\n        model = OCRModel(num_chars=len(CHARSET)).to(device)\n        criterion = CTCLossWithBlankPenalty(\n            blank=0, zero_infinity=True, blank_penalty_weight=BLANK_PENALTY_WEIGHT,\n            entropy_weight=ENTROPY_WEIGHT, label_smoothing=LABEL_SMOOTHING\n        )\n        \n        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n\n        best_loss = float('inf')\n        \n        for epoch in range(EPOCHS):\n            # Filter full dataset based on curriculum phase\n            if epoch < 10:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 5]\n                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]  # lbl je řetězec\n                print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n            elif epoch < 15:\n                filtered_data = [(img, lbl, lbl_len) for img, lbl, lbl_len in full_dataset.data if lbl_len <= 7]\n                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]\n                print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n            else:\n                filtered_data = full_dataset.data\n                sample_labels = [lbl for _, lbl, _ in filtered_data[:3]]\n                print(f\"Epoch {epoch+1}, Filtered data size: {len(filtered_data)}, Sample labels: {sample_labels}\")\n\n            # Create a new dataset with filtered data\n            curr_dataset = OCRDataset(image_dir=OUTPUT_DIR, labels_file=LABELS_FILE)\n            curr_dataset.data = filtered_data  # Overwrite with filtered data\n\n            # Split into train and validation\n            train_size = int(0.8 * len(curr_dataset))\n            val_size = len(curr_dataset) - train_size\n            train_dataset, val_dataset = torch.utils.data.random_split(curr_dataset, [train_size, val_size])\n            print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n            \n            # Create data loaders\n            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n            val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n            \n            # Trénink s TensorBoard logováním\n            model.train()\n            total_loss = 0\n            global_step = epoch * len(train_loader)\n            for batch_idx, (imgs, labels, label_lengths) in enumerate(train_loader):\n                imgs, labels = imgs.to(device), labels.to(device)\n                label_lengths = label_lengths.to(device)\n\n                if global_step < WARMUP_STEPS:\n                    lr_scale = min(1.0, float(global_step + 1) / WARMUP_STEPS)\n                    for param_group in optimizer.param_groups:\n                        param_group['lr'] = LEARNING_RATE * lr_scale\n\n                optimizer.zero_grad()\n                outputs = model(imgs)\n                outputs = outputs / TEMPERATURE\n                outputs = outputs.log_softmax(2)\n\n                batch_size = imgs.size(0)\n                seq_length = outputs.size(0)\n                input_lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n\n                loss = criterion(outputs, labels, input_lengths, label_lengths)\n                if torch.isnan(loss) or torch.isinf(loss):\n                    print(f\"Warning: NaN or Inf loss at batch {batch_idx}. Skipping...\")\n                    continue\n\n                loss.backward()\n                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n                optimizer.step()\n                total_loss += loss.item()\n                global_step += 1\n\n                if batch_idx % 10 == 0:\n                    with torch.no_grad():\n                        pred_texts = beam_search_decode(outputs, idx_to_char, label_lengths)\n                        raw_outputs = outputs.argmax(2).cpu().numpy()[:3]\n                        blank_probs = outputs[:, :, 0].exp().mean().item()\n                        label_sequences = split_labels(labels, label_lengths)\n                        ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                        for label_seq in label_sequences[:3]]\n                        \n                        # Logování do TensorBoard\n                        writer.add_scalar('Loss/train_batch', loss.item(), global_step)\n                        writer.add_scalar('Blank_Probability/train_batch', blank_probs, global_step)\n                        writer.add_scalar('Gradient_Norm/train_batch', grad_norm.item(), global_step)\n                        \n                        print(f\"Batch {batch_idx}, Gradient norm: {grad_norm.item():.4f}\")\n                        print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n                        print(f\"Avg Blank Probability: {blank_probs:.4f}\")\n                        print(f\"Sample predictions: {pred_texts[:3]}\")\n                        print(f\"Ground Truth (first 3): {ground_truth}\")\n                        print(f\"Raw outputs (first 3): {raw_outputs}\")\n                        print(f\"Input length: {seq_length}, Label lengths: {label_lengths[:3].tolist()}\")\n\n            avg_loss = total_loss / len(train_loader)\n            writer.add_scalar('Loss/train_epoch', avg_loss, epoch)\n            print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.4f}\")\n\n            # Validace s TensorBoard logováním\n            model.eval()\n            val_loss = 0\n            val_blank_probs = 0\n            with torch.no_grad():\n                for batch_idx, (imgs, labels, label_lengths) in enumerate(val_loader):\n                    imgs, labels = imgs.to(device), labels.to(device)\n                    label_lengths = label_lengths.to(device)\n                    outputs = model(imgs)\n                    outputs = outputs.log_softmax(2)\n                    seq_length = outputs.size(0)\n                    input_lengths = torch.full((imgs.size(0),), seq_length, dtype=torch.long).to(device)\n                    val_loss += criterion(outputs, labels, input_lengths, label_lengths).item()\n                    val_blank_probs += outputs[:, :, 0].exp().mean().item()\n                \n                val_loss /= len(val_loader)\n                val_blank_probs /= len(val_loader)\n                pred_texts = beam_search_decode(outputs, idx_to_char, label_lengths)\n                label_sequences = split_labels(labels, label_lengths)\n                ground_truth = [''.join([idx_to_char.get(idx.item(), '') for idx in label_seq])\n                                for label_seq in label_sequences[:5]]\n                \n                # Logování validace do TensorBoard\n                writer.add_scalar('Loss/val_epoch', val_loss, epoch)\n                writer.add_scalar('Blank_Probability/val_epoch', val_blank_probs, epoch)\n                print(f\"Validation Loss: {val_loss:.4f}\")\n                print(\"Validation Predictions:\", pred_texts[:5])\n                print(\"Ground Truth:\", ground_truth)\n\n            scheduler.step()\n            print(f\"Current Learning Rate: {optimizer.param_groups[0]['lr']}\")\n\n            if val_loss < best_loss:\n                best_loss = val_loss\n                torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'best_ocr_model.pth'))\n\n        torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'final_ocr_model.pth'))\n    \n    # Uzavření TensorBoard writeru\n    writer.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:53:01.478350Z","iopub.execute_input":"2025-03-10T04:53:01.478733Z","iopub.status.idle":"2025-03-10T05:08:19.433179Z","shell.execute_reply.started":"2025-03-10T04:53:01.478697Z","shell.execute_reply":"2025-03-10T05:08:19.432234Z"}},"outputs":[{"name":"stdout","text":"Generated 0/5120 images\nGenerated 100/5120 images\nGenerated 200/5120 images\nGenerated 300/5120 images\nGenerated 400/5120 images\nGenerated 500/5120 images\nGenerated 600/5120 images\nGenerated 700/5120 images\nGenerated 800/5120 images\nGenerated 900/5120 images\nGenerated 1000/5120 images\nGenerated 1100/5120 images\nGenerated 1200/5120 images\nGenerated 1300/5120 images\nGenerated 1400/5120 images\nGenerated 1500/5120 images\nGenerated 1600/5120 images\nGenerated 1700/5120 images\nGenerated 1800/5120 images\nGenerated 1900/5120 images\nGenerated 2000/5120 images\nGenerated 2100/5120 images\nGenerated 2200/5120 images\nGenerated 2300/5120 images\nGenerated 2400/5120 images\nGenerated 2500/5120 images\nGenerated 2600/5120 images\nGenerated 2700/5120 images\nGenerated 2800/5120 images\nGenerated 2900/5120 images\nGenerated 3000/5120 images\nGenerated 3100/5120 images\nGenerated 3200/5120 images\nGenerated 3300/5120 images\nGenerated 3400/5120 images\nGenerated 3500/5120 images\nGenerated 3600/5120 images\nGenerated 3700/5120 images\nGenerated 3800/5120 images\nGenerated 3900/5120 images\nGenerated 4000/5120 images\nGenerated 4100/5120 images\nGenerated 4200/5120 images\nGenerated 4300/5120 images\nGenerated 4400/5120 images\nGenerated 4500/5120 images\nGenerated 4600/5120 images\nGenerated 4700/5120 images\nGenerated 4800/5120 images\nGenerated 4900/5120 images\nGenerated 5000/5120 images\nGenerated 5100/5120 images\nDataset generated! Images saved in '/kaggle/working/synthetic_data/images', labels in '/kaggle/working/synthetic_data/labels.txt'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAh8AAAC+CAYAAACVgm2zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAb1ElEQVR4nO3de3BU5f3H8U8uZBMI2TSx2RBJMMULKHhpIrhixUosUMdLQasMrfHSWm1QITNVqdVOtRqmzlRrB3FwWrBTKcqMYHUqDg2KOg231KhIiagUUNyNl4blmoTs8/ujzfntOYFsNtmc3U3er5mdOc95zp7z7JO9fHOe73lOmjHGCAAAwCXpiW4AAAAYWgg+AACAqwg+AACAqwg+AACAqwg+AACAqwg+AACAqwg+AACAqwg+AACAqwg+AACAqwg+AAy4LVu26MILL9SIESOUlpampqYmrV27Vueee66ys7OVlpam1tbWRDcTgEsyE90AAINbR0eHrr32WmVnZ+uxxx7T8OHDVVpaqosvvlhnnXWWFi9eLI/HoxEjRiS6qQBcQvABYEB99NFH2r17t55++mn96Ec/kiStXbtWBw4c0EMPPaSqqqoEtxCA2xh2ATCgWlpaJEn5+fk9rgMwdKRxV1sAA+XGG2/UM888Y1s3depUbdiwwbauurpay5cvd7FlABKJYRcAA+YnP/mJTj75ZD3yyCO68847df7558vn8+mMM87Q0qVL9eCDD6q8vFxjx45NdFMBuIjgA8CA8fv9amtr0yOPPKJvfetbuuaaayRJn376qZYuXaqZM2eqsrIywa0E4DZyPgAAgKsIPgAAgKsIPgAAgKsIPgAAgKsIPgAAgKsIPgAAgKsIPgAAgKuY4RQAALiKMx8AAMBVBB8AAMBVBB8AAMBVBB8AAMBVBB8AAMBVAxZ8LF68WKeccoqys7M1efJkbd68eaAOBQAAUsiAXGr73HPP6YYbbtBTTz2lyZMn6/HHH9eqVavU3NysoqKiHp8bDoe1b98+jRw5UmlpafFuGgAAGADGGB04cEAlJSVKT49ybsMMgEmTJpmamhqr3NnZaUpKSkxdXV3U5+7du9dI4sGDBw8ePHik4GPv3r1Rf+szFWft7e1qbGzUwoULrXXp6emqqqpSQ0NDt+3b2trU1tZmlc3/TsQ0NDQoNzdXkuTz+WzPOXr0aK/bE23baPWRbYsm2rbR6mN5XZJ05MiRAWtLLNv3t49j3b6ntsT6uvrT9lhfV3//JrG8tmht6+m9E+ux4/1e60+fx/o3aW9vj2l7ANGNHDky6jZxDz6++OILdXZ2dgsYfD6fduzY0W37uro6/epXv+q2Pjc313oBeXl5trqsrKxet2fYsGEDWh/LtpmZPXd3RkZGr48lqcfTWtH2Fc9juT08Fs/jmSijjuFwuE91fdk+Wn1nZ2evjxXtvRat3unYsWMnrIv2Xop6+jWG7aP97RmqBRKvN5/DuAcfsVq4cKFqa2utcigUUmlpqYLBoA4ePChJKisrsz0nluDDGbgAkfixglvieeYz2pmreJ4h6m+743lGN55nqqPtL57t7s3+4nlmM55nPqPt66OPPrKWjx07po0bN/Zqv3EPPk466SRlZGQoGAza1geDQRUXF3fb3uPxyOPxxLsZAAAgScX9UtusrCxVVFSovr7eWhcOh1VfXy+/3x/vwwEAgBQzIMMutbW1qq6uVmVlpSZNmqTHH39chw4d0k033TQQhwMAAClkQIKP6667Tp9//rkeeOABBQIBnXvuuVq7dm23JNSeBAIBDR8+XFL0pECgrwbyvUU+CSJFy1Ujlw3x4uZ3z5o1a6zlw4cPJy7no8u8efM0b968gdo9AABIUdzbBQAAuIrgAwAAuCrh83ycSDAYVE5OTqKbAfQZuUoAEqE/3z2x5otEzhkSy/whnPkAAACuIvgAAACuIvgAAACuSuqcj65p1xk7B+KLOUgAHE+sv7eR96SJ5S7RnPkAAACuIvgAAACuIvgAAACuStqcjz179lj3OiDnA4iveH6myB8Bhq7I75JYvlc48wEAAFxF8AEAAFyVtMMuLS0tysxM2uYB+B+GRYGhi+nVAQBASiD4AAAAriL4AAAArkrapIpgMKiMjAxJjCkDiA8uCwbi6+jRo9Zy5FTr0XDmAwAAuIrgAwAAuIrgAwAAuCppcz5aWlqUnv7f2CiZcj4YMwZSVzJ9lwBDGWc+AACAqwg+AACAqwg+AACAq5I25+Pzzz+3lpNpnHYg20I+CTB08flHKoqc5yNyORrOfAAAAFcRfAAAAFfFHHy88cYbuuKKK1RSUqK0tDStWbPGVm+M0QMPPKBRo0YpJydHVVVV2rlzZ7zaCwAAUlzMOR+HDh3SOeeco5tvvlmzZs3qVv+b3/xGTzzxhJ555hmVl5fr/vvv1/Tp07V9+3ZlZ2f3qZGBQMBWLi4u7tN+kl0y5bYAcBf5ZEhF4XD4uMvRxBx8zJw5UzNnzjxunTFGjz/+uH7xi1/oqquukiT96U9/ks/n05o1a3T99dfHejgAADDIxDXnY9euXQoEAqqqqrLWeb1eTZ48WQ0NDcd9Tltbm0KhkO0BAAAGr7gGH13DIz6fz7be5/N1GzrpUldXJ6/Xaz1KS0vj2SQAAJBkEj7Px8KFC1VbW2uVQ6FQtwDEGbg4gxskFuPJQHIjnwwDpa2tzVpub2/v9fPieuajKxE0GAza1geDwRMmiXo8HuXl5dkeAABg8Ipr8FFeXq7i4mLV19db60KhkDZt2iS/3x/PQwEAgBQV87DLwYMH9eGHH1rlXbt2qampSQUFBSorK9P8+fP161//Wqeddpp1qW1JSYmuvvrqeLYbAACkqJiDj61bt+rb3/62Ve7K16iurtby5ct1991369ChQ7r11lvV2tqqiy66SGvXru3zHB9S95yPiRMn9nlfSD3p6UzECwxW5Iyltsj7uUTmf0QTc/BxySWX9Ji8lJaWpgcffFAPPvhgrLsGAABDAP9SAgAAVxF8AAAAVyV8no/ecF66i6EllvsFAPEU+d7r6Oiw1UWOdUtSZ2fnCZ8rScOGDbOVc3JybOXMTPvXceTxnGPp0T4TGRkZMR1rsCA/zH2RaRixzCfDXwoAALiK4AMAALiK4AMAALgqJQb+/v3vf9vK5AAgFTD+nHqc3y2HDx+2lp3zDb3zzju28j/+8Q9b+dixY7Zy5PxIknTZZZfZys77YrS0tFjLTU1NPR7bmW9y6aWX2spTpkyxlQdrzge/De6LzH1K2L1dAAAAoiH4AAAAriL4AAAArkqJgb/IsU8gVTD+nHqcc3ns27fPWn7++edtdW+++aatfNZZZ9nK48ePt5WLi4ttZefcHV988YWt/Nxzz1nLr7/+uq3u9NNPt5XPPPNMW3nkyJG2snP+Bd6biTdYcsIi38fkfAAAgKRF8AEAAFyVEsMuzkvcAGAgOIcnPvzwQ2t527ZttrqZM2faynPmzLGVPR6PreycXt15eazzctr333/fWr7uuutsdVdeeaWtnJWV1WN5sF5am8oGy9AX06sDAICUQPABAABcRfABAABclRIDgbt377aVYxlXApBc0tLSEt0Ei/O7xJmHsX//fmvZeRlueXm5rezM8Rg+fLit7HzdkdNSS9KXX35pK0fmaYwZM6bHfUc7VjL1OQaXyPex8zPSE858AAAAVxF8AAAAVxF8AAAAV6VEzodzevVkyvlgLBWITTJ9fp1tcZYj8y6OHDliq3NOh75jxw5becSIEbZyUVGRrezMEcnIyLCVI8fSI3NPpO55cDk5ObZyQUGBreycbn2wTO2N1MU7EAAAuIrgAwAAuIrgAwAAuIqcj35ysy3klwDuirwfi3MejvXr19vK7777rq3snAdkxowZtrIzB8R5P5bPP//cWl67dq2tbuvWrbbyqaeeaitPmzbNVs7NzRUwEJjnAwAApISYgo+6ujqdf/75GjlypIqKinT11VerubnZts3Ro0dVU1OjwsJC5ebmavbs2QoGg3FtNAAASF0xBR8bNmxQTU2NNm7cqHXr1qmjo0Pf+c53dOjQIWubBQsW6KWXXtKqVau0YcMG7du3T7NmzYp7wwEAQGqKKefDOe64fPlyFRUVqbGxURdffLH279+vP/zhD1qxYoUuvfRSSdKyZcs0fvx4bdy4URdccEFcGu285t3r9cZlv8kumXJdgMHImVcVmYeRnZ1tqxs/fryt7MzxKCwstJXz8/NtZedcG5H5Jc5jjxo1ylbnzBfx+Xy2sjPHI9p8JkBfJSTnoysI6JrQprGxUR0dHaqqqrK2GTdunMrKytTQ0NCfQwEAgEGiz1e7hMNhzZ8/X1OmTNGECRMkSYFAQFlZWd0ifJ/Pp0AgcNz9tLW1qa2tzSqHQqG+NgkAAKSAPp/5qKmp0bZt27Ry5cp+NaCurk5er9d6lJaW9mt/AAAgufXpzMe8efP08ssv64033tDo0aOt9cXFxWpvb1dra6vt7EcwGFRxcfFx97Vw4ULV1tZa5VAoFDUAcZ5FycvL68OrQKIwXwlSRWQehjPno+uMb5eLL77YVnbeu8X5vj927FiPx47MZZs6daqtrrKy8oTtlLrfJ8Z5bHI+kGgxnfkwxmjevHlavXq11q9f3y3BqqKiQsOGDVN9fb21rrm5WXv27JHf7z/uPj0ej/Ly8mwPAAAweMV05qOmpkYrVqzQiy++qJEjR1pnILxer3JycuT1enXLLbeotrZWBQUFysvL0x133CG/3x+3K10AAEBqiyn4WLJkiSTpkksusa1ftmyZbrzxRknSY489pvT0dM2ePVttbW2aPn26nnzyybg0FgAApL6Ygo/ejBNmZ2dr8eLFWrx4cZ8bFY3zXi+nn376gB0L8cd4M5JVT/N8OHM0wuGwrRxt3g6nzs7OEx7LWe88Vmam/avbmV8STX8+g+RsIVLkPB/R8pgicW8XAADgKoIPAADgKoIPAADgqj7PcJpIe/bssZXJIUAiMPY9+DjzNiJzKaLlfPRXTzkizmMl8juP71tEipyhnJwPAACQtAg+AACAqwg+AACAq1Iy58N5bxfGIJEIA/2+I6fEfc7cip7yMJzzdPQ3L8M5z0dHR8cJt3Xum+/A3uEzlTw48wEAAFxF8AEAAFxF8AEAAFyVkjkfznu7AIMR4/iJ19O9XZw5H079/ftF5pAM9LGGioHsp6GaTxJ5b5do79NInPkAAACuIvgAAACuIvgAAACuSsmcD+e9XWIZZ+qvoTquB/SV834pqSRyno9E3tvFze849M1Qzbsh5wMAAKQEgg8AAOCqlBx2SeSltkP11BrQVwM5ZDDQw6CRl9pGG2Zx1sc6LOOcXr2nfuvvsTC0JcNQaOJbAAAAhhSCDwAA4CqCDwAA4KqUzPkIBoO2MnkYseOSYQwGA/3ZT+T06pHHi5bTwXcgYhHPPKzIS21jyT3izAcAAHAVwQcAAHAVwQcAAHBVSuZ8fPLJJ7ayz+fr9XM9Hk9M9dnZ2T1uHzkmHG3baMd2Pj+Wtvb32M76WNoa67572les2zvnRoi272hti2X7WF9XtGPH8+/d335Bd85xcmfZOXdCrHkYPf39mV4dgw1nPgAAgKtiCj6WLFmis88+W3l5ecrLy5Pf79crr7xi1R89elQ1NTUqLCxUbm6uZs+e3e3KFAAAMLTFFHyMHj1aixYtUmNjo7Zu3apLL71UV111ld5//31J0oIFC/TSSy9p1apV2rBhg/bt26dZs2YNSMMBAEBqSjP9vEC8oKBAjz76qK655hp9/etf14oVK3TNNddIknbs2KHx48eroaFBF1xwQa/2FwqF5PV6+9MkAEmsP/lFbuf4ZGRkWMtd/2R1KS0ttZXHjBljKztzQJzHdr6WUChkKzc2NlrLEyZMsNWNHTvWVs7JyenW9p6O3Z8cMedzY/2b9CdXqj/vnf7urz/5gH1pW6qoqKiwlsPhsPbt26f9+/crLy+vx+f1Oeejs7NTK1eu1KFDh+T3+9XY2KiOjg5VVVVZ24wbN05lZWVqaGg44X7a2toUCoVsDwAAMHjFHHy89957ys3Nlcfj0W233abVq1frzDPPVCAQUFZWlvLz823b+3w+BQKBE+6vrq5OXq/Xejj/mwAAAINLzMHHGWecoaamJm3atEm33367qqurtX379j43YOHChdq/f7/12Lt3b5/3BQAAkl+/cz6qqqo0duxYXXfddZo2bZr+85//2M5+jBkzRvPnz9eCBQt6tT9yPgAAiJ+BnENo37591rIxRsaYgc356BIOh9XW1qaKigoNGzZM9fX1Vl1zc7P27Nkjv9/f38MAAIBBIqYZThcuXKiZM2eqrKxMBw4c0IoVK/T666/r1Vdfldfr1S233KLa2loVFBQoLy9Pd9xxh/x+f6+vdAEAAINfTMFHS0uLbrjhBn322Wfyer06++yz9eqrr+qyyy6TJD322GNKT0/X7Nmz1dbWpunTp+vJJ5+MqUHcGhoAgPiJ9rsaWR8Oh3vc1lkf+dyu5d78jvc75yPePvnkE654AQAgRe3du1ejR4/ucZukCz66JikxxqisrEx79+6NmriC/xcKhVRaWkq/xYA+6xv6LXb0Wd/Qb7FLRJ8ZY3TgwAGVlJR0m2TPKenuapuenq7Ro0dbk4113UcGsaHfYkef9Q39Fjv6rG/ot9i53We9vVqVu9oCAABXEXwAAABXJW3w4fF49Mtf/jLq5Ciwo99iR5/1Df0WO/qsb+i32CV7nyVdwikAABjckvbMBwAAGJwIPgAAgKsIPgAAgKsIPgAAgKuSNvhYvHixTjnlFGVnZ2vy5MnavHlzopuUNOrq6nT++edr5MiRKioq0tVXX63m5mbbNkePHlVNTY0KCwuVm5ur2bNnKxgMJqjFyWfRokVKS0vT/PnzrXX02fF9+umn+sEPfqDCwkLl5ORo4sSJ2rp1q1VvjNEDDzygUaNGKScnR1VVVdq5c2cCW5xYnZ2duv/++1VeXq6cnByNHTtWDz30ULd7YAz1PnvjjTd0xRVXqKSkRGlpaVqzZo2tvjd99NVXX2nu3LnKy8tTfn6+brnlFh08eNDFV+G+nvqto6ND99xzjyZOnKgRI0aopKREN9xwg+2291KS9JtJQitXrjRZWVnmj3/8o3n//ffNj3/8Y5Ofn2+CwWCim5YUpk+fbpYtW2a2bdtmmpqazHe/+11TVlZmDh48aG1z2223mdLSUlNfX2+2bt1qLrjgAnPhhRcmsNXJY/PmzeaUU04xZ599trnrrrus9fRZd1999ZUZM2aMufHGG82mTZvMxx9/bF599VXz4YcfWtssWrTIeL1es2bNGvPOO++YK6+80pSXl5sjR44ksOWJ8/DDD5vCwkLz8ssvm127dplVq1aZ3Nxc87vf/c7ahj4z5m9/+5u57777zAsvvGAkmdWrV9vqe9NHM2bMMOecc47ZuHGjefPNN82pp55q5syZ4/IrcVdP/dba2mqqqqrMc889Z3bs2GEaGhrMpEmTTEVFhW0fydBvSRl8TJo0ydTU1Fjlzs5OU1JSYurq6hLYquTV0tJiJJkNGzYYY/77Bhw2bJhZtWqVtc2//vUvI8k0NDQkqplJ4cCBA+a0004z69atM1OnTrWCD/rs+O655x5z0UUXnbA+HA6b4uJi8+ijj1rrWltbjcfjMX/5y1/caGLSufzyy83NN99sWzdr1iwzd+5cYwx9djzOH9He9NH27duNJLNlyxZrm1deecWkpaWZTz/91LW2J9LxgjanzZs3G0lm9+7dxpjk6bekG3Zpb29XY2OjqqqqrHXp6emqqqpSQ0NDAluWvPbv3y9JKigokCQ1Njaqo6PD1ofjxo1TWVnZkO/DmpoaXX755ba+keizE/nrX/+qyspKXXvttSoqKtJ5552np59+2qrftWuXAoGArd+8Xq8mT548ZPvtwgsvVH19vT744ANJ0jvvvKO33npLM2fOlESf9UZv+qihoUH5+fmqrKy0tqmqqlJ6ero2bdrkepuT1f79+5WWlqb8/HxJydNvSXdjuS+++EKdnZ3y+Xy29T6fTzt27EhQq5JXOBzW/PnzNWXKFE2YMEGSFAgElJWVZb3Zuvh8PgUCgQS0MjmsXLlS//znP7Vly5ZudfTZ8X388cdasmSJamtr9fOf/1xbtmzRnXfeqaysLFVXV1t9c7zP61Dtt3vvvVehUEjjxo1TRkaGOjs79fDDD2vu3LmSRJ/1Qm/6KBAIqKioyFafmZmpgoIC+vF/jh49qnvuuUdz5syxbi6XLP2WdMEHYlNTU6Nt27bprbfeSnRTktrevXt11113ad26dcrOzk50c1JGOBxWZWWlHnnkEUnSeeedp23btumpp55SdXV1gluXnJ5//nk9++yzWrFihc466yw1NTVp/vz5Kikpoc/gmo6ODn3/+9+XMUZLlixJdHO6Sbphl5NOOkkZGRndrjIIBoMqLi5OUKuS07x58/Tyyy/rtdde0+jRo631xcXFam9vV2trq237odyHjY2Namlp0Te/+U1lZmYqMzNTGzZs0BNPPKHMzEz5fD767DhGjRqlM88807Zu/Pjx2rNnjyRZfcPn9f/97Gc/07333qvrr79eEydO1A9/+EMtWLBAdXV1kuiz3uhNHxUXF6ulpcVWf+zYMX311VdDvh+7Ao/du3dr3bp11lkPKXn6LemCj6ysLFVUVKi+vt5aFw6HVV9fL7/fn8CWJQ9jjObNm6fVq1dr/fr1Ki8vt9VXVFRo2LBhtj5sbm7Wnj17hmwfTps2Te+9956ampqsR2VlpebOnWst02fdTZkypdtl3B988IHGjBkjSSovL1dxcbGt30KhkDZt2jRk++3w4cNKT7d/tWZkZCgcDkuiz3qjN33k9/vV2tqqxsZGa5v169crHA5r8uTJrrc5WXQFHjt37tTf//53FRYW2uqTpt9cS22NwcqVK43H4zHLly8327dvN7feeqvJz883gUAg0U1LCrfffrvxer3m9ddfN5999pn1OHz4sLXNbbfdZsrKysz69evN1q1bjd/vN36/P4GtTj6RV7sYQ58dz+bNm01mZqZ5+OGHzc6dO82zzz5rhg8fbv785z9b2yxatMjk5+ebF1980bz77rvmqquuGnKXjUaqrq42J598snWp7QsvvGBOOukkc/fdd1vb0Gf/vfLs7bffNm+//baRZH7729+at99+27oqozd9NGPGDHPeeeeZTZs2mbfeesucdtppg/5S2576rb293Vx55ZVm9OjRpqmpyfb70NbWZu0jGfotKYMPY4z5/e9/b8rKykxWVpaZNGmS2bhxY6KblDQkHfexbNkya5sjR46Yn/70p+ZrX/uaGT58uPne975nPvvss8Q1Ogk5gw/67PheeuklM2HCBOPxeMy4cePM0qVLbfXhcNjcf//9xufzGY/HY6ZNm2aam5sT1NrEC4VC5q677jJlZWUmOzvbfOMb3zD33Xef7cufPjPmtddeO+73WHV1tTGmd3305Zdfmjlz5pjc3FyTl5dnbrrpJnPgwIEEvBr39NRvu3btOuHvw2uvvWbtIxn6Lc2YiGn3AAAABljS5XwAAIDBjeADAAC4iuADAAC4iuADAAC4iuADAAC4iuADAAC4iuADAAC4iuADAAC4iuADAAC4iuADAAC4iuADAAC4iuADAAC46v8ATLAFn1ZVQTUAAAAASUVORK5CYII=\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {32: 2, 34: 1, 11: 1, 42: 1, 1: 2, 19: 1}\nBatch 0, Gradient norm: 15.1737\nEpoch 1, Batch 0/66, Loss: 34.7964\nAvg Blank Probability: 0.0148\nSample predictions: ['lv2a', 'elj3faja', 'kv-jaG']\nGround Truth (first 3): ['Up', '4Kv4', 'OFf']\nRaw outputs (first 3): [[12  5 11 11 19 12  6 47  1 27  1  1  1 50  1 19 56 10 10 56 10 34 27  1\n  32 33 32 10 43 42 34 32]\n [22 12 22  5 27 32  1 10 56  1 24 56  8  1  1 32 11  1 42 62  4 47 44 19\n  57 50  1  6  1 27 23 34]\n [55 10 63 34 19 56 47 11 48  1  1 42 24  1  1 43 12 32  1 10 34 56  1  1\n  48  1 22 12  1  1  1 11]]\nInput length: 15, Label lengths: [2, 4, 3]\nToken distribution (Batch 31): {56: 1, 17: 1}\nBatch 10, Gradient norm: 17.9900\nEpoch 1, Batch 10/66, Loss: 36.7388\nAvg Blank Probability: 0.0147\nSample predictions: ['Qj', '3a', 'asvlPj']\nGround Truth (first 3): ['X', 'K', '6eE']\nRaw outputs (first 3): [[43 56  1 12  6  1 36 43 29  6 13 30 12  4 25 12 10 63 14  1 29  6  4 56\n  34 11 42  6  1 43  1 56]\n [10  1 19  1  1 60 61  6  1 16  1  1 48 34 10  5 63 22 42 43 24 24  1  1\n  47 30 47  1 19  1 56 17]\n [ 1 34 22 10  1 32 12 10 43 56 42  1 10 32  2 50 22  6 12 62 47  1 43 34\n  22 30  6 43  1 47  1 10]]\nInput length: 15, Label lengths: [1, 1, 3]\nToken distribution (Batch 31): {4: 2, 1: 1, 5: 1}\nBatch 20, Gradient norm: 244.1730\nEpoch 1, Batch 20/66, Loss: 31.4936\nAvg Blank Probability: 0.0146\nSample predictions: ['UfADyQUlAj', 'HIFsFyml', 'sflVd2asa']\nGround Truth (first 3): ['u6XUi', 'qUYe', '*afWc']\nRaw outputs (first 3): [[47 34 19 14 24 42 12  6 47  1 10  6  1  1  1 12 22  8 63  6 63  6  1  6\n  56  1 56 45  1 32  1  4]\n [ 6 35 19 34 19 17 57 47  5 19 10 56 47  1 24 24  1 43  1 63 10 47 27 10\n   5 27 42 43  7 10 32  4]\n [27  0  6 32 22 34 32  1 16 19 12 11 56 11 47 50 35 47  5  1 25 47 22 10\n  13  1 16 10 13  6  1  1]]\nInput length: 15, Label lengths: [5, 4, 5]\nToken distribution (Batch 31): {4: 1, 47: 1, 33: 1, 35: 1}\nBatch 30, Gradient norm: 18.1004\nEpoch 1, Batch 30/66, Loss: 36.9031\nAvg Blank Probability: 0.0147\nSample predictions: ['HjyU', 'ayFLv8FrFH', 'HQaUHaFgda']\nGround Truth (first 3): ['9K', 'jEXUx', '8aW40']\nRaw outputs (first 3): [[34  1 34 10  1  6 50 20 56  5 35 32  1 27  4  1  1 48 63 21 19  1 10  1\n  34 10 34  6 11 10  1  4]\n [10 25 43 47  1 30 11  1 32  7  4 22 32  6 12 11  1 34 11 56 32 56 25  6\n  32 10 63 10 47 55 11 47]\n [25 32  1 34  7  1 63 50 60 14  1 47  1  1 30 19 11 63 11 61 63 34  4  6\n  32 36 41 34  1 10 47 33]]\nInput length: 15, Label lengths: [2, 5, 5]\nToken distribution (Batch 31): {10: 2, 11: 2, 12: 1, 1: 1, 50: 1, 5: 1, 35: 1, 19: 1}\nBatch 40, Gradient norm: 26.7990\nEpoch 1, Batch 40/66, Loss: 36.4066\nAvg Blank Probability: 0.0149\nSample predictions: ['Aj', 'kd', 'HaXyXI2']\nGround Truth (first 3): ['K', 'z', '5*m2']\nRaw outputs (first 3): [[27 11 34 19 34 34 11 19 34  1 34 48 10 12  1 43 22  1 11  2 11 11  1 56\n  10 55 10 10  1 10 32 10]\n [10  4  1 47 48 47 47  1 25 22 35  4  6  8 35  1 12 32  5  6  1  6 47 50\n  43  1 29 19 16 11  5 11]\n [29 55  1 20  1  1 47 56 63 34  1 59 10 32  1  1 27 32 10 43 35 12 32  6\n  11 10  1 10  1 19  1 11]]\nInput length: 15, Label lengths: [1, 1, 4]\nToken distribution (Batch 31): {1: 2, 42: 1, 10: 1}\nBatch 50, Gradient norm: 21.0954\nEpoch 1, Batch 50/66, Loss: 39.6180\nAvg Blank Probability: 0.0153\nSample predictions: ['a3', '3l', 'HUkHd3FU']\nGround Truth (first 3): ['0', '3', 'Ox9Z']\nRaw outputs (first 3): [[ 1 56 34  1 10 24  1 10 42 22  1 63 24 12  1 19 16 50 10 47 63  1 24 32\n  10 10 25 10  1 19 56  1]\n [56 12 47  6  1 42 22  6 32 24 22 47 10  5 22 33  1 19  4 23  1 48  1  1\n   5 27 12  2  6 12 12  1]\n [10 22 11  1  1 32 10  1 10  1 11  4  1 10 34 19 35 56 11  5  1  6 32 32\n   1 56  4 46  4  1 48 42]]\nInput length: 15, Label lengths: [1, 1, 4]\nToken distribution (Batch 31): {11: 1, 16: 1, 19: 1, 1: 1}\nBatch 60, Gradient norm: 1393.7267\nEpoch 1, Batch 60/66, Loss: 35.5535\nAvg Blank Probability: 0.0151\nSample predictions: ['jdP-XFd-sa', 'fsakeaVAPA', 'k8Fa']\nGround Truth (first 3): ['p46O6', 'oChe-', 'Jf']\nRaw outputs (first 3): [[10  6 11  6  1 34  4 46 56 12 35 24 43 43  1  1 10 22  1 11 22 47 33 34\n   4 34 25 63 35  1 11 11]\n [ 4 19 61 35  1 10  1 35 12 10 11 19 42  4  4  1  4 47 10 43  1 32 19 10\n   1  1 10 34 27  1 10 16]\n [42  1 32  4 34 25 56 32  1  4  1 12 42  1 50 10  9 22 19 34 27  1  1  1\n   1  1  1 12 19  4 12 19]]\nInput length: 15, Label lengths: [5, 5, 2]\nEpoch 1/20, Loss: 37.6908\nToken distribution (Batch 8): {1: 10}\nValidation Loss: 36.7360\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['Ems', 'Dt', '4z', 'OdrNd', '8QWWA']\nCurrent Learning Rate: 6.620929820988267e-07\nEpoch 2, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {1: 2, 43: 1, 34: 1}\nBatch 0, Gradient norm: 14.8117\nEpoch 2, Batch 0/66, Loss: 31.4835\nAvg Blank Probability: 0.0154\nSample predictions: ['pyjaQJea', 'UeFeaw', 'fPj3']\nGround Truth (first 3): ['VNbV', 'pn9', 'K3']\nRaw outputs (first 3): [[16 47  6  1 11  6  5  1 12 11  1 34 34 16  1 12 33 47 56 11 56 11 11 22\n  22 22  1 32 57 34 12  1]\n [25  5 42 37 12  1 10 11 56 22  1 12 33  1 50 10 12 10 10  1 10 57  1 10\n  35 42  1 16  5  4 50 43]\n [10 32 10  1  5 47 11 19 16 10 42 11 50  6 11 63 56 20 35  1 27 11  1  5\n   5 11  4 20  1  1 34  1]]\nInput length: 15, Label lengths: [4, 3, 2]\nToken distribution (Batch 31): {63: 1, 43: 1, 35: 1, 42: 1}\nBatch 10, Gradient norm: 19.9045\nEpoch 2, Batch 10/66, Loss: 38.6195\nAvg Blank Probability: 0.0155\nSample predictions: ['jI4vsf', 'eskjkaUk', 'a']\nGround Truth (first 3): ['CVN', '76rX', 'w']\nRaw outputs (first 3): [[10  5  1  4  1  1 34 42  1  1 11 12 10 11 12 34 11  4  1  5  6  1 10 47\n  12 10  1 19 14  4 10 63]\n [35 19  1 22 12 25 14 22  1 19  1  1 43  6 10 10 47 56  1 16 48 32  1 35\n   1 19  1 10  4 34 10 43]\n [57 11 19 12  1 11 10 10  9 31  1 22 11 32 35 10 47 11 10 34 35 34  4 11\n  33 25 48 27 32 43  1 35]]\nInput length: 15, Label lengths: [3, 4, 1]\nToken distribution (Batch 31): {34: 2, 6: 1, 1: 3, 32: 1, 19: 1, 10: 1, 7: 1}\nBatch 20, Gradient norm: 13.9126\nEpoch 2, Batch 20/66, Loss: 30.7857\nAvg Blank Probability: 0.0156\nSample predictions: ['ksajXHyVaC', 'aldjaVaj', 'yUajsjsH']\nGround Truth (first 3): ['4hA6-', 'qLqg', 'LE5c']\nRaw outputs (first 3): [[11  1 25  1 47 56  1 10  1  1 47 42 10 16 22 43 10 50 24 43 10 63 10 63\n  16 63 34 12 24 56  1 34]\n [19 12 47 34 22 56 50 22 47  1 12 10 42 10  1 10  1 21 27 38  4 56 11 10\n  16 32 30 46 55 43  1  6]\n [ 1  4  1 10 60  1 22  4  1 10  1 32  1 10 32 24  1 56  1 24  4 25 50 10\n  22  4 11 12  1 32  1  1]]\nInput length: 15, Label lengths: [5, 4, 4]\nToken distribution (Batch 31): {34: 2, 47: 1, 12: 1, 42: 1, 51: 1}\nBatch 30, Gradient norm: 22.1915\nEpoch 2, Batch 30/66, Loss: 39.8862\nAvg Blank Probability: 0.0159\nSample predictions: ['jaFsvUad', 'AasP', 'da']\nGround Truth (first 3): ['3CFh', 'TK', 'B']\nRaw outputs (first 3): [[10 27  4 10 11 35 42  6 47 42 11 11 10 14  1 34 63 63 47 63 47 19  1  1\n   4 11 63 34 34  1 35 34]\n [ 1  1  1 12 35 20 34 19  1 47 42 35 57 63  4 32 27 25 10 42  1 47  1 34\n  28  1 35 34 32 32 13 47]\n [32 19  1 57  1 19 34 32  1 28 42 32 11  1 56 32 10  9 38 56 32 11 27 47\n  11 11 10  1 34 22  1 12]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {25: 1, 43: 1, 4: 2, 30: 1, 10: 1, 1: 1, 12: 1, 19: 1, 55: 1}\nBatch 40, Gradient norm: 30.4993\nEpoch 2, Batch 40/66, Loss: 46.9363\nAvg Blank Probability: 0.0161\nSample predictions: ['g642Udxde', 'kPFp', 'aRk']\nGround Truth (first 3): ['-Bk62', 'Ad', '7-']\nRaw outputs (first 3): [[ 7 11  1  1 11 35 10  4 11 60 30  5 11 10  1  1 19  1 22 10  1 34  1  1\n  56 34 34 11 25 35 43 25]\n [ 7 42 44  1 12 56 10 34 32 10 47 11  1 63  6 42 34  4 10 34 19 27 16 27\n  19  1  5 33 42 34  5 43]\n [59 32 11 47 43 33  1  1  1 61 42  6 12  1 24  6 12 19  1 42  1  1 42  0\n  30 10  1 22 56 35 11  4]]\nInput length: 15, Label lengths: [5, 2, 2]\nToken distribution (Batch 31): {1: 2, 4: 1, 11: 1, 34: 1, 22: 1}\nBatch 50, Gradient norm: 15.7778\nEpoch 2, Batch 50/66, Loss: 32.4832\nAvg Blank Probability: 0.0164\nSample predictions: ['kakvgUav', 'aiXsaXU', 'Da']\nGround Truth (first 3): ['3uam', 'A6TT', 'E']\nRaw outputs (first 3): [[11  1 30 63 25  1 56  6 63 43 12  1  1  6  1 30  1 11  1 11  1 13 10 22\n  32 12 24  1 19 11  6  1]\n [ 1  9  1  6 47 56 47  1 34 19 10 12 19  1  1 50  0  9  4 34  4 43 10 12\n  32  2  5 11  4 35 10  1]\n [11 50 48 56 42  1  4 18  1 34  1 34  1  5  1 16 16  1 34 42  1 56  1 22\n  11 46 25 11 33 47 47  4]]\nInput length: 15, Label lengths: [4, 4, 1]\nToken distribution (Batch 31): {50: 1, 11: 1}\nBatch 60, Gradient norm: 266.5745\nEpoch 2, Batch 60/66, Loss: 42.7046\nAvg Blank Probability: 0.0167\nSample predictions: ['3ajn', 'FAPsjAkH', 'ajeFey8F']\nGround Truth (first 3): ['tP', 'orH2', 'jxG9']\nRaw outputs (first 3): [[56 32  1 28 14 10 19  1 34 11  6 16  6 56 10 56  1 34  1  1  6 34 19 12\n  56 47 12 42 10  1  4  0]\n [ 1 27 10 10  5  1  1  1  1 47 47  1  1 42  1 60 59  1  1  5  1 34  1 32\n  43 32  6  0 55 50  1 11]\n [10 42  5 55 57 32 25 28 34 34 48  1 50  1  6 32  5 47 50 10 43 47 33  1\n   1  6  1  5 47 48 48 10]]\nInput length: 15, Label lengths: [2, 4, 4]\nEpoch 2/20, Loss: 37.0417\nToken distribution (Batch 8): {1: 4}\nValidation Loss: 37.0868\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['nxOD', 'DYK', 'kXK', 'Bw', '*4VnO']\nCurrent Learning Rate: 1.3141026047511628e-06\nEpoch 3, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {11: 1, 47: 1, 1: 2}\nBatch 0, Gradient norm: 22.7006\nEpoch 3, Batch 0/66, Loss: 38.2405\nAvg Blank Probability: 0.0167\nSample predictions: ['fIDaEe', '3ajk', 'aj']\nGround Truth (first 3): ['NXr', 'Ii', 'Z']\nRaw outputs (first 3): [[ 6 56  1 34 34  1  4 63 12 10  4 24 47 32 57 56  4  5  1 43 34 10  1 35\n  35  6 22  4 10  4 12 11]\n [35  1 10 11  1 35 13 11 42 34  1  1 16 48  1  1 63  1 56 22 47 43 12 22\n  57  1  1 34  4 32 24 47]\n [30 10 34 36 34 56  1 35 32  1  5 19  1 11 34 28 43 28  1 56 50 56  1 55\n  47 56 35  1  4  0 57  1]]\nInput length: 15, Label lengths: [3, 2, 1]\nToken distribution (Batch 31): {56: 1, 35: 1, 24: 1, 4: 1, 18: 1, 6: 1, 27: 1, 1: 3}\nBatch 10, Gradient norm: 241.7781\nEpoch 3, Batch 10/66, Loss: 43.8721\nAvg Blank Probability: 0.0173\nSample predictions: ['yjs2jsja', 'aX', 'HekladQjA']\nGround Truth (first 3): ['2b6t', 'z', 'UM8yk']\nRaw outputs (first 3): [[25  1 34 12  5  0 10 24  5 63 34  1 50 11 19 61  1 25  6 10 35  1 51 11\n  63  1 11  1  6 34  4 56]\n [10 50 34 10 35 56  9 34  1 47 56 32 10 10 32 25  1 61  6 35  1 10 30 10\n   6  1 34  0 32 32 56 35]\n [19  1  5 10  1 22 42 35  1  9 34 32 11  1 32 12 34  1 24 56  4 11 63 32\n   1  6 32 24  0 25 10 24]]\nInput length: 15, Label lengths: [4, 1, 5]\nToken distribution (Batch 31): {1: 2, 42: 2, 34: 1, 22: 1}\nBatch 20, Gradient norm: 932.3429\nEpoch 3, Batch 20/66, Loss: 35.1023\nAvg Blank Probability: 0.0176\nSample predictions: ['fx-s3ka', 'jnaIxa', 'VFtaQ']\nGround Truth (first 3): ['AaGy', 'JnBX', 'QVW']\nRaw outputs (first 3): [[ 6 10 48 12  1  4  1  1  1 10  6 56 11 30 43  4 47 63 11 47 42 56 35 63\n  63 11 63 16  6 16  1  1]\n [24 14 32  7 34 22 11  1  6  1 22 57 32  6 56 35 35 28 11 30  4 55  1 12\n  30  1  4 32 16  1 10 42]\n [63  1 20 10 45 47 43  5 32 27 10  4 11 35 56  1  6  1 50 56 11 30  4 56\n   1 11  0 32 11  1  6 42]]\nInput length: 15, Label lengths: [4, 4, 3]\nToken distribution (Batch 31): {4: 1, 12: 1}\nBatch 30, Gradient norm: 18.1164\nEpoch 3, Batch 30/66, Loss: 32.9311\nAvg Blank Probability: 0.0179\nSample predictions: ['lF2kgU', '4kva', 'kA']\nGround Truth (first 3): ['yz2K', 'Pn', 'd']\nRaw outputs (first 3): [[12 57 11  4 12 27 14 19 12  4 11 12 34  5 56 42 24  1  1  1 25  1 11 32\n   1  1  1  1 44 10 34  4]\n [32 11 27 24 42  1 24 32  1 32 22 30  1 35 34 10 12 12 47  6 10 12 10 19\n   1 19  4  5  1  5 47 12]\n [32 22  7 19 11  9 10 32 61 51 61 32 22 10 56 32 46 59 28  1 34  1  1 24\n   0 35  1  1 10  1  1  1]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {47: 1, 22: 1}\nBatch 40, Gradient norm: 25.7426\nEpoch 3, Batch 40/66, Loss: 38.7953\nAvg Blank Probability: 0.0187\nSample predictions: ['Pjlx', 'vald3tUl', 'FG']\nGround Truth (first 3): ['HJ', 'lCXSq', 's']\nRaw outputs (first 3): [[42 22 32  1 34 47  4 48 34 32 34 56 32  1  1  4 10  6 34 26 10 47 63 12\n  12 61  1 54 63 34  1 47]\n [10  1 33  1 10 17 10  5 63  0  1 22 24 12 34 48  1  1 11 12 42  1 19  1\n   6 12 25 13 42 22  1 22]\n [12  1  1  0  6  0 33  4 35 36 32 17 10 51  1 19 35 43 11 32 43  1  1 32\n  10 32  1  0  1  6  1 47]]\nInput length: 15, Label lengths: [2, 5, 1]\nToken distribution (Batch 31): {1: 2, 50: 1, 34: 2, 11: 2, 27: 2, 19: 1}\nBatch 50, Gradient norm: 27.5964\nEpoch 3, Batch 50/66, Loss: 39.7892\nAvg Blank Probability: 0.0191\nSample predictions: ['qs', 'QjyE2Pwka', 'jI']\nGround Truth (first 3): ['h', 'HzLVh', 'P']\nRaw outputs (first 3): [[17 43 10 42 19  4  0  4 27  0  4  1 32  6 56 16 17  1 42 47 34 19 10  6\n   1 12 22 63 48 32 63  1]\n [19 10 35  1 47 50 10  1  1  0 25 47 11  5 42 35 47 43 50 11 27  0 56  1\n  63 47 22 27 34  1 34 50]\n [ 6 25 27  4 30 10 25 48  1  1  1  0 27  1 34 10 47  0  1 47  4  1 42  1\n  42 12 10 63  1  1  1 34]]\nInput length: 15, Label lengths: [1, 5, 1]\nToken distribution (Batch 31): {56: 1, 1: 3, 6: 2, 21: 1, 29: 1, 5: 1, 32: 1}\nBatch 60, Gradient norm: 30.3336\nEpoch 3, Batch 60/66, Loss: 36.3214\nAvg Blank Probability: 0.0197\nSample predictions: ['-fxU', 'a3OsafFV', 'jsUkaAH']\nGround Truth (first 3): ['x*', 'z2xI', 'ddhf']\nRaw outputs (first 3): [[63  1 10 47 34  1  4  1  4  0 35  0 19 47 10 33  1 11  0 34  0  1  0  7\n  10 22 12 11  6  4 47 56]\n [ 6 56 19 12  1  1 27 63  5 16  1 10 47 23 12 11 34  1 19 24 46 31  6 50\n  56  1 28 10  1 11  1  1]\n [24 41 47 48  0 30  4  0 10  1 19  5  4 11  0 11 10  1  1 13 35  1 35 47\n  32  4 47 34 35 34  1  1]]\nInput length: 15, Label lengths: [2, 4, 4]\nEpoch 3/20, Loss: 36.5203\nToken distribution (Batch 8): {1: 8}\nValidation Loss: 36.4694\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['XgM1X', 'UVE', 'oChe-', 'NjDj6', 'i9ud8']\nCurrent Learning Rate: 1.949837371817195e-06\nEpoch 4, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {47: 2, 18: 1, 19: 1, 10: 1, 27: 1, 55: 1, 35: 2, 9: 1}\nBatch 0, Gradient norm: 29.0152\nEpoch 4, Batch 0/66, Loss: 39.5264\nAvg Blank Probability: 0.0198\nSample predictions: ['IafvFAX', 'e2df', 'fH']\nGround Truth (first 3): ['r8lu', 'Xf', '-']\nRaw outputs (first 3): [[35  5  0 56 63 16 47  1  1  1  1 61  4  4 27 35  1 56 10 10 20  1 11 30\n  19  1 22  1  1 63  0 47]\n [ 1 55 34 35 34  7 10 47 34 56 35 42 12 47 32 34  4 10  0 32 56 32 10 47\n   0 47 11 25 30 12 10  0]\n [ 6  4  1 19  4 48  0  1  0 43 40  1  1  1 19 12 11  1 34 35  1 10 63 61\n  19 32  1 14  0 35  1 19]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {6: 1, 47: 1}\nBatch 10, Gradient norm: 32.3440\nEpoch 4, Batch 10/66, Loss: 40.6138\nAvg Blank Probability: 0.0208\nSample predictions: ['HFrUHU3v', 'va', 'fadja2a']\nGround Truth (first 3): ['zypb', 'P0', 'hrNK']\nRaw outputs (first 3): [[34 22  0 32  1 30 42  4  6 10 32 12 42 12  1 10 63  6 63 63 11 32 12 34\n   1 35  1  1  0  1 10  6]\n [32  1  1  1 22  1 47 32  0  4 43 34 19 47 10  1 11  5  6  0 24  1 12  1\n  12 50  6 12 34 12 32  0]\n [18  1  4 24 32 22  1  5  1  0  0 34 20 10  0  0  0 34  6  0  1  1  7  1\n   0 34 12 34 42 11 16  1]]\nInput length: 15, Label lengths: [4, 2, 4]\nToken distribution (Batch 31): {1: 2, 10: 1, 22: 1}\nBatch 20, Gradient norm: 27.7335\nEpoch 4, Batch 20/66, Loss: 35.4300\nAvg Blank Probability: 0.0213\nSample predictions: ['-UlI', 'tHQauBaisa', 'avVQ']\nGround Truth (first 3): ['WJ', 'tgEPL', '-k']\nRaw outputs (first 3): [[63 20  1 25  0 34 27 19 13 10 47 33 34 47  1 12  0  1 24  6  1 12 11 27\n  28  1  6 22 43 10  1  1]\n [47 34 22  6  0 63 11 24 11  1 22  4  1 47  1  1 56 47 10 33  1  0  1 22\n  25  1 34  1 61 34  0 10]\n [12 43  0  0  0  4  6 20  0 32  8  4 34  7 47  1 10 12  1 26 16  1 11 47\n  34  1 34  6 32 30  1  0]]\nInput length: 15, Label lengths: [2, 5, 2]\nToken distribution (Batch 31): {1: 1, 56: 1, 27: 1, 34: 2, 9: 1}\nBatch 30, Gradient norm: 28.2137\nEpoch 4, Batch 30/66, Loss: 36.2449\nAvg Blank Probability: 0.0223\nSample predictions: ['Asa3a3', 'aUjy', 'fFaHaA']\nGround Truth (first 3): ['DwBi', 'G5', 'SqlG']\nRaw outputs (first 3): [[27  1  6  1 23 34 32  1 10 34 47 10  0  4  0 25 22 56  0  1  0 20 42 48\n  10 25  1 11 56 12  4  1]\n [19 47  6  6 19 43  0 11 47  0  1 33 13 22 12 10  0 22  1 34 27 12 19 13\n  34  1 12 10  1  6 19 56]\n [ 1 10  0  1 19  0  0  0 10  0  5  1 10  0 56 22  1 27  0  1 19 34  4 63\n   0 12 32 41 34 11  0 27]]\nInput length: 15, Label lengths: [4, 2, 4]\nToken distribution (Batch 31): {14: 1, 1: 1}\nBatch 40, Gradient norm: 86.4801\nEpoch 4, Batch 40/66, Loss: 35.7849\nAvg Blank Probability: 0.0232\nSample predictions: ['VA', 'fF', 'aHsH']\nGround Truth (first 3): ['o', 'D', 'ce']\nRaw outputs (first 3): [[48  6  1 10 32 22  1  1 50 43 32 10 32 24  4  1 27 32 47  1 29 50 11 34\n  34  0 12 63  0  0  0 14]\n [27 32 34  5  0 11  0 10 24  0 32 47  0 56  0  0 48 10 24  0  0  1 22  1\n   0 56 34  0 10 32  1  1]\n [ 5  0 19  0 57  1  0 42 30 56  1 24  1 56 12  1  1 34  0 36  1 42  0 11\n  29 22  0  1  0  0  1  1]]\nInput length: 15, Label lengths: [1, 1, 2]\nToken distribution (Batch 31): {10: 1, 1: 2, 11: 1, 6: 2, 47: 1, 26: 1}\nBatch 50, Gradient norm: 81.8872\nEpoch 4, Batch 50/66, Loss: 38.8911\nAvg Blank Probability: 0.0245\nSample predictions: ['kdx7faEH', 'jaF', 'jp']\nGround Truth (first 3): ['V6lI', '55', '3']\nRaw outputs (first 3): [[11 10 10 30  6 10 25 47 25  1  0  5 25 19  6  0  1  0  0 16 22 47  0 56\n  12  4  0  0  0  0 47 10]\n [ 0  1 16  0  0  0 48  0 34 47  0  1  0  4  0 34 10  6  0  0  7 34  0  1\n   1  0 10 20 22  0  0  1]\n [24 32  0  0 34  1 10 20 10 63 12  0 32 42  0  0 10 10 12  0  0 11  0 56\n  12 11  0 19 22  0 34  1]]\nInput length: 15, Label lengths: [4, 2, 1]\nToken distribution (Batch 31): {35: 2, 9: 1, 22: 1}\nBatch 60, Gradient norm: 24.8371\nEpoch 4, Batch 60/66, Loss: 31.8142\nAvg Blank Probability: 0.0260\nSample predictions: ['aXHAa8', 'laXUjtakjF', 'lHiaFHav']\nGround Truth (first 3): ['TDXV', 'jfCBl', 'vOUX']\nRaw outputs (first 3): [[ 1  0 12 12 34  0 56 34  0 11 11  0 33  0 48  0  1 10 34 10 11 10  5 10\n   6 33 57 22 47 27  1 35]\n [ 1  1 34 10  0  0  0  1 11  0 63 32  0 56  0 47  1  5  0  0  7  0 47 34\n   0 25 12  1  0  1 63 35]\n [50 50  0  0  0 48  0  1  0 27  0  0  1 22  1 32  0  0 11  0  0  0 19 10\n   0 34 48  1  0  7  0  0]]\nInput length: 15, Label lengths: [4, 5, 4]\nEpoch 4/20, Loss: 35.7199\nToken distribution (Batch 8): {1: 10}\nValidation Loss: 36.5853\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['sIU', 'Dt', 'w19', 'h44Q', 'VjYzO']\nCurrent Learning Rate: 2.5688935140233206e-06\nEpoch 5, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {35: 1, 11: 1}\nBatch 0, Gradient norm: 35.0110\nEpoch 5, Batch 0/66, Loss: 36.6920\nAvg Blank Probability: 0.0269\nSample predictions: ['kHiFajak', 'kAf3kQ', 'alafsHUHa']\nGround Truth (first 3): ['*m4W', 'FZD', '*glGz']\nRaw outputs (first 3): [[11 11  1 63  0 11 50  0  0 13  0 11 17 14  6 22 61  0  0  0  0 10  0  1\n   0  1  0  4 32 57 12 35]\n [34 27 12 12 10  0 10 42 24 34  0 27 32  1  0  4 28  0  1  0  1  0 16 11\n   0 63  0  0  0 20  0 11]\n [ 0  0  0  0  1  0  0  0  0 47  6  0  1 35  0 47  0  0  0  0  0  0  0 50\n  51  0 32  0 12 34 27 63]]\nInput length: 15, Label lengths: [4, 3, 5]\nToken distribution (Batch 31): {23: 1, 56: 1}\nBatch 10, Gradient norm: 25.6357\nEpoch 5, Batch 10/66, Loss: 30.7180\nAvg Blank Probability: 0.0287\nSample predictions: ['kaUsP3ailI', 'aUjljcA3lr', 'kCRIkj']\nGround Truth (first 3): ['4ylL0', 'xDoww', 'Azb']\nRaw outputs (first 3): [[ 0  0 11  0 50  0 11  1  1 12 42  0  0 11  0  0 34  1 34  0 34  1  0  1\n  32 34 35  1 24 35  0 23]\n [ 0 47 29  1 25  0  0  0  0 47  0  0  0  0  0  0  0  1 24 34 12  0  0  1\n   0  0  0  6  1  0  0 56]\n [47  0  0  0  0 34 34 32  0  0  0  0  0  0  0  0  0  1 53  0 42 30  0  0\n  27  0  0  0  0  1 11  0]]\nInput length: 15, Label lengths: [5, 5, 3]\nToken distribution (Batch 31): {1: 2}\nBatch 20, Gradient norm: 32.1045\nEpoch 5, Batch 20/66, Loss: 34.1304\nAvg Blank Probability: 0.0297\nSample predictions: ['aUHceas', 'fvHa', '3HaOialXk']\nGround Truth (first 3): ['FqIm', 'by', '-RY61']\nRaw outputs (first 3): [[ 1  6  0 63  0 13  0 22  1  0 35  0 43  0 14  1 47  1  0 10  4  0 10  0\n   4  4  0 59 11 38  0  0]\n [ 0 22  0  0  0  1  0 32  0  0  0 48  0  0  0  1  0  0  0  0 47  0  0  0\n   0  0  0  0 12  1  0  0]\n [ 0 34  0  0  0  0  1  0 34  0  0  0  0  0 12  4 12  0  1 34  1  0 27  0\n   0  0  0  1 42 32  0  0]]\nInput length: 15, Label lengths: [4, 2, 5]\nToken distribution (Batch 31): {4: 1, 43: 1, 22: 1, 32: 2, 12: 1, 10: 1, 9: 1, 5: 1, 19: 1}\nBatch 30, Gradient norm: 37.5236\nEpoch 5, Batch 30/66, Loss: 35.6982\nAvg Blank Probability: 0.0324\nSample predictions: ['kHXaJlHU', 'UlIU', 'Hkja4vsFkH']\nGround Truth (first 3): ['uJJX-', 'Pv', 'xM7tm']\nRaw outputs (first 3): [[ 0  0 34  0 10 11 12 50  0  0 11  0  0  0  0  1 34  0  0  1  4  0  0 32\n   0  0  0  0  0  0  0  4]\n [ 0 12  0  0  0  4  0  6 34  0 29  0  0  0  0  0  0  0  0  0 27  0  0  0\n   0  0  1  0  0 24  0 43]\n [34  0  0  0  0  0  1  0  0  0  0  0  0 25  0  0  0  1  0  0 34  0  0  0\n  11  0  0  0  0  0  0 22]]\nInput length: 15, Label lengths: [5, 2, 5]\nToken distribution (Batch 31): {22: 1, 12: 1, 24: 1, 19: 1}\nBatch 40, Gradient norm: 178.7263\nEpoch 5, Batch 40/66, Loss: 32.0512\nAvg Blank Probability: 0.0344\nSample predictions: ['ZHFgsIla', 'aFA3qajH', 'kftDIH']\nGround Truth (first 3): ['ZXrt', '7SGL', 'Q5C']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0 34  0  0  0 12 47 44 19  0  6 24  0  0  0  0 12  0\n  34  0  0 42  0  0 17 22]\n [ 0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0 29 34  0  0  0  0  0 34\n   1  0  0  0  0 32  0  0]\n [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  32  0  0  0  0 50  0  0]]\nInput length: 15, Label lengths: [4, 4, 3]\nToken distribution (Batch 31): {22: 2, 32: 1, 35: 1, 19: 1, 1: 1, 12: 1, 34: 1}\nBatch 50, Gradient norm: 32.7235\nEpoch 5, Batch 50/66, Loss: 30.1693\nAvg Blank Probability: 0.0374\nSample predictions: ['JIUH', '4Q', 'ajHaP']\nGround Truth (first 3): ['36', 'p', 'L2B']\nRaw outputs (first 3): [[ 0  0  1  0  0 32  0  1 10  0  0  0  0 12 13  0  0  1 48  4  0 56  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0 63  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  1  0  0  0  0  0  5  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [2, 1, 3]\nToken distribution (Batch 31): {1: 3, 34: 1, 25: 1, 47: 2, 7: 1}\nBatch 60, Gradient norm: 37.1241\nEpoch 5, Batch 60/66, Loss: 31.3752\nAvg Blank Probability: 0.0412\nSample predictions: ['pFVU', 'vPjHiePO-l', 'sFHXleGHai']\nGround Truth (first 3): ['4z', 'b4YLU', 'VjYzO']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 36 50 10  0  1  0  0  0\n   0  0 11  0  0  0  6  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [2, 5, 5]\nEpoch 5/20, Loss: 33.5794\nToken distribution (Batch 8): {1: 8}\nValidation Loss: 37.6900\nValidation Predictions: ['a', 'a', 'a', 'a', 'a']\nGround Truth: ['rFyEG', '8', 'A5', 'F*y3i', 'K']\nCurrent Learning Rate: 3.1704304652404295e-06\nEpoch 6, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {6: 1, 11: 1, 1: 2, 50: 1, 35: 1}\nBatch 0, Gradient norm: 115.2911\nEpoch 6, Batch 0/66, Loss: 34.1658\nAvg Blank Probability: 0.0422\nSample predictions: ['faYa', 'jHwVal2aIH', 'HVea']\nGround Truth (first 3): ['4F', 'tKd4F', 'IC']\nRaw outputs (first 3): [[ 0 10  0  0  0  0  0  0 34  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [2, 5, 2]\nToken distribution (Batch 31): {34: 1, 4: 1, 50: 1, 47: 1}\nBatch 10, Gradient norm: 47.8229\nEpoch 6, Batch 10/66, Loss: 30.6105\nAvg Blank Probability: 0.0471\nSample predictions: ['aduU', 'FHF3sla', 'vFm']\nGround Truth (first 3): ['p9', '7SGL', 'yN']\nRaw outputs (first 3): [[ 0  0 22  0  0  0  0  0  0  0  0  0  0 63  0  1  0  0  0  0  0  0 32  0\n   0  0  0 47  0  0  0 34]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [2, 4, 2]\nToken distribution (Batch 31): {12: 1, 5: 1, 35: 1, 34: 4, 32: 2, 1: 1}\nBatch 20, Gradient norm: 101.0199\nEpoch 6, Batch 20/66, Loss: 31.1423\nAvg Blank Probability: 0.0515\nSample predictions: ['0IlP', 'dfUl', 'fjAaH']\nGround Truth (first 3): ['Os7', 'RS', '7lDV']\nRaw outputs (first 3): [[ 0  0  0  0  0  0  0  0 10  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [3, 2, 4]\nToken distribution (Batch 31): {34: 2, 5: 1, 27: 1, 0: 1, 9: 1, 6: 1, 55: 1}\nBatch 30, Gradient norm: 69.9785\nEpoch 6, Batch 30/66, Loss: 31.0320\nAvg Blank Probability: 0.0596\nSample predictions: ['HaP', 'HAHahH', 'dk9FHdv']\nGround Truth (first 3): ['kX', 'uHJ', 'AaGy']\nRaw outputs (first 3): [[ 0  0  4  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   0  0  0  0  0  0  0  0]]\nInput length: 15, Label lengths: [2, 3, 4]\nToken distribution (Batch 31): {6: 1, 34: 1, 0: 2}\nBatch 40, Gradient norm: 43.3611\nEpoch 6, Batch 40/66, Loss: 26.9290\nAvg Blank Probability: 0.0674\nSample predictions: ['FAsi', 'fIjal', 'a3I4']\nGround Truth (first 3): ['S65', '8NA', 'dX*TW']\nRaw outputs (first 3): [[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 3, 5]\nToken distribution (Batch 31): {10: 1, 13: 1, 0: 2, 19: 1, 1: 1}\nBatch 50, Gradient norm: 60.3145\nEpoch 6, Batch 50/66, Loss: 32.3172\nAvg Blank Probability: 0.0780\nSample predictions: ['a3m', 'XUdHmU', 'ak']\nGround Truth (first 3): ['sLL', 'c6jM0', 'I']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 5, 1]\nToken distribution (Batch 31): {50: 2, 0: 4}\nBatch 60, Gradient norm: 59.0043\nEpoch 6, Batch 60/66, Loss: 29.0172\nAvg Blank Probability: 0.0910\nSample predictions: ['g', 'sHA', 'AI']\nGround Truth (first 3): ['R', 'GHo', 'YT']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 3, 2]\nEpoch 6/20, Loss: 30.5529\nToken distribution (Batch 8): {12: 1, 1: 5}\nValidation Loss: 34.4039\nValidation Predictions: ['Ha', 'la', 'la', 'la', 'la']\nGround Truth: ['CFS', 'efa8', 'Z*', 'JkOF3', '55Gq']\nCurrent Learning Rate: 3.753105077304556e-06\nEpoch 7, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {1: 1, 0: 1}\nBatch 0, Gradient norm: 60.0532\nEpoch 7, Batch 0/66, Loss: 29.8764\nAvg Blank Probability: 0.0974\nSample predictions: ['yis', 'Hlrl', 'ReY']\nGround Truth (first 3): ['jNX', '68hng', 'Pv']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 5, 2]\nToken distribution (Batch 31): {47: 1, 17: 1, 0: 7, 25: 1}\nBatch 10, Gradient norm: 86.9718\nEpoch 7, Batch 10/66, Loss: 29.0414\nAvg Blank Probability: 0.1150\nSample predictions: ['a', 'ay', 'lf']\nGround Truth (first 3): ['E0V2k', 'VudB', 'Q*']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 4, 2]\nToken distribution (Batch 31): {19: 1, 0: 7}\nBatch 20, Gradient norm: 54.3851\nEpoch 7, Batch 20/66, Loss: 23.2167\nAvg Blank Probability: 0.1423\nSample predictions: ['U', 'a', 'U']\nGround Truth (first 3): ['Ufo', 'a', 'KV2']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 1, 3]\nToken distribution (Batch 31): {19: 1, 32: 1, 0: 4}\nBatch 30, Gradient norm: 278.9072\nEpoch 7, Batch 30/66, Loss: 24.1749\nAvg Blank Probability: 0.1724\nSample predictions: ['R', 'a', 'a']\nGround Truth (first 3): ['U7Dtf', 'ZxKU', 'dWi3']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 4, 4]\nToken distribution (Batch 31): {0: 2}\nBatch 40, Gradient norm: 176.0908\nEpoch 7, Batch 40/66, Loss: 22.4290\nAvg Blank Probability: 0.2025\nSample predictions: ['d', '<empty>', 'c']\nGround Truth (first 3): ['uJJX-', 'wSqWA', 'xl1Yx']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 5, 5]\nToken distribution (Batch 31): {34: 1, 0: 1}\nBatch 50, Gradient norm: 679.3298\nEpoch 7, Batch 50/66, Loss: 22.7141\nAvg Blank Probability: 0.2435\nSample predictions: ['H', 'l', '<empty>']\nGround Truth (first 3): ['nQD9O', 'L2B', 'bFM5']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 3, 4]\nToken distribution (Batch 31): {0: 8}\nBatch 60, Gradient norm: 87.4530\nEpoch 7, Batch 60/66, Loss: 21.1316\nAvg Blank Probability: 0.3042\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['RD6', 'iF', 'n3jVe']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 2, 5]\nEpoch 7/20, Loss: 24.4435\nToken distribution (Batch 8): {12: 4}\nValidation Loss: 32.8371\nValidation Predictions: ['l', 'l', 'l', 'l', 'l']\nGround Truth: ['Yvw', 'j4CGh', 'L', 'PuL', 'Ocf0']\nCurrent Learning Rate: 4.314960635550496e-06\nEpoch 8, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {0: 4}\nBatch 0, Gradient norm: 378668.9062\nEpoch 8, Batch 0/66, Loss: 19.2674\nAvg Blank Probability: 0.3278\nSample predictions: ['<empty>', '<empty>', 'B']\nGround Truth (first 3): ['MJOdz', '05', '5I8']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 2, 3]\nToken distribution (Batch 31): {0: 2}\nBatch 10, Gradient norm: 62.8534\nEpoch 8, Batch 10/66, Loss: 18.6444\nAvg Blank Probability: 0.3932\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['t0K4D', 'TK', 'ALMJ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 2, 4]\nToken distribution (Batch 31): {0: 8}\nBatch 20, Gradient norm: 479.6618\nEpoch 8, Batch 20/66, Loss: 17.3288\nAvg Blank Probability: 0.4712\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['T-F', '9W', 'IG']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 2, 2]\nToken distribution (Batch 31): {0: 8}\nBatch 30, Gradient norm: 112.0935\nEpoch 8, Batch 30/66, Loss: 15.8015\nAvg Blank Probability: 0.5537\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['KqsU', 'F6Y', '8MW']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 3, 3]\nToken distribution (Batch 31): {0: 2}\nBatch 40, Gradient norm: 48.1746\nEpoch 8, Batch 40/66, Loss: 15.4147\nAvg Blank Probability: 0.6213\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['lAV', '5Lpu', 'L-eej']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 4, 5]\nToken distribution (Batch 31): {0: 10}\nBatch 50, Gradient norm: 98.4978\nEpoch 8, Batch 50/66, Loss: 13.9407\nAvg Blank Probability: 0.6979\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['G', 'Q*', 'K']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 2, 1]\nToken distribution (Batch 31): {0: 10}\nBatch 60, Gradient norm: 22.9190\nEpoch 8, Batch 60/66, Loss: 13.9394\nAvg Blank Probability: 0.7662\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['l', 'ZrSBq', 'c']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 5, 1]\nEpoch 8/20, Loss: 16.2463\nToken distribution (Batch 8): {0: 8}\nValidation Loss: 27.5991\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['r*dU-', 'On', '2hT', 'iE3z5', 'q']\nCurrent Learning Rate: 4.853252642935678e-06\nEpoch 9, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {0: 6}\nBatch 0, Gradient norm: 9383.9600\nEpoch 9, Batch 0/66, Loss: 13.1536\nAvg Blank Probability: 0.8041\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['HT', 'Hlb', 'L7Vk']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 3, 4]\nToken distribution (Batch 31): {0: 10}\nBatch 10, Gradient norm: 8.0678\nEpoch 9, Batch 10/66, Loss: 13.4841\nAvg Blank Probability: 0.8561\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['ad', 'mQxk', 'YhVSr']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 4, 5]\nToken distribution (Batch 31): {0: 2}\nBatch 20, Gradient norm: 115871.8047\nEpoch 9, Batch 20/66, Loss: 13.4788\nAvg Blank Probability: 0.8851\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['0*T', '-zp9', 'DwBi']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 4, 4]\nToken distribution (Batch 31): {0: 8}\nBatch 30, Gradient norm: 143.0387\nEpoch 9, Batch 30/66, Loss: 13.5055\nAvg Blank Probability: 0.8817\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['dm', 's0', 'K2s']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 2, 3]\nToken distribution (Batch 31): {0: 2}\nBatch 40, Gradient norm: 16.9647\nEpoch 9, Batch 40/66, Loss: 13.7501\nAvg Blank Probability: 0.8816\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['z', 'g8X', 'Z']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 3, 1]\nToken distribution (Batch 31): {0: 2}\nBatch 50, Gradient norm: 12.3080\nEpoch 9, Batch 50/66, Loss: 13.5392\nAvg Blank Probability: 0.8734\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['KbANC', 'xj3G', 'T5Y']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 4, 3]\nToken distribution (Batch 31): {0: 8}\nBatch 60, Gradient norm: 50.4948\nEpoch 9, Batch 60/66, Loss: 13.4826\nAvg Blank Probability: 0.8668\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['8', 'w1', 'Mk']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 2, 2]\nEpoch 9/20, Loss: 13.4694\nToken distribution (Batch 8): {0: 2}\nValidation Loss: 26.0831\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['*B', 'EG', 'L2B', 'XSpH', 'DK']\nCurrent Learning Rate: 5.3641803596496334e-06\nEpoch 10, Filtered data size: 2604, Sample labels: ['qV8i', 'i', 'PnB']\nTrain size: 2083, Val size: 521\nToken distribution (Batch 31): {0: 8}\nBatch 0, Gradient norm: 36.4926\nEpoch 10, Batch 0/66, Loss: 13.3124\nAvg Blank Probability: 0.8573\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['3U6', 'Nsc6', 'p']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 4, 1]\nToken distribution (Batch 31): {0: 4}\nBatch 10, Gradient norm: 7827813.5000\nEpoch 10, Batch 10/66, Loss: 13.3949\nAvg Blank Probability: 0.8651\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['ahDQZ', 'A', 'f']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 1, 1]\nToken distribution (Batch 31): {0: 6}\nBatch 20, Gradient norm: 25.7416\nEpoch 10, Batch 20/66, Loss: 13.2088\nAvg Blank Probability: 0.8566\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['o68L', 'bneT', 'O5al']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 4, 4]\nToken distribution (Batch 31): {0: 4}\nBatch 30, Gradient norm: 30.2539\nEpoch 10, Batch 30/66, Loss: 13.5112\nAvg Blank Probability: 0.8613\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['j-D*x', 'c8sos', 'FLP']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 5, 3]\nToken distribution (Batch 31): {0: 6}\nBatch 40, Gradient norm: 56680732.0000\nEpoch 10, Batch 40/66, Loss: 13.2517\nAvg Blank Probability: 0.8548\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['hACa', '5Za', 'oiUh']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 3, 4]\nToken distribution (Batch 31): {0: 2}\nBatch 50, Gradient norm: 100245584.0000\nEpoch 10, Batch 50/66, Loss: 13.0449\nAvg Blank Probability: 0.8533\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['jY*7c', '5', 's0']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 1, 2]\nToken distribution (Batch 31): {0: 2}\nBatch 60, Gradient norm: 2171541.5000\nEpoch 10, Batch 60/66, Loss: 13.2875\nAvg Blank Probability: 0.8388\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['pRXvu', 'oZROy', 'n4LAz']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 5, 5]\nEpoch 10/20, Loss: 13.3783\nToken distribution (Batch 8): {0: 2}\nValidation Loss: 26.8693\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['Ck', 'R', 'En', 'jAh4', 'Du38J']\nCurrent Learning Rate: 5.842470688388886e-06\nEpoch 11, Filtered data size: 3620, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {0: 8}\nBatch 0, Gradient norm: 6.4993\nEpoch 11, Batch 0/91, Loss: 13.3297\nAvg Blank Probability: 0.8334\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['uCYo', 'P', 'wx-je']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 1, 5]\nToken distribution (Batch 31): {0: 4}\nBatch 10, Gradient norm: 6.1158\nEpoch 11, Batch 10/91, Loss: 13.5718\nAvg Blank Probability: 0.8421\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['RqAgCd', 'biTha', '93']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 5, 2]\nToken distribution (Batch 31): {0: 8}\nBatch 20, Gradient norm: 242310224.0000\nEpoch 11, Batch 20/91, Loss: 13.1056\nAvg Blank Probability: 0.8472\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['gSGYn-', 'T9vty', '4haKGSo']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 5, 7]\nToken distribution (Batch 31): {0: 10}\nBatch 30, Gradient norm: 10.7850\nEpoch 11, Batch 30/91, Loss: 13.5173\nAvg Blank Probability: 0.8574\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Oqb511L', 'P', 'SF']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 1, 2]\nToken distribution (Batch 31): {0: 14}\nBatch 40, Gradient norm: 83.1509\nEpoch 11, Batch 40/91, Loss: 13.3305\nAvg Blank Probability: 0.8522\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['aIZk9O', '30Ez6', 'K8vUvMN']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 5, 7]\nToken distribution (Batch 31): {0: 8}\nBatch 50, Gradient norm: 72428.1328\nEpoch 11, Batch 50/91, Loss: 13.6349\nAvg Blank Probability: 0.8818\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['7ZZ', 'uWA78n0', 'dNm']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 7, 3]\nToken distribution (Batch 31): {0: 6}\nBatch 60, Gradient norm: 397.0757\nEpoch 11, Batch 60/91, Loss: 13.3076\nAvg Blank Probability: 0.8820\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['I*0', 'l', '3uam']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 1, 4]\nToken distribution (Batch 31): {0: 2}\nBatch 70, Gradient norm: 28290546.0000\nEpoch 11, Batch 70/91, Loss: 13.9061\nAvg Blank Probability: 0.8948\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['hQ', 'iikgJBB', 'ZyI9z8r']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 7, 7]\nToken distribution (Batch 31): {0: 10}\nBatch 80, Gradient norm: 23.6152\nEpoch 11, Batch 80/91, Loss: 14.0092\nAvg Blank Probability: 0.8998\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['3', 'd40XO', 'UeXm8Z']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 5, 6]\nToken distribution (Batch 15): {0: 10}\nBatch 90, Gradient norm: 65182231429120.0000\nEpoch 11, Batch 90/91, Loss: 14.0733\nAvg Blank Probability: 0.9060\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['HL', '9vQ54v5', 'TBnHM5*']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 7, 7]\nEpoch 11/20, Loss: 13.6024\nToken distribution (Batch 19): {0: 12}\nValidation Loss: 22.2619\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['bLBIm9', 'h65z19', 'Noe', 'U-xr4', 'dh8hotR']\nCurrent Learning Rate: 8.592089814637925e-06\nEpoch 12, Filtered data size: 3620, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {0: 2}\nBatch 0, Gradient norm: 8761979904.0000\nEpoch 12, Batch 0/91, Loss: 14.2063\nAvg Blank Probability: 0.9113\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['h7epS8M', 'O-ir', 'c']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 4, 1]\nToken distribution (Batch 31): {0: 14}\nBatch 10, Gradient norm: 26.0705\nEpoch 12, Batch 10/91, Loss: 14.2177\nAvg Blank Probability: 0.9070\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['QGLe0', 'er', 'lm']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 2, 2]\nToken distribution (Batch 31): {0: 14}\nBatch 20, Gradient norm: 137788384.0000\nEpoch 12, Batch 20/91, Loss: 14.5699\nAvg Blank Probability: 0.9199\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['kHfqx', 'wn4a7rf', '1N']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 7, 2]\nToken distribution (Batch 31): {0: 10}\nBatch 30, Gradient norm: 34.6120\nEpoch 12, Batch 30/91, Loss: 14.8673\nAvg Blank Probability: 0.9232\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Yvw', 'rT', 'yGW']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 2, 3]\nToken distribution (Batch 31): {0: 8}\nBatch 40, Gradient norm: 35.2108\nEpoch 12, Batch 40/91, Loss: 14.7242\nAvg Blank Probability: 0.9274\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['q6gTu', 'Ocf0', '02']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 4, 2]\nToken distribution (Batch 31): {0: 6}\nBatch 50, Gradient norm: 33.3800\nEpoch 12, Batch 50/91, Loss: 14.7021\nAvg Blank Probability: 0.9206\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['yeZBt6x', 'WJ3im', 'rj2Y']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 5, 4]\nToken distribution (Batch 31): {0: 10}\nBatch 60, Gradient norm: 313.8644\nEpoch 12, Batch 60/91, Loss: 14.3658\nAvg Blank Probability: 0.9141\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['2JT', 'nQoAFh', 'q']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 6, 1]\nToken distribution (Batch 31): {0: 4}\nBatch 70, Gradient norm: 15.7516\nEpoch 12, Batch 70/91, Loss: 14.2391\nAvg Blank Probability: 0.9100\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['k', 'T1', 'XaGhKvP']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 2, 7]\nToken distribution (Batch 31): {0: 6}\nBatch 80, Gradient norm: 23.9868\nEpoch 12, Batch 80/91, Loss: 13.9900\nAvg Blank Probability: 0.8919\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['YWmFk6', 'AjNIAzj', 'xe5']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 7, 3]\nToken distribution (Batch 15): {0: 12}\nBatch 90, Gradient norm: 7258.2407\nEpoch 12, Batch 90/91, Loss: 13.7089\nAvg Blank Probability: 0.8929\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['3', 'BQ', 'j39MjIY']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 2, 7]\nEpoch 12/20, Loss: 14.3463\nToken distribution (Batch 19): {0: 4}\nValidation Loss: 22.5666\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['uduag5', 'v', 'kXK', '4oAo', 'Xgg*r']\nCurrent Learning Rate: 7.218847050625474e-06\nEpoch 13, Filtered data size: 3620, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {0: 14}\nBatch 0, Gradient norm: 43199336.0000\nEpoch 13, Batch 0/91, Loss: 13.8213\nAvg Blank Probability: 0.9050\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['DMYT*', '2m09p04', 'rsJczXz']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 7, 7]\nToken distribution (Batch 31): {0: 10}\nBatch 10, Gradient norm: 21.6945\nEpoch 13, Batch 10/91, Loss: 13.8915\nAvg Blank Probability: 0.8885\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Zax', 'GblpNE', 'AO5O8Xz']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 6, 7]\nToken distribution (Batch 31): {0: 8}\nBatch 20, Gradient norm: 109817.9688\nEpoch 13, Batch 20/91, Loss: 13.3166\nAvg Blank Probability: 0.8643\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['c', 'DZ', 'yE']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 2, 2]\nToken distribution (Batch 31): {0: 8}\nBatch 30, Gradient norm: 13.7018\nEpoch 13, Batch 30/91, Loss: 13.4852\nAvg Blank Probability: 0.8613\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Gpz4l', 'gHBHK', 'wL7']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 5, 3]\nToken distribution (Batch 31): {0: 12}\nBatch 40, Gradient norm: 9.5127\nEpoch 13, Batch 40/91, Loss: 13.4311\nAvg Blank Probability: 0.8475\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['xM7tm', '-', '7BJ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 1, 3]\nToken distribution (Batch 31): {0: 10}\nBatch 50, Gradient norm: 8.7381\nEpoch 13, Batch 50/91, Loss: 13.5133\nAvg Blank Probability: 0.8481\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['3cT-U7', 'R', '2XR']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 1, 3]\nToken distribution (Batch 31): {0: 6}\nBatch 60, Gradient norm: 12.3292\nEpoch 13, Batch 60/91, Loss: 13.4761\nAvg Blank Probability: 0.8533\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['vYIU0WD', 'v8Nha', 'G4R']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 5, 3]\nToken distribution (Batch 31): {0: 14}\nBatch 70, Gradient norm: 41.7061\nEpoch 13, Batch 70/91, Loss: 13.3430\nAvg Blank Probability: 0.8523\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['RdZ1x', 'WOr3O', 'BVzm05v']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 5, 7]\nToken distribution (Batch 31): {0: 2}\nBatch 80, Gradient norm: 7.0361\nEpoch 13, Batch 80/91, Loss: 13.4651\nAvg Blank Probability: 0.8503\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['oe', 'eKSRDzi', 'bxDZ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 7, 4]\nToken distribution (Batch 15): {0: 2}\nBatch 90, Gradient norm: 3328495616.0000\nEpoch 13, Batch 90/91, Loss: 13.0620\nAvg Blank Probability: 0.8346\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['FqXD', 't5ttxVy', 'LkN']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 7, 3]\nEpoch 13/20, Loss: 13.4997\nToken distribution (Batch 19): {0: 14}\nValidation Loss: 23.8227\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['oiUh', 'PfCU3-m', 'n', 'o*N', 'C']\nCurrent Learning Rate: 5.914085502344079e-06\nEpoch 14, Filtered data size: 3620, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {0: 14}\nBatch 0, Gradient norm: 2654.1855\nEpoch 14, Batch 0/91, Loss: 13.4141\nAvg Blank Probability: 0.8426\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['e', 'E6RxizT', 'QjW7gxl']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 7, 7]\nToken distribution (Batch 31): {0: 10}\nBatch 10, Gradient norm: 28563.5254\nEpoch 14, Batch 10/91, Loss: 13.3185\nAvg Blank Probability: 0.8507\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['7N7d', '0D', 'ixDqn']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 2, 5]\nToken distribution (Batch 31): {0: 2}\nBatch 20, Gradient norm: 5009785.5000\nEpoch 14, Batch 20/91, Loss: 13.3274\nAvg Blank Probability: 0.8386\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['tKd4F', 'tkL', 'V*czz']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 3, 5]\nToken distribution (Batch 31): {0: 6}\nBatch 30, Gradient norm: 1450930304.0000\nEpoch 14, Batch 30/91, Loss: 13.3220\nAvg Blank Probability: 0.8576\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['XaGhKvP', 'VQ', 'PVS8nuq']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 2, 7]\nToken distribution (Batch 31): {0: 10}\nBatch 40, Gradient norm: 58.1562\nEpoch 14, Batch 40/91, Loss: 13.5330\nAvg Blank Probability: 0.8568\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['DQsMZ9', 'TAi', 'Q8dF']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 3, 4]\nToken distribution (Batch 31): {0: 14}\nBatch 50, Gradient norm: 11895.3975\nEpoch 14, Batch 50/91, Loss: 13.6423\nAvg Blank Probability: 0.8780\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['*tIE', 'bVwNB', '19VXY']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 5, 5]\nToken distribution (Batch 31): {0: 12}\nBatch 60, Gradient norm: 177720.9844\nEpoch 14, Batch 60/91, Loss: 13.5295\nAvg Blank Probability: 0.8757\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['u', '37', '6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 2, 1]\nToken distribution (Batch 31): {0: 12}\nBatch 70, Gradient norm: 432871342080.0000\nEpoch 14, Batch 70/91, Loss: 13.6362\nAvg Blank Probability: 0.8702\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['h', 'UVE', 'j']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 3, 1]\nToken distribution (Batch 31): {0: 8}\nBatch 80, Gradient norm: 2468795.7500\nEpoch 14, Batch 80/91, Loss: 13.4207\nAvg Blank Probability: 0.8747\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['6JT6A', '*ukzOg', 'ks']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 6, 2]\nToken distribution (Batch 15): {0: 6}\nBatch 90, Gradient norm: 1796.7284\nEpoch 14, Batch 90/91, Loss: 13.1991\nAvg Blank Probability: 0.8640\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['b3OhG', 'yn*', 'rOq']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 3, 3]\nEpoch 14/20, Loss: 13.4754\nToken distribution (Batch 19): {0: 14}\nValidation Loss: 23.4720\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['exRVivK', '1', 'zLD', 'ALMJ', '32']\nCurrent Learning Rate: 4.709932729367743e-06\nEpoch 15, Filtered data size: 3620, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 2896, Val size: 724\nToken distribution (Batch 31): {0: 10}\nBatch 0, Gradient norm: 13.7263\nEpoch 15, Batch 0/91, Loss: 13.5305\nAvg Blank Probability: 0.8638\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Ub', '7VLzPb', '-k']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 6, 2]\nToken distribution (Batch 31): {0: 8}\nBatch 10, Gradient norm: 13.7958\nEpoch 15, Batch 10/91, Loss: 13.4374\nAvg Blank Probability: 0.8623\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['HlfFN', '5hb', 'Hl']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 3, 2]\nToken distribution (Batch 31): {0: 14}\nBatch 20, Gradient norm: 58.6459\nEpoch 15, Batch 20/91, Loss: 13.4342\nAvg Blank Probability: 0.8460\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['7Ifh9Q', 'UuGt', 'W4WB']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 4, 4]\nToken distribution (Batch 31): {0: 2}\nBatch 30, Gradient norm: 8785223.0000\nEpoch 15, Batch 30/91, Loss: 13.3673\nAvg Blank Probability: 0.8518\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['TA9pm', 'EItm', 'C']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 4, 1]\nToken distribution (Batch 31): {0: 4}\nBatch 40, Gradient norm: 6.2397\nEpoch 15, Batch 40/91, Loss: 13.4664\nAvg Blank Probability: 0.8534\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['ViIigG', '9k0', 'PCa']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 3, 3]\nToken distribution (Batch 31): {0: 10}\nBatch 50, Gradient norm: 4.8339\nEpoch 15, Batch 50/91, Loss: 13.5139\nAvg Blank Probability: 0.8467\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['v', 'u', 'cCNy0u1']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 1, 7]\nToken distribution (Batch 31): {0: 14}\nBatch 60, Gradient norm: 8.1102\nEpoch 15, Batch 60/91, Loss: 13.4997\nAvg Blank Probability: 0.8455\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['n3jVe', 'Sbl', 'HEu9kyT']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 3, 7]\nToken distribution (Batch 31): {0: 4}\nBatch 70, Gradient norm: 701840621568.0000\nEpoch 15, Batch 70/91, Loss: 13.3770\nAvg Blank Probability: 0.8452\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['uwYu', 'ZEvd7', 'N94']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 5, 3]\nToken distribution (Batch 31): {0: 10}\nBatch 80, Gradient norm: 57694.2422\nEpoch 15, Batch 80/91, Loss: 13.3964\nAvg Blank Probability: 0.8436\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Zg', 'Uw0', 'fA']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 3, 2]\nToken distribution (Batch 15): {0: 2}\nBatch 90, Gradient norm: 5.2205\nEpoch 15, Batch 90/91, Loss: 13.1249\nAvg Blank Probability: 0.8321\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['6Ki', 'uVaQJ', 'cqS']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 5, 3]\nEpoch 15/20, Loss: 13.3857\nToken distribution (Batch 19): {0: 14}\nValidation Loss: 24.7001\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['G', 'Wa131', 'q', 'SdH', 'mSQ']\nCurrent Learning Rate: 3.6360389693210727e-06\nEpoch 16, Filtered data size: 5120, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {0: 8}\nBatch 0, Gradient norm: 206.5979\nEpoch 16, Batch 0/128, Loss: 13.4014\nAvg Blank Probability: 0.8350\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['v', 'xpYZA5', 'Ub']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 6, 2]\nToken distribution (Batch 31): {0: 10}\nBatch 10, Gradient norm: 6720399752560640.0000\nEpoch 16, Batch 10/128, Loss: 13.3495\nAvg Blank Probability: 0.8464\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['ubsoqa', 'blCQ', 'pX']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 4, 2]\nToken distribution (Batch 31): {0: 6}\nBatch 20, Gradient norm: 87859.5078\nEpoch 16, Batch 20/128, Loss: 13.4295\nAvg Blank Probability: 0.8423\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['2JJ', 'ZGrO', 'xFfxJd']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 4, 6]\nToken distribution (Batch 31): {0: 10}\nBatch 30, Gradient norm: inf\nEpoch 16, Batch 30/128, Loss: 13.3744\nAvg Blank Probability: 0.8257\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['xXf5uZ', 'lw', 'I0kNxv']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 2, 6]\nToken distribution (Batch 31): {0: 15}\nBatch 40, Gradient norm: 15.7232\nEpoch 16, Batch 40/128, Loss: 13.6607\nAvg Blank Probability: 0.8542\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Y1amuTnSp', 'w2kXVHIec', 'BahV']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [9, 9, 4]\nToken distribution (Batch 31): {0: 2}\nBatch 50, Gradient norm: 778.4604\nEpoch 16, Batch 50/128, Loss: 13.5002\nAvg Blank Probability: 0.8457\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['V90V682C', 'L', 'QUXKSN']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 1, 6]\nToken distribution (Batch 31): {0: 14}\nBatch 60, Gradient norm: 27342678016.0000\nEpoch 16, Batch 60/128, Loss: 13.7133\nAvg Blank Probability: 0.8508\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['oPE*cz', 'RlxA*QNSli', 'fWbbc6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 10, 6]\nToken distribution (Batch 31): {0: 12}\nBatch 70, Gradient norm: inf\nEpoch 16, Batch 70/128, Loss: 13.5757\nAvg Blank Probability: 0.8669\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['56', 'v*LHo0TY', 'lSPYJWf']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 8, 7]\nToken distribution (Batch 31): {0: 8}\nBatch 80, Gradient norm: 13096.2295\nEpoch 16, Batch 80/128, Loss: 13.7871\nAvg Blank Probability: 0.8703\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['iA', 'Yp5', '5rxkXtyka']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 3, 9]\nToken distribution (Batch 31): {0: 12}\nBatch 90, Gradient norm: 161.2438\nEpoch 16, Batch 90/128, Loss: 13.8783\nAvg Blank Probability: 0.8775\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['tkg', 'Ocf0', 'Qi']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 4, 2]\nToken distribution (Batch 31): {0: 8}\nBatch 100, Gradient norm: 12.3390\nEpoch 16, Batch 100/128, Loss: 13.7946\nAvg Blank Probability: 0.8818\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['EqtUXBUD', 'RMii', 'rQVG7a8bAn']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 4, 10]\nToken distribution (Batch 31): {0: 2}\nBatch 110, Gradient norm: 19.2012\nEpoch 16, Batch 110/128, Loss: 14.0271\nAvg Blank Probability: 0.8791\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['eMBEWR', 'xd', 'YiJn5tka6z']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 2, 10]\nToken distribution (Batch 31): {0: 10}\nBatch 120, Gradient norm: 23.0943\nEpoch 16, Batch 120/128, Loss: 13.5544\nAvg Blank Probability: 0.8685\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['UKi-iSUyo', 'Q', 'ooEkgjnB']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [9, 1, 8]\nEpoch 16/20, Loss: 13.6450\nToken distribution (Batch 31): {0: 4}\nValidation Loss: 21.3761\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['5N0ju', 'MDVk', 'PbuH2h-L38', 'rdC-', '0bL-p5o']\nCurrent Learning Rate: 2.718847050625474e-06\nEpoch 17, Filtered data size: 5120, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {0: 15}\nBatch 0, Gradient norm: 112.8306\nEpoch 17, Batch 0/128, Loss: 13.7896\nAvg Blank Probability: 0.8772\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['xc', 'RkYgh', 'b33h*xc-']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 5, 8]\nToken distribution (Batch 31): {0: 2}\nBatch 10, Gradient norm: inf\nEpoch 17, Batch 10/128, Loss: 13.7251\nAvg Blank Probability: 0.8887\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['S', 'NJlcyoqK', 'nkX7OoRR9E']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 8, 10]\nToken distribution (Batch 31): {0: 15}\nBatch 20, Gradient norm: 73311416.0000\nEpoch 17, Batch 20/128, Loss: 14.0159\nAvg Blank Probability: 0.8753\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['-Bs', 'LJI8DCME', 'yuDw3']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 8, 5]\nToken distribution (Batch 31): {0: 6}\nBatch 30, Gradient norm: 118867.2578\nEpoch 17, Batch 30/128, Loss: 13.6213\nAvg Blank Probability: 0.8688\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['K7ebq', 'dP', '7FqjaQiPG']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 2, 9]\nToken distribution (Batch 31): {0: 10}\nBatch 40, Gradient norm: 23.9373\nEpoch 17, Batch 40/128, Loss: 14.1310\nAvg Blank Probability: 0.8771\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['gZ9rU', 'jAh4', 'kXK']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [5, 4, 3]\nToken distribution (Batch 31): {0: 15}\nBatch 50, Gradient norm: 18.8962\nEpoch 17, Batch 50/128, Loss: 13.9420\nAvg Blank Probability: 0.8796\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['HkIUAN8CPh', '6', 'WOr3O']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [10, 1, 5]\nToken distribution (Batch 31): {0: 6}\nBatch 60, Gradient norm: 18.4637\nEpoch 17, Batch 60/128, Loss: 14.0392\nAvg Blank Probability: 0.8802\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['wCG6wX7fc', '76rX', 'w']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [9, 4, 1]\nToken distribution (Batch 31): {0: 15}\nBatch 70, Gradient norm: 151073013760.0000\nEpoch 17, Batch 70/128, Loss: 13.7503\nAvg Blank Probability: 0.8722\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['p1TWXUAoWG', 'VNbV', '*dgl1']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [10, 4, 5]\nToken distribution (Batch 31): {0: 15}\nBatch 80, Gradient norm: 19.9009\nEpoch 17, Batch 80/128, Loss: 13.7402\nAvg Blank Probability: 0.8729\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['9KxJ3uEnv4', '7ONq2*yVPG', 'LQY']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [10, 10, 3]\nToken distribution (Batch 31): {0: 12}\nBatch 90, Gradient norm: 756513664.0000\nEpoch 17, Batch 90/128, Loss: 13.8785\nAvg Blank Probability: 0.8664\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['p9', 'Aofdh5RsDS', 'q']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 10, 1]\nToken distribution (Batch 31): {0: 4}\nBatch 100, Gradient norm: 1682606.6250\nEpoch 17, Batch 100/128, Loss: 13.6228\nAvg Blank Probability: 0.8612\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['NNv8U8', '60ko', '97Vu2R']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 4, 6]\nToken distribution (Batch 31): {0: 2}\nBatch 110, Gradient norm: 40.1599\nEpoch 17, Batch 110/128, Loss: 13.6620\nAvg Blank Probability: 0.8710\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Z5bX87Rpgi', 'bVwNB', '607MvwXKzK']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [10, 5, 10]\nToken distribution (Batch 31): {0: 14}\nBatch 120, Gradient norm: inf\nEpoch 17, Batch 120/128, Loss: 13.8427\nAvg Blank Probability: 0.8696\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Q', 'io', 'Y5jwp']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 2, 5]\nEpoch 17/20, Loss: 13.8069\nToken distribution (Batch 31): {0: 15}\nValidation Loss: 21.4571\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['rn3tWG', 'Cg0k4r', 'Yp5', 'kPzmE48bf0', '8AIjG']\nCurrent Learning Rate: 1.98094128230469e-06\nEpoch 18, Filtered data size: 5120, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {0: 2}\nBatch 0, Gradient norm: 17120089866240.0000\nEpoch 18, Batch 0/128, Loss: 13.6376\nAvg Blank Probability: 0.8701\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['yzB', 'MFC1jnHEBt', '7FqjaQiPG']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 10, 9]\nToken distribution (Batch 31): {0: 10}\nBatch 10, Gradient norm: 4314.2524\nEpoch 18, Batch 10/128, Loss: 13.9728\nAvg Blank Probability: 0.8642\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['8SCvKN0S', 'JwDvNN', '4oAo']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 6, 4]\nToken distribution (Batch 31): {0: 10}\nBatch 20, Gradient norm: 5023468516192288768.0000\nEpoch 18, Batch 20/128, Loss: 13.5698\nAvg Blank Probability: 0.8656\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['KtQhCC', 'k1Z', 'rf2o']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 3, 4]\nToken distribution (Batch 31): {0: 4}\nBatch 30, Gradient norm: 6184668160.0000\nEpoch 18, Batch 30/128, Loss: 13.6534\nAvg Blank Probability: 0.8668\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['PwC8ai3', 'zBv', 'K0b']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 3, 3]\nToken distribution (Batch 31): {0: 12}\nBatch 40, Gradient norm: inf\nEpoch 18, Batch 40/128, Loss: 13.6282\nAvg Blank Probability: 0.8729\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['TOI', 'bVwNB', 'IsX3zLd']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 5, 7]\nToken distribution (Batch 31): {0: 14}\nBatch 50, Gradient norm: 4857.3042\nEpoch 18, Batch 50/128, Loss: 13.8500\nAvg Blank Probability: 0.8807\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['WpNtD7cz', 'E6HnJZsVV', 'eQ8pMyQp']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 9, 8]\nToken distribution (Batch 31): {0: 6}\nBatch 60, Gradient norm: 19624.7246\nEpoch 18, Batch 60/128, Loss: 13.8725\nAvg Blank Probability: 0.8715\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['5yccyJ', 'Bq', '0x']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 2, 2]\nToken distribution (Batch 31): {0: 14}\nBatch 70, Gradient norm: 18.2332\nEpoch 18, Batch 70/128, Loss: 13.9013\nAvg Blank Probability: 0.8831\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['JfCY', 'CZfOCe9FV', '4yILIwOF']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 9, 8]\nToken distribution (Batch 31): {0: 4}\nBatch 80, Gradient norm: 21.8667\nEpoch 18, Batch 80/128, Loss: 14.0313\nAvg Blank Probability: 0.8802\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['kAWIPaZw4', '7lDV', 'zninSN1y7G']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [9, 4, 10]\nToken distribution (Batch 31): {0: 10}\nBatch 90, Gradient norm: 44155981824.0000\nEpoch 18, Batch 90/128, Loss: 13.7639\nAvg Blank Probability: 0.8778\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['3JuRA61mc', '2f', 'P7QbB']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [9, 2, 5]\nToken distribution (Batch 31): {0: 4}\nBatch 100, Gradient norm: inf\nEpoch 18, Batch 100/128, Loss: 13.7616\nAvg Blank Probability: 0.8783\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['2UiKEQ', '5JsDVGajf', '56']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 9, 2]\nToken distribution (Batch 31): {0: 8}\nBatch 110, Gradient norm: 5197232.5000\nEpoch 18, Batch 110/128, Loss: 13.4153\nAvg Blank Probability: 0.8674\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['b005xtkb', 'X9rqrpSp', 'zOxS']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 8, 4]\nToken distribution (Batch 31): {0: 15}\nBatch 120, Gradient norm: 136557084672.0000\nEpoch 18, Batch 120/128, Loss: 13.8459\nAvg Blank Probability: 0.8702\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['r5y8', 'JHJlmh0i', 'NS7KJL6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 8, 7]\nEpoch 18/20, Loss: 13.7980\nToken distribution (Batch 31): {0: 15}\nValidation Loss: 21.3959\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['nq', 'fxHGS', '9IIwuwWAr', 'nwEPlz6V', '4rz']\nCurrent Learning Rate: 1.4404913533436183e-06\nEpoch 19, Filtered data size: 5120, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {0: 10}\nBatch 0, Gradient norm: 18.6800\nEpoch 19, Batch 0/128, Loss: 13.8831\nAvg Blank Probability: 0.8712\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Y', 'vpIY', 'AfNS6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 4, 5]\nToken distribution (Batch 31): {0: 2}\nBatch 10, Gradient norm: 565.7795\nEpoch 19, Batch 10/128, Loss: 13.9499\nAvg Blank Probability: 0.8690\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['rMdg2h0uii', 'M*li4jM', 'KFJJ7Egd']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [10, 7, 8]\nToken distribution (Batch 31): {0: 15}\nBatch 20, Gradient norm: 16.8064\nEpoch 19, Batch 20/128, Loss: 13.7912\nAvg Blank Probability: 0.8679\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['CYefHF', '1BaHucs7', '45t061hgf9']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 8, 10]\nToken distribution (Batch 31): {0: 14}\nBatch 30, Gradient norm: 125297590272.0000\nEpoch 19, Batch 30/128, Loss: 13.4600\nAvg Blank Probability: 0.8740\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['uduag5', 'fr1jAmXu', 'RMaR5*7p']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 8, 8]\nToken distribution (Batch 31): {0: 2}\nBatch 40, Gradient norm: inf\nEpoch 19, Batch 40/128, Loss: 13.6632\nAvg Blank Probability: 0.8648\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['7zV', '-i6LwZrz47', 'lj1']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 10, 3]\nToken distribution (Batch 31): {0: 15}\nBatch 50, Gradient norm: 174906272.0000\nEpoch 19, Batch 50/128, Loss: 13.6019\nAvg Blank Probability: 0.8759\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['1', '0pQUIWd', '4RpW']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 7, 4]\nToken distribution (Batch 31): {0: 14}\nBatch 60, Gradient norm: 41067352064.0000\nEpoch 19, Batch 60/128, Loss: 13.5344\nAvg Blank Probability: 0.8596\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['NkE9', 'GRgo5', 'MRrU']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 5, 4]\nToken distribution (Batch 31): {0: 14}\nBatch 70, Gradient norm: 7064576851968.0000\nEpoch 19, Batch 70/128, Loss: 13.7637\nAvg Blank Probability: 0.8829\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['waV', 'Mx', 'yn*']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [3, 2, 3]\nToken distribution (Batch 31): {0: 12}\nBatch 80, Gradient norm: 3717924.2500\nEpoch 19, Batch 80/128, Loss: 13.9712\nAvg Blank Probability: 0.8786\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['O', 'C5Wdy4c', 'WLe']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 7, 3]\nToken distribution (Batch 31): {0: 2}\nBatch 90, Gradient norm: 18.0738\nEpoch 19, Batch 90/128, Loss: 13.7847\nAvg Blank Probability: 0.8718\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['lZ2TUT', 'q9zklSaiuC', 'AXtKCJ05k']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 10, 9]\nToken distribution (Batch 31): {0: 15}\nBatch 100, Gradient norm: 157784464.0000\nEpoch 19, Batch 100/128, Loss: 13.6492\nAvg Blank Probability: 0.8789\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['P5-Gz9K', 'zYARCOeb', '2j']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 8, 2]\nToken distribution (Batch 31): {0: 15}\nBatch 110, Gradient norm: 22.9102\nEpoch 19, Batch 110/128, Loss: 14.1745\nAvg Blank Probability: 0.8832\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['hACa', 'g', 'kOnkX']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 1, 5]\nToken distribution (Batch 31): {0: 8}\nBatch 120, Gradient norm: 21.3031\nEpoch 19, Batch 120/128, Loss: 13.8575\nAvg Blank Probability: 0.8762\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['**GKC5p', 'MI', 'Ql1pa--3']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 2, 8]\nEpoch 19/20, Loss: 13.8165\nToken distribution (Batch 31): {0: 14}\nValidation Loss: 21.1698\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['Tn', 'zypb', 'U6LgEHC8oW', 'c', 'NXr']\nCurrent Learning Rate: 1.110804934643761e-06\nEpoch 20, Filtered data size: 5120, Sample labels: ['qV8i', 'i', 'mer*BH']\nTrain size: 4096, Val size: 1024\nToken distribution (Batch 31): {0: 14}\nBatch 0, Gradient norm: 16.3139\nEpoch 20, Batch 0/128, Loss: 13.7323\nAvg Blank Probability: 0.8708\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['PDeSdwlOT', 'kPAyIFQu', 'fForlf']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [9, 8, 6]\nToken distribution (Batch 31): {0: 15}\nBatch 10, Gradient norm: 52796121088.0000\nEpoch 20, Batch 10/128, Loss: 13.9052\nAvg Blank Probability: 0.8777\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['pOTlc0P5pw', 'u6XUi', 'n']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [10, 5, 1]\nToken distribution (Batch 31): {0: 4}\nBatch 20, Gradient norm: 26.0068\nEpoch 20, Batch 20/128, Loss: 14.1948\nAvg Blank Probability: 0.8897\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['6', '7N7d', 'g']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 4, 1]\nToken distribution (Batch 31): {0: 15}\nBatch 30, Gradient norm: 1246224128.0000\nEpoch 20, Batch 30/128, Loss: 13.5029\nAvg Blank Probability: 0.8733\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['T6', 'AE', 'q']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [2, 2, 1]\nToken distribution (Batch 31): {0: 8}\nBatch 40, Gradient norm: 23.1160\nEpoch 20, Batch 40/128, Loss: 14.2195\nAvg Blank Probability: 0.8826\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['MmvXqd05', '55kxoPw', 'K9']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 7, 2]\nToken distribution (Batch 31): {0: 8}\nBatch 50, Gradient norm: 10398698865426432.0000\nEpoch 20, Batch 50/128, Loss: 13.5102\nAvg Blank Probability: 0.8783\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['9KaMuuhtgy', 'RQz0Sj', '8']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [10, 6, 1]\nToken distribution (Batch 31): {0: 15}\nBatch 60, Gradient norm: 69916655616.0000\nEpoch 20, Batch 60/128, Loss: 13.8812\nAvg Blank Probability: 0.8664\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['Q', '1qwdH4orZZ', 'b0sr']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 10, 4]\nToken distribution (Batch 31): {0: 15}\nBatch 70, Gradient norm: 21.8636\nEpoch 20, Batch 70/128, Loss: 13.8865\nAvg Blank Probability: 0.8794\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['zapD0Ga3q', 'hjpH', 'H9Ih-81']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [9, 4, 7]\nToken distribution (Batch 31): {0: 15}\nBatch 80, Gradient norm: 1803308608398557184.0000\nEpoch 20, Batch 80/128, Loss: 13.7918\nAvg Blank Probability: 0.8733\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['bUNq', '*m4W', 'BGcfsHl0j6']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [4, 4, 10]\nToken distribution (Batch 31): {0: 2}\nBatch 90, Gradient norm: 24.1187\nEpoch 20, Batch 90/128, Loss: 14.2137\nAvg Blank Probability: 0.8876\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['1', 'OWs', '2UiKEQ']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [1, 3, 6]\nToken distribution (Batch 31): {0: 15}\nBatch 100, Gradient norm: 3139808998195200.0000\nEpoch 20, Batch 100/128, Loss: 13.8506\nAvg Blank Probability: 0.8801\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['09Vsfm3', 'k1Z', 'A8Be2f']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [7, 3, 6]\nToken distribution (Batch 31): {0: 2}\nBatch 110, Gradient norm: 13906.2451\nEpoch 20, Batch 110/128, Loss: 13.7379\nAvg Blank Probability: 0.8807\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['uBJcLx', 'l', '*mfyDLwx']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [6, 1, 8]\nToken distribution (Batch 31): {0: 4}\nBatch 120, Gradient norm: 19.1465\nEpoch 20, Batch 120/128, Loss: 13.9883\nAvg Blank Probability: 0.8771\nSample predictions: ['<empty>', '<empty>', '<empty>']\nGround Truth (first 3): ['UtXibJFR', 'GMTm', '65GcR']\nRaw outputs (first 3): [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\nInput length: 15, Label lengths: [8, 4, 5]\nEpoch 20/20, Loss: 13.8654\nToken distribution (Batch 31): {0: 15}\nValidation Loss: 21.6153\nValidation Predictions: ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>']\nGround Truth: ['K7ebq', 'GXX3PhE', 'kuG', 'Bw', 'DV14']\nCurrent Learning Rate: 1e-06\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"def zip_folder_with_shutil(source_folder, output_path):\n    '''Function for zip dir data'''\n    shutil.make_archive(output_path, 'zip', source_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:08:19.434151Z","iopub.execute_input":"2025-03-10T05:08:19.434472Z","iopub.status.idle":"2025-03-10T05:08:19.438916Z","shell.execute_reply.started":"2025-03-10T05:08:19.434445Z","shell.execute_reply":"2025-03-10T05:08:19.438032Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/backgrounds', '/kaggle/working/backgrounds')\nzip_folder_with_shutil('/kaggle/working/synthetic_data', '/kaggle/working/synthetic_data')\nzip_folder_with_shutil('/kaggle/working/model_dir', '/kaggle/working/model_dir')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:08:19.439702Z","iopub.execute_input":"2025-03-10T05:08:19.440018Z","iopub.status.idle":"2025-03-10T05:08:22.680277Z","shell.execute_reply.started":"2025-03-10T05:08:19.439986Z","shell.execute_reply":"2025-03-10T05:08:22.679241Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/runs', '/kaggle/working/runs')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:08:22.681234Z","iopub.execute_input":"2025-03-10T05:08:22.681562Z","iopub.status.idle":"2025-03-10T05:08:22.688323Z","shell.execute_reply.started":"2025-03-10T05:08:22.681524Z","shell.execute_reply":"2025-03-10T05:08:22.687340Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"#!tensorboard --logdir=/kaggle/working/runs --port 6006","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:08:22.689347Z","iopub.execute_input":"2025-03-10T05:08:22.689705Z","iopub.status.idle":"2025-03-10T05:08:22.701865Z","shell.execute_reply.started":"2025-03-10T05:08:22.689671Z","shell.execute_reply":"2025-03-10T05:08:22.700817Z"}},"outputs":[],"execution_count":28}]}