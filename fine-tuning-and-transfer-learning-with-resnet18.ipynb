{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <font style=\"color:blue\">Obsah</font>\n\n- [Spusťte TensorBoard](#launch)\n- [Nástroje pro zpracování dat](#utils)\n- [Přidaní vložení dat / Projektor](#embeds)\n- [Konfigurace systému](#sys-config)\n- [Konfigurace tréninku](#train-config)\n- [Nastavení systému](#sys-setup)\n- [Přidejte PR křivky do TensorBoard](#pr-curves)\n- [Odešlete nesprávnou předpověď do TensorBoard](#wrong-preds)\n- [Tréninková funkce](#train-fn)\n- [Funkce validace](#validate-fn)\n- [Přidejte histogram vah a síť grafů](#hist)\n- [Hlavní funkce pro trénink a validaci](#main)\n- [Optimalizátor a plánovač](#optim)\n- [ResNet Model](#model)\n- [Transfer Learning](#tl)\n- [Fine-Tuning](#fine-tune)","metadata":{}},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Přenos učení a jemné ladění</font>\n\nNaučte se vyladit předem trénovaný model pro jiný úkol.\n\nKdyž trénujeme síť od nuly, čelíme dvěma omezením:\n\n- Potřebné obrovské množství dat - Protože síť má miliony parametrů, k získání optimální sady parametrů potřebujete hodně dat.\n\n\n- Potřebný vysoký výpočetní výkon - I když máte dostatek dat, školení obecně vyžaduje více iterací, což si zase vybírá daň na výpočetních zdrojích.\n\nPředtrénované modely jsou trénovány na velmi rozsáhlých problémech klasifikace obrázků. Konvoluční vrstvy fungují jako extraktor prvků a plně propojené vrstvy se chovají jako klasifikátory.\n\nTyto velmi velké modely viděly obrovské množství obrázků, takže mají tendenci učit se dobré, rozlišující vlastnosti. Buď použijte konvoluční vrstvy pouze jako extraktor prvků a změňte poslední vrstvu v souladu s problémem. Nebo vyladit již natrénované konvoluční vrstvy tak, aby vyhovovaly aktuálnímu problému. První přístup se nazývá **Transfer Learning** a druhý **Fine-tuning**.\n\nChcete-li síť doladit, stačí upravit parametry již natrénované sítě tak, aby se přizpůsobila nové úloze. Počáteční vrstvy sítě se učí velmi obecné rysy. Ale jak postupujeme výše v síti, vrstvy mají tendenci učit se vzory specifičtější pro úkol, na který jsou trénovány. Počáteční vrstvy tedy zmrazíme nebo ponecháme nedotčené pro jemné doladění (Fine-tuning) a znovu trénujeme pouze pozdější vrstvy pro daný úkol.\n\nJemné doladění (Fine-tuning) se tak vyhne oběma výše uvedeným omezením.\n\n1. Pro školení zde není potřeba mnoho dat, protože:\n\n - Za prvé, netrénujeme celou síť.\n\n - Za druhé, část, která je trénována, není trénována od nuly.\n\n2. Je třeba aktualizovat méně parametrů, takže je také potřeba méně času.\n\n\nObecně platí, že když máme malou tréninkovou sadu a model byl předem vycvičen k řešení podobného úkolu, používáme přenosové učení (Transfer learning). Pokud však máme dostatek dat, snažíme se konvoluční vrstvy vyladit, aby se naučily robustnější funkce relevantní pro náš problém. Pro podrobný přehled Fine-tuning and Transfer Learning [**klikněte sem**](http://cs231n.github.io/transfer-learning/).","metadata":{"id":"qfHId531-K4V"}},{"cell_type":"code","source":"%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:36:11.156576Z","iopub.execute_input":"2024-10-02T08:36:11.156891Z","iopub.status.idle":"2024-10-02T08:36:11.167689Z","shell.execute_reply.started":"2024-10-02T08:36:11.156857Z","shell.execute_reply":"2024-10-02T08:36:11.166928Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt  # one of the best graphics library for python\nplt.style.use('ggplot')","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:36:11.169354Z","iopub.execute_input":"2024-10-02T08:36:11.169654Z","iopub.status.idle":"2024-10-02T08:36:11.178920Z","shell.execute_reply.started":"2024-10-02T08:36:11.169623Z","shell.execute_reply":"2024-10-02T08:36:11.178062Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport shutil\n\nfrom typing import Iterable\nfrom dataclasses import dataclass\n\nimport multiprocessing as mp\nmp.set_start_method('spawn', force=True)\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\ntorch.multiprocessing.set_start_method('spawn', force=True)\n\nfrom torchvision import datasets, transforms, models\nfrom torchvision.models import ResNet18_Weights\n\nfrom torch.optim import lr_scheduler\n\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:36:11.179995Z","iopub.execute_input":"2024-10-02T08:36:11.180302Z","iopub.status.idle":"2024-10-02T08:36:28.577687Z","shell.execute_reply.started":"2024-10-02T08:36:11.180254Z","shell.execute_reply":"2024-10-02T08:36:28.576790Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Spusťte TensorBoard</font><a name=\"launch\"></a>\n\nPo zahájení tréninku použijte tlačítko aktualizace na ovládacím panelu k zobrazení tréninkových metrik v reálném čase.\n\n[Zde najdete odkaz na protokoly tensorboard.dev](https://tensorboard.dev/experiment/gEH87smeTpKbyVOdgRVknA/). \n\n**Poznámka:** V době nahrávání tohoto protokolu tensorbaord.dev podporuje pouze `skaláry`, `grafy`, `histogramy`, `distribuce` a `hparamy`. Odkaz tedy nemá `images`, `pr-curves` a `projectors`. ","metadata":{}},{"cell_type":"code","source":"!tensorboard --version","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:36:28.579554Z","iopub.execute_input":"2024-10-02T08:36:28.580104Z","iopub.status.idle":"2024-10-02T08:36:35.683516Z","shell.execute_reply.started":"2024-10-02T08:36:28.580067Z","shell.execute_reply":"2024-10-02T08:36:35.682387Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"2.16.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n!tar xf ./ngrok-v3-stable-linux-amd64.tgz -C /usr/local/bin","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:36:35.685063Z","iopub.execute_input":"2024-10-02T08:36:35.685393Z","iopub.status.idle":"2024-10-02T08:36:38.914477Z","shell.execute_reply.started":"2024-10-02T08:36:35.685361Z","shell.execute_reply":"2024-10-02T08:36:38.913178Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"--2024-10-02 08:36:36--  https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\nResolving bin.equinox.io (bin.equinox.io)... 18.205.222.128, 54.237.133.81, 52.202.168.65, ...\nConnecting to bin.equinox.io (bin.equinox.io)|18.205.222.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 9085090 (8.7M) [application/octet-stream]\nSaving to: 'ngrok-v3-stable-linux-amd64.tgz'\n\nngrok-v3-stable-lin 100%[===================>]   8.66M  14.4MB/s    in 0.6s    \n\n2024-10-02 08:36:37 (14.4 MB/s) - 'ngrok-v3-stable-linux-amd64.tgz' saved [9085090/9085090]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"***Add to the console:***\n\n```cmd\n!ngrok authtoken <authtoken>\n```","metadata":{}},{"cell_type":"code","source":"pool = mp.Pool(processes = 10)\nresults_of_processes = [pool.apply_async(os.system, args=(cmd, ), callback = None )\n                        for cmd in [\n                        f\"tensorboard --logdir ./log_resnet18/ --load_fast=false --host 0.0.0.0 --port 6006 &\",\n                        \"/usr/local/bin/ngrok http 6006 &\"\n                        ]]","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:36:48.128575Z","iopub.execute_input":"2024-10-02T08:36:48.129077Z","iopub.status.idle":"2024-10-02T08:36:48.292110Z","shell.execute_reply.started":"2024-10-02T08:36:48.129028Z","shell.execute_reply":"2024-10-02T08:36:48.290738Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:36:48.294167Z","iopub.execute_input":"2024-10-02T08:36:48.294564Z","iopub.status.idle":"2024-10-02T08:36:49.781320Z","shell.execute_reply.started":"2024-10-02T08:36:48.294507Z","shell.execute_reply":"2024-10-02T08:36:49.780136Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"https://6fcf-35-247-48-158.ngrok-free.app\n","output_type":"stream"}]},{"cell_type":"code","source":"#%load_ext tensorboard\n# %reload_ext tensorboard\n\n#%tensorboard --logdir=log_resnet18/transfer_learning","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:36:49.782911Z","iopub.execute_input":"2024-10-02T08:36:49.783254Z","iopub.status.idle":"2024-10-02T08:36:49.787582Z","shell.execute_reply.started":"2024-10-02T08:36:49.783221Z","shell.execute_reply":"2024-10-02T08:36:49.786629Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:green\">Nástroje pro zpracování dat</font><a name=\"utils\"></a>","metadata":{"lines_to_next_cell":2}},{"cell_type":"code","source":"!wget \"https://www.dropbox.com/sh/n5nya3g3airlub6/AACi7vaUjdTA0t2j_iKWgp4Ra?dl=1\" -O ./data.zip","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:36:49.790592Z","iopub.execute_input":"2024-10-02T08:36:49.791185Z","iopub.status.idle":"2024-10-02T08:37:37.231801Z","shell.execute_reply.started":"2024-10-02T08:36:49.791134Z","shell.execute_reply":"2024-10-02T08:37:37.230759Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"--2024-10-02 08:36:50--  https://www.dropbox.com/sh/n5nya3g3airlub6/AACi7vaUjdTA0t2j_iKWgp4Ra?dl=1\nResolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://www.dropbox.com/scl/fo/t88xubtku433w1t10t7he/AEmJ4AwgZ3Svjp29IdawVbE?rlkey=9vuxo0sqr57tsoqn8wgk9pjzc&dl=1 [following]\n--2024-10-02 08:36:50--  https://www.dropbox.com/scl/fo/t88xubtku433w1t10t7he/AEmJ4AwgZ3Svjp29IdawVbE?rlkey=9vuxo0sqr57tsoqn8wgk9pjzc&dl=1\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://uca12ac777d640e491fcadc61d7f.dl.dropboxusercontent.com/zip_download_get/B_FuIlCHeiI0umPnJeVLM6Y__KREcsABR9qpCCgq_CcrwXxvnFfMu4Q2S6FI27frY-R0kTeWIYegZJ6YunkKW1PGCYdiwifht9Yl2zUW730Esg# [following]\n--2024-10-02 08:36:52--  https://uca12ac777d640e491fcadc61d7f.dl.dropboxusercontent.com/zip_download_get/B_FuIlCHeiI0umPnJeVLM6Y__KREcsABR9qpCCgq_CcrwXxvnFfMu4Q2S6FI27frY-R0kTeWIYegZJ6YunkKW1PGCYdiwifht9Yl2zUW730Esg\nResolving uca12ac777d640e491fcadc61d7f.dl.dropboxusercontent.com (uca12ac777d640e491fcadc61d7f.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\nConnecting to uca12ac777d640e491fcadc61d7f.dl.dropboxusercontent.com (uca12ac777d640e491fcadc61d7f.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\nHTTP request sent, awaiting response... ","output_type":"stream"},{"name":"stderr","text":"TensorBoard 2.16.2 at http://0.0.0.0:6006/ (Press CTRL+C to quit)\n","output_type":"stream"},{"name":"stdout","text":"200 OK\nLength: 197683526 (189M) [application/zip]\nSaving to: './data.zip'\n\n./data.zip          100%[===================>] 188.53M  7.97MB/s    in 43s     \n\n2024-10-02 08:37:37 (4.36 MB/s) - './data.zip' saved [197683526/197683526]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### <font style=\"color:green\">Extrahujte data</font>","metadata":{}},{"cell_type":"code","source":"!unzip -q ./data.zip","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:37.233171Z","iopub.execute_input":"2024-10-02T08:37:37.233501Z","iopub.status.idle":"2024-10-02T08:37:39.693427Z","shell.execute_reply.started":"2024-10-02T08:37:37.233467Z","shell.execute_reply":"2024-10-02T08:37:39.692173Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"warning:  stripped absolute path spec from /\nmapname:  conversion of  failed\n","output_type":"stream"}]},{"cell_type":"code","source":"!apt-get install tree\n!tree -d ./cat-dog-panda","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:39.695020Z","iopub.execute_input":"2024-10-02T08:37:39.695362Z","iopub.status.idle":"2024-10-02T08:37:43.611684Z","shell.execute_reply.started":"2024-10-02T08:37:39.695322Z","shell.execute_reply":"2024-10-02T08:37:43.610711Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ntree is already the newest version (2.0.2-1).\n0 upgraded, 0 newly installed, 0 to remove and 67 not upgraded.\n\u001b[01;34m./cat-dog-panda\u001b[0m\n|-- \u001b[01;34mtraining\u001b[0m\n|   |-- \u001b[01;34mcat\u001b[0m\n|   |-- \u001b[01;34mdog\u001b[0m\n|   `-- \u001b[01;34mpanda\u001b[0m\n`-- \u001b[01;34mvalidation\u001b[0m\n    |-- \u001b[01;34mcat\u001b[0m\n    |-- \u001b[01;34mdog\u001b[0m\n    `-- \u001b[01;34mpanda\u001b[0m\n\n8 directories\n","output_type":"stream"}]},{"cell_type":"code","source":"def image_preprocess_transforms():\n    \n    preprocess = transforms.Compose([\n        transforms.Resize(224),\n        transforms.CenterCrop(224),\n        transforms.ToTensor()\n        ])\n    \n    return preprocess","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.613133Z","iopub.execute_input":"2024-10-02T08:37:43.613454Z","iopub.status.idle":"2024-10-02T08:37:43.618807Z","shell.execute_reply.started":"2024-10-02T08:37:43.613422Z","shell.execute_reply":"2024-10-02T08:37:43.617849Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def image_common_transforms(mean, std):\n    preprocess = image_preprocess_transforms()\n    \n    common_transforms = transforms.Compose([\n        preprocess,\n        transforms.Normalize(mean, std)\n    ])\n    \n    return common_transforms\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.620040Z","iopub.execute_input":"2024-10-02T08:37:43.620314Z","iopub.status.idle":"2024-10-02T08:37:43.631700Z","shell.execute_reply.started":"2024-10-02T08:37:43.620284Z","shell.execute_reply":"2024-10-02T08:37:43.630887Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def data_augmentation_preprocess(mean, std):\n    \n    initail_transoform = transforms.RandomChoice([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(90)\n        ])\n    \n    common_transforms = image_common_transforms(mean, std)\n                \n    aug_transforms = transforms.Compose([\n        initail_transoform,\n        transforms.RandomGrayscale(p=0.1),\n        common_transforms\n        ])\n    \n    return aug_transforms\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.632712Z","iopub.execute_input":"2024-10-02T08:37:43.632997Z","iopub.status.idle":"2024-10-02T08:37:43.645859Z","shell.execute_reply.started":"2024-10-02T08:37:43.632967Z","shell.execute_reply":"2024-10-02T08:37:43.645064Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def data_loader(data_root, transform, batch_size=16, shuffle=False, num_workers=2, persistent_workers=False):\n    dataset = datasets.ImageFolder(root=data_root, transform=transform)\n    \n    loader = torch.utils.data.DataLoader(dataset, \n                                         batch_size=batch_size,\n                                         num_workers=num_workers,\n                                         shuffle=shuffle,\n                                         persistent_workers=persistent_workers)\n    \n    return loader","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.650103Z","iopub.execute_input":"2024-10-02T08:37:43.650415Z","iopub.status.idle":"2024-10-02T08:37:43.656861Z","shell.execute_reply.started":"2024-10-02T08:37:43.650376Z","shell.execute_reply":"2024-10-02T08:37:43.655946Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def get_mean_std():\n    \n    mean = [0.485, 0.456, 0.406] \n    std = [0.229, 0.224, 0.225]\n    \n    return mean, std","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.658007Z","iopub.execute_input":"2024-10-02T08:37:43.658441Z","iopub.status.idle":"2024-10-02T08:37:43.665463Z","shell.execute_reply.started":"2024-10-02T08:37:43.658400Z","shell.execute_reply":"2024-10-02T08:37:43.664693Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def get_data(batch_size, data_root, tb_writer, num_workers=4, data_augmentation=True):\n    \n    train_data_path = os.path.join(data_root, 'training')\n       \n    mean, std = get_mean_std()\n    \n    common_transforms = image_common_transforms(mean, std)\n        \n   \n    # if data_augmentation is true \n    # data augmentation implementation\n    if data_augmentation:    \n        train_transforms = data_augmentation_preprocess(mean, std)\n    # else do common transforms\n    else:\n        train_transforms = common_transforms\n        \n        \n    # train dataloader\n    \n    train_loader = data_loader(train_data_path, \n                               train_transforms, \n                               batch_size=batch_size, \n                               shuffle=True, \n                               num_workers=num_workers,\n                               persistent_workers=False)\n    \n    # test dataloader\n    \n    test_data_path = os.path.join(data_root, 'validation')\n    \n    test_loader = data_loader(test_data_path, \n                              common_transforms, \n                              batch_size=batch_size, \n                              shuffle=False, \n                              num_workers=num_workers,\n                              persistent_workers=False)\n    \n    # test dataloader\n    \n    testdata = datasets.ImageFolder(root=test_data_path, transform=common_transforms)\n    \n    # add embedding / projector\n    \n    add_data_embedings(testdata, tb_writer, n=100)\n    \n    return train_loader, test_loader","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.666600Z","iopub.execute_input":"2024-10-02T08:37:43.666933Z","iopub.status.idle":"2024-10-02T08:37:43.676808Z","shell.execute_reply.started":"2024-10-02T08:37:43.666903Z","shell.execute_reply":"2024-10-02T08:37:43.675980Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Přidaní vložení dat / Projektor</font><a name=\"embeds\"></a>","metadata":{}},{"cell_type":"code","source":"animal_classes = ['cat', 'dog', 'panda']\n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.678180Z","iopub.execute_input":"2024-10-02T08:37:43.678529Z","iopub.status.idle":"2024-10-02T08:37:43.689473Z","shell.execute_reply.started":"2024-10-02T08:37:43.678488Z","shell.execute_reply":"2024-10-02T08:37:43.688641Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def get_random_inputs_labels(inputs, targets, n=100):\n    \"\"\"\n    get random inputs and labels\n    \"\"\"\n\n    assert len(inputs) == len(targets)\n\n    rand_indices = torch.randperm(len(targets))\n    \n    data = inputs[rand_indices][:n]\n    \n    labels = targets[rand_indices][:n]\n    \n    class_labels = [animal_classes[lab] for lab in labels]\n    \n    return data, class_labels","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.690615Z","iopub.execute_input":"2024-10-02T08:37:43.690984Z","iopub.status.idle":"2024-10-02T08:37:43.698779Z","shell.execute_reply.started":"2024-10-02T08:37:43.690943Z","shell.execute_reply":"2024-10-02T08:37:43.697990Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def add_data_embedings(dataset, tb_writer, n=100):\n    \"\"\"\n    Add a few inputs and labels to tensorboard. \n    \"\"\"\n    \n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=n, num_workers=4, shuffle=True)\n    \n    images, labels = next(iter(dataloader))\n    \n    tb_writer.add_embedding(mat = images.view(-1, 3 * 224 * 224), \n                            metadata=labels, \n                            label_img=images)\n    \n    return","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.699946Z","iopub.execute_input":"2024-10-02T08:37:43.700310Z","iopub.status.idle":"2024-10-02T08:37:43.707282Z","shell.execute_reply.started":"2024-10-02T08:37:43.700260Z","shell.execute_reply":"2024-10-02T08:37:43.706543Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">Konfigurace systému</font><a name=\"sys-config\"></a>","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass SystemConfiguration:\n    '''\n    Describes the common system setting needed for reproducible training\n    '''\n    seed: int = 21  # seed number to set the state of all random number generators\n    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.708312Z","iopub.execute_input":"2024-10-02T08:37:43.708618Z","iopub.status.idle":"2024-10-02T08:37:43.720367Z","shell.execute_reply.started":"2024-10-02T08:37:43.708587Z","shell.execute_reply":"2024-10-02T08:37:43.719607Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">Konfigurace školení</font><a name=\"train-config\"></a>","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass TrainingConfiguration:\n    '''\n    Describes configuration of the training process\n    '''\n    batch_size: int = 32  \n    epochs_count: int = 20 \n    init_learning_rate: float = 0.001  # initial learning rate for lr scheduler\n    decay_rate: float = 0.1  \n    log_interval: int = 500  \n    test_interval: int = 1  \n    data_root: str = \"./cat-dog-panda\" \n    num_workers: int = 2 \n    device: str = 'cuda'  \n    \n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.721410Z","iopub.execute_input":"2024-10-02T08:37:43.721710Z","iopub.status.idle":"2024-10-02T08:37:43.730696Z","shell.execute_reply.started":"2024-10-02T08:37:43.721654Z","shell.execute_reply":"2024-10-02T08:37:43.729805Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">Nastavení systému</font><a name=\"sys-setup\"></a>","metadata":{}},{"cell_type":"code","source":"def setup_system(system_config: SystemConfiguration) -> None:\n    torch.manual_seed(system_config.seed)\n    if torch.cuda.is_available():\n        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.731877Z","iopub.execute_input":"2024-10-02T08:37:43.732148Z","iopub.status.idle":"2024-10-02T08:37:43.739282Z","shell.execute_reply.started":"2024-10-02T08:37:43.732119Z","shell.execute_reply":"2024-10-02T08:37:43.738350Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def prediction(model, device, batch_input, max_prob=True):\n    \"\"\"\n    get prediction for batch inputs\n    \"\"\"\n    \n    # send model to cpu/cuda according to your system configuration\n    model.to(device)\n    \n    # it is important to do model.eval() before prediction\n    model.eval()\n\n    data = batch_input.to(device)\n\n    output = model(data)\n\n    # get probability score using softmax\n    prob = F.softmax(output, dim=1)\n    \n    if max_prob:\n        # get the max probability\n        pred_prob = prob.data.max(dim=1)[0]\n    else:\n        pred_prob = prob.data\n    \n    # get the index of the max probability\n    pred_index = prob.data.max(dim=1)[1]\n    \n    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.740305Z","iopub.execute_input":"2024-10-02T08:37:43.740609Z","iopub.status.idle":"2024-10-02T08:37:43.749907Z","shell.execute_reply.started":"2024-10-02T08:37:43.740578Z","shell.execute_reply":"2024-10-02T08:37:43.748596Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def get_target_and_prob(model, dataloader, device):\n    \"\"\"\n    get targets and prediction probabilities\n    \"\"\"\n    \n    pred_prob = []\n    targets = []\n    \n    for _, (data, target) in enumerate(dataloader):\n        \n        _, prob = prediction(model, device, data, max_prob=False)\n        \n        pred_prob.append(prob)\n        \n        target = target.numpy()\n        targets.append(target)\n        \n    targets = np.concatenate(targets)\n    targets = targets.astype(int)\n    pred_prob = np.concatenate(pred_prob, axis=0)\n    \n    return targets, pred_prob\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.751138Z","iopub.execute_input":"2024-10-02T08:37:43.751418Z","iopub.status.idle":"2024-10-02T08:37:43.761466Z","shell.execute_reply.started":"2024-10-02T08:37:43.751388Z","shell.execute_reply":"2024-10-02T08:37:43.760705Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Přidejte PR křivky do TensorBoard</font><a name=\"pr-curves\"></a>","metadata":{}},{"cell_type":"code","source":"def add_pr_curves_to_tensorboard(model, dataloader, device, tb_writer, epoch, num_classes=3):\n    \"\"\"\n    Add precession and recall curve to tensorboard.\n    \"\"\"\n    \n    targets, pred_prob = get_target_and_prob(model, dataloader, device)\n    \n    for cls_idx in range(num_classes):\n        binary_target = targets == cls_idx\n        true_prediction_prob = pred_prob[:, cls_idx]\n        \n        tb_writer.add_pr_curve(animal_classes[cls_idx], \n                               binary_target, \n                               true_prediction_prob, \n                               global_step=epoch)\n        \n    return\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.762536Z","iopub.execute_input":"2024-10-02T08:37:43.762865Z","iopub.status.idle":"2024-10-02T08:37:43.771216Z","shell.execute_reply.started":"2024-10-02T08:37:43.762835Z","shell.execute_reply":"2024-10-02T08:37:43.770359Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Odešlete nesprávnou předpověď do TensorBoard</font><a name=\"wrong-preds\"></a>","metadata":{}},{"cell_type":"code","source":"def add_wrong_prediction_to_tensorboard(model, dataloader, device, tb_writer, \n                                        epoch, tag='Wrong_Predections', max_images='all'):\n    \"\"\"\n    Add wrong predicted images to tensorboard.\n    \"\"\"\n    #number of images in one row\n    num_images_per_row = 8\n    im_scale = 3\n    \n    plot_images = []\n    wrong_labels = []\n    pred_prob = []\n    right_label = []\n    \n    mean, std = get_mean_std()\n    \n    for _, (data, target) in enumerate(dataloader):\n        \n        \n        images = data.numpy()\n        pred, prob = prediction(model, device, data)\n        target = target.numpy()\n        indices = pred.astype(int) != target.astype(int)\n        \n        plot_images.append(images[indices])\n        wrong_labels.append(pred[indices])\n        pred_prob.append(prob[indices])\n        right_label.append(target[indices])\n        \n    plot_images = np.concatenate(plot_images, axis=0).squeeze()\n    plot_images = (np.moveaxis(plot_images, 1, -1) * std) + mean\n    wrong_labels = np.concatenate(wrong_labels)\n    wrong_labels = wrong_labels.astype(int)\n    right_label = np.concatenate(right_label)\n    right_label = right_label.astype(int)\n    pred_prob = np.concatenate(pred_prob)\n    \n    \n    if max_images == 'all':\n        num_images = len(images)\n    else:\n        num_images = min(len(plot_images), max_images)\n        \n    fig_width = int(num_images_per_row * im_scale)\n    \n    if num_images % num_images_per_row == 0:\n        num_row = int(num_images/num_images_per_row)\n    else:\n        num_row = int(num_images/num_images_per_row) + 1\n        \n    fig_height = int(num_row * im_scale)\n        \n    plt.style.use('default')\n    plt.rcParams[\"figure.figsize\"] = (fig_width, fig_height)\n    fig = plt.figure()\n    \n    for i in range(num_images):\n        plt.subplot(num_row, num_images_per_row, i+1, xticks=[], yticks=[])\n        plt.imshow((plot_images[i]*255).astype(np.uint8))\n        plt.gca().set_title('{0}({1:.2}), {2}'.format(animal_classes[wrong_labels[i]], \n                                                          pred_prob[i], \n                                                          animal_classes[right_label[i]]))\n        \n    tb_writer.add_figure(tag, fig, global_step=epoch)\n    \n    return\n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.772643Z","iopub.execute_input":"2024-10-02T08:37:43.773072Z","iopub.status.idle":"2024-10-02T08:37:43.788570Z","shell.execute_reply.started":"2024-10-02T08:37:43.773032Z","shell.execute_reply":"2024-10-02T08:37:43.787509Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">Tréninková funkce</font><a name=\"train-fn\"></a>\n\nJste obeznámeni s tréninkovou pipeline používaným v PyTorch.","metadata":{}},{"cell_type":"code","source":"def train(\n    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n    train_loader: torch.utils.data.DataLoader, epoch_idx: int, tb_writer: SummaryWriter\n) -> None:\n    \n    # change model in training mode\n    model.train()\n    \n    # to get batch loss\n    batch_loss = np.array([])\n    \n    # to get batch accuracy\n    batch_acc = np.array([])\n        \n    for batch_idx, (data, target) in enumerate(train_loader):\n        \n        # clone target\n        indx_target = target.clone()\n        # send data to device (it is mandatory if GPU has to be used)\n        data = data.to(train_config.device)\n        # send target to device\n        target = target.to(train_config.device)\n\n        # reset parameters gradient to zero\n        optimizer.zero_grad()\n        \n        # forward pass to the model\n        output = model(data)\n        \n        # cross entropy loss\n        loss = F.cross_entropy(output, target)\n        \n        # find gradients w.r.t training parameters\n        loss.backward()\n        # Update parameters using gradients\n        optimizer.step()\n        \n        batch_loss = np.append(batch_loss, [loss.item()])\n        \n        # get probability score using softmax\n        prob = F.softmax(output, dim=1)\n            \n        # get the index of the max probability\n        pred = prob.data.max(dim=1)[1]  \n                        \n        # correct prediction\n        correct = pred.cpu().eq(indx_target).sum()\n            \n        # accuracy\n        acc = float(correct) / float(len(data))\n        \n        batch_acc = np.append(batch_acc, [acc])\n\n        if batch_idx % train_config.log_interval == 0 and batch_idx > 0:\n            \n            total_batch = epoch_idx * len(train_loader.dataset)/train_config.batch_size + batch_idx\n            tb_writer.add_scalar('Loss/train-batch', loss.item(), total_batch)\n            tb_writer.add_scalar('Accuracy/train-batch', acc, total_batch)\n            \n    epoch_loss = batch_loss.mean()\n    epoch_acc = batch_acc.mean()\n    return epoch_loss, epoch_acc","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.789939Z","iopub.execute_input":"2024-10-02T08:37:43.790370Z","iopub.status.idle":"2024-10-02T08:37:43.801711Z","shell.execute_reply.started":"2024-10-02T08:37:43.790329Z","shell.execute_reply":"2024-10-02T08:37:43.800928Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">Validační funkce</font><a name=\"validate-fn\"></a>","metadata":{}},{"cell_type":"code","source":"def validate(\n    train_config: TrainingConfiguration,\n    model: nn.Module,\n    test_loader: torch.utils.data.DataLoader\n) -> float:\n    # \n    model.eval()\n    test_loss = 0\n    count_corect_predictions = 0\n    for data, target in test_loader:\n        indx_target = target.clone()\n        data = data.to(train_config.device)\n        \n        target = target.to(train_config.device)\n        \n        output = model(data)\n        # add loss for each mini batch\n        test_loss += F.cross_entropy(output, target).item()\n        \n        # get probability score using softmax\n        prob = F.softmax(output, dim=1)\n        \n        # get the index of the max probability\n        pred = prob.data.max(dim=1)[1] \n        \n        # add correct prediction count\n        count_corect_predictions += pred.cpu().eq(indx_target).sum()\n\n    # average over number of mini-batches\n    test_loss = test_loss / len(test_loader)  \n    \n    # average over number of dataset\n    accuracy = 100. * count_corect_predictions / len(test_loader.dataset)\n    \n    return test_loss, accuracy/100.0","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.802830Z","iopub.execute_input":"2024-10-02T08:37:43.803142Z","iopub.status.idle":"2024-10-02T08:37:43.813925Z","shell.execute_reply.started":"2024-10-02T08:37:43.803107Z","shell.execute_reply":"2024-10-02T08:37:43.813159Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Přidejte histogram vah</font><a name=\"hist\"></a>","metadata":{}},{"cell_type":"code","source":"def add_model_weights_as_histogram(model, tb_writer, epoch):\n    for name, param in model.named_parameters():\n        tb_writer.add_histogram(name.replace('.', '/'), param.data.cpu().abs(), epoch)\n    return","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.815126Z","iopub.execute_input":"2024-10-02T08:37:43.815476Z","iopub.status.idle":"2024-10-02T08:37:43.823182Z","shell.execute_reply.started":"2024-10-02T08:37:43.815436Z","shell.execute_reply":"2024-10-02T08:37:43.822440Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Přidejte síťový graf</font><a name=\"graph\"></a>","metadata":{}},{"cell_type":"code","source":"def add_network_graph_tensorboard(model, inputs, tb_writer):\n    tb_writer.add_graph(model, inputs)\n    return","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.824276Z","iopub.execute_input":"2024-10-02T08:37:43.824606Z","iopub.status.idle":"2024-10-02T08:37:43.832875Z","shell.execute_reply.started":"2024-10-02T08:37:43.824575Z","shell.execute_reply":"2024-10-02T08:37:43.831948Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">Main funkce pro Trainink and Validaci</font><a name=\"main\"></a>\n\nPoužijte konfigurační parametry definované výše a začněte trénovat. Důležité akce v níže uvedeném kódu:\n\n1. Nastavte systémové parametry, jako je CPU/GPU, počet vláken atd.\n\n\n2. Načtěte data pomocí dataloaderů.\n\n\n3. Pro každou epochu zavolejte funkci vlaku. Pro každý testovací interval zavolejte funkci ověření.\n\n\n4. Proveďte `scheduler.step()` pro aktualizaci rychlosti učení pro další epochu.\n\n\n5. Nastavte proměnné pro sledování ztrát a přesnosti a začněte trénovat.\n","metadata":{}},{"cell_type":"code","source":"def main(model, optimizer, tb_writer, scheduler=None, system_configuration=SystemConfiguration(), \n         training_configuration=TrainingConfiguration(), data_augmentation=False):\n    \n    # system configuration\n    setup_system(system_configuration)\n\n    # batch size\n    batch_size_to_set = training_configuration.batch_size\n    # num_workers\n    num_workers_to_set = training_configuration.num_workers\n    # epochs\n    epoch_num_to_set = training_configuration.epochs_count\n\n    # if GPU is available use training config, \n    # else lower batch_size, num_workers and epochs count\n    if torch.cuda.is_available():\n        device = \"cuda\"\n    else:\n        device = \"cpu\"\n        batch_size_to_set = 16\n        num_workers_to_set = 2\n\n    # data loader\n    train_loader, test_loader = get_data(\n        batch_size=batch_size_to_set,\n        data_root=training_configuration.data_root,\n        tb_writer=tb_writer,\n        num_workers=num_workers_to_set,\n        data_augmentation=data_augmentation\n    )\n    \n    \n    # Update training configuration\n    training_configuration = TrainingConfiguration(\n        device=device,\n        batch_size=batch_size_to_set,\n        num_workers=num_workers_to_set\n    )\n        \n    # send model to device (GPU/CPU)\n    model.to(training_configuration.device)\n    \n    \n    # add network graph with inputs info\n    images, labels = next(iter(test_loader))\n    images = images.to(training_configuration.device)\n    add_network_graph_tensorboard(model, images, tb_writer)\n\n    best_loss = torch.tensor(np.inf)\n    \n    # epoch train/test loss\n    epoch_train_loss = np.array([])\n    epoch_test_loss = np.array([])\n    \n    # epoch train/test accuracy\n    epoch_train_acc = np.array([])\n    epoch_test_acc = np.array([])\n    \n    add_wrong_prediction_to_tensorboard(model, test_loader, \n                                                training_configuration.device, \n                                                tb_writer, 0, max_images=300)\n    \n    \n    # training time measurement\n    t_begin = time.time()\n    for epoch in range(training_configuration.epochs_count):\n        \n        # Traing\n        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch, tb_writer)\n        \n        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n        \n        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n        \n        # add scalar (loss/accuracy) to tensorboard\n        tb_writer.add_scalar('Loss/Train',train_loss, epoch)\n        tb_writer.add_scalar('Accuracy/Train', train_acc, epoch)\n\n        elapsed_time = time.time() - t_begin\n        speed_epoch = elapsed_time / (epoch + 1)\n        speed_batch = speed_epoch / len(train_loader)\n        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n        \n        # add time metadata to tensorboard\n        tb_writer.add_scalar('Time/elapsed_time', elapsed_time, epoch)\n        tb_writer.add_scalar('Time/speed_epoch', speed_epoch, epoch)\n        tb_writer.add_scalar('Time/speed_batch', speed_batch, epoch)\n        tb_writer.add_scalar('Time/eta', eta, epoch)\n        \n\n        # Validate\n        if epoch % training_configuration.test_interval == 0:\n            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n            \n            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n        \n            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n            \n            # add scalar (loss/accuracy) to tensorboard\n            tb_writer.add_scalar('Loss/Validation', current_loss, epoch)\n            tb_writer.add_scalar('Accuracy/Validation', current_accuracy, epoch)\n            \n            # add scalars (loss/accuracy) to tensorboard\n            tb_writer.add_scalars('Loss/train-val', {'train': train_loss, \n                                           'validation': current_loss}, epoch)\n            tb_writer.add_scalars('Accuracy/train-val', {'train': train_acc, \n                                               'validation': current_accuracy}, epoch)\n            \n            if current_loss < best_loss:\n                best_loss = current_loss\n                \n            # add wrong predicted image to tensorboard\n            add_wrong_prediction_to_tensorboard(model, test_loader, \n                                                training_configuration.device, \n                                                tb_writer, epoch, max_images=300)\n        \n        # scheduler step/ update learning rate\n        if scheduler is not None:\n            scheduler.step()\n            \n        # adding model weights to tensorboard as histogram\n        add_model_weights_as_histogram(model, tb_writer, epoch)\n        \n        # add pr curves to tensor board\n        add_pr_curves_to_tensorboard(model, test_loader, \n                                     training_configuration.device, \n                                     tb_writer, epoch, num_classes=3)\n        \n                \n    print(\"Total time: {:.2f}, Best Loss: {:.3f}\".format(time.time() - t_begin, best_loss))\n    \n    \n    \n    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.834081Z","iopub.execute_input":"2024-10-02T08:37:43.834356Z","iopub.status.idle":"2024-10-02T08:37:43.854676Z","shell.execute_reply.started":"2024-10-02T08:37:43.834326Z","shell.execute_reply":"2024-10-02T08:37:43.853845Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">Optimalizátor a plánovač</font><a name=\"optim\"></a>\n\nOptimalizátor a plánovač považujeme za metodu, protože ji používáme ve všech trénovacích experimentech.","metadata":{}},{"cell_type":"code","source":"def get_optimizer_and_scheduler(model):\n    train_config = TrainingConfiguration()\n\n    init_learning_rate = train_config.init_learning_rate\n\n    # optimizer\n    optimizer = optim.SGD(\n        model.parameters(),\n        lr = init_learning_rate,\n        momentum = 0.9\n    )\n\n    decay_rate = train_config.decay_rate\n\n    lmbda = lambda epoch: 1/(1 + decay_rate * epoch)\n\n    # Scheduler\n    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lmbda)\n    \n    return optimizer, scheduler\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.860347Z","iopub.execute_input":"2024-10-02T08:37:43.860639Z","iopub.status.idle":"2024-10-02T08:37:43.866797Z","shell.execute_reply.started":"2024-10-02T08:37:43.860608Z","shell.execute_reply":"2024-10-02T08:37:43.865965Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Model ResNet</font><a name=\"model\"></a>\n\nNahrajte model `resnet18` s jeho předem připravenými vah.\n\nVrstvy jsou nakonfigurovány tak, že pokud předáte příznak `transfer_learning`, nahradí pouze poslední vrstvy sítě. V opačném případě přeškolí všechny vrstvy, ale s předtrénovanými vahami a ne od nuly.","metadata":{}},{"cell_type":"code","source":"def pretrained_resnet18(transfer_learning=True, num_class=3):\n    #resnet = models.resnet18(pretrained=True)\n    resnet = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n    \n    if transfer_learning:\n        for param in resnet.parameters():\n            param.requires_grad = False\n            \n    last_layer_in = resnet.fc.in_features\n    resnet.fc = nn.Linear(last_layer_in, num_class)\n    \n    return resnet","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.867837Z","iopub.execute_input":"2024-10-02T08:37:43.868123Z","iopub.status.idle":"2024-10-02T08:37:43.877266Z","shell.execute_reply.started":"2024-10-02T08:37:43.868092Z","shell.execute_reply":"2024-10-02T08:37:43.876472Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def pretrained_resnet18_B(transfer_learning=True, fine_tune_from_layer3=False, num_class=3):\n    \"\"\"\n    Load a pretrained ResNet18 model and configure it for transfer learning or fine-tuning.\n    \n    Args:\n        transfer_learning (bool): Whether to freeze the entire model except the final layer.\n        fine_tune_from_layer3 (bool): If True, fine-tune layers after Layer 3 (Layer 4 + FC layer).\n        num_class (int): Number of output classes for the final layer.\n        \n    Returns:\n        resnet: A modified ResNet18 model ready for transfer learning or fine-tuning.\n    \"\"\"\n    # Načtení předtrénovaného modelu\n    resnet = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n    \n    # Freeze the entire model if transfer_learning is True\n    if transfer_learning:\n        for param in resnet.parameters():\n            param.requires_grad = False\n    \n    # Pokud fine_tune_from_layer3 je True, odemkneme vrstvy po Layer 3 (tj. Layer 4 a dál)\n    if fine_tune_from_layer3:\n        for param in resnet.layer4.parameters():  # Odblokujeme váhy Layer 4\n            param.requires_grad = True\n    \n    # Nahrazení poslední plně propojené vrstvy podle počtu tříd\n    last_layer_in = resnet.fc.in_features\n    resnet.fc = nn.Linear(last_layer_in, num_class)\n    \n    # Odemknutí poslední vrstvy (klasifikátor)\n    for param in resnet.fc.parameters():\n        param.requires_grad = True\n\n    return resnet","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.878247Z","iopub.execute_input":"2024-10-02T08:37:43.878551Z","iopub.status.idle":"2024-10-02T08:37:43.891283Z","shell.execute_reply.started":"2024-10-02T08:37:43.878508Z","shell.execute_reply":"2024-10-02T08:37:43.890511Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Transfer Learning</font><a name=\"tl\"></a>\n","metadata":{}},{"cell_type":"code","source":"#model = pretrained_resnet18(transfer_learning=True)\nmodel = pretrained_resnet18_B(transfer_learning=True, fine_tune_from_layer3=False, num_class=3)\n\nprint(model)\n# get optimizer and scheduler\noptimizer, scheduler = get_optimizer_and_scheduler(model)\n\n# Tensorboard summary writer\ntransfer_learning_sw = SummaryWriter('log_resnet18/transfer_learning')   \n\n# train and validate\nmodel, train_loss_exp2, train_acc_exp2, val_loss_exp2, val_acc_exp2 = main(model, \n                                                                           optimizer,\n                                                                           transfer_learning_sw,\n                                                                           scheduler,\n                                                                           data_augmentation=True)\ntransfer_learning_sw.close()","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:37:43.892356Z","iopub.execute_input":"2024-10-02T08:37:43.892717Z","iopub.status.idle":"2024-10-02T08:48:00.669053Z","shell.execute_reply.started":"2024-10-02T08:37:43.892674Z","shell.execute_reply":"2024-10-02T08:48:00.667964Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 83.1MB/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=3, bias=True)\n)\n","output_type":"stream"},{"name":"stderr","text":"W1002 08:39:51.850360 136433090164288 security_validator.py:60] In 3.0, this warning will become an error:\nIllegal Content-Security-Policy for script-src: 'unsafe-inline'\nIllegal Content-Security-Policy for connect-src: data:\nIllegal Content-Security-Policy for connect-src: www.gstatic.com\nIllegal Content-Security-Policy for script-src-elem: 'unsafe-inline'\n","output_type":"stream"},{"name":"stdout","text":"Total time: 553.95, Best Loss: 0.047\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Fine-Tuning</font><a name=\"fine-tune\"></a>\n","metadata":{}},{"cell_type":"code","source":"#model = pretrained_resnet18(transfer_learning=False)\nmodel = pretrained_resnet18_B(transfer_learning=True, fine_tune_from_layer3=True, num_class=3)\n\nprint(model)\n\n# get optimizer and scheduler\noptimizer, scheduler = get_optimizer_and_scheduler(model)\n\n# Tensorboard summary writer\nfine_tuning_sw = SummaryWriter('log_resnet18/fine_tuning')   \n\nmodel, train_loss_exp9, train_acc_exp9, val_loss_exp9, val_acc_exp9 = main(model, \n                                                                           optimizer, \n                                                                           fine_tuning_sw,\n                                                                           scheduler,\n                                                                           data_augmentation=True)\n\nfine_tuning_sw.close()","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:48:00.670398Z","iopub.execute_input":"2024-10-02T08:48:00.670761Z","iopub.status.idle":"2024-10-02T08:58:07.774299Z","shell.execute_reply.started":"2024-10-02T08:48:00.670724Z","shell.execute_reply":"2024-10-02T08:58:07.773442Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=3, bias=True)\n)\nTotal time: 546.09, Best Loss: 0.030\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Jak bylo uvedeno výše, zobrazte data pomocí tensorboardu.","metadata":{}},{"cell_type":"markdown","source":"### ***Reference a dokumentace***\n\n[Image Classification Architecture](https://www.youtube.com/watch?v=NnB9Zm5bnok)\n\n[Fine Tuning and Transfer Learning](https://www.youtube.com/watch?v=5xCj0zOyw-g)","metadata":{}},{"cell_type":"code","source":"!rm /kaggle/working/ngrok-v3-stable-linux-amd64.tgz\n!rm /kaggle/working/data.zip","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:58:07.775590Z","iopub.execute_input":"2024-10-02T08:58:07.775941Z","iopub.status.idle":"2024-10-02T08:58:09.858521Z","shell.execute_reply.started":"2024-10-02T08:58:07.775906Z","shell.execute_reply":"2024-10-02T08:58:09.857254Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}]},{"cell_type":"code","source":"def zip_folder_with_shutil(source_folder, output_path):\n   shutil.make_archive(output_path, 'zip', source_folder)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:58:09.860190Z","iopub.execute_input":"2024-10-02T08:58:09.860548Z","iopub.status.idle":"2024-10-02T08:58:09.865704Z","shell.execute_reply.started":"2024-10-02T08:58:09.860514Z","shell.execute_reply":"2024-10-02T08:58:09.864723Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"zip_folder_with_shutil('/kaggle/working/log_resnet18', '/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2024-10-02T09:31:13.908279Z","iopub.execute_input":"2024-10-02T09:31:13.908831Z","iopub.status.idle":"2024-10-02T09:31:29.246911Z","shell.execute_reply.started":"2024-10-02T09:31:13.908793Z","shell.execute_reply":"2024-10-02T09:31:29.245866Z"},"trusted":true},"execution_count":42,"outputs":[]}]}